[
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "second of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Bit",
        "clean": "Bit",
        "text": "The bit (a portmanteau of binary digit) is a basic unit of information used in computing and digital communications.  A binary digit can have only one of two values, and may be physically represented with a two-state device. These state values are most commonly represented as either a 0or1.\nThe two values of a binary digit can also be interpreted as logical values (true/false, yes/no), algebraic signs (+/\u2212), activation states (on/off), or any other two-valued attribute. The correspondence between these values and the physical states of the underlying storage or device is a matter of convention, and different assignments may be used even within the same device or program. The length of a binary number may be referred to as its bit-length.\nIn information theory, one bit is typically defined as the information entropy of a binary random variable that is 0 or 1 with equal probability, or the information that is gained when the value of such a variable becomes known.Confusion often arises because the words bit and binary digit are used interchangeably. But, within Shannon's information theory, a bit and a binary digit are fundamentally different types of entities. A binary digit is a number that can adopt one of two possible values (0 or 1), whereas a bit is the maximum amount of information that can be conveyed by a binary digit (when averaged over both of its states). By analogy, just as a pint-sized bottle can contain between zero and one pint, so a binary digit can convey between zero and one bit of information. A less confusing terminology is to refer to bits as Shannons (see below).\nIn quantum computing, a quantum bit or qubit is a quantum system that can exist in superposition of two classical (i.e., non-quantum) bit values.\nThe symbol for binary digit is either simply bit (recommended by the IEC 80000-13:2008 standard) or lowercase b (recommended by the IEEE 1541-2002 and IEEE Std 260.1-2004 standards). A group of eight binary digits is commonly called one byte, but historically the size of the byte is not strictly defined.\nAs a unit of information in information theory, the bit has alternatively been called a shannon, named after Claude Shannon, the founder of field of information theory. This usage distinguishes the quantity of information from the form of the state variables used to represent it. When the logical values are not equally probable or when a signal is not conveyed perfectly through a communication system, a binary digit in the representation of the information will convey less than one bit of information. However, the shannon unit terminology is uncommon in practice.\n\n\n== History ==\nThe encoding of data by discrete bits was used in the punched cards invented by Basile Bouchon and Jean-Baptiste Falcon (1732), developed by Joseph Marie Jacquard (1804), and later adopted by Semen Korsakov, Charles Babbage, Hermann Hollerith, and early computer manufacturers like IBM. Another variant of that idea was the perforated paper tape. In all those systems, the medium (card or tape) conceptually carried an array of hole positions; each position could be either punched through or not, thus carrying one bit of information. The encoding of text by bits was also used in Morse code (1844) and early digital communications machines such as teletypes and stock ticker machines (1870).\nRalph Hartley suggested the use of a logarithmic measure of information in 1928. Claude E. Shannon first used the word bit in his seminal 1948 paper A Mathematical Theory of Communication.\nHe attributed its origin to John W. Tukey, who had written a Bell Labs memo on 9 January 1947 in which he contracted \"binary information digit\" to simply \"bit\". Vannevar Bush had written in 1936 of \"bits of information\" that could be stored on the punched cards used in the mechanical computers of that time. The first programmable computer, built by Konrad Zuse, used binary notation for numbers.\n\n\n== Physical representation ==\nA bit can be stored by a digital device or other physical system that exists in either of two possible distinct states. These may be the two stable states of a flip-flop, two positions of an electrical switch, two distinct voltage or current levels allowed by a circuit, two distinct levels of light intensity, two directions of magnetization or polarization, the orientation of reversible double stranded DNA, etc.\nBits can be implemented in several forms. In most modern computing devices, a bit is usually represented by an electrical voltage or current pulse, or by the electrical state of a flip-flop circuit.\nFor devices using positive logic, a digit value of 1 (or a logical value of true) is represented by a more positive voltage relative to the representation of 0. The specific voltages are different for different logic families and variations are permitted to allow for component aging and noise immunity. For example, in transistor\u2013transistor logic (TTL) and compatible circuits, digit values 0 and 1 at the output of a device are represented by no higher than 0.4 volts and no lower than 2.6 volts, respectively; while TTL inputs are specified to recognize 0.8 volts or below as 0 and 2.2 volts or above as 1.\n\n\n=== Transmission and processing ===\nBits are transmitted one at a time in serial transmission, and by a multiple number of bits in parallel transmission. A bitwise operation optionally processes bits one at a time. Data transfer rates are usually measured in decimal SI multiples of the unit bit per second (bit/s), such as kbit/s.\n\n\n=== Storage ===\nIn the earliest non-electronic information processing devices, such as Jacquard's loom or Babbage's Analytical Engine, a bit was often stored as the position of a mechanical lever or gear, or the presence or absence of a hole at a specific point of a paper card or tape. The first electrical devices for discrete logic (such as elevator and traffic light control circuits, telephone switches, and Konrad Zuse's computer) represented bits as the states of electrical relays which could be either \"open\" or \"closed\". When relays were replaced by vacuum tubes, starting in the 1940s, computer builders experimented with a variety of storage methods, such as pressure pulses traveling down a mercury delay line, charges stored on the inside surface of a cathode-ray tube, or opaque spots printed on glass discs by photolithographic techniques.\nIn the 1950s and 1960s, these methods were largely supplanted by magnetic storage devices such as magnetic core memory, magnetic tapes, drums, and disks, where a bit was represented by the polarity of magnetization of a certain area of a ferromagnetic film, or by a change in polarity from one direction to the other. The same principle was later used in the magnetic bubble memory developed in the 1980s, and is still found in various magnetic strip items such as metro tickets and some credit cards.\nIn modern semiconductor memory, such as dynamic random-access memory, the two values of a bit may be represented by two levels of electric charge stored in a capacitor. In certain types of programmable logic arrays and read-only memory, a bit may be represented by the presence or absence of a conducting path at a certain point of a circuit. In optical discs, a bit is encoded as the presence or absence of a microscopic pit on a reflective surface. In one-dimensional bar codes, bits are encoded as the thickness of alternating black and white lines.\n\n\n== Unit and symbol ==\nThe bit is not defined in the International System of Units (SI). However, the International Electrotechnical Commission issued standard IEC 60027, which specifies that the symbol for binary digit should be bit, and this should be used in all multiples, such as kbit, for kilobit. However, the lower-case letter b is widely used as well and was recommended by the IEEE 1541 Standard (2002). In contrast, the upper case letter B is the standard and customary symbol for byte.\n\n\n=== Multiple bits ===\nMultiple bits may be expressed and represented in several ways. For convenience of representing commonly reoccurring groups of bits in information technology, several units of information have traditionally been used. The most common is the unit byte, coined by Werner Buchholz in June 1956, which historically was used to represent the group of bits used to encode a single character of text (until UTF-8 multibyte encoding took over) in a computer and for this reason it was used as the basic addressable element in many computer architectures. The trend in hardware design converged on the most common implementation of using eight bits per byte, as it is widely used today. However, because of the ambiguity of relying on the underlying hardware design, the unit octet was defined to explicitly denote a sequence of eight bits.\nComputers usually manipulate bits in groups of a fixed size, conventionally named \"words\". Like the byte, the number of bits in a word also varies with the hardware design, and is typically between 8 and 80 bits, or even more in some specialized computers. In the 21st century, retail personal or server computers have a word size of 32 or 64 bits.\nThe International System of Units defines a series of decimal prefixes for multiples of standardized units which are commonly also used with the bit and the byte. The prefixes kilo (103) through yotta (1024) increment by multiples of 1000, and the corresponding units are the kilobit (kbit) through the yottabit (Ybit).\n\n\n== Information capacity and information compression ==\nWhen the information capacity of a storage system or a communication channel is presented in bits or bits per second, this often refers to binary digits, which is a computer hardware capacity to store binary data (0 or 1, up or down, current or not, etc.). Information capacity of a storage system is only an upper bound to the quantity of information stored therein. If the two possible values of one bit of storage are not equally likely, that bit of storage contains less than one bit of information. Indeed, if the value is completely predictable, then the reading of that value provides no information at all (zero entropic bits, because no resolution of uncertainty occurs and therefore no information is available). If a computer file that uses n bits of storage contains only m < n bits of information, then that information can in principle be encoded in about m bits, at least on the average. This principle is the basis of data compression technology. Using an analogy, the hardware binary digits refer to the amount of storage space available (like the number of buckets available to store things), and the information content the filling, which comes in different levels of granularity (fine or coarse, that is, compressed or uncompressed information). When the granularity is finer\u2014when information is more compressed\u2014the same bucket can hold more.\nFor example, it is estimated that the combined technological capacity of the world to store information provides 1,300 exabytes of hardware digits in 2007. However, when this storage space is filled and the corresponding content is optimally compressed, this only represents 295 exabytes of information.\nWhen optimally compressed, the resulting carrying capacity approaches Shannon information or information entropy.\n\n\n== Bit-based computing ==\nCertain bitwise computer processor instructions (such as bit set) operate at the level of manipulating bits rather than manipulating data interpreted as an aggregate of bits.\nIn the 1980s, when bitmapped computer displays became popular, some computers provided specialized bit block transfer (\"bitblt\" or \"blit\") instructions to set or copy the bits that corresponded to a given rectangular area on the screen.\nIn most computers and programming languages, when a bit within a group of bits, such as a byte or word, is referred to, it is usually specified by a number from 0 upwards corresponding to its position within the byte or word. However, 0 can refer to either the most or least significant bit depending on the context.\n\n\n== Other information units ==\n\nOther units of information, sometimes used in information theory, include the natural digit also called a nat or nit and defined as log2 e (\u2248 1.443) bits, where e is the base of the natural logarithms; and the dit, ban, or hartley, defined as log2 10 (\u2248 3.322) bits. This value, slightly less than 10/3, may be understood because 103 = 1000 \u2248 1024 = 210: three decimal digits are slightly less information than ten binary digits, so one decimal digit is slightly less than 10/3 binary digits. Conversely, one bit of information corresponds to about ln 2 (\u2248 0.693) nats, or log10 2 (\u2248 0.301) hartleys. As with the inverse ratio, this value, approximately 3/10, but slightly more, corresponds to the fact that 210 = 1024 ~ 1000 = 103: ten binary digits are slightly more information than three decimal digits, so one binary digit is slightly more than 3/10 decimal digits. Some authors also define a binit as an arbitrary information unit equivalent to some fixed but unspecified number of bits.\n\n\n== See also ==\nInteger (computer science)\nPrimitive data type\nTrit (Trinary digit)\nBitstream\nEntropy (information theory)\nBaud (bits per second)\nBinary numeral system\nTernary numeral system\nShannon (unit)\n\n\n== References ==\n\n\n== External links ==\nBit Calculator \u2013 a tool providing conversions between bit, byte, kilobit, kilobyte, megabit, megabyte, gigabit, gigabyte\nBitXByteConverter \u2013 a tool for computing file sizes, storage capacity, and digital information in various units",
        "unit": "bit",
        "url": "https://en.wikipedia.org/wiki/Bit"
    },
    {
        "_id": "Density",
        "clean": "Density",
        "text": "The density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is \u03c1 (the lower case Greek letter rho), although the Latin letter D can also be used. Mathematically, density is defined as mass divided by volume:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            m\n            V\n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {m}{V}}}\n  where \u03c1 is the density, m is the mass, and V is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate \u2013 this quantity is more specifically called specific weight.\nFor a pure substance the density has the same numerical value as its mass concentration.\nDifferent materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.\nTo simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity \"relative density\" or \"specific gravity\", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.\nThe density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.\nThe reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.\n\n\n== History ==\nIn a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, \"Eureka! Eureka!\" (\u0395\u03cd\u03c1\u03b7\u03ba\u03b1! Greek \"I have found it\"). As a result, the term \"eureka\" entered common parlance and is used today to indicate a moment of enlightenment.\nThe story first appeared in written form in Vitruvius' books of architecture, two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.From the equation for density (\u03c1 = m/V), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m3) and the cgs unit of gram per cubic centimetre (g/cm3) are probably the most commonly used units for density. One g/cm3 is equal to one thousand kg/m3.  One cubic centimetre (abbreviation cc) is equal to one millilitre. In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.\n\n\n== Measurement of density ==\n\n\n=== Homogeneous materials ===\nThe density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.\n\n\n=== Heterogeneous materials ===\nIf the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        d\n        m\n        \n          /\n        \n        d\n        V\n      \n    \n    {\\displaystyle \\rho ({\\vec {r}})=dm/dV}\n  , where \n  \n    \n      \n        d\n        V\n      \n    \n    {\\displaystyle dV}\n   is an elementary volume at position \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . The mass of the body then can be expressed as\n\n  \n    \n      \n        m\n        =\n        \n          \u222b\n          \n            V\n          \n        \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        V\n        .\n      \n    \n    {\\displaystyle m=\\int _{V}\\rho ({\\vec {r}})\\,dV.}\n  \n\n\n=== Non-compact materials ===\nIn practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules.\nVoids are regions which contain something other than the considered material.  Commonly the void is air, but it could also be vacuum,  liquid, solid, or a different gas or gaseous mixture.\nThe bulk volume of a material\u2014inclusive of the void fraction\u2014is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions.\nMass divided by bulk volume determines bulk density.  This is not the same thing as volumetric mass density.\nTo determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning.  For the close-packing of equal spheres the non-void fraction can be at most about 74%.  It can also be determined empirically.  Some bulk materials, however, such as sand, have a variable void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling.\nIn practice, the void fraction is not necessarily air, or even gaseous.  In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water\u2014once any air bubbles are thoroughly driven out\u2014is potentially more consistent than dry sand measured with an air void.\nIn the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).\nMass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.\n\n\n== Changes of density ==\n\nIn general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 \u00b0C and 4 \u00b0C; similar behavior is observed in silicon at low temperatures.\nThe effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10\u22126 bar\u22121 (1 bar = 0.1 MPa) and a typical thermal expansivity is 10\u22125 K\u22121. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.\nIn contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              M\n              P\n            \n            \n              R\n              T\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\rho ={\\frac {MP}{RT}},}\n  where M is the molar mass, P is the pressure, R is the universal gas constant, and T is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.\nIn the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              \u03c1\n              \n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            \n              1\n              +\n              \u03b1\n              \u22c5\n              \u0394\n              T\n            \n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {\\rho _{T_{0}}}{1+\\alpha \\cdot \\Delta T}}}\n  where \n  \n    \n      \n        \n          \u03c1\n          \n            \n              T\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho _{T_{0}}}\n   is the density at a reference temperature, \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is the thermal expansion coefficient of the material at temperatures close to \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  .\n\n\n== Density of solutions ==\nThe density of a solution is the sum of mass (massic) concentrations of the components of that solution.\nMass (massic) concentration of each given component \u03c1i in a solution sums to density of the solution.\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03f1\n          \n            i\n          \n        \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\varrho _{i}\\,}\n  Expressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \u03c6\n          \n            i\n          \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            \n              \n                \u2211\n                \n                  i\n                \n              \n              \n                V\n                \n                  i\n                \n              \n              +\n              \n                \u2211\n                \n                  i\n                \n              \n              \n                \n                  \n                    V\n                    \n                      E\n                    \n                  \n                \n                \n                  i\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\rho _{i}{\\frac {V_{i}}{V}}\\,=\\sum _{i}\\rho _{i}\\varphi _{i}=\\sum _{i}\\rho _{i}{\\frac {V_{i}}{\\sum _{i}V_{i}+\\sum _{i}{V^{E}}_{i}}}}\n  provided that there is no interaction between the components.\nKnowing the relation between excess volumes and activity coefficients of the  components, one can determine the activity coefficients.\n\n  \n    \n      \n        \n          \n            \n              \n                V\n                \n                  E\n                \n              \n              \u00af\n            \n          \n          \n            i\n          \n        \n        =\n        R\n        T\n        \n          \n            \n              \u2202\n              ln\n              \u2061\n              \n                \u03b3\n                \n                  i\n                \n              \n            \n            \n              \u2202\n              P\n            \n          \n        \n      \n    \n    {\\displaystyle {\\overline {V^{E}}}_{i}=RT{\\frac {\\partial \\ln \\gamma _{i}}{\\partial P}}}\n  \n\n\n== Densities ==\n\n\n=== Various materials ===\n\n\n=== Others ===\n\n\n=== Water ===\n\n\n=== Air ===\n\n\n=== Molar volumes of liquid and solid phase of elements ===\n\n\n== Common units ==\nThe SI unit for density is:\n\nkilogram per cubic metre (kg/m3)The litre and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:\n\nkilogram per litre (kg/L)\ngram per millilitre (g/mL)\nmetric ton per cubic metre (t/m3)Densities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m3). Liquid water has a density of about 1 kg/dm3, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm3.\n\nkilogram per cubic decimetre (kg/dm3)\ngram per cubic centimetre (g/cm3)\n1 g/cm3 = 1000 kg/m3\nmegagram (metric ton) per cubic metre (Mg/m3)In US customary units density can be stated in:\n\nAvoirdupois ounce per cubic inch (1 g/cc \u2248 0.578036672 oz/cu in)\nAvoirdupois ounce per fluid ounce (1 g/cc \u2248 1.04317556 oz/fl. oz = 1.04317556 lbs/pint)\nAvoirdupois pound per cubic inch (1 g/cc \u2248 0.036127292 lb/cu in)\npound per cubic foot (1 g/cc \u2248 62.427961 lb/cu ft)\npound per cubic yard (1 g/cc \u2248 1685.5549 lb/cu yd)\npound per US liquid gallon (1 g/cc \u2248 8.34540445 lb/gal)\npound per US bushel (1 g/cc \u2248 77.6888513 lb/bu)\nslug per cubic footImperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The Imperial gallon was based on the concept that an Imperial fluid ounce of water would have a mass of one Avoirdupois ounce, and indeed 1 g/cc \u2248 1.00224129 ounces per Imperial fluid ounce = 10.0224129 pounds per Imperial gallon. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n \"Density\". Encyclop\u00e6dia Britannica. 8 (11th ed.). 1911. \n \"Density\". The New Student's Reference Work. 1914. \nVideo: Density Experiment with Oil and Alcohol\nVideo: Density Experiment with Whiskey and Water\nGlass Density Calculation \u2013 Calculation of the density of glass at room temperature and of glass melts at 1000 \u2013 1400\u00b0C\nList of Elements of the Periodic Table \u2013 Sorted by Density\nCalculation of saturated liquid densities for some components\nField density test\nOn-line calculator for densities and partial molar volumes of aqueous solutions of some common electrolytes and their mixtures, at temperatures up to 323.15 K.\nWater \u2013 Density and specific weight\nTemperature dependence of the density of water \u2013 Conversions of density units\nA delicious density experiment\nWater density calculator Water density for a given salinity and temperature.\nLiquid density calculator Select a liquid from the list and calculate density as a function of temperature.\nGas density calculator Calculate density of a gas for as a function of temperature and pressure.\nDensities of various materials.\nDetermination of Density of Solid, instructions for performing classroom experiment.\ndensity prediction\ndensity prediction",
        "unit": "density",
        "url": "https://en.wikipedia.org/wiki/Density"
    },
    {
        "_id": "Kilobyte",
        "clean": "Kilobyte",
        "text": "The kilobyte is a multiple of the unit byte for digital information. \nThe International System of Units (SI) defines the prefix kilo as 1000 (103); per this definition, one kilobyte is 1000 bytes. The internationally recommended unit symbol for the kilobyte is kB.In some areas of information technology, particularly in reference to digital memory capacity, kilobyte instead denotes 1024 (210) bytes. This arises from the powers-of-two sizing common to memory circuit design. In this context, the symbols K and KB are often used.\n\n\n== Definitions and usage ==\n\n\n=== Base 10 (1000 bytes) ===\nIn the International System of Units (SI) the prefix kilo means 1000 (103); therefore, one kilobyte is 1000 bytes. The unit symbol is kB.\nThis is the definition recommended by the International Electrotechnical Commission (IEC). \nThis definition, and the related definitions of the prefixes mega (1000000), giga (1000000000), etc., are most commonly used for data transfer rates\nin computer networks, internal bus, hard drive and flash media transfer speeds, and for the capacities of most storage media, particularly hard drives, flash-based storage, and DVDs. It is also consistent with the other uses of the SI prefixes in computing, such as CPU clock speeds or measures of performance.\nThe IEC 80000-13 standard uses the term 'byte' to mean eight bits (1 B = 8 bit).  Therefore, 1 kB = 8000 bit. One thousand kilobytes (1000 kB) is equal to one megabyte (1 MB), where 1 MB is one million bytes.\n\n\n=== Base 2 (1024 bytes) ===\nThe kilobyte has traditionally been used to refer to 1024 bytes (210 B), a usage still common. The usage of the metric prefix kilo for binary multiples arose as a convenience, because 1000 approximates 1024.The binary interpretation of metric prefixes is still prominently used by the Microsoft Windows operating system, which is used on 90% of the world's personal computers. They are also used for random-access memory capacities, such as main memory and CPU cache sizes, due to the binary addressing of memory.The binary representation of 1024 bytes typically uses the symbol KB, with an uppercase letter K. The B is often omitted in informal use. For example, a processor with 65,536 bytes of cache memory might be said to have \"64K\" of cache. In this convention, one thousand and twenty-four kilobytes (1024 KB) is equal to one megabyte (1 MB), where 1 MB is 10242 bytes.\n\n\n==== Kibibyte ====\nIn December 1998, the IEC addressed such multiple usages and definitions by creating prefixes such as kibi, mebi, gibi, etc., to unambiguously denote powers of 1024. Thus the kibibyte, symbol KiB, represents 210 = 1024 bytes. These prefixes  are now part of the International System of Quantities. The IEC further specified that the kilobyte should only be used to refer to 1000 bytes. In practice, kilobyte is still commonly used to refer to 1024 bytes.One thousand and twenty-four kibibytes (1024 KiB) is equal to one mebibyte (1 MiB), where 1 MiB is 10242 bytes.\n\n\n== Examples ==\nThe Shugart SA-400 5\u200b1\u20444-inch floppy disk (1976) held 109,375 bytes unformatted, and was advertised as 110 Kbyte, using the 1000 convention.  Likewise, the 8-inch DEC RX01 floppy (1975) held 256,256 bytes formatted, and was advertised as 256k.  On the other hand, the Tandon 5\u200b1\u20444-inch DD floppy format (1978) held 368,640 (which is 360\u00d71024) bytes, but was advertised as 360 KB, following the 1024 convention.\nOn modern systems, all versions of Microsoft Windows including the newest (as of 2015) Windows 10 divide by 1024 and represent a 65,536-byte file as 64 KB. Conversely, Mac OS X Snow Leopard and newer represent this as 66 kB, rounding to the nearest 1000 bytes. File sizes are reported with decimal prefixes.\nThe binary interpretation is still used in marketing and billing by some telecommunication companies, such as Vodafone, AT&T, Orange and Telstra.\n\n\n== See also ==\nHistory of the floppy disk\nBinary prefix\nTimeline of binary prefixes\nGigabyte \u00a7 Consumer confusion\nJEDEC memory standards \u00a7 Unit prefixes for semiconductor storage capacity\nUnits of information \u00a7 Size examples\n\n\n== Notes ==\n\n\n== References ==\n\n\"Terms, Definitions, and Letter Symbols for Microcomputers, Microprocessors, and Memory Integrated Circuits\" (PDF). JEDEC Solid State Technology Association. December 2002. Retrieved 22 September 2013.",
        "unit": "kilobyte",
        "url": "https://en.wikipedia.org/wiki/Kilobyte"
    },
    {
        "_id": "Pound_(mass)",
        "clean": "Pound (mass)",
        "text": "The pound or pound-mass is a unit of mass \nused in the imperial, United States customary and other systems of measurement. Various definitions have been used; the most common today is the international avoirdupois pound, which is legally defined as exactly 0.45359237 kilograms, and which is divided into 16 avoirdupois ounces. The international standard symbol for the avoirdupois pound is lb; an alternative symbol is lbm (for most pound definitions), # (chiefly in the U.S.), and \u2114 or \u2033\u0336 (specifically for the apothecaries' pound).\nThe unit is descended from the Roman libra (hence the abbreviation \"lb\").  The English word pound is cognate with, among others,  German Pfund, Dutch pond, and Swedish pund.  All ultimately derive from a borrowing into Proto-Germanic of the  Latin expression l\u012bbra pond\u014d (\"a pound by weight\"), in which the word pond\u014d is the ablative case of the Latin noun pondus (\"weight\").Usage of the unqualified term pound reflects the historical conflation of mass and weight. This accounts for the modern distinguishing terms pound-mass and pound-force.\n\n\n== Current use ==\nThe United States and countries of the Commonwealth of Nations agreed upon common definitions for the pound and the yard. Since 1 July 1959, the international avoirdupois pound (symbol lb) has been defined as exactly 0.45359237 kg.In the United Kingdom, the use of the international pound was implemented in the Weights and Measures Act 1963.\nThe yard or the metre shall be the unit of measurement of length and the pound or the kilogram shall be the unit of measurement of mass by reference to which any measurement involving a measurement of length or mass shall be made in the United Kingdom; and- (a) the yard shall be 0.9144 metre exactly; (b) the pound shall be 0.45359237 kilogram exactly.\n\nAn avoirdupois pound is equal to 16 avoirdupois ounces and to exactly 7,000 grains. The conversion factor between the kilogram and the international pound was therefore chosen to be divisible by 7, and an (international) grain is thus equal to exactly 64.79891 milligrams.\nIn the UK, the process of metrication and European units of measurement directives were expected to eliminate the use of the pound and ounce, but in 2007 the European Commission abandoned the requirement for metric-only labelling on packaged goods there, and allowed for dual metric\u2013imperial marking to continue indefinitely. When used as a measurement of body weight the UK practice remains to use the stone of 14 pounds as the primary measure e.g. \"11 stone 4 pounds\", rather than \"158 pounds\" (as done in the US), or \"72 kilograms\" as used elsewhere.\nThe US has not adopted the metric system despite many efforts to do so, and the pound remains widely used as one of the key United States customary units.\n\n\n== Historic use ==\n\nHistorically, in different parts of the world, at different points in time, and for different applications, the pound (or its translation) has referred to broadly similar but not identical standards of mass or force.\n\n\n=== Roman libra ===\n\nThe libra (Latin for \"scales / balance\") is an ancient Roman unit of mass that was equivalent to approximately 328.9 grams. It was divided into 12 unciae (singular: uncia), or ounces. The libra is the origin of the abbreviation for pound, \"lb\".\n\n\n=== In Britain ===\nA number of different definitions of the pound have historically been used in Britain. Amongst these were the avoirdupois pound and the obsolete Tower, merchant's and London pounds. Troy pounds and ounces remain in use only for the weight of certain precious metals, especially in the trade; these are normally quoted just in ounces (e.g. \"500 ounces\") and, when the type of ounce is not explicitly stated, the troy system is assumed.\nHistorically, the pound sterling was a Tower pound of silver. In 1528, the standard was changed to the Troy pound.\n\n\n==== Avoirdupois pound ====\nThe avoirdupois pound, also known as the wool pound, first came into general use c. 1300. It was initially equal to 6992 troy grains. The pound avoirdupois was divided into 16 ounces. During the reign of Queen Elizabeth, the avoirdupois pound was redefined as 7,000 troy grains. Since then, the grain has often been an integral part of the avoirdupois system. By 1758, two Elizabethan Exchequer standard weights for the avoirdupois pound existed, and when measured in troy grains they were found to be of 7,002 grains and 6,999 grains.\n\n\n==== Imperial Standard Pound ====\nIn the United Kingdom, weights and measures have been defined by a long series of Acts of Parliament, the intention of which has been to regulate the sale of commodities. Materials traded in the marketplace are quantified according to accepted units and standards in order to avoid fraud. The standards themselves are legally defined so as to facilitate the resolution of disputes brought to the courts; only legally defined measures will be recognised by the courts. Quantifying devices used by traders (weights, weighing machines, containers of volumes, measures of length) are subject to official inspection, and penalties apply if they are fraudulent.\nThe Weights and Measures Act of 1878 marked a major overhaul of the British system of weights and measures, and the definition of the pound given there remained in force until the 1960s. The pound was defined thus (Section 4) \"The ... platinum weight ... deposited in the Standards department of the Board of Trade ... shall continue to be the imperial standard of ... weight ... and the said platinum weight shall continue to be the Imperial Standard for determining the Imperial Standard Pound for the United Kingdom\". Paragraph 13 states that the weight in vacuo of this standard shall be called the Imperial Standard Pound, and that all other weights mentioned in the act and permissible for commerce shall be ascertained from it alone. The First Schedule of the Act gave more details of the standard pound: it is a platinum cylinder nearly 1.35 inches (34 mm) high, and 1.15 inches (29 mm) diameter, and the edges are carefully rounded off. It has a groove about 0.34 inches (8.6 mm) from the top, to allow the cylinder to be lifted using an ivory fork. It was constructed following the destruction of the Houses of Parliament by fire in 1834, and is stamped P.S. 1844, 1 lb (P.S. stands for \"Parliamentary Standard\"). This definition of the Imperial pound remains unchanged.\n\n\n==== Relationship to the kilogram ====\nThe 1878 Act said that contracts worded in terms of metric units would be deemed by the courts to be made according to the Imperial units defined in the Act, and a table of metric equivalents was supplied so that the Imperial equivalents could be legally calculated. This defined, in UK law, metric units in terms of Imperial ones. The equivalence for the pound was given as 1 lb = 453.59265 g or 0.45359 kg, which made the kilogram equivalent to about 2.2046213 lb. In 1883, it was determined jointly by the Standards Department of the Board of Trade and the Bureau International that 0.4535924277 kg was a better approximation, and this figure, rounded to 0.45359243 kg was given legal status by an Order in Council in May 1898.However, in 1963, a new Weights and Measures Act reversed this relationship and the pound was defined for the first time as a mass equal to 0.45359237 kg to match the definition of the international pound agreed in 1959.\n\n\n==== Troy pound ====\n\nA troy pound is equal to 12 troy ounces and to 5,760 grains, that is exactly 373.2417216 grams. Troy weights were used in England by jewellers. Apothecaries also used the troy pound and ounce, but added the drachms and scruples unit in the Apothecaries' system of weights.\nTroy weight may take its name from the French market town of Troyes in France where English merchants traded at least as early as the early 9th century.The troy pound is no longer in general use or a legal unit for trade (it was abolished in the United Kingdom on 6 January 1879 by the Weights and Measures Act of 1878), but the troy ounce, \u200b1\u204412 of a troy pound, is still used for measurements of gems such as opals, and precious metals such as silver, platinum and particularly gold.\n\n\n==== Tower pound ====\n\nThe system called Tower weight was the more general name for King Offa's pound. This dates to 757 AD and was based on the silver penny. This in turn was struck over Arabic dirhams (2d). The pound was based on the weight of 120 Arabic silver dirhams, which have been found in Offa's Dyke. The same coin weight was used throughout the Hanseatic League.The Tower pound was also called the Moneyers' Pound (referring to the Saxon moneyers before the Conquest), the easterling pound, which may refer to traders of eastern Germany, or to traders on the shore of the eastern Baltic sea, or dealers of Asiatic goods who settled at the Steelyard wharf; and the Rochelle Pound by French writers, because it was also in use at Rochelle. An almost identical weight was employed by the Germans for weighing gold and silver.\nThe mercantile pound (1304) of 6750 troy grains, or 9600 Tower grains, derives from this pound, as 25 shilling-weights or 15 Tower ounces, for general commercial use. Multiple pounds based on the same ounce were quite common. In much of Europe, the apothecaries' and commercial pounds were different numbers of the same ounce.The Tower system was referenced to a standard prototype found in the Tower of London and ran concurrently with the avoirdupois and troy systems until the reign of Henry VIII, when a royal proclamation dated 1526 required that the troy pound to be used for mint purposes instead of the Tower pound. No standards of the Tower pound are known to have survived.The Tower pound was equivalent to about 350 grams.\n\n\n==== Merchants' pound ====\nThe merchants' pound (mercantile pound, libra mercantoria, or commercial pound) was considered to be composed of 25 rather than 20 Tower shillings of 12 pence. It was equal to 9,600 wheat grains (15 tower ounces or 6,750 grains) and was used in England until the 14th century for goods other than money and medicine (\"electuaries\").\n\n\n==== London pound ====\nThe London pound is that of the Hansa, as used in their various trading places.  The London pound is based on 16 ounces, each ounce divided as the tower ounce.  It never became a legal standard in England; the use of this pound waxed and waned with the influence of the Hansa itself.\nA London pound was equal to 7,200 troy grains (16 troy ounces) or, equivalently, 10,240 tower grains (16 tower ounces).\n\n\n=== In the United States ===\nIn the United States, the avoirdupois pound as a unit of mass has been officially defined in terms of the kilogram since the Mendenhall Order of 1893. That Order defined the pound to be 2.20462 pounds to a kilogram. The following year, this relationship was refined as 2.20462234 pounds to a kilogram, following a determination of the British pound.According to a 1959 NIST publication, the United States 1894 pound differed from the international pound by approximately one part in 10 million. The difference is so insignificant that it can be ignored for almost all practical purposes.\n\n\n=== Byzantine litra ===\n\nThe Byzantines used a series of measurements known as pounds (Latin: libra, Greek: \u03bb\u03af\u03c4\u03c1\u03b1, litra). The most common was the logarik\u0113 litra (\u03bb\u03bf\u03b3\u03b1\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"pound of account\"), established by Constantine the Great in 309/310. It formed the basis of the Byzantine monetary system, with one litra of gold equivalent to 72 solidi. A hundred litrai were known as a kent\u0113narion (\u03ba\u03b5\u03bd\u03c4\u03b7\u03bd\u03ac\u03c1\u03b9\u03bf\u03bd, \"hundredweight\"). Its weight seems to have decreased gradually from the original 324 grams to 319. Due to its association with gold, it was also known as the chrysaphik\u0113 litra (\u03c7\u03c1\u03c5\u03c3\u03b1\u03c6\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"gold pound\") or thalassia litra (\u03b8\u03b1\u03bb\u03ac\u03c3\u03c3\u03b9\u03b1 \u03bb\u03af\u03c4\u03c1\u03b1, \"maritime pound\"), but it could also be used as a measure of land, equalling a fortieth of the thalassios modios.The soualia litra was specifically used for weighing olive oil or wood, and corresponded to 4/5 of the logarik\u0113, i.e. 256 g. Some outlying regions, especially in later times, adopted various local measures, based on Italian, Arab or Turkish measures. The most important of these was the argyrik\u0113 litra (\u03b1\u03c1\u03b3\u03c5\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"silver pound\") of 333 g, found in Trebizond and Cyprus, and probably of Arab origin.\n\n\n=== French livre ===\n\nSince the Middle Ages, various pounds (livre) have been used in France. Since the 19th century, a livre has referred to the metric pound, 500g.\nThe livre esterlin was equivalent to about 367.1 grams (5,665 gr) and was used between the late 9th century and the mid-14th century.The livre poids de marc or livre de Paris was equivalent to about 489.5 grams (7,554 gr) and was used between the 1350s and the late 18th century. It was introduced by the government of John II.\nThe livre m\u00e9trique was set equal to the kilogram by the decree of 13 Brumaire an IX between 1800 and 1812. This was a form of official metric pound.The livre usuelle (customary unit) was defined as 500 grams by the decree of 28 March 1812. It was abolished as a unit of mass effective 1 January 1840 by a decree of 4 July 1837, but is still used informally.\n\n\n=== German and Austrian Pfund ===\nOriginally derived from the Roman libra, the definition varied throughout Germany in the Middle Ages and onward. The measures and weights of the Habsburg monarchy were reformed in 1761 by Empress Maria Theresia of Austria. The unusually heavy Habsburg (civil) pound of 16 ounces was later defined in terms of 560.012 grams. Bavarian reforms in 1809 and 1811 adopted essentially the same standard pound. In Prussia, a reform in 1816 defined a uniform civil pound in terms of the Prussian foot and distilled water, resulting in a Prussian pound of 467.711 grams.\nBetween 1803 and 1815, all German regions west of the River Rhine were French, organised in the departements: Roer, Sarre, Rhin-et-Moselle, and Mont-Tonnerre. As a result of the Congress of Vienna, these became part of various German states. However, many of these regions retained the metric system and adopted a metric pound of precisely 500 grams. In 1854, the pound of 500 grams also became the official mass standard of the German Customs Union, but local pounds continued to co-exist with the Zollverein pound for some time in some German states. Nowadays, the term Pfund is still in common use and universally refers to a pound of 500 grams.\n\n\n=== Russian funt ===\nThe Russian pound (\u0424\u0443\u043d\u0442, funt) is an obsolete Russian unit of measurement of mass. It is equal to 409.51718 grams. In 1899, the Russian pound was the basic unit of weight and all other units of weight were formed from it.\n\n\n=== Sk\u00e5lpund ===\nThe Sk\u00e5lpund was a Scandinavian measurement that varied in weight between regions. From the 17th century onward, it was equal to 425.076 grams in Sweden but was abandoned in 1889 when Sweden switched to the metric system.\nIn Norway, the same name was used for a weight of 498.1 grams. In Denmark, it equalled 471 grams.\nIn the 19th century, Denmark followed Germany's lead and redefined the pound as 500 grams.\n\n\n=== Jersey pound ===\nA Jersey pound is an obsolete unit of mass used on the island of Jersey from the 14th century to the 19th century. It was equivalent to about 7,561 grains (490 grams). It may have been derived from the French livre poids de marc.\n\n\n=== Trone pound ===\nThe trone pound is one of a number of obsolete Scottish units of measurement. It was equivalent to between 21 and 28 avoirdupois ounces (about 600-800 grams).\n\n\n=== Metric pounds ===\nIn many countries, upon the introduction of a metric system, the pound (or its translation) became an informal term for 500 grams. In German, the term is Pfund, in French livre, in Dutch pond, in Spanish and Portuguese libra, in Italian libbra, and in Danish and Swedish pund.\nThough not from the same linguistic origin, the Chinese j\u012bn (\u65a4, also known as \"catty\") has a modern definition of exactly 500 grams, divided into 10 li\u01ceng (\u4e24). Traditionally about 605 grams, the jin has been in use for more than two thousand years, serving the same purpose as \"pound\" for the common-use measure of weight.\nHundreds of older pounds were replaced in this way. Examples of the older pounds are one of around 459 to 460 grams in Spain, Portugal, and Latin America; one of 498.1 grams in Norway; and several different ones in what is now Germany.\nAlthough the use of the pound as an informal term persists in these countries to a varying degree, scales and measuring devices are denominated only in grams and kilograms. A pound of product must be determined by weighing the product in grams as the use of the pound is not sanctioned for trade within the European Union.\n\n\n== Use in weaponry ==\nSmoothbore cannon and carronades are designated by the weight in imperial pounds of round solid iron shot of diameter to fit the barrel. A cannon that fires a six-pound ball, for example, is called a six-pounder. Standard sizes are 6, 12, 18, 24, 32 and 42 pounds; 68-pounders also exist, and other nonstandard weapons use the same scheme. See carronade.\nA similar definition, using lead balls, exists for determining the gauge of shotguns.\n\n\n== See also ==\nPound-force\n\n\n== Notes ==\n\n\n== External links ==\n\n\n=== Conversion between units ===\nU.S. National Institute of Standards and Technology Special Publication 811\nNational Institute of Standards and Technology Handbook 130",
        "unit": "pound-mass",
        "url": "https://en.wikipedia.org/wiki/Pound_(mass)"
    },
    {
        "_id": "Fahrenheit",
        "clean": "Fahrenheit",
        "text": "The Fahrenheit scale is a temperature scale based on one proposed in 1724 by Dutch\u2013German\u2013Polish physicist Daniel Gabriel Fahrenheit (1686\u20131736). It uses the degree Fahrenheit (symbol: \u00b0F) as the unit. Several accounts of how he originally defined his scale exist. The lower defining point, 0 \u00b0F, was established as the temperature of a solution of brine made from equal parts of ice, water and salt (ammonium chloride). Further limits were established as the melting point of ice (32 \u00b0F) and his best estimate of the average human body temperature (96 \u00b0F, about 2.6 \u00b0F less than the modern value due to a later redefinition of the scale). The scale is now usually defined by two fixed points: the temperature at which water freezes into ice is defined as 32 \u00b0F, and the boiling point of water is defined to be 212 \u00b0F, a 180 \u00b0F separation, as defined at sea level and standard atmospheric pressure. \nBy the end of the 20th century, Fahrenheit was used as the official temperature scale only in the United States (including its unincorporated territories), its freely associated states in the Western Pacific (Palau, the Federated States of Micronesia and the Marshall Islands), the Bahamas, Belize, Liberia and the Cayman Islands. All other countries in the world now use the Celsius scale, named after Swedish astronomer Anders Celsius, defined since 1954 by absolute zero being \u2212273.15 \u00b0C and the triple point of water being at 0.01 \u00b0C. Before 1954, the Celsius scale was based on 0 \u00b0C for the freezing point of water and 100 \u00b0C for the boiling point of water at 1 atm. Since the conversion between \u00b0C and \u00b0F was kept unchanged the definition of \u00b0F is now based on the triple point, too; the freezing and boiling points of water are only very good approximations. \n\n\n== Definition and conversion ==\nOn the Fahrenheit scale, the freezing point of water is 32 degrees Fahrenheit (\u00b0F) and the boiling point is 212 \u00b0F (at standard atmospheric pressure). This puts the boiling and freezing points of water 180 degrees apart. Therefore, a degree on the Fahrenheit scale is \u200b1\u2044180 of the interval between the freezing point and the boiling point. On the Celsius scale, the freezing and boiling points of water are 100 degrees apart. A temperature interval of 1 \u00b0F is equal to an interval of \u200b5\u20449 degrees Celsius. The Fahrenheit and Celsius scales intersect at \u221240\u00b0 (i.e., \u221240 \u00b0F = \u221240 \u00b0C). \nAbsolute zero is \u2212273.15 \u00b0C or \u2212459.67 \u00b0F. The Rankine temperature scale uses degree intervals of the same size as those of the Fahrenheit scale, except that absolute zero is 0 \u00b0R \u2014 the same way that the Kelvin temperature scale matches the Celsius scale, except that absolute zero is 0 K.The Fahrenheit scale uses the symbol \u00b0 to denote a point on the temperature scale (as does Celsius) and the letter F to indicate the use of the Fahrenheit scale (e.g. \"Gallium melts at 85.5763 \u00b0F\"), as well as to denote a difference between temperatures or an uncertainty in temperature (e.g. \"The output of the heat exchanger experiences an increase of 72 \u00b0F\" and \"Our standard uncertainty is \u00b15 \u00b0F\").\nFor an exact conversion, the following formulas can be applied. Here, f is the value in Fahrenheit and c the value in Celsius:\n\nf \u00b0Fahrenheit to c \u00b0Celsius : (f \u2212 32) \u00b0F \u00d7 5\u00b0C/9\u00b0F = (f \u2212 32)/1.8 \u00b0C = c \u00b0C\nc \u00b0Celsius to f \u00b0Fahrenheit : (c \u00b0C \u00d7 9\u00b0F/5\u00b0C) + 32 \u00b0F = (c \u00d7 1.8) \u00b0F + 32 \u00b0F = f \u00b0FThis is also an exact conversion making use of the identity -40 \u00b0F = -40 \u00b0C. Again, f is the value in Fahrenheit and c the value in Celsius:\n\nf \u00b0Fahrenheit to c \u00b0Celsius : ((f + 40) \u00f7 1.8) \u2212 40 = c.\nc \u00b0Celsius to f \u00b0Fahrenheit : ((c + 40) \u00d7 1.8) \u2212 40 = f.\n\n\n== History ==\n\nFahrenheit proposed his temperature scale in 1724, basing it on two reference points of temperature. In his initial scale (which is not the final Fahrenheit scale), the zero point was determined by placing the thermometer in  a mixture of ice, water, and ammonium chloride (salis Armoniaci). This is a frigorific mixture which stabilizes its temperature automatically: that stable temperature was defined as 0 \u00b0F (\u221217.78 \u00b0C). The second point, 96 degrees, was approximately the human body's temperature (sanguine hominis sani, the blood of a healthy man).According to a story in Germany, Fahrenheit actually chose the lowest air temperature measured in his hometown Danzig in winter 1708/09 as 0 \u00b0F, and only later had the need to be able to make this value reproducible using brine. This is one explanation given why 0 \u00b0F is \u221217.78 \u00b0C, but the ammonium chloride cooling temperature actually is \u22123 \u00b0C, whereas that of NaCl is \u221221.1 \u00b0C; the other explanation is that he did not have a good enough brine solution to obtain the eutectic equilibrium exactly (i.e. he might have had a mixture of salts, or it had not fully dissolved). In any case, the definition of the Fahrenheit scale has changed since.\nAccording to a letter Fahrenheit wrote to his friend Herman Boerhaave, his scale was built on the work of Ole R\u00f8mer, whom he had met earlier. In R\u00f8mer's scale, brine freezes at zero, water freezes and melts at 7.5 degrees, body temperature is 22.5, and water boils at 60 degrees. Fahrenheit multiplied each value by four in order to eliminate fractions and increase the granularity of the scale. He then re-calibrated his scale using the melting point of ice and normal human body temperature (which were at 30 and 90 degrees); he adjusted the scale so that the melting point of ice would be 32 degrees and body temperature 96 degrees, so that 64 intervals would separate the two, allowing him to mark degree lines on his instruments by simply bisecting the interval six times (since 64 is 2 to the sixth power).Fahrenheit observed that water boils at about 212 degrees using this scale. The use of the freezing and boiling points of water as thermometer fixed reference points became popular following the work of Anders Celsius and these fixed points were adopted by a committee of the Royal Society led by Henry Cavendish in 1776. Under this system, the Fahrenheit scale is redefined slightly so that the freezing point of water is exactly 32 \u00b0F, and the boiling point is exactly 212 \u00b0F or 180 degrees higher. It is for this reason that normal human body temperature is approximately 98\u00b0 (oral temperature) on the revised scale (whereas it was 90\u00b0 on Fahrenheit's multiplication of R\u00f8mer, and 96\u00b0 on his original scale).The Rankine temperature scale was based upon the Fahrenheit temperature scale, with its zero representing absolute zero instead.\n\n\n== Usage ==\n\nThe Fahrenheit scale was the primary temperature standard for climatic, industrial and medical purposes in English-speaking countries until the 1960s. In the late 1960s and 1970s, the Celsius scale replaced Fahrenheit in almost all of those countries\u2014with the notable exception of the United States\u2014typically during their metrication process.\nFahrenheit is used in the United States, its territories and associated states (all served by the U.S. National Weather Service), as well as the Bahamas, Belize, and the Cayman Islands for everyday applications. For example, U.S. weather forecasts, food cooking, and freezing temperatures are typically given in degrees Fahrenheit. Scientists, such as meteorologists, use Celsius or Kelvin in all countries.Early in the 20th century, Halsey and Dale suggested that the resistance to the use of centigrade (now Celsius) system in the U.S. included the larger size of each degree Celsius and the lower zero point in the Fahrenheit system.Canada has passed legislation favoring the International System of Units, while also maintaining legal definitions for traditional Canadian imperial units. Canadian weather reports are conveyed using degrees Celsius with occasional reference to Fahrenheit especially for cross-border broadcasts. Virtually all Canadian ovens make legal use of the Fahrenheit scale. Thermometers, both digital and analog, sold in Canada usually employ both the Celsius and Fahrenheit scales.  Also, in some instances (swimming pool temperature, thermostats, or cooking temperatures for example), temperatures are still expressed in Fahrenheit.\n\nWithin the European Union, it is mandatory to use kelvins or degrees Celsius when quoting temperature for \"economic, public health, public safety and administrative\" purposes, though degrees Fahrenheit may be used alongside degrees Celsius as a supplementary unit. For example, the laundry symbols used in the United Kingdom follow the recommendations of ISO 3758:2005 showing the temperature of the washing machine water in degrees Celsius only. The equivalent label in North America uses one to six dots to denote temperature with an optional temperature in degrees Celsius.Within the unregulated sector, such as journalism, the use of Fahrenheit in the United Kingdom follows no fixed pattern with degrees Fahrenheit often appearing alongside degrees Celsius. The Daily Mail, on its daily weather page, quotes Celsius first, followed by Fahrenheit in brackets, The Daily Telegraph does not mention Fahrenheit on its daily weather page while The Times also has an all-metric daily weather page but has a Celsius-to-Fahrenheit conversion table. When publishing news stories, much of the UK  press and population have adopted a convention of using degrees Celsius in headlines and discussion relating to low temperatures and Fahrenheit for high temperatures. In February 2006, the writer of an article in The Times suggested that the rationale was one of emphasis:  \"\u22126 \u00b0C\" sounds colder than \"21 \u00b0F\" and \"94 \u00b0F\" sounds more impressive than \"34 \u00b0C\".\n\n\n== Unicode representation of symbol ==\nUnicode provides the Fahrenheit symbol at code point U+2109 \u2109 degree fahrenheit. However, this is a compatibility character encoded for roundtrip compatibility with legacy encodings. The Unicode standard explicitly discourages the use of this character: \"The sequence U+00B0 \u00b0 degree sign +U+0046 F latin capital letter f is preferred over U+2109 \u2109 degree fahrenheit, and those two sequences should be treated as identical for searching.\"\n\n\n== See also ==\n\nComparison of temperature scales\nDegree of frost\n\n\n== Notes and references ==\n\n\n== External links ==\nDaniel Gabriel Fahrenheit (Polish-born Dutch physicist) -- Encyclop\u00e6dia Britannica\n\"At Auction | One of Only Three Original Fahrenheit Thermometers\" Enfilade page for 2012 Christie's sale of a Fahrenheit mercury thermometer with some nice pictures\nChristie's press release",
        "unit": "degree fahrenheit",
        "url": "https://en.wikipedia.org/wiki/Fahrenheit"
    },
    {
        "_id": "Ton",
        "clean": "Ton",
        "text": "The ton is a unit of measure. It has a long history and has acquired a number of meanings and uses over the years. It is used principally as a unit of mass. Its original use as a measurement of volume has continued in the capacity of cargo ships and in terms such as the freight ton. It can also be used as a measure of energy, for truck classification, or as a colloquial term.\nIt is derived from the tun, the term applied to a cask of the largest capacity. This could contain a volume between 175 and 213 imperial gallons (210 and 256 US gal; 800 and 970 l), which could weigh around 2,000 pounds (910 kg) and occupy some 60 cubic feet (1.7 m3) of space. The origin for the word ton comes from ancient Greek \u03b8\u03cd\u03bd\u03bd\u03bf\u03c2 (th\u00fannos, tuna fish).\nIn the United Kingdom the ton is defined as 2,240 avoirdupois pounds (1,016 kg). This is equivalent to 20 hundredweight, a hundredweight being eight stone, and a stone weighing 14 pounds.  From 1965 the UK embarked upon a programme of metrication and gradually introduced metric units, including the tonne (metric ton), defined as 1000 kg (2,204 lb). The UK Weights and Measures Act 1985 explicitly excluded from use for trade many units and terms, including the ton and the term \"metric ton\" for \"tonne\".In the United States and Canada a ton is defined to be 2,000 pounds (907 kg).\nWhere confusion is possible, the 2240 lb ton is called \"long ton\" and the 2000 lb ton \"short ton\"; the tonne is distinguished by its spelling, but usually pronounced the same as ton, hence the US term \"metric ton\". In the UK the final \"e\" of \"tonne\" can also be pronounced (), or \"metric ton\" when it is necessary to make the distinction.\nWhere accuracy is required the correct term must be used, but for many purposes this is not necessary: the metric and long tons differ by only 1.6%, and the short ton is within 11% of both. The ton is the heaviest unit of weight referred to in colloquial speech.\nThe term \"ton\" is also  used to refer to a number of units of volume, ranging from 35 to 100 cubic feet (0.99 to 2.83 m3) in capacity.\nIt can also be used as a unit of energy, expressed as an equivalent of coal burnt or TNT detonated.\nIn refrigeration, a ton is a unit of power, sometimes called a ton of refrigeration.  It is the power required to melt or freeze one short ton of ice per day.  The refrigeration ton hour is a unit of energy, the energy required to melt or freeze \u200b1\u204424 short ton of ice.\n\n\n== Units of mass/weight ==\nThere are several similar units of mass or volume called the ton:\n\n\n=== Others ===\nThe long ton is used for petroleum products such as aviation fuel.\nDeadweight ton (abbreviation 'DWT' or 'dwt') is a measure of a ship's carrying capacity, including bunker oil, fresh water, ballast water, crew and provisions. It is expressed in tonnes (1000 kg) or long tons (2240 pounds, about 1016 kg). This measurement is also used in the U.S. tonnage of naval ships.\nIncreasingly, tonnes are being used rather than long tons in measuring the displacement of ships. See tonnage.\nHarbour ton used in South Africa in the 20th century, 2000 pounds or one short ton.Both the long ton and the short ton are 20 hundredweight, the long hundredweight and the short hundredweight being 112 and 100 pounds respectively. Before the twentieth century there were several definitions. Prior to the 15th century in England, the ton was 20 hundredweight, each of 108 lb, giving a ton of 2,160 pounds (980 kg).  In the nineteenth century in different parts of Britain, definitions of 2240, 2352, and 2400 lb were used, with 2000 lb for explosives; the legal ton was usually [sic] 2240 lb.\nAssay ton (abbreviation 'AT') is not a unit of measurement, but a standard quantity used in assaying ores of precious metals; it is \u200b29 1\u20446 grams (short assay ton) or \u200b32 2\u20443 grams (long assay ton), the amount which bears the same ratio to a milligram as a short or long ton bears to a troy ounce. In other words, the number of milligrams of a particular metal found in a sample of this size gives the number of troy ounces contained in a short or long ton of ore.\nIn documents that predate 1960 the word ton is sometimes spelled tonne, but in more recent documents tonne refers exclusively to the metric ton.\nIn nuclear power plants tHM and MTHM mean tonnes of heavy metals, and MTU means tonnes of uranium. In the steel industry, the abbreviation THM means 'tons/tonnes hot metal', which refers to the amount of liquid iron or steel that is produced, particularly in the context of blast furnace production or specific consumption.\nA dry ton or dry tonne has the same mass value, but the material (sludge, slurries, compost, and similar mixtures in which solid material is soaked with or suspended in water) has been dried to a relatively low, consistent moisture level (dry weight). If the material is in its natural, wet state, it is called a wet ton or wet tonne.\n\n\n== Units of volume ==\n\nThe displacement, essentially the weight, of a ship is traditionally expressed in long tons. To simplify measurement it is determined by measuring the volume, rather than weight, of water displaced, and calculating the weight from the volume and density.\nFor practical purposes the displacement ton (DT) is a unit of volume, 35 cubic feet (0.9911 m3), the approximate volume occupied by one ton of seawater (the actual volume varies with salinity and temperature). It is slightly less than the 224 imperial gallons (1.018 m3) of the water ton (based on distilled water).\nOne measurement ton or freight ton is equal to 40 cubic feet (1.133 m3), but historically it has had several different definitions. It is sometimes abbreviated as \"MTON\".  It is used to determine the amount of money to be charged as \"Freight\" in carrying different sorts of cargo. In general if a cargo is heavier than salt water, the actual tonnage is used. If it is lighter than salt water, e.g. feathers, freight is calculated using Measurement Tons of 40 cubic feet. The freight ton represents the volume of a truck, train or other freight carrier. In the past it has been used for a cargo ship but the register ton is now preferred. It is correctly abbreviated as \"FT\" but some users are now using freight ton to represent a weight of 1 tonne (1,000 kg; 2,205 lb), thus the more common abbreviations are now M/T, MT, or MTON (for measurement ton), which still cause it to be confused with the tonne, or even the megatonne.\nThe register ton is a unit of volume used for the cargo capacity of a ship, defined as 100 cubic feet (2.832 m3). It is often abbreviated RT or GRT for gross registered ton (The former providing confusion with the refrigeration ton). It is known as a tonneau de mer in Belgium, but, in France, a tonneau de mer is 1.44 cubic metres (50.85 cu ft).\nThe Panama Canal/Universal Measurement System (PC/UMS) is based on net tonnage, modified for Panama Canal billing purposes. PC/UMS is based on a mathematical formula to calculate a vessel's total volume; a PC/UMS net ton is equivalent to 100 cubic feet of capacity.The water ton is used chiefly in Great Britain, in statistics dealing with petroleum products, and is defined as 224 imperial gallons (35.96 cu ft; 1.018 m3), the volume occupied by 1 long ton (2,240 lb; 1,016 kg) of water under the conditions that define the imperial gallon.\n\n\n== Units of energy and power ==\n\n\n=== Ton of TNT ===\n\nA ton of TNT or tonne of TNT is a unit of energy equal to 109 (thermochemical) calories, also known as a gigacalorie (Gcal), equal to 4.184 gigajoules (GJ).\nA kiloton of TNT or kilotonne of TNT is a unit of energy equal to 1012 calories, also known as a teracalorie (Tcal), equal to 4.184 terajoules (TJ).\nA megaton of TNT (1,000,000 metric tonnes) or megatonne of TNT is a unit of energy equal to 1015 calories, also known (infrequently) as a petacalorie (Pcal), equal to 4.184 petajoules (PJ).Note that these are small calories (cal). The large or dietary calorie (Cal) is equal to one kilocalorie (kcal), and is gradually being replaced by the latter correct term.\nEarly values for the explosive energy released by trinitrotoluene (TNT) ranged from 900 to 1100 calories per gram. In order to standardise the use of the term TNT as a unit of energy, an arbitrary value was assigned based on 1000 calories (1 kcal or 4.184 kJ) per gram. Thus there is no longer a direct connection to the chemical TNT itself. It is now merely a unit of energy that happens to be expressed using words normally associated with mass (e.g., kilogram, tonne, pound). The definition applies for both spellings: ton of TNT and tonne of TNT.\nMeasurements in tons of TNT have been used primarily to express nuclear weapon yields, though they have also been used since in seismology as well.\n\n\n=== Tonne of oil equivalent ===\nA tonne of oil equivalent (toe), sometimes ton of oil equivalent, is a conventional value, based on the amount of energy released by burning one tonne of crude oil. The unit is used, for example, by the International Energy Agency (IEA), for the reported world energy consumption as TPES in millions of toe (Mtoe).\nOther sources convert 1 toe into 1.28 tonne of coal equivalent (tce). 1 toe is also standardized as 7.33 barrel of oil equivalent (boe).\n\n\n=== Tonne of coal equivalent ===\nA tonne of coal equivalent (tce), sometimes ton of coal equivalent, is a conventional value, based on the amount of energy released by burning one tonne of coal. Plural name is tonnes of coal equivalent.\n\nPer the World Coal Association: 1 tonne of coal equivalent (tce) corresponds to 0.697 tonne of oil equivalent (toe)\nPer the International Energy Agency 1 tonne of coal equivalent (tce) corresponds to 0.700 tonne of oil equivalent (toe)\n\n\n=== Refrigeration ===\n\nThe unit ton is used in refrigeration and air conditioning to measure the rate of heat absorption. Prior to the introduction of mechanical refrigeration, cooling was accomplished by delivering ice.  Installing one ton of mechanical refrigeration capacity replaced the daily delivery of one ton of ice.\n\nIn North America, a standard ton of refrigeration is 12,000 BTU/h (3,517 W). \"The heat absorption per day is approximately the heat of fusion of 1 ton of ice at 32 \u00b0F (0 \u00b0C).\" This is approximately the power required to melt one short ton (2,000 lb or 907 kg) of ice at 0 \u00b0C (32 \u00b0F) in 24 hours, thus representing the delivery of 1 short ton (0.893 long tons; 0.907 t) of ice per day.\nA less common usage is the power required to cool 1 long ton (2,240 lb or 1,016 kg = 1 long ton or 1.120 short tons or 1.016 t) of water by 1 \u00b0F (0.56 \u00b0C) every 10 minutes = 13,440 BTU/h (3,939 W).A refrigeration ton should be regarded as power produced by a chiller when operating in standard AHRI conditions, which are typically 44 \u00b0F (7 \u00b0C) for chilled water unit, and 95 \u00b0F (35 \u00b0C) air entering the condenser. This is commonly referred to as \"true ton\". Manufacturers can also provide tables for chillers operating at other chilled water temperature conditions (as 65 \u00b0F or 18.3 \u00b0C) which can show more favorable data, which are not valid when making performance comparisons among units unless conversion rates are applied.The refrigeration ton is commonly abbreviated as RT.\n\n\n== Informal tons ==\nTon is also used informally, often as slang, to mean a large amount of something, material or not.  For example, \"I have a ton of homework to do this weekend.\"\nIn Britain, a ton is colloquially used to refer to 100 of a given unit. Ton can thus refer to a speed of 100 miles per hour, and is prefixed by an indefinite article, e.g. \"Lee was doing a ton down the motorway\"; to money e.g. \"How much did you pay for that?\" \"A ton\" (\u00a3100); to 100 points in a game e.g. \"Eric just threw a ton in our darts game\" (in some games, e.g. cricket, more commonly called a century); or to a hundred of any other countable figure.\nIn Dutch, when talking about money a ton is used to indicate 100,000. For example a house costing 2 ton would cost 200,000 euros.  This convention has been in use since at least the 18th century.\nIn Finnish, tonni is often used as a synonym for one thousand (1000), especially when referring to money. For example, \"tonnin seteli\" was a 1000 mark's banknote and a popular TV show was called \"Kymppitonni\" (\"ten tons\" = 10,000 marks).\n\n\n== See also ==\n\n\n== References ==",
        "unit": "ton",
        "url": "https://en.wikipedia.org/wiki/Ton"
    },
    {
        "_id": "Foot_(unit)",
        "clean": "Foot (unit)",
        "text": "The foot (pl. feet; abbreviation: ft; symbol: \u2032, the prime symbol) is a unit of length in the imperial and US customary systems of measurement. Since 1959, both units have been defined by international agreement as equivalent to 0.3048 meters exactly. In both systems, the foot comprises 12 inches and three feet compose a yard.\nHistorically the \"foot\" was a part of many local systems of units, including the Greek, Roman, Chinese, French, and English systems. It varied in length from country to country, from city to city, and sometimes from trade to trade. Its length was usually between 250 mm and 335 mm and was generally, but not always, subdivided into 12 inches or 16 digits.\nThe United States is the only industrialized nation that uses the international foot and the survey foot (a customary unit of length) in preference to the meter in its commercial, engineering, and standards activities. The foot is legally recognized in the United Kingdom; road signs must use imperial units (however distances on road signs are always marked in miles or yards, not feet), while its usage is widespread among the British public as a measurement of height. The foot is recognized as an alternative expression of length in Canada officially defined as a unit derived from the meter although both the U.K. and Canada have partially metricated their units of measurement. The measurement of altitude in international aviation is one of the few areas where the foot is used outside the English-speaking world.\nThe length of the international foot corresponds to a human foot with shoe size of 13 (UK), 14 (US male), 15.5 (US female) or 46 (EU sizing).\n\n\n== Historical origin ==\n\nHistorically the human body has been used to provide the basis for units of length. The foot of a white male is typically about 15.3% of his height, giving a person of 160 cm (5 ft 3 in) a foot of 245 mm (9.6in) and one of 180 cm (5 ft 11 in) a foot of 275 mm (10.8in). These figures are less than the foot used in most cities over time, suggesting that the \"foot\" was actually a synonym for a \"shoe\".Archeologists believe that the Egyptians, Ancient Indians and Mesopotamians preferred the cubit while the Romans and the Greeks preferred the foot. Under the Harappan linear measures, Indus cities during the Bronze Age used a foot of 13.2 inches (333.5 mm) and a cubit of 20.8 inches (528.3 mm). The Egyptian equivalent of the foot\u2014a measure of four palms or 16 digits\u2014was known as the djeser and has been reconstructed as about 30 cm (12 in).\nThe Greek foot (\u03c0\u03bf\u03cd\u03c2, pous) had a length of \u200b1\u2044600 of a stadion, one stadion being about 181.2 m, therefore a foot being at the time about 302 mm. Its exact size varied from city to city and could range as much as between 270 mm and 350 mm, but lengths used for temple construction appear to have been about 295 mm to 325 mm, the former being close to the size of the Roman foot.\nThe standard Roman foot (pes) was normally about 295.7 mm (97% of today's measurement), but in the provinces, the pes Drusianus (foot of Nero Claudius Drusus) was used, with a length of about 334 mm. (In reality, this foot predated Drusus.)Originally both the Greeks and the Romans subdivided the foot into 16 digits, but in later years, the Romans also subdivided the foot into 12 unciae (from which both the English words \"inch\" and \"ounce\" are derived).\nAfter the fall of the Roman Empire, some Roman traditions were continued but others fell into disuse. In AD 790 Charlemagne attempted to reform the units of measure in his domains. His units of length were based on the toise and in particular the toise de l'\u00c9critoire, the distance between the fingertips of the outstretched arms of a man. The toise has 6 pieds (feet) each of 326.6 mm (12.86 in).\nHe was unsuccessful in introducing a standard unit of length throughout his realm: an analysis of the measurements of Charlieu Abbey shows that during the 9th century the Roman foot of 296.1 mm was used; when it was rebuilt in the 10th century, a foot of about 320 mm was used. At the same time, monastic buildings used the Carolingian foot of 340 mm.The procedure for verification of the foot as described in the 16th century by Jacob Koebel in his book Geometrei. Von k\u00fcnstlichem Feldmessen und absehen is:\nStand at the door of a church on a Sunday and bid 16 men to stop, tall ones and small ones, as they happen to pass out when the service is finished; then make them put their left feet one behind the other, and the length thus obtained shall be a right and lawful rood to measure and survey the land with, and the 16th part of it shall be the right and lawful foot.\n\n\n=== England ===\n\nThe measures of Iron Age Britain are uncertain and proposed reconstructions such as the Megalithic Yard are controversial. Later Welsh legend credited Dyfnwal Moelmud with the establishment of their units, including a foot of 9 inches. The Belgic or North German foot of 335 mm (13.2 inches) was introduced to England either by the Belgic Celts during their invasions prior to the Romans or by the Anglo-Saxons in the 5th & 6th century.\nRoman units were introduced following their invasion in AD 43. The Roman foot had been previously standardized by Agrippa at around 296 mm or 11.65 inches. Following the Roman withdrawal and Saxon invasions, the Roman foot continued to be used in the construction crafts while the Belgic foot was used for land measurement. Both the Welsh and Belgic feet seem to have been based on multiples of the barleycorn, but by as early as 950 the English kings seem to have (ineffectually) ordered measures to be based upon an iron yardstick at Winchester and then London. Henry I was said to have ordered a new standard to be based upon his own arm and, by the c.\u20091300 Act concerning the Composition of Yards and Perches traditionally credited to Edward I or II, the statute foot was a different measure exactly \u200b10\u204411 of the old foot. The barleycorn, inch, ell, and yard were likewise shrunk, while rods and furlongs remained the same. The ambiguity over the state of the mile was resolved by the 1593 Act against Converting of Great Houses into Several Tenements and for Restraint of Inmates and Inclosures in and near about the City of London and Westminster, which codified the statute mile as comprising 5,280 feet. The differences among the various physical standard yards around the world, revealed by increasingly powerful microscopes, eventually led to the 1959 adoption of the international foot defined in terms of the meter.\n\n\n== Definition ==\n\n\n=== International foot ===\nThe international yard and pound agreement of July 1959 defined the length of the international yard in the United States and countries of the Commonwealth of Nations as exactly 0.9144 meters. Consequently, the international foot is defined to be equal to exactly 0.3048 meters. This was 2 ppm shorter than the previous U.S. definition and 1.7 ppm longer than the previous British definition.The international standard symbol for a foot is \"ft\" (see ISO 31-1, Annex A). In some cases, the foot is denoted by a prime, which is often marked by an apostrophe, and the inch by a double prime; for example, 2 feet 4 inches is sometimes denoted as 2\u2032\u22124\u2033, 2\u2032 4\u2033 or 2\u20324\u2033.  (See 'minute' for another case where prime and double prime symbols are used to denote first and second cuts in refining measurement.)\n\n\n=== Pre-1959 ===\nIn the United States, the foot was defined as 12 inches, with the inch being defined by the Mendenhall Order of 1893 by 39.37 inches = 1 m. In Imperial units, the foot was defined as \u200b1\u20443 yard, with the yard being realized as a physical standard (separate from the standard meter).\nThe yard standards of the different Commonwealth countries were periodically compared with one another. The value of the United Kingdom primary standard of the yard was determined in terms of the meter by the National Physical Laboratory in 1964 as 0.9143969 m, implying a pre-1959 foot in the UK of approximately 0.304798966667 m.\n\n\n=== Survey foot ===\nWhen the international foot was defined in 1959, a great deal of survey data was already available based on the former definitions, especially in the United States and in India. The small difference between the survey and the international foot would not be detectable on a survey of a small parcel, but becomes significant for mapping, or when the state plane coordinate system (SPCS) is used in the US, because the origin of the system may be hundreds of thousands of feet (hundreds of miles) from the point of interest. Hence the previous definitions continued to be used for surveying in the United States and India for many years, and are denoted survey feet to distinguish them from the international foot. The United Kingdom was unaffected by this problem, as the retriangulation of Great Britain (1936\u201362) had been done in meters.\n\n\n==== US survey foot ====\nThe United States survey foot is defined as exactly \u200b1200\u20443937 meters, approximately 0.304800609601 m. \nOut of the 50 states, 24 have legislated that surveying measures should be based on the U.S. survey foot, eight have legislated that they be made on the basis of the international foot, and 18 have not specified the conversion factor from metric units.In 1986 the National Geodetic Survey (NGS) released the North American Datum of 1983, which underlies the state plane coordinate systems and is entirely defined in meters. An NGS policy from 1991 has this to say about the units used with the new datum to define the SPCS 83:\n\nIn preparation for the adjustment of the North American Datum of 1983, 31 states enacted legislation for the State Plane Coordinate System of 1983 (SPCS 83). All states defined SPCS 83 with metric parameters. Within the legislation, the U.S. Survey Foot was specified in 11 states and the International Foot was specified in 6 states. In all other states the meter is the only referenced unit of measure in the SPCS 83 legislation. The remaining 19 states do not yet have any legislation concerning SPCS 83.\nSince then, 42 states have abandoned the non-metric versions of SPCS 83: seven states continue to keep location data in survey feet as well as in meters, while one state keeps data in international feet as well as in meters. State legislation is also important for determining the conversion factor to be used for everyday land surveying and real estate transactions, although the difference (2 ppm) is of no practical significance given the precision of normal surveying measurements over short distances (usually much less than a mile).\n\n\n==== Indian survey foot ====\nThe Indian survey foot is defined as exactly 0.3047996 m, presumably derived from a measurement of the previous Indian standard of the yard. The current National Topographic Database of the Survey of India is based on the metric WGS-84 datum, which is also used by the Global Positioning System.\n\n\n== Historical use ==\n\n\n=== Metric foot ===\nAn ISO 2848 measure of 3 basic modules (30 cm) is called a \"metric foot\", but there were earlier distinct definitions of a metric foot during metrication in France and Germany.\n\n\n==== France ====\nIn 1799 the meter became the official unit of length in France. This was not fully enforced, and in 1812 Napoleon introduced the system of mesures usuelles which restored the traditional French measurements in the retail trade, but redefined them in terms of metric units. The foot, or pied m\u00e9trique, was defined as one third of a meter. This unit continued in use until 1837.\n\n\n==== Germany ====\nIn southwestern Germany in 1806, the Confederation of the Rhine was founded and three different reformed feet were defined, all of which were based on the metric system:\nIn Hesse, the Fu\u00df (foot) was redefined as 25 cm.\nIn Baden, the Fu\u00df was redefined as 30 cm.\nIn the Palatinate, the Fu\u00df was redefined as being \u200b33 1\u20443 cm (as in France).\n\n\n=== Other obsolete feet ===\nPrior to the introduction of the metric system, many European cities and countries used the foot, but it varied considerably in length: the voet in Ieper, Belgium, was 273.8 millimetres (10.78 in) while the piede in Venice was 347.73 millimetres (13.690 in). Lists of conversion factors between the various units of measure were given in many European reference works including:\n\nTrait\u00e9, Paris \u2013 1769\nPalaiseau \u2013 Bordeaux: 1816 \nde Gelder, Amsterdam and The Hague \u2013 1824\nHorace, Brussels \u2013 1840\nNoback & Noback (2 volumes), Leipzig \u2013 1851\nBruhns, Leipzig \u2013 1881Many of these standards were peculiar to a particular city, especially in Germany (which, before German Unification in 1871, consisted of many kingdoms, principalities, free cities and so on). In many cases the length of the unit was not uniquely fixed: for example, the English foot was stated as 11 pouces 2.6 lignes (French inches and lines) by Picard, 11 pouces 3.11 lignes by Maskelyne and 11 pouces 3 lignes by D'Alembert.Most of the various feet in this list ceased to be used when the countries adopted the metric system. The Netherlands and modern Belgium adopted the metric system in 1817, having used the mesures usuelles under Napoleon and the newly formed German Empire adopted the metric system in 1871.The palm (typically 200 mm to 280 mm) was used in many Mediterranean cities instead of the foot. Horace Doursther, whose reference was published in Belgium which had the smallest foot measurements, grouped both units together, while J.F.G. Palaiseau devoted three chapters to units of length: one for linear measures (palms and feet), one for cloth measures (ells) and one for distances traveled (miles and leagues). In the table below, arbitrary cut-off points of 270 mm and 350 mm have been chosen.\n\n(In Belgium, the words pied (French) and voet (Dutch) would have been used interchangeably.)\nNotes\n\n\n== See also ==\nAnthropic units\nEnglish units\nMermin's foot\nMetric foot\nHistory of measurement\nImperial units\nInternational System of Units\nPous\nSystems of measurement\nUnited States customary units\nUnits of measurement\n\n\n== Notes ==\n\n\n== References ==",
        "unit": "foot",
        "url": "https://en.wikipedia.org/wiki/Foot_(unit)"
    },
    {
        "_id": "South_African_rand",
        "clean": "South African rand",
        "text": "The rand (sign: R; code: ZAR) is the currency of South Africa. The Rand is subdivided into 100 cents (sign: \"c\"). The ISO 4217 code is ZAR, from Dutch Zuid-Afrikaanse Rand (South African Rand). The Rand is legal tender in the Common Monetary Area between South Africa, Swaziland, Lesotho, and Namibia, although the last three countries do have their own currencies pegged at par with rand.\nBefore 1976, the rand was legal tender in Botswana.\n\n\n== Etymology ==\nThe Rand takes its name from the WitwatersRand (\"white waters' ridge\" in English), the ridge upon which Johannesburg is built and where most of South Africa's gold deposits were found.\n\n\n== History ==\nThe Rand was introduced in the-then Union of South Africa on 14 February 1961, three months before the Republic of South Africa was established. A Decimal Coinage Commission had been set up in 1956 to consider a move away from the denominations of pounds, shillings, and pence, submitting its recommendation on 8 August 1958. It replaced the South African pound as legal tender, at the rate of 2 Rand to 1 pound, or 10 shillings to the Rand. The government introduced a mascot, Decimal Dan, \"the Rand-cent man\" (known in Afrikaans as Daan Desimaal). This was accompanied by a radio jingle, to inform the public about the new currency.\n\n\n=== Brief exchange rate history ===\n\n\n==== 1971\u20132000 ====\n\nOne Rand was worth US$1.40 from the time of its inception in 1961 until late-1971. Its value thereafter fluctuated as various exchange rate dispensations were implemented by the South African authorities. By the early-1980s, high inflation and mounting political pressure combined with sanctions placed against the country due to international opposition to the apartheid system started to erode its value. The currency broke above parity with the dollar for the first time in March 1982, and continued to trade between R 1 and R 1.30 to the dollar until June 1984, when depreciation of the currency gained momentum. By February 1985, it was trading over R 2 per dollar, and in July that year, all foreign exchange trading was suspended for three days to try to stop the depreciation.\nBy the time that State President P. W. Botha made his Rubicon speech on 15 August 1985, it had weakened to R 2.40 per dollar. The currency recovered somewhat between 1986\u201388, trading near the R 2 level most of the time and even breaking beneath it sporadically. The recovery was short-lived, however, and by the end of 1989, the Rand was trading at levels more than R 2.50 per dollar.\nAs it became clear in the early-1990s that the country was destined for Black majority rule and one reform after the other was announced, uncertainty about the future of the country hastened the depreciation until the level of R 3 to the dollar was breached in November 1992. A host of local and international events influenced the currency after that, most notably the 1994 presiential election which had it weaken to over R 3.60 to the dollar, the election of Tito Mboweni as the new governor of the South African Reserve Bank, and the inauguration of President Thabo Mbeki in 1999 which had it quickly slide to over R 6 to the dollar. The controversial land reform programme that was initiated in Zimbabwe, followed by the September 11, 2001 attacks, propelled it to its weakest historical level of R 13.84 to the dollar in December 2001.\n\n\n==== 2001\u20132011 ====\n\nThis sudden depreciation in 2001 led to a formal investigation, which in turn led to a dramatic recovery. By the end of 2002, the currency was trading  under R 9 to the dollar again, and by the end of 2004 was trading under R 5.70 to the dollar. The currency softened somewhat in 2005, and was trading around R 6.35 to the dollar at the end of the year. At the start of 2006, however, the currency resumed its rally, and as of 19 January 2006, was trading under R 6 to the dollar again. However, during the second and third quarters of 2006 (i.e. April through September), the Rand weakened significantly.\nIn sterling terms, it fell from around 9.5p to just over 7p, losing some 25% of its international trade-weighted value in just six months. In late-2007, the Rand rallied modestly to just over 8p, only to experience a precipitous slide during the first quarter of 2008.\nThis downward slide could be attributed to a range of factors: South Africa's worsening current account deficit, which widened to a 36\u2011year high of 7.3% of gross domestic product (GDP) in 2007; inflation at a five-year high of just under 9%; escalating global risk aversion as investors' concerns over the spreading impact of the sub-prime crisis grew; and a general flight to \"safe havens\", away from the perceived risks of emerging markets. The Rand depreciation was exacerbated by the Eskom electricity crisis, which arose from the utility being unable to meet the country's rapidly growing energy demands.\n\n\n==== 2012\u2013present ====\nA stalled mining industry in late-2012 led to new lows in early-2013. In late-January 2014, the Rand slid to R11.25 to the dollar, with analysts attributing the shift to \"word from the US Federal Reserve that it would trim back stimulus spending, which led to a massive sell-off in emerging economies.\" In 2014, South Africa experienced it's worst year against the US dollar since 2009, and in March 2015, the Rand traded at its worst since 2002. At the time, Trading Economics released data that the Rand \"averaged R4.97 to the dollar between 1972 and 2015, reaching an all time high of R12.45 in December of 2001 and a record low of R0.67 in June of 1973.\" By the end of 2014, the Rand had weakened to R 15.05 per dollar, partly due to South Africa's consistent trade account deficit with the rest of the world.\nFrom 9 December 2015 to 13 December 2015, over a four-day period, the Rand dropped over 10% due to what some suspected was  President Zuma's surprise announcement that he would be replacing the then-Finance Minister Nhlanhla Nene with the little-known David van Rooyen. The rapid drop in value was stemmed when Zuma backtracked and announced that the better-known previous Minister of Finance, Pravin Gordhan, would instead be appointed to the post. Zuma's surprise sacking of Nene damaged international confidence in the Rand, with it experiencing significant exchange volatility throughout much of January 2016, reaching an all-time low of R 17.9169 to the US dollar on the 9 January 2016 before rebounding to R 16.57 later the same day.The January drop in value was also partly caused by Japanese retail investors cutting their losses in the currency to look for higher-yield investments elsewhere and due to concerns over the impact of the economic slowdown in China, South Africa's largest export partner.  By mid-January, economists were speculating that the Rand could expect to see further volatility for the rest of 2016.\nBy 29 April, it reached its highest performance over the previous five months, exchanging at a rate of 14.16 to the United States dollar.Following the United Kingdom's vote to leave the European Union (EU), the Rand dropped in value over 8% against the United States dollar on 24 June 2016, the currency's largest single-day decline since the 2008 economic crash.  This was partly due to a general global financial retreat from currencies seen as risky to the US dollar and partly due to concerns over how the UK's withdrawal from the EU would impact South Africa's economy and trade relations.In April 2017, a Reuters poll estimated that the Rand would remain relatively stable for the rest of the year, as two polls found that analysts had already factored in a possible downgrade to \"junk\" status. At the time, Moody's graded South Africa two notches above junk status. When President Jacob Zuma narrowly won a motion of no-confidence in South Africa in August 2017, the Rand continued to slide, dropping 1.7% that day. In September 2017, Goldman Sachs Group said that the debt and corruption of Eskom Holdings was the biggest risk to South Africa's economy and exchange rate of the Rand. At the time, it had no permanent CEO, and Colin Coleman of Goldman Sachs in Africa said the company was \"having discussions on solutions\" on finding credible management. In October 2017, the Rand firmed against the US dollar as it recovered from a six-month low. Reuters noted that \"South Africa is highly susceptible to global investor sentiment as the country relies on foreign money to cover it's large budget and current account deficits.\" On November 13, 2017, the Rand \"tumbled\" over a full percent when the budget chief Michael Sachs stood down from his position in Zuma's administration.\n\n\n== Coins ==\n\nCoins were introduced in 1961 in denominations of \u200b1\u20442, 1, \u200b2 1\u20442, 5, 10, 20, and 50 cents. In 1965, 2-cent coins replaced the \u200b2 1\u20442-cent coins. The \u200b1\u20442-cent coin was last struck for circulation in 1973. The 2-Rand coin was introduced in 1989, followed by 5-Rand coins in 1994. Production of the 1- and 2-cent coins was discontinued in 2002, primarily due to inflation having devalued them, but they remain legal tender.  Shops normally round the total purchase price of goods to the nearest 10 cents (in favour of the consumer).\nIn an effort to curb counterfeiting, a new 5-Rand coin was released in August 2004. Security features introduced on the coin include a bimetal design (similar to the \u20ac1 and \u20ac2 coins, the Thai 10-baht coin, the British \u00a32 coin, and the Canadian $2 coin), a specially serrated security groove along the rim and microlettering.\n\n\n== Banknotes ==\nThe first series of Rand banknotes was introduced in 1961 in denominations of 1-, 2-, 10-, and 20-Rand, with similar designs and colours to the preceding pound notes to ease the transition. They bore the image of what was believed at the time to be Jan van Riebeeck, the first V.O.C. administrator of Cape Town. It was later discovered that the image was not in fact Van Riebeeck at all, a portrait of Bartholomeus Vermuyden had been mistaken for Van Riebeeck. Like the last pound notes, they were printed in two variants, one with English written first and the other with Afrikaans written first.\nIn 1966, a second series was released with designs which moved away from the previous pound notes. Notes with denominations of 1-, 5- and 10-Rand were produced with predominantly one colour per note. A smaller 1-Rand note with the same design was introduced in 1973 and a 2-Rand note was introduced in 1974. The 20-Rand denomination from the first series was dropped. All notes bore the image of Jan van Riebeeck. The practice of having an English and an Afrikaans version of each note was continued in this series.\nThe 1978 series began with denominations of 2-, 5-, 10- and 20-Rand, with a 50-Rand introduced in 1984. This series had only one language variant for each denomination of note. Afrikaans was the first language on the 2-, 10-, and 50-Rand, while English was the first language on the 5- and 20-Rand. The 1-Rand note was replaced by a coin.\nIn the 1990s, the notes were redesigned with images of the Big Five wildlife species. 10-, 20- and 50-Rand notes were introduced in 1992 & 1993, retaining the colour scheme of the previous issue. Coins were introduced for the 2- and 5-Rand, replacing the notes of the previous series, mainly because of the severe wear and tear experienced with low-denomination notes in circulation. In 1994, 100- and 200-Rand notes were introduced.\nThe 2005 series has the same principal design, but with additional security features such as colour-shifting ink on the 50-Rand and higher and the EURion constellation. The obverses of all denominations were printed in English, while two other official languages were printed on the reverse, thus making use of all 11 official languages of South Africa.\nIn 2010, the South African Reserve Bank and commercial banks withdrew all 1994 series 200-Rand banknotes due to relatively high-quality counterfeit notes in circulation.In 2011, the South African Reserve Bank issued 100-Rand banknotes which were defective because they lacked fluorescent printing visible under UV light. In June, printing of this denomination was moved from the South African Bank Note Company to Crane Currency\u2019s Swedish division (Tumba Bruk), which reportedly produced 80 million 100-Rand notes. The South African Reserve Bank shredded 3.6 million 100-Rand banknotes printed by Crane Currency because they had the same serial numbers as a batch printed by the South African Bank Note Company. In addition, the notes printed in Sweden were not the correct colour, and they were 1 mm short.On 11 February 2012, President Jacob Zuma announced that the country would be issuing a new set of banknotes bearing Nelson Mandela's image. They were entered into circulation on 6 November 2012. These contained the same denominations of 10-, 20-, 50-, 100- and 200-Rand.\nIn 2013, the 2012 series was updated with the addition of the EURion constellation to all five denominations.On 18 July 2018, a special commemorative series of banknotes was released in commemoration of the 100th anniversary of Nelson Mandela's birth. This series includes notes of all denominations, 10-, 20-, 50-, 100- and 200-Rand. These notes will circulate alongside the existing notes. The notes depict the standard face of Nelson Mandela on the obverse, but instead of the Big Five animals on the reverse, they show a younger Mandela with different iconic scenes relating to his legacy. These scenes comprise: the rolling hills of the Eastern Cape, featuring Mandela\u2019s humble birthplace of Mvezo (10-Rand); the home of Mandela in Soweto, where he defined his political life alongside other struggle icons (20-Rand); the site where Mandela was captured near Howick, following 17 months in hiding, where a monument to him has been erected (50-Rand); the place of Mandela's 27-year imprisonment at Robben Island, showing a pile of quarried limestone (100-Rand); the statue of Mandela at the Union Buildings in remembrance of when he was inaugurated there in 1994 (200-Rand).\n\n\n=== First series ===\n\n\n=== Second series ===\n\n\n=== Third series ===\n\n\n=== Fourth series ===\n\n\n=== Fifth series ===\n\n\n=== Sixth series ===\n\n\n=== Seventh series ===\n\n\n== See also ==\nFinancial Rand\nWitwatersRand\nKrugerRand\nCoins of the South African Rand\nSouth African pound\nEconomy of South Africa\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nSouth African Reserve Bank Currency Page\nUS Federal Reserve Bank historical exchange rate data\nSouth African Currency Page, with a short description of each note.\nSouth African Currency Page (old Rand), a short description of pre-1994 (apartheid-era) notes.",
        "unit": "south african rand",
        "url": "https://en.wikipedia.org/wiki/South_African_rand"
    },
    {
        "_id": "Pound_sterling",
        "clean": "Pound sterling",
        "text": "The pound sterling (symbol: \u00a3; ISO code: GBP), commonly known as the pound and less commonly referred to as Sterling, is the official currency of the United Kingdom, Jersey, Guernsey, the Isle of Man, South Georgia and the South Sandwich Islands, the British Antarctic Territory, and Tristan da Cunha. It is subdivided into 100 pence (singular: penny, abbreviated: p). A number of nations that do not use sterling also have currencies called the pound.  At various times, the pound sterling was commodity money or bank notes backed by silver or gold, but it is currently fiat money, backed only by the economy in the areas where it is accepted. The pound sterling is the world's oldest currency still in use and which has been in continuous use since its inception.Sterling is the fourth most-traded currency in the foreign exchange market, after the United States dollar, the euro, and the Japanese yen. Together with those three currencies and the Chinese yuan  it forms the basket of currencies which calculate the value of IMF special drawing rights. Sterling is also the third most-held reserve currency in global reserves (about 4%).The British Crown dependencies of Guernsey, Jersey and the Isle of Man produce their own local issues of sterling: the \"Guernsey pound\", the \"Jersey pound\" and the Manx pound), Gibraltar (alongside the Gibraltar pound), the Falkland Islands (alongside the Falkland Islands pound), Saint Helena and Ascension Island in Saint Helena, Ascension and Tristan da Cunha (alongside the Saint Helena pound). The Bank of England is the central bank for the pound sterling, issuing its own coins and banknotes, and regulating issuance of banknotes by private banks in Scotland and Northern Ireland. Banknotes issued by other jurisdictions are not regulated by the Bank of England; local governments use Bank of England notes as backing for local issuance by allowing them to be exchanged 1:1 at face value.\n\n\n== Names ==\nThe full official name pound sterling (plural: pounds sterling), is used mainly in formal contexts and also when it is necessary to distinguish the United Kingdom currency from other currencies with the same name. Otherwise the term pound is normally used. The currency name is sometimes abbreviated to just sterling, particularly in the wholesale financial markets, but not when referring to specific amounts; for example, \"Payment is accepted in sterling\" but never \"These cost five sterling\". The abbreviations \"ster.\" and \"stg.\" are sometimes used. The term \"British pound\" is sometimes incorrectly used in less formal contexts, and it is not an official name of the currency.\nThe exchange rate of the pound sterling against the US Dollar is referred to as \"cable\" in the wholesale foreign exchange markets. The origins of this term are attributed to the fact that in the 1800s, the GBP/USD exchange rate was transmitted via transatlantic cable. Forex traders of GBP/USD are sometimes referred to as \"cable dealers\". GBP/USD is now the only currency pair with its own name in the foreign exchange markets, after IEP/USD, known as \"wire\" particularly in the forward FX markets, no longer exists after the Irish Pound was replaced by the euro in 1999.\n\nThere is apparent convergence of opinion regarding the origin of the term \"pound sterling\", toward its derivation from the name of a small Norman silver coin, and away from its association with Easterlings (Germanic traders) or other etymologies. Hence, the Oxford English Dictionary (and sources derived therefrom) state that the \"most plausible\" etymology is derivation from the Old English steorra for \"star\" with the added diminutive suffix \"-ling\", to mean \"little star\" and to refer to a silver penny of the English Normans. As another established source notes, the compound expression was then derived:silver coins known as \"sterlings\" were issued in the Saxon kingdoms, 240 of them being minted from a pound of silver... Hence, large payments came to be reckoned in \"pounds of sterlings,\" a phrase later shortened...\n However, the perceived narrow window of the issuance of this coin, and the fact that coin designs changed frequently in the period in question, led Philip Grierson to reject this in favour of a more complex theory.Another argument that the Hanseatic League was the origin for both the origin of its definition and manufacture, and in its name is that the German name for the Baltic is \"Ost See\", or \"East Sea\", and from this the Baltic merchants were called \"Osterlings\", or \"Easterlings\". In 1260, Henry III granted them a charter of protection and land for their Kontor, the Steelyard of London, which by the 1340s was also called \"Easterlings Hall\", or Esterlingeshalle. Because the League's money was not frequently debased like that of England, English traders stipulated to be paid in pounds of the \"Easterlings\", which was contracted to \"'sterling\".For further discussion of the etymology of \"sterling\", see sterling silver.\nThe currency sign for the pound is \u00a3, which is usually written with a single cross-bar (as on sterling bank notes), though a version with a double cross-bar (\u20a4) is also sometimes seen. This symbol derives from medieval Latin documents; the Roman words libra, solidus, and denarius (\u00a3sd) referred to pounds, shillings and pence in the British pre-decimal (duodecimal) currency system and the black-letter \"L\" was the abbreviation for libra, the basic Roman unit of weight.\nThe ISO 4217 currency code is GBP, formed from \"GB\", the ISO 3166-1 alpha-2 code for the United Kingdom, and the first letter of \"pound\". It does not stand for \"Great Britain Pound\" or \"Great British Pound\". Occasionally, the abbreviation \"UKP\" is used but this is non-standard because the ISO 3166 country code for the United Kingdom is GB (see Terminology of the British Isles). The Crown dependencies use their own (non-ISO) codes: GGP (Guernsey pound), JEP (Jersey pound) and IMP (Isle of Man pound). Stocks are often traded in pence, so traders may refer to pence sterling, GBX (sometimes GBp), when listing stock prices.\nA common slang term for the pound sterling or pound is quid, which is singular and plural, except in the common phrase \"Quids in!\" The term may have come via Italian immigrants from \"scudo\", the name for a number of coins used in Italy until the 19th century; or from Latin 'quid' via the common phrase quid pro quo, literally, \"what for what,\" or, figuratively, \"An equal exchange or substitution\".\n\n\n== Subdivisions and other units ==\n\n\n=== Decimal coinage ===\nSince decimalisation in 1971 (see Decimal Day), the pound has been divided into 100 pence (until 1981 described on the coinage as \"new pence\"). The symbol for the penny is \"p\"; hence an amount such as 50p (\u00a30.50) properly pronounced \"fifty pence\" is more colloquially, quite often, pronounced \"fifty pee\" /f\u026afti pi/. This also helped to distinguish between new and old pence amounts during the changeover to the decimal system. A decimal halfpenny was issued until 1984, but was removed due to having a higher cost to manufacture than its face value.\n\n\n=== Pre-decimal ===\n\nBefore decimalisation, the pound was divided into 20 shillings and each shilling into 12 pence, making 240 pence to the pound. The symbol for the shilling was \"s.\"\u2014not from the first letter of the word, but from the Latin solidus. The symbol for the penny was \"d.\", from the French denier, from the Latin denarius (the solidus and denarius were Roman coins). A mixed sum of shillings and pence, such as 3 shillings and 6 pence, was written as \"3/6\" or \"3s. 6d.\" and spoken as \"three and six\" or \"three and sixpence\" except for \"1/1,\" \"2/1\" etc., which were spoken as \"one and a penny\", \"two and a penny\", etc.). 5 shillings, for example, was written as \"5s.\" or, more commonly, \"5/\u2013\".\nVarious coin denominations had, and in some cases continue to have, special names\u2014such as crown, farthing, sovereign and guinea. See Coins of the pound sterling and List of British coins and banknotes for details.\nBy the 1950s, coins of Kings George III, George IV and William IV had disappeared from circulation, but coins (at least the penny) bearing the head of any British king or queen from Queen Victoria onwards could be found in circulation. Silver coins were replaced by those in cupro-nickel in 1947, and by the 1960s the silver coins were rarely seen. Silver/cupro-nickel shillings (from any period after 1816) and florins (2 shillings) remained as legal tender after decimalisation (as 5p and 10p respectively) until 1993, but are now officially demonetised.\n\n\n== History ==\nThe pound sterling is the world's oldest currency still in use.\n\n\n=== Anglo-Saxon ===\n\nThe pound was a unit of account in Anglo-Saxon England, equal to 240 silver pennies and equivalent to one pound weight of silver. It evolved into the modern British currency, the pound sterling.\nThe accounting system of 4 farthings = 1 penny, 12 pence = 1 shilling, 20 shillings = 1 pound was adopted from that introduced by Charlemagne to the Frankish Empire (see French livre).\nThe origins of sterling lie in the reign of King Offa of Mercia (757\u2013796), who introduced the silver penny. It copied the denarius of the new currency system of Charlemagne's Frankish Empire. As in the Carolingian system, 240 pennies weighed 1 pound (corresponding to Charlemagne's libra), with the shilling corresponding to Charlemagne's solidus and equal to 12d. At the time of the penny's introduction, it weighed 22.5 troy grains of fine silver (32 tower grains; about 1.5 g), indicating that the Mercian pound weighed 5,400 troy grains (the Mercian pound became the basis of the tower pound, which also weighed 5,400 troy grains, equivalent to 7,680 tower grains, about 350g).\n\n\n=== Medieval ===\nThe early pennies were struck from fine silver (as pure as was available). However, in 1158, a new coinage was introduced by King Henry II (known as the Tealby penny) which was struck from 0.925 (92.5%) silver. This became the standard until the 20th century and is today known as sterling silver, named after its association with the currency. Sterling silver is harder than the 0.999 (99.9%) fine silver that was traditionally used, and so sterling silver coins did not wear down as rapidly as fine silver coins. The English currency was almost exclusively silver until 1344, when the gold noble was successfully introduced into circulation. However, silver remained the legal basis for sterling until 1816.\nDuring the time of Henry III, the pound sterling equalled the tower (weight) pound. In the 28th year of Edward I (around 1300), the tale (money) pound, or pound sterling, first began to differ from (weigh less than) the tower pound, from which it originated, for by indenture of that year the pound weight was to contain 20s. 3d. in tale pound. In the 27th year of Edward III (around 1354), the pound sterling was now only 80% of the pound weight, or 9 oz 12 dwt (or 9.6 oz) tower. By an Act of 13 Henry IV (around 1412), the pound weight of standard silver was to contain thirty shillings in tale, or one and a half pounds sterling; thus the pound sterling reduced to two-thirds of a pound weight, or 8 oz tower. The pound sterling was adjusted in weight several more times thereafter.\nIn the reign of Henry IV (1399\u20131413), the penny was reduced in weight to 15 grains (0.97 g) of silver, with a further reduction to 12 grains (0.78 g) in 1464.\n\n\n=== Tudor ===\nDuring the reigns of Henry VIII and Edward VI, the silver coinage was drastically debased, although the pound was redefined to the troy pound of 5,760 grains (373 g) in 1526. In 1544, a silver coinage was issued containing just one-third silver and two-thirds copper\u2014equating to .333 silver, or 33.3% pure. The result was a coin copper in appearance but relatively pale in colour. In 1552, a new silver coinage was introduced, struck in sterling silver. However, the penny's weight was reduced to 8 grains (0.52 g), so 1 troy pound of sterling silver produced 60 shillings of coins. This silver standard was known as the \"60-shilling standard\" and lasted until 1601 when a \"62-shilling standard\" was introduced, reducing the penny's weight to \u200b7 23\u204431 grains (0.50 g).\nThroughout this period, the size and value of the gold coinage fluctuated considerably.\n\n\n=== Unofficial gold standard ===\nIn 1663, a new gold coinage was introduced based on the 22 carat fine guinea. Fixed in weight at \u200b44 1\u20442 to the troy pound from 1670, this coin's value varied considerably until 1717, when it was fixed at 21 shillings (21/-, 1.05 pounds). However, despite the efforts of Sir Isaac Newton, Master of the Mint, to reduce the guinea's value, this valuation overvalued gold relative to silver when compared to the valuations in other European countries. In line with Gresham's Law, British merchants sent silver abroad in payments whilst goods for export were paid for with gold. As a consequence of these flows of silver out and gold in, Great Britain was effectively on a gold standard. Trade with China aggravated this outflow, as the Chinese refused to accept anything but silver in payment for exports. From the mid-17th century, around 28,000 metric tons (27,600 imperial tons) of silver were received by China, principally from European powers, in exchange for Chinese tea and other goods. In order to trade with China, Great Britain had first to trade with the other European nations to receive silver, which led to the East India Company redressing this trade imbalance through the indirect sale of opium to the Chinese.Domestic offtake further reduced silver in circulation, as the improving fortunes of the merchant class led to increased demand for tablewares. Silversmiths had always regarded coinage as a source of raw material, already verified for fineness by the government. As a result, sterling coins were being melted and fashioned into sterling silverware at an accelerating rate. A 1697 Act of Parliament tried to stem this tide by raising the minimum acceptable fineness on wrought plate from sterling's 92.5% to a new Britannia silver standard of 95.83%. Silverware made purely from melted coins would be found wanting when the silversmith took his wares to the Assay Office, thus discouraging the melting of coins.\n\n\n=== Establishment of modern currency ===\nThe Bank of England was founded in 1694, followed by the Bank of Scotland a year later. Both began to issue paper money.\n\n\n=== Currency of Great Britain (1707) and the United Kingdom (1801) ===\nThe pound Scots once had much the same value as the pound sterling, but it suffered far higher devaluation until in the 17th century it was pegged to sterling at a value of 12 pounds Scots = 1 pound sterling.\nIn 1707, the Kingdom of England and the Kingdom of Scotland merged to form the Kingdom of Great Britain. In accordance with the Treaty of Union, the currency of Great Britain was sterling, with the pound Scots soon being replaced by sterling at the pegged value.\nIn 1801, Great Britain and the Kingdom of Ireland were united to form the United Kingdom of Great Britain and Ireland. However, the Irish pound continued to exist and was not replaced by sterling until January 1826. The conversion rate had long been thirteen Irish pounds to twelve pounds sterling.\n\n\n=== Use in the Empire ===\n\nSterling circulated in much of the British Empire. In some parts, it was used alongside local currencies. For example, the gold sovereign was legal tender in Canada despite the use of the Canadian dollar. Several colonies and dominions adopted the pound as their own currency. These included Australia, Barbados, British West Africa, Cyprus, Fiji, British India, the Irish Free State, Jamaica, New Zealand, South Africa and Southern Rhodesia. Some of these retained parity with sterling throughout their existence (e.g. the South African pound), whilst others deviated from parity after the end of the gold standard (e.g. the Australian pound). These currencies and others tied to sterling constituted the sterling area.\nThe original English colonies on mainland North America were not party to the sterling area because the above-mentioned silver shortage in England coincided with these colonies' formative years. As a result of equitable trade (and rather less equitable piracy), the Spanish milled dollar became the most common coin within the English colonies.\n\n\n=== Gold standard ===\nDuring the American war of independence and the Napoleonic wars, Bank of England notes were legal tender, and their value floated relative to gold. The Bank also issued silver tokens to alleviate the shortage of silver coins. In 1816, the gold standard was adopted officially, with the silver standard reduced to 66 shillings (66/-, \u00a33 6s), rendering silver coins a \"token\" issue (i.e. not containing their value in precious metal). In 1817, the sovereign was introduced, valued at 20 shillings. Struck in 22\u2011carat gold, it contained 113 grains (7.3 g) of gold and replaced the guinea as the standard British gold coin without changing the gold standard. In 1825, the Irish pound, which had been pegged to sterling since 1801 at a rate of 13 Irish pounds = 12 pounds sterling, was replaced, at the same rate, with sterling.\nBy the 19th century the pound sterling was widely accepted outside Britain. The American Nellie Bly carried Bank of England notes on her 1889\u20131890 trip around the world in 72 days. During the late 19th and early 20th centuries, many other countries adopted the gold standard. As a consequence, conversion rates between different currencies could be determined simply from the respective gold standards. The pound sterling was equal to 4.85 United States dollars, 5.25 Canadian dollars, 12.10 Dutch guilders, 26.28 French francs (or equivalent currencies in the Latin Monetary Union), 20.43 German marks or 24.02 Austro-Hungarian krone. After the International Monetary Conference of 1867 in Paris, the possibility of the UK joining the Latin Monetary Union was discussed, and a Royal Commission on International Coinage examined the issues, resulting in a decision against joining monetary union.\nThe gold standard was suspended at the outbreak of the war in 1914, with Bank of England and Treasury notes becoming legal tender. Before World War I, the United Kingdom had one of the world's strongest economies, holding 40% of the world's overseas investments. But after the end of the war, the country was indebted: Britain owed \u00a3850 million (\u00a337.3 billion as of 2015) with interest costing the country some 40% of all government spending. To try to resume stability, a version of the gold standard was reintroduced in 1925, under which the currency was fixed to gold at its pre-war peg, but one could only exchange currency for gold bullion, not for coins. This was abandoned on 21 September 1931, during the Great Depression, and sterling suffered an initial devaluation of some 25%.\n\n\n=== Bretton Woods ===\n\nIn 1940, an agreement with the US pegged the pound to the U.S. dollar at a rate of \u00a31 = $4.03. (Only the year before, it had been $4.86.) This rate was maintained through the Second World War and became part of the Bretton Woods system which governed post-war exchange rates. Under continuing economic pressure, and despite months of denials that it would do so, on 19 September 1949 the government devalued the pound by 30.5% to $2.80. The move prompted several other currencies to be devalued against the dollar.\nOperation Bernhard was the codename of a secret Nazi plan devised during the Second World War by the RSHA and the SS to destabilise the British economy via economic warfare by flooding the global economy and the British Empire with forged Bank of England \u00a35, \u00a310, \u00a320, and \u00a350 notes.\nIn 1961, 1964, and 1966, the pound came under renewed pressure, as speculators were selling pounds for dollars. In summer 1966, with the value of the pound falling in the currency markets, exchange controls were tightened by the Wilson government. Among the measures, tourists were banned from taking more than \u00a350 out of the country in travellers' cheques and remittances, plus \u00a315 in cash; this restriction was not lifted until 1979. The pound was devalued by 14.3% to $2.40 on 18 November 1967.\n\n\n=== Decimalisation ===\n\nUntil decimalisation, amounts were stated in pounds, shillings, and pence, with various widely understood notations. The same amount was denoted by 32s 6d, 32/6, \u00a31 12s 6d, \u00a31/12/6. It was customary to specify some prices (for example professional fees and auction prices for works of art) in guineas (one guinea was 21 shillings) although guinea coins were no longer in use.\nFormal parliamentary proposals to decimalise sterling were first made in 1824 when Sir John Wrottesley, MP for Staffordshire, asked in the British House of Commons whether consideration had been given to decimalising the currency. Wrottesley raised the issue in the House of Commons again in 1833, and it was again raised by John Bowring, MP for Kilmarnock Burghs, in 1847 whose efforts led to the introduction in 1848 of what was in effect the first decimal coin in the United Kingdom, the florin, valued at one-tenth of a pound sterling. However, full decimalisation was resisted, although the florin coin, re-designated as ten new pence, survived the transfer to a full decimal system in 1971, with examples surviving in British coinage until 1993.\nJohn Benjamin Smith, MP for Stirling Burghs, raised the issue of full decimalisation again in Parliament in 1853, resulting in the Chancellor of the Exchequer, William Gladstone, announcing soon afterwards that \"the great question of a decimal coinage\" was \"now under serious consideration\". A full proposal for the decimalisation of sterling was then tabled in the House of Commons in June 1855, by William Brown, MP for Lancashire Southern, with the suggestion that the pound sterling be divided into one thousand parts, each called a \"mil\", or alternatively a farthing, as the pound was then equivalent to 960 farthings which could easily be rounded up to one thousand farthings in the new system. This did not result in the conversion of the pound sterling into a decimal system, but it was agreed to establish a Royal Commission to look into the issue. However, largely due to the hostility to decimalisation of two of the appointed commissioners, Lord Overstone (a banker) and John Hubbard (Governor of the Bank of England), decimalisation in Britain was effectively quashed for over a hundred years.However, the pound sterling was decimalised in various British colonial territories before the United Kingdom (and in several cases in line with William Brown's proposal that the pound be divided into 1,000 parts, called mils). These included Hong Kong from 1863 to 1866; Cyprus from 1955 until 1960 (and continued on the island as the division of the Cypriot pound until 1983); and the Palestine Mandate from 1926 until 1948.Towards the end of the Second World War, various attempts to decimalise the pound sterling in the United Kingdom were made. Later, in 1966, the British government decided to include in the Queen's Speech a plan to convert the pound into a decimal currency. As a result of this, on 15 February 1971, the UK decimalised the pound sterling, replacing the shilling and penny with a single subdivision, the new penny. For example, a price tag of \u00a31 12s 6d became \u200b\u00a31.62 1\u20442. The word \"new\" was omitted from coins minted after 1981.\n\n\n=== Free-floating pound ===\nWith the breakdown of the Bretton Woods system, the pound floated from August 1971 onwards. At first it appreciated a little, rising to almost $2.65 in March 1972 from $2.42, the upper bound of the band in which it had been fixed. The sterling area effectively ended at this time, when the majority of its members also chose to float freely against the pound and the dollar.\n\n\n=== 1976 sterling crisis ===\nJames Callaghan became Prime Minister in 1976. He was immediately told the economy was facing huge problems, according to documents released in 2006 by the National Archives. The effects of the 1973 oil crisis were still being felt, with inflation rising to over 27% in 1975. Financial markets were beginning to believe the pound was overvalued, and in April that year The Wall Street Journal advised the sale of sterling investments in the face of high taxes, in a story that ended with \"goodbye, Great Britain. It was nice knowing you\". At the time the UK government was running a budget deficit, and Labour's strategy emphasised high public spending. Callaghan was told there were three possible outcomes: a disastrous free fall in sterling, an internationally unacceptable siege economy, or a deal with key allies to prop up the pound while painful economic reforms were put in place. The US government feared the crisis could endanger NATO and the European Economic Community (EEC), and in light of this the US Treasury set out to force domestic policy changes. In November 1976 the International Monetary Fund (IMF) announced the conditions for a loan, including deep cuts in public expenditure.\n\n\n=== 1979\u201389 ===\nThe Conservative Party was elected to office in 1979, on a programme of fiscal austerity. Initially the pound rocketed, moving above US$2.40, as interest rates rose in response to the monetarist policy of targeting money supply. The high exchange rate was widely blamed for the deep recession of 1981. Sterling fell sharply after 1980; at its lowest, the pound stood at just $1.03 in March 1985, before rising to $1.70 in December 1989.\n\n\n=== Following the Deutsche Mark ===\nIn 1988, Margaret Thatcher's Chancellor of the Exchequer, Nigel Lawson, decided that the pound should \"shadow\" the West German Deutsche Mark, with the unintended result of a rapid rise in inflation as the economy boomed due to low interest rates. (For ideological reasons, the Conservative Government declined to use alternative mechanisms to control the explosion of credit. For this reason, former Prime Minister Edward Heath referred to Lawson as a \"one club golfer\").Following German re-unification in 1990, the reverse held true, as high borrowing costs to fund Eastern reconstruction, a need exacerbated by the political choice to make the Ostmark equivalent to the Deutsche Mark (DM), meant rates in other countries shadowing the DM, especially the UK, were far too high relative to domestic circumstances, leading to a housing decline and recession.\n\n\n=== Following the European Currency Unit ===\nOn 8 October 1990 the Conservative government (Third Thatcher ministry) decided to join the European Exchange Rate Mechanism (ERM), with the pound set at DM2.95. However, the country was forced to withdraw from the system on \"Black Wednesday\" (16 September 1992) as Britain's economic performance made the exchange rate unsustainable.\n'Black Wednesday' saw interest rates jump from 10% to 15% in an unsuccessful attempt to stop the pound from falling below the ERM limits. The exchange rate fell to DM2.20. Those who had argued for a lower GBP/DM exchange rate were vindicated as the cheaper pound encouraged exports and contributed to the economic prosperity of the 1990s.\n\n\n=== Following inflation targets ===\nIn 1997, the newly elected Labour government handed over day-to-day control of interest rates to the Bank of England (a policy that had originally been advocated by the Liberal Democrats). The Bank is now responsible for setting its base rate of interest so as to keep inflation (as measured by the Consumer Price Index (CPI)) very close to 2% per annum. Should CPI inflation be more than one percentage point above or below the target, the governor of the Bank of England is required to write an open letter to the Chancellor of the Exchequer explaining the reasons for this and the measures which will be taken to bring this measure of inflation back in line with the 2% target. On 17 April 2007, annual CPI inflation was reported at 3.1% (inflation of the Retail Prices Index was 4.8%). Accordingly, and for the first time, the Governor had to write publicly to the government explaining why inflation was more than one percentage point higher than its target.\n\n\n=== Euro ===\n\nAs a member of the European Union, the United Kingdom could have adopted the euro as its currency. However, the subject was always politically controversial, and the UK negotiated an opt-out on this issue.\nIn 2007, Gordon Brown, then Chancellor of the Exchequer, ruled out membership for the foreseeable future, saying that the decision not to join had been right for Britain and for Europe.On 1 January 2008, with the Republic of Cyprus switching its currency from the Cypriot pound to the euro, the British sovereign bases on Cyprus (Akrotiri and Dhekelia) followed suit making the Sovereign Base Areas the only territory under British sovereignty to officially use the euro.The 2016 referendum which started the process of United Kingdom's withdrawal from the European Union makes adoption of the euro almost impossible.The government of former Prime Minister Tony Blair had pledged to hold a public referendum to decide on membership should \"five economic tests\" be met, to increase the likelihood that adoption of the euro would be in the national interest. In addition to these internal (national) criteria, the UK would have to meet the European Union's economic convergence criteria (Maastricht criteria) before being allowed to adopt the euro. The Conservative and Liberal Democrat coalition government (2010\u20132015) ruled out joining the euro for that parliamentary term. Currently, the UK's annual government deficit, as a percentage of the GDP, is above the defined threshold.\nThe idea of replacing the pound with the euro was always controversial with the British public, partly because of the pound's identity as a symbol of British sovereignty and because it would, according to many critics, have led to suboptimal interest rates, harming the British economy. In December 2008, the results of a BBC poll of 1000 people suggested that 71% would vote no to the euro, 23% would vote yes, while 6% said they were unsure. The pound did not join the Second European Exchange Rate Mechanism (ERM II) after the euro was created. Denmark and the UK have opt-outs from entry to the euro. Theoretically, every other EU nation must eventually sign up.\nThe Scottish Conservative Party claimed that there was an issue for Scotland in that the adoption of the euro would mean the end of nationally distinctive banknotes, as the euro banknotes do not have national designs. Before the 'No' vote in the Scottish independence referendum in 2014, the Scottish National Party affirmed that the euro would not be the national currency of an independent Scotland.\n\n\n=== Recent exchange rates ===\n\nThe pound and the euro fluctuate in value against one another, although there may be correlation between movements in their respective exchange rates with other currencies such as the US dollar. Inflation concerns in the UK led the Bank of England to raise interest rates in late 2006 and 2007. This caused the pound to appreciate against other major currencies and, with the US dollar depreciating at the same time, the pound hit a 15-year high against the US dollar on 18 April 2007, reaching US$2 the day before, for the first time since 1992. The pound and many other currencies continued to appreciate against the dollar; sterling hit a 26-year high of US$2.1161 on 7 November 2007 as the dollar fell worldwide. From mid-2003 to mid-2007, the pound/euro rate remained range-bound (within \u00b1 5%) of \u20ac1.45.Following the global financial crisis in late 2008, the pound depreciated sharply, reaching \u00a31 per $1.38 (US) on 23 January 2009 and falling below \u20ac1.25 against the euro in April 2008. A further decline occurred during the remainder of 2008, most dramatically on 29 December when its euro rate hit an all-time low at \u20ac1.0219, while its US dollar rate depreciated. The pound appreciated in early 2009 reaching a peak against the euro in mid-July of \u20ac1.17. The following months the pound remained broadly steady against the euro, with the pound's current (27 May 2011) value at \u20ac1.15 and US$1.65.\nOn 5 March 2009, the Bank of England announced that it would pump \u00a375 billion of new capital into the British economy, through a process known as quantitative easing. This was the first time in the United Kingdom's history that this measure had been used, although the Bank's Governor Mervyn King suggested it was not an experiment.The process saw the Bank of England creating new money for itself, which it then used to purchase assets such as government bonds, secured commercial paper, or corporate bonds. The initial amount stated to be created through this method was \u00a375 billion, although Chancellor of the Exchequer Alistair Darling had given permission for up to \u00a3150 billion to be created if necessary. It was expected that the process would occur over a period of three months with results only likely in the long term. By 5 November 2009, some \u00a3175 billion had been injected using quantitative easing and the effectiveness of the process remained less successful in the long term. In July 2012, the final increase in the asset purchases finance meant QE had peaked at \u00a3375 billion, then holding solely UK Government bonds, representing one third of the UK national debt.The result of the 2016 UK referendum on EU membership caused a major decline in the pound against other world currencies as the future of international trade relationships and domestic political leadership became unclear. The referendum result weakened sterling against euro overnight by 5%. The night before the vote \u00a31 was trading for \u20ac1.30; on the day following the referendum, when the result was clear, \u00a31 was trading at \u20ac1.23. By October 2016, the exchange rate was \u20ac1.12 to the pound, a fall of 14% since the referendum. By the end of August 2017 the pound fell lower at \u20ac1.08. Against the US dollar, meanwhile, the pound fell from $1.466 to $1.3694 when the referendum result was first revealed, and down to $1.2232 by October 2016, a fall of 16%.\n\n\n=== Annual inflation rate ===\nThe Bank of England had stated (2009) that the decision had been taken to prevent the rate of inflation falling below the 2% target rate. Mervyn King, the Governor of the Bank of England, also had suggested there were no other monetary options left as interest rates had already been cut to their lowest level ever (0.5%) and it was unlikely that they would be cut further.The inflation rate per annum rose in following years, reaching 5.2% (based on the Consumer Price Index) in September 2011, then decreased to around 2.5% in the following year.\n\n\n== Coins ==\n\n\n=== Pre-decimal coins ===\nThe silver penny (plural: pence; abbreviation: d) was the principal and often the only coin in circulation from the 8th century until the 13th century. Although some fractions of the penny were struck (see farthing and halfpenny), it was more common to find pennies cut into halves and quarters to provide smaller change. Very few gold coins were struck, with the gold penny (worth 20 silver pence) a rare example. However, in 1279, the groat, worth 4d, was introduced, with the half groat following in 1344. 1344 also saw the establishment of a gold coinage with the introduction (after the failed gold florin) of the noble worth six shillings and eight pence (6/8) (i.e. 3 nobles to the pound), together with the half and quarter noble. Reforms in 1464 saw a reduction in value of the coinage in both silver and gold, with the noble renamed the ryal and worth 10/- (i.e. 2 to the pound) and the angel introduced at the noble's old value of 6/8.\nThe reign of Henry VII saw the introduction of two important coins: the shilling (abbr.: s; known as the testoon) in 1487 and the pound (known as the sovereign, abbr.: \u00a3 or L) in 1489. In 1526, several new denominations of gold coins were added, including the crown and half crown worth five shillings (5/-), and two shillings and six pence (2/6, two and six) respectively. Henry VIII's reign (1509\u20131547) saw a high level of debasement which continued into the reign of Edward VI (1547\u20131553). This debasement was halted in 1552, and a new silver coinage was introduced, including coins for 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. In the reign of Elizabeth I (1558\u20131603), silver \u200b3\u20444d and \u200b1 1\u20442d coins were added, but these denominations did not last. Gold coins included the half-crown, crown, angel, half-sovereign and sovereign. Elizabeth's reign also saw the introduction of the horse-drawn screw press to produce the first \"milled\" coins.\nFollowing the succession of the Scottish King James VI to the English throne, a new gold coinage was introduced, including the spur ryal (15/-), the unite (20/-) and the rose ryal (30/-). The laurel, worth 20/-, followed in 1619. The first base metal coins were also introduced: tin and copper farthings. Copper halfpenny coins followed in the reign of Charles I. During the English Civil War, a number of siege coinages were produced, often in unusual denominations.\nFollowing the restoration of the monarchy in 1660, the coinage was reformed, with the ending of production of hammered coins in 1662. The guinea was introduced in 1663, soon followed by the \u200b1\u20442, 2 and 5 guinea coins. The silver coinage consisted of denominations of 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. Due to the widespread export of silver in the 18th century, the production of silver coins gradually came to a halt, with the half crown and crown not issued after the 1750s, the 6d and 1/- stopping production in the 1780s. In response, copper 1d and 2d coins and a gold \u200b1\u20443 guinea (7/-) were introduced in 1797. The copper penny was the only one of these coins to survive long.\nTo alleviate the shortage of silver coins, between 1797 and 1804, the Bank of England counterstamped Spanish dollars (8 reales) and other Spanish and Spanish colonial coins for circulation. A small counterstamp of the King's head was used. Until 1800, these circulated at a rate of 4/9 for 8 reales. After 1800, a rate of 5/- for 8 reales was used. The Bank then issued silver tokens for 5/- (struck over Spanish dollars) in 1804, followed by tokens for 1/6 and 3/- between 1811 and 1816.\nIn 1816, a new silver coinage was introduced in denominations of 6d, 1/-, 2/6 (half-crown) and 5/- (crown). The crown was only issued intermittently until 1900. It was followed by a new gold coinage in 1817 consisting of 10/- and \u00a31 coins, known as the half sovereign and sovereign. The silver 4d coin was reintroduced in 1836, followed by the 3d in 1838, with the 4d coin issued only for colonial use after 1855. In 1848, the 2/- florin was introduced, followed by the short-lived double florin in 1887. In 1860, copper was replaced by bronze in the farthing (quarter penny, \u200b1\u20444d), halfpenny and penny.\nDuring the First World War, production of the sovereign and half-sovereign was suspended, and although the gold standard was later restored, the coins saw little circulation thereafter. In 1920, the silver standard, maintained at .925 since 1552, was reduced to .500. In 1937, a nickel-brass 3d coin was introduced; the last silver 3d coins were issued seven years later. In 1947, the remaining silver coins were replaced with cupro-nickel, with the exception of Maundy coinage which was then restored to .925. Inflation caused the farthing to cease production in 1956 and be demonetised in 1960. In the run-up to decimalisation, the halfpenny and half-crown were demonetised in 1969.\n\n\n=== Decimal coins ===\nBritish coinage timeline:\n\n1968: The first decimal coins were introduced. These were cupro-nickel 5p and 10p coins which were equivalent to, and circulated alongside, the one shilling coin and the two shilling or florin coin respectively.\n1969: The curved equilateral heptagonal cupro-nickel 50p coin replaced the 10/- note.\n1971: The decimal coinage was completed when decimalisation came into effect in 1971 with the introduction of the bronze \u200b1\u20442p, 1p and 2p coins and the withdrawal of the 1d and 3d coins.\n1980: Withdrawal of 6d coins, which had circulated at a value of \u200b2 1\u20442p.\n1982: The word \"new\" was dropped from the coinage and a 20p coin was introduced.\n1983: A \u00a31 coin was introduced.\n1983: The \u200b1\u20442p coin was last produced.\n1984: The \u200b1\u20442p coin was demonetised.\n1990: The crown, worth 25p, was re-tariffed for future issues as a commemorative coin at \u00a35.\n1990s: The 5p, 10p and 50p coins became smaller.\n1991: Pre-decimal 1/- coins, which had continued to circulate with a value of 5p, were demonetised in 1991 after the 5p coin became smaller. At the same time larger first generation decimal 5p coins were demonetised.\n1992: Bronze was replaced with copper-plated steel.\n1993: Pre-decimal 2/- coins, or florin, a legacy of the 1848 attempt at decimalisation were demonetised. At the same time larger first generation decimal 10p coins were demonetised.\n1998: The bi-metallic \u00a32 coin was introduced.\n2007: By now the value of copper in the pre-1992 1p and 2p coins (which are 97% copper) exceeded those coins' face value to such an extent that melting down the coins by entrepreneurs was becoming worthwhile (with a premium of up to 11%, with smelting costs reducing this to around 4%)\u2014although this is illegal, and the market value of copper has subsequently fallen dramatically from these earlier peaks.\nIn April 2008, an extensive redesign of the coinage was unveiled. The 1p, 2p, 5p, 10p, 20p and 50p coins feature parts of the Royal Shield on their reverse; and the reverse of the pound coin showed the whole shield. The coins were issued gradually into circulation, starting in mid-2008. They have the same sizes, shapes and weights as those with the old designs which, apart from the round pound coin which was withdrawn in 2017, continue to circulate.\n2012: The 5p and 10p coins were changed from cupro-nickel to nickel-plated steel.\n2017: A more secure twelve-sided \u00a31 coin was introduced to reduce forgery. The old round \u00a31 coin ceased to be legal tender on 15 October 2017.At present, the oldest circulating coins in the UK are the 1p and 2p copper coins introduced in 1971. No other coins from before 1982 are in circulation. Prior to the demonetisation of the larger 10p in 1993, the oldest circulating coins had usually dated from 1947: although older coins (shilling; florin, sixpence to 1980) were still legal tender, inflation meant that their silver content was worth more than their face value, which meant that they tended to be removed from circulation. Before decimalisation in 1971, a handful of change might have contained coins 100 or more years old, bearing any of five monarchs' heads, especially in the copper coins.\n\n\n== Banknotes ==\n\nThe first sterling notes were issued by the Bank of England shortly after its foundation in 1694. Denominations were initially handwritten on the notes at the time of issue. From 1745, the notes were printed in denominations between \u00a320 and \u00a31000, with any odd shillings added by hand. \u00a310 notes were added in 1759, followed by \u00a35 in 1793 and \u00a31 and \u00a32 in 1797. The lowest two denominations were withdrawn after the end of the Napoleonic wars. In 1855, the notes were converted to being entirely printed, with denominations of \u00a35, \u00a310, \u00a320, \u00a350, \u00a3100, \u00a3200, \u00a3300, \u00a3500 and \u00a31000 issued.\nThe Bank of Scotland began issuing notes in 1695. Although the pound Scots was still the currency of Scotland, these notes were denominated in sterling in values up to \u00a3100. From 1727, the Royal Bank of Scotland also issued notes. Both banks issued some notes denominated in guineas as well as pounds. In the 19th century, regulations limited the smallest note issued by Scottish banks to be the \u00a31 denomination, a note not permitted in England.\nWith the extension of sterling to Ireland in 1825, the Bank of Ireland began issuing sterling notes, later followed by other Irish banks. These notes included the unusual denominations of 30/- and \u00a33. The highest denomination issued by the Irish banks was \u00a3100.\nIn 1826, banks at least 65 miles (105 km) from London were given permission to issue their own paper money. From 1844, new banks were excluded from issuing notes in England and Wales but not in Scotland and Ireland. Consequently, the number of private banknotes dwindled in England and Wales but proliferated in Scotland and Ireland. The last English private banknotes were issued in 1921.\nIn 1914, the Treasury introduced notes for 10/- and \u00a31 to replace gold coins. These circulated until 1928, when they were replaced by Bank of England notes. Irish independence reduced the number of Irish banks issuing sterling notes to five operating in Northern Ireland. The Second World War had a drastic effect on the note production of the Bank of England. Fearful of mass forgery by the Nazis (see Operation Bernhard), all notes for \u00a310 and above ceased production, leaving the bank to issue only 10/-, \u00a31 and \u00a35 notes. Scottish and Northern Irish issues were unaffected, with issues in denominations of \u00a31, \u00a35, \u00a310, \u00a320, \u00a350 and \u00a3100.\nThe Bank of England reintroduced \u00a310 notes in 1964. In 1969, the 10/- note was replaced by the 50p coin to prepare for decimalisation. \u00a320 Bank of England notes were reintroduced in 1970, followed by \u00a350 in 1981. A \u00a31 coin was introduced in 1983, and Bank of England \u00a31 notes were withdrawn in 1988. Scottish and Northern Irish banks followed, with only the Royal Bank of Scotland continuing to issue this denomination.\nUK notes include raised print (e.g. on the words \"Bank of England\"); watermarks; embedded metallic thread; holograms; and fluorescent ink visible only under UV lamps. Three printing techniques are involved: offset litho, intaglio and letterpress; and the notes incorporate a total of 85 specialized inks.The Bank of England produces notes named \"giant\" and \"titan\". A giant is a one million pound note, and a titan is a one hundred million pound bank note, of which there are about 40. Giants and titans are used only within the banking system.\n\n\n=== Polymer banknotes ===\nThe \u00a35 polymer banknote, issued by Northern Bank (now Danske Bank) in 2000, was the only polymer note in circulation until 2016, although Danske Bank also produces paper-based \u00a310, \u00a320 and \u00a350 notes. The Bank of England introduced \u00a35 polymer banknotes in September 2016, and the paper \u00a35 notes were withdrawn on 5 May 2017. This date was picked due to its short format, 5/5. A polymer \u00a310 banknote was introduced on 14 September 2017, and the paper note was withdrawn on 1 March 2018. A polymer \u00a320 banknote will be introduced in 2020.\n\n\n== Monetary policy ==\nAs the central bank of the United Kingdom which has been delegated authority by the government, the Bank of England sets the monetary policy for the British pound by controlling the amount of money in circulation.  It has a monopoly on issuance of banknotes in England and Wales, and regulates the amount of banknotes issued by seven authorized banks in Scotland and Northern Ireland.  HM Treasury has reserve powers to give orders to the committee \"if they are required in the public interest and by extreme economic circumstances\" but such orders must be endorsed by Parliament within 28 days.Unlike banknotes which have separate issuers in Scotland and Northern Ireland, all UK coins are issued by the Royal Mint, which is an independent enterprise (wholly owned by the Treasury) which also mints coins for other countries.\nIn Britain's Crown Dependencies, the Manx pound, Jersey pound, and Guernsey pound are unregulated by the Bank of England and are issued independently.  However, they are maintained at a fixed exchange rate by their respective governments, and Bank of England notes have been made legal tender on the islands, forming a sort of one-way de facto currency union.  These currencies do not have ISO 4217 codes so \"GBP\" is usually used to represent all of them; informal codes are used where the difference is important.\nBritish Overseas Territories are responsible for the monetary policy of their own currencies (where they exist), and have their own ISO 4217 codes.  The Falkland Islands pound, Gibraltar pound, and Saint Helena pound are set at a fixed 1:1 exchange rate with the British pound by local governments.\n\n\n== Legal tender and national issues ==\n\nLegal tender in the United Kingdom is defined such that \"a debtor cannot successfully be sued for non-payment if he pays into court in legal tender.\" Parties can alternatively settle a debt by other means with mutual consent. Strictly speaking it is necessary for the debtor to offer the exact amount due as there is no obligation for the other party to provide change.Throughout the UK, \u00a31 and \u00a32 coins are legal tender for any amount, with the other coins being legal tender only for limited amounts. Bank of England notes are legal tender for any amount in England and Wales, but not in Scotland or Northern Ireland. (Bank of England 10/- and \u00a31 notes were legal tender, as were Scottish banknotes, during World War II under the Currency (Defence) Act 1939, which was repealed on 1 January 1946.) Channel Islands and Isle of Man banknotes are legal tender only in their respective jurisdictions.Bank of England, Scottish, Northern Irish, Channel Islands, Isle of Man, Gibraltar, and Falkland banknotes may be offered anywhere in the UK, although there is no obligation to accept them as a means of payment, and acceptance varies. For example, merchants in England generally accept Scottish and Northern Irish bills, but some unfamiliar with them may reject them. However, Scottish and Northern Irish bills both tend to be accepted in Scotland and Northern Ireland, respectively. Merchants in England generally do not accept Jersey, Guernsey, Isle of Man, Gibraltar, and Falkland notes but Isle of Man notes are generally accepted in Northern Ireland. Bank of England notes are generally accepted in the Falklands and Gibraltar, but for example Scottish and Northern Irish notes are not. Since all of the bills are denominated in pounds sterling, banks will exchange them for locally issued bills at face value, though some in the UK have had trouble exchanging Falkland Islands pounds.Commemorative \u00a35 and 25p (crown) coins, rarely seen in circulation, are legal tender, as are the bullion coins issued by the Mint.\n\n\n== Value ==\nIn 2006, the House of Commons Library published a research paper which included an index of prices in pounds for each year between 1750 and 2005, where 1974 was indexed at 100.Regarding the period 1750\u20131914 the document states: \"Although there was considerable year on year fluctuation in price levels prior to 1914 (reflecting the quality of the harvest, wars, etc.) there was not the long-term steady increase in prices associated with the period since 1945\". It goes on to say that \"Since 1945 prices have risen in every year with an aggregate rise of over 27 times\".\nThe value of the index in 1751 was 5.1, increasing to a peak of 16.3 in 1813 before declining very soon after the end of the Napoleonic Wars to around 10.0 and remaining in the range 8.5\u201310.0 at the end of the nineteenth century. The index was 9.8 in 1914 and peaked at 25.3 in 1920, before declining to 15.8 in 1933 and 1934\u2014prices were only about three times as high as they had been 180 years earlier.Inflation had a dramatic effect during and after World War II\u2014the index was 20.2 in 1940, 33.0 in 1950, 49.1 in 1960, 73.1 in 1970, 263.7 in 1980, 497.5 in 1990, 671.8 in 2000 and 757.3 in 2005.\nThe following table shows the equivalent amount of goods and services that, in a particular year, could be purchased with \u00a31.The table shows that from 1971 to 2015 the British pound lost about 92% of its buying power.\n\nThe smallest coin in 1971 was the \u200b1\u20442p, worth about 6.4p in 2015 prices.\n\n\n== Exchange rate ==\nThe pound is freely bought and sold on the foreign exchange markets around the world, and its value relative to other currencies therefore fluctuates.As of  27 August 2017, \u00a31 was worth US$1.289, \u20ac1.0808, \u00a5141, CHF 1.22329, A$1.6247, C$1.6083 or INR 82.50.\n\n\n== Reserve ==\nSterling is used as a reserve currency around the world and is currently ranked fourth in value held as reserves.\n\nCurrency composition of official foreign exchange reserves (1965\u20132017)\n\n\n== See also ==\nAngevin pound\nGreen pound\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nRoyal Mint\nCoin Types from Great Britain Lists, pictures, and values of Great Britain coin types\nBritish Coins \u2013 information about British coins (from 1656 to 1952)\nA history of sterling Daily Telegraph\nPurchasing Power of British Pounds from 1264 to 2007\nFive Ways to Compute the Relative Value of a UK Pound Amount, 1830\u2013present\nImages of historic and modern British bank notes\nCurrent wholesale exchange rates between currencies\nHistorical Currency Converter Historical value of the pound in other currencies\nThe banknotes of the United Kingdom (in English) (in German)",
        "unit": "pound sterling",
        "url": "https://en.wikipedia.org/wiki/Pound_sterling"
    },
    {
        "_id": "Radioactive_decay",
        "clean": "Radioactive decay",
        "text": "Radioactive decay (also known as nuclear decay, radioactivity or nuclear radiation) is the process by which an unstable atomic nucleus loses energy (in terms of mass in its rest frame) by emitting radiation, such as an alpha particle, beta particle with neutrino or only a neutrino in the case of electron capture, or a gamma ray or electron in the case of internal conversion. A material containing such unstable nuclei is considered radioactive. Certain highly excited short-lived nuclear states can decay through neutron emission, or more rarely, proton emission.\nRadioactive decay is a stochastic (i.e. random) process at the level of a singular quantum of single atoms, in that, according to quantum theory, it is impossible to predict when a particular atom will decay, regardless of how long the atom has existed. However, for a collection of atoms, the collection's expected decay rate is characterized in terms of their measured decay constants or half-lives. This is the basis of radiometric dating. The half-lives of radioactive atoms have no known upper limit, spanning a time range of over 55 orders of magnitude, from nearly instantaneous to far longer than the age of the universe.\nA radioactive nucleus with zero spin can have no defined orientation, and hence emits the total momentum of its decay products isotropically (all directions and without bias). If there are multiple particles produced during a single decay, as in beta decay, their relative angular distribution, or spin directions may not be isotropic. Decay products from a nucleus with spin may be distributed non-isotropically with respect to that spin direction, either because of an external influence such as an electromagnetic field, or because the nucleus was produced in a dynamic process that constrained the direction of its spin. Such a parent process could be a previous decay, or a nuclear reaction.The decaying nucleus is called the parent radionuclide (or parent radioisotope), and the process produces at least one daughter nuclide. Except for gamma decay or internal conversion from a nuclear excited state, the decay is a nuclear transmutation resulting in a daughter containing a different number of protons or neutrons (or both). When the number of protons changes, an atom of a different chemical element is created.\nThe first decay processes to be discovered were alpha decay, beta decay, and gamma decay. Alpha decay occurs when the nucleus ejects an alpha particle (helium nucleus). This is the most common process of emitting nucleons, but highly excited nuclei can eject single nucleons, or in the case of cluster decay, specific light nuclei of other elements. Beta decay occurs in two ways:\n(i) beta-minus decay, when the nucleus emits an electron and an antineutrino in a process that changes a neutron to a proton, or\n(ii) beta-plus decay, when the nucleus emits a positron and a neutrino in a process that changes a proton to a neutron. \nHighly excited neutron-rich nuclei, formed as the product of other types of decay, occasionally lose energy by way of neutron emission, resulting in a change from one isotope to another of the same element. The nucleus may capture an orbiting electron, causing a proton to convert into a neutron in a process called electron capture. All of these processes result in a well-defined nuclear transmutation.\nBy contrast, there are radioactive decay processes that do not result in a nuclear transmutation. The energy of an excited nucleus may be emitted as a gamma ray in a process called gamma decay, or that energy may be lost when the nucleus interacts with an orbital electron causing its ejection from the atom, in a process called internal conversion.\nAnother type of radioactive decay results in products that vary, appearing as two or more \"fragments\" of the original nucleus with a range of possible masses. This decay, called spontaneous fission, happens when a large unstable nucleus spontaneously splits into two (or occasionally three) smaller daughter nuclei, and generally leads to the emission of gamma rays, neutrons, or other particles from those products.\nFor a summary table showing the number of stable and radioactive nuclides in each category, see radionuclide. There are 28 naturally occurring chemical elements on Earth that are radioactive, consisting of 33 radionuclides (5 elements have 2 different radionuclides) that date before the time of formation of the solar system. These 33 are known as primordial nuclides. Well-known examples are uranium and thorium, but also included are naturally occurring long-lived radioisotopes, such as potassium-40. Another 50 or so shorter-lived radionuclides, such as radium and radon, found on Earth, are the products of decay chains that began with the primordial nuclides, or are the product of ongoing cosmogenic processes, such as the production of carbon-14 from nitrogen-14 in the atmosphere by cosmic rays. Radionuclides may also be produced artificially in particle accelerators or nuclear reactors, resulting in 650 of these with half-lives of over an hour, and several thousand more with even shorter half-lives. [See here for a list of these sorted by half life.]\n\n\n== History of discovery ==\n\nRadioactivity was discovered in 1896 by the French scientist Henri Becquerel, while working with phosphorescent materials. These materials glow in the dark after exposure to light, and he suspected that the glow produced in cathode ray tubes by X-rays might be associated with phosphorescence. He wrapped a photographic plate in black paper and placed various phosphorescent salts on it. All results were negative until he used uranium salts. The uranium salts caused a blackening of the plate in spite of the plate being wrapped in black paper. These radiations were given the name \"Becquerel Rays\".\nIt soon became clear that the blackening of the plate had nothing to do with phosphorescence, as the blackening was also produced by non-phosphorescent salts of uranium and metallic uranium. It became clear from these experiments that there was a form of invisible radiation that could pass through paper and was causing the plate to react as if exposed to light.\nAt first, it seemed as though the new radiation was similar to the then recently discovered X-rays. Further research by Becquerel, Ernest Rutherford, Paul Villard, Pierre Curie, Marie Curie, and others showed that this form of radioactivity was significantly more complicated. Rutherford was the first to realize that all such elements decay in accordance with the same mathematical exponential formula. Rutherford and his student Frederick Soddy were the first to realize that many decay processes resulted in the transmutation of one element to another. Subsequently, the radioactive displacement law of Fajans and Soddy was formulated to describe the products of alpha and beta decay.The early researchers also discovered that many other chemical elements, besides uranium, have radioactive isotopes. A systematic search for the total radioactivity in uranium ores also guided Pierre and Marie Curie to isolate two new elements: polonium and radium. Except for the radioactivity of radium, the chemical similarity of radium to barium made these two elements difficult to distinguish.\nMarie and Pierre Curie\u2019s study of radioactivity is an important factor in science and medicine. After their research on Becquerel's rays led them to the discovery of both radium and polonium, they coined the term \"radioactivity\". Their research on the penetrating rays in uranium and the discovery of radium launched an era of using radium for the treatment of cancer. Their exploration of radium could be seen as the first peaceful use of nuclear energy and the start of modern nuclear medicine.\n\n\n== Early health dangers ==\n\nThe dangers of ionizing radiation due to radioactivity and X-rays were not immediately recognized.\n\n\n=== X-rays ===\nThe discovery of x\u2011rays by Wilhelm R\u00f6ntgen in 1895 led to widespread experimentation by scientists, physicians, and inventors. Many people began recounting stories of burns, hair loss and worse in technical journals as early as 1896. In February of that year, Professor Daniel and Dr. Dudley of Vanderbilt University performed an experiment involving X-raying Dudley's head that resulted in his hair loss. A report by Dr. H.D. Hawks, of his suffering severe hand and chest burns in an X-ray demonstration, was the first of many other reports in Electrical Review.Other experimenters, including Elihu Thomson and Nikola Tesla, also reported burns. Thomson deliberately exposed a finger to an X-ray tube over a period of time and suffered pain, swelling, and blistering. Other effects, including ultraviolet rays and ozone, were sometimes blamed for the damage, and many physicians still claimed that there were no effects from X-ray exposure at all.Despite this, there were some early systematic hazard investigations, and as early as 1902 William Herbert Rollins wrote almost despairingly that his warnings about the dangers involved in the careless use of X-rays were not being heeded, either by industry or by his colleagues. By this time, Rollins had proved that X-rays could kill experimental animals, could cause a pregnant guinea pig to abort, and that they could kill a fetus. He also stressed that \"animals vary in susceptibility to the external action of X-light\" and warned that these differences be considered when patients were treated by means of X-rays.\n\n\n=== Radioactive substances ===\n\nHowever, the biological effects of radiation due to radioactive substances were less easy to gauge. This gave the opportunity for many physicians and corporations to market radioactive substances as patent medicines. Examples were radium enema treatments, and radium-containing waters to be drunk as tonics. Marie Curie protested against this sort of treatment, warning that the effects of radiation on the human body were not well understood. Curie later died from aplastic anaemia, likely caused by exposure to ionizing radiation. By the 1930s, after a number of cases of bone necrosis and death of radium treatment enthusiasts, radium-containing medicinal products had been largely removed from the market (radioactive quackery).\n\n\n=== Radiation protection ===\n\nOnly a year after R\u00f6ntgen's discovery of X rays, the American engineer Wolfram Fuchs (1896) gave what is probably the first protection advice, but it was not until 1925 that the first International Congress of Radiology (ICR) was held and considered establishing international protection standards. The effects of radiation on genes, including the effect of cancer risk, were recognized much later. In 1927, Hermann Joseph Muller published research showing genetic effects and, in 1946, was awarded the Nobel Prize in Physiology or Medicine for his findings.\nThe second ICR was held in Stockholm in 1928 and proposed the adoption of the rontgen unit, and the 'International X-ray and Radium Protection Committee' (IXRPC) was formed. Rolf Sievert was named Chairman, but a driving force was George Kaye of the British National Physical Laboratory. The committee met in 1931, 1934 and 1937.\nAfter World War II, the increased range and quantity of radioactive substances being handled as a result of military and civil nuclear programmes led to large groups of occupational workers and the public being potentially exposed to harmful levels of ionising radiation. This was considered at the first post-war ICR convened in London in 1950, when the present International Commission on Radiological Protection (ICRP) was born.\nSince then the ICRP has developed the present international system of radiation protection, covering all aspects of radiation hazard.\n\n\n== Units of radioactivity ==\n\nThe International System of Units (SI) unit of radioactive activity is the becquerel (Bq), named in honor of the scientist Henri Becquerel. One Bq is defined as one transformation (or decay or disintegration) per second.\nAn older unit of radioactivity is the curie, Ci, which was originally defined as \"the quantity or mass of radium emanation in equilibrium with one gram of radium (element)\". Today, the curie is defined as 3.7\u00d71010 disintegrations per second, so that 1 curie (Ci) = 3.7\u00d71010 Bq.\nFor radiological protection purposes, although the United States Nuclear Regulatory Commission permits the use of the unit curie alongside SI units, the European Union European units of measurement directives required that its use for \"public health ... purposes\" be phased out by 31 December 1985.The effects of ionizing radiation are often measured in units of gray for mechanical or sievert for damage to tissue.\n\n\n== Types of decay ==\n\nEarly researchers found that an electric or magnetic field could split radioactive emissions into three types of beams. The rays were given the names alpha, beta, and gamma, in increasing order of their ability to penetrate matter. Alpha decay is observed only in heavier elements of atomic number 52 (tellurium) and greater, with the exception of beryllium-8 which decays to two alpha particles. The other two types of decay are produced by all of the elements. Lead, atomic number 82, is the heaviest element to have any isotopes stable (to the limit of measurement) to radioactive decay. Radioactive decay is seen in all isotopes of all elements of atomic number 83 (bismuth) or greater. Bismuth-209, however, is only very slightly radioactive, with a half-life greater than the age of the universe; radioisotopes with extremely long half-lives are considered effectively stable for practical purposes.\n\nIn analysing the nature of the decay products, it was obvious from the direction of the electromagnetic forces applied to the radiations by external magnetic and electric fields that alpha particles carried a positive charge, beta particles carried a negative charge, and gamma rays were neutral. From the magnitude of deflection, it was clear that alpha particles were much more massive than beta particles. Passing alpha particles through a very thin glass window and trapping them in a discharge tube allowed researchers to study the emission spectrum of the captured particles, and ultimately proved that alpha particles are helium nuclei. Other experiments showed beta radiation, resulting from decay and cathode rays, were high-speed electrons. Likewise, gamma radiation and X-rays were found to be high-energy electromagnetic radiation.\nThe relationship between the types of decays also began to be examined: For example, gamma decay was almost always found to be associated with other types of decay, and occurred at about the same time, or afterwards. Gamma decay as a separate phenomenon, with its own half-life (now termed isomeric transition), was found in natural radioactivity to be a result of the gamma decay of excited metastable nuclear isomers, which were in turn created from other types of decay.\nAlthough alpha, beta, and gamma radiations were most commonly found, other types of emission were eventually discovered. Shortly after the discovery of the positron in cosmic ray products, it was realized that the same process that operates in classical beta decay can also produce positrons (positron emission), along with neutrinos (classical beta decay produces antineutrinos). In a more common analogous process, called electron capture, some proton-rich nuclides were found to capture their own atomic electrons instead of emitting positrons, and subsequently these nuclides emit only a neutrino and a gamma ray from the excited nucleus (and often also Auger electrons and characteristic X-rays, as a result of the re-ordering of electrons to fill the place of the missing captured electron). These types of decay involve the nuclear capture of electrons or emission of electrons or positrons, and thus acts to move a nucleus toward the ratio of neutrons to protons that has the least energy for a given total number of nucleons. This consequently produces a more stable (lower energy) nucleus.\n(A theoretical process of positron capture, analogous to electron capture, is possible in antimatter atoms, but has not been observed, as complex antimatter atoms beyond antihelium are not experimentally available. Such a decay would require antimatter atoms at least as complex as beryllium-7, which is the lightest known isotope of normal matter to undergo decay by electron capture.)\nShortly after the discovery of the neutron in 1932, Enrico Fermi realized that certain rare beta-decay reactions immediately yield neutrons as a decay particle (neutron emission). Isolated proton emission was eventually observed in some elements. It was also found that some heavy elements may undergo spontaneous fission into products that vary in composition. In a phenomenon called cluster decay, specific combinations of neutrons and protons other than alpha particles (helium nuclei) were found to be spontaneously emitted from atoms.\nOther types of radioactive decay were found to emit previously-seen particles, but via different mechanisms. An example is internal conversion, which results in an initial electron emission, and then often further characteristic X-rays and Auger electrons emissions, although the internal conversion process involves neither beta nor gamma decay. A neutrino is not emitted, and none of the electron(s) and photon(s) emitted originate in the nucleus, even though the energy to emit all of them does originate there. Internal conversion decay, like isomeric transition gamma decay and neutron emission, involves the release of energy by an excited nuclide, without the transmutation of one element into another.\nRare events that involve a combination of two beta-decay type events happening simultaneously are known (see below). Any decay process that does not violate the conservation of energy or momentum laws (and perhaps other particle conservation laws) is permitted to happen, although not all have been detected. An interesting example discussed in a final section, is bound state beta decay of rhenium-187. In this process, beta electron-decay of the parent nuclide is not accompanied by beta electron emission, because the beta particle has been captured into the K-shell of the emitting atom. An antineutrino is emitted, as in all negative beta decays.\nRadionuclides can undergo a number of different reactions. These are summarized in the following table. A nucleus with mass number A and atomic number Z is represented as (A, Z). The column \"Daughter nucleus\" indicates the difference between the new nucleus and the original nucleus. Thus, (A \u2212 1, Z) means that the mass number is one less than before, but the atomic number is the same as before.\nIf energy circumstances are favorable, a given radionuclide may undergo many competing types of decay, with some atoms decaying by one route, and others decaying by another. An example is copper-64, which has 29 protons, and 35 neutrons, which decays with a half-life of about 12.7 hours. This isotope has one unpaired proton and one unpaired neutron, so either the proton or the neutron can decay to the opposite particle. This particular nuclide (though not all nuclides in this situation) is almost equally likely to decay through positron emission (18%), or through electron capture (43%), as it does through electron emission (39%). The excited energy states resulting from these decays which fail to end in a ground energy state, also produce later internal conversion and gamma decay in almost 0.5% of the time.\nMore common in heavy nuclides is competition between alpha and beta decay. The daughter nuclides will then normally decay through beta or alpha, respectively, to end up in the same place.\n\nRadioactive decay results in a reduction of summed rest mass, once the released energy (the disintegration energy) has escaped in some way. Although decay energy is sometimes defined as associated with the difference between the mass of the parent nuclide products and the mass of the decay products, this is true only of rest mass measurements, where some energy has been removed from the product system. This is true because the decay energy must always carry mass with it, wherever it appears (see mass in special relativity) according to the formula E = mc2. The decay energy is initially released as the energy of emitted photons plus the kinetic energy of massive emitted particles (that is, particles that have rest mass). If these particles come to thermal equilibrium with their surroundings and photons are absorbed, then the decay energy is transformed to thermal energy, which retains its mass.\nDecay energy therefore remains associated with a certain measure of mass of the decay system, called invariant mass, which does not change during the decay, even though the energy of decay is distributed among decay particles. The energy of photons, the kinetic energy of emitted particles, and, later, the thermal energy of the surrounding matter, all contribute to the invariant mass of the system. Thus, while the sum of the rest masses of the particles is not conserved in radioactive decay, the system mass and system invariant mass (and also the system total energy) is conserved throughout any decay process. This is a restatement of the equivalent laws of conservation of energy and conservation of mass.\n\n\n== Radioactive decay rates ==\nThe decay rate, or activity, of a radioactive substance is characterized by:\nConstant quantities:\n\nThe half-life\u2014t1/2, is the time taken for the activity of a given amount of a radioactive substance to decay to half of its initial value; see List of nuclides.\nThe decay constant\u2014 \u03bb, \"lambda\" the reciprocal of the mean lifetime, sometimes referred to as simply decay rate.\nThe mean lifetime\u2014 \u03c4, \"tau\" the average lifetime (1/e life) of a radioactive particle before decay.Although these are constants, they are associated with the statistical behavior of populations of atoms. In consequence, predictions using these constants are less accurate for minuscule samples of atoms.\nIn principle a half-life, a third-life, or even a (1/\u221a2)-life, can be used in exactly the same way as half-life; but the mean life and half-life t1/2 have been adopted as standard times associated with exponential decay.\nTime-variable quantities:\n\nTotal activity\u2014 A, is the number of decays per unit time of a radioactive sample.\nNumber of particles\u2014N, is the total number of particles in the sample.\nSpecific activity\u2014SA, number of decays per unit time per amount of substance of the sample at time set to zero (t = 0). \"Amount of substance\" can be the mass, volume or moles of the initial sample.These are related as follows:\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              (\n              2\n              )\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        (\n        2\n        )\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln(2)}{\\lambda }}=\\tau \\ln(2)}\n  \n\n  \n    \n      \n        A\n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03bb\n        N\n      \n    \n    {\\displaystyle A=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}=\\lambda N}\n  \n\n  \n    \n      \n        \n          S\n          \n            A\n          \n        \n        \n          a\n          \n            0\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \n            \n              |\n            \n          \n          \n            t\n            =\n            0\n          \n        \n        =\n        \u03bb\n        \n          N\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle S_{A}a_{0}=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}{\\bigg |}_{t=0}=\\lambda N_{0}}\n  where N0 is the initial amount of active substance \u2014 substance that has the same percentage of unstable particles as when the substance was formed.\n\n\n== Mathematics of radioactive decay ==\n\n\n=== Universal law of radioactive decay ===\nRadioactivity is one very frequently given example of exponential decay. The law describes the statistical behaviour of a large number of nuclides, rather than individual atoms. In the following formalism, the number of nuclides or the nuclide population N, is of course a discrete variable (a natural number)\u2014but for any physical sample N is so large that it can be treated as a continuous variable. Differential calculus is used to model the behaviour of nuclear decay.\nThe mathematics of radioactive decay depend on a key assumption that a nucleus of a radionuclide has no \"memory\" or way of translating its history into its present behavior. A nucleus does not \"age\" with the passage of time. Thus, the probability of its breaking down does not increase with time, but stays constant no matter how long the nucleus has existed. This constant probability may vary greatly between different types of nuclei, leading to the many different observed decay rates. However, whatever the probability is, it does not change. This is in marked contrast to complex objects which do show aging, such as automobiles and humans. These systems do have a chance of breakdown per unit of time, that increases from the moment they begin their existence.\n\n\n==== One-decay process ====\nConsider the case of a nuclide A that decays into another B by some process A \u2192 B (emission of other particles, like electron neutrinos \u03bde and electrons e\u2212 as in beta decay, are irrelevant in what follows). The decay of an unstable nucleus is entirely random in time so it is impossible to predict when a particular atom will decay. However, it is equally likely to decay at any instant in time. Therefore, given a sample of a particular radioisotope, the number of decay events \u2212dN expected to occur in a small interval of time dt is proportional to the number of atoms present N, that is\n\n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u221d\n        N\n        .\n      \n    \n    {\\displaystyle -{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}\\propto N.}\n  Particular radionuclides decay at different rates, so each has its own decay constant \u03bb. The expected decay \u2212dN/N is proportional to an increment of time, dt:\n\nThe negative sign indicates that N decreases as time increases, as the decay events follow one after another. The solution to this first-order differential equation is the function:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  where N0 is the value of N at time t = 0, with the decay constant expressed as \u03bb or 1/\u03c4We have for all time t:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            \n              t\n              o\n              t\n              a\n              l\n            \n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle N_{A}+N_{B}=N_{\\mathrm {total} }=N_{A0},}\n  where Ntotal is the constant number of particles throughout the decay process, which is equal to the initial number of A nuclides since this is the initial substance.\nIf the number of non-decayed A nuclei is:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        \n        \n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-{\\lambda }t}\\,\\!}\n  then the number of nuclei of B, i.e. the number of decayed A nuclei, is\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}=N_{A0}-N_{A}=N_{A0}-N_{A0}e^{-{\\lambda }t}=N_{A0}\\left(1-e^{-{\\lambda }t}\\right).}\n  The number of decays observed over a given interval obeys Poisson statistics. If the average number of decays is <N>, the probability of a given number of decays N is\n\n  \n    \n      \n        P\n        (\n        N\n        )\n        =\n        \n          \n            \n              \u27e8\n              N\n              \n                \u27e9\n                \n                  N\n                \n              \n              exp\n              \u2061\n              (\n              \u2212\n              \u27e8\n              N\n              \u27e9\n              )\n            \n            \n              N\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P(N)={\\frac {\\langle N\\rangle ^{N}\\exp(-\\langle N\\rangle )}{N!}}.}\n  \n\n\n==== Chain-decay processes ====\nChain of two decays\nNow consider the case of a chain of two decays: one nuclide A decaying into another B by one process, then B decaying into another C by a second process, i.e. A \u2192 B \u2192 C. The previous equation cannot be applied to the decay chain, but can be generalized as follows. Since A decays into B, then B decays into C, the activity of A adds to the total number of B nuclides in the present sample, before those B nuclides decay and reduce the number of nuclides leading to the later sample. In other words, the number of second generation nuclei B increases as a result of the first generation nuclei decay of A, and decreases as a result of its own decay into the third generation nuclei C. The sum of these two terms gives the law for a decay chain for two nuclides:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            B\n          \n        \n        \n          N\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            A\n          \n        \n        \n          N\n          \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}=-\\lambda _{B}N_{B}+\\lambda _{A}N_{A}.}\n  The rate of change of NB, that is dNB/dt, is related to the changes in the amounts of A and B, NB can increase as B is produced from A and decrease as B produces C.\nRe-writing using the previous results:\n\nThe subscripts simply refer to the respective nuclides, i.e. NA is the number of nuclides of type A, NA0 is the initial number of nuclides of type A, \u03bbA is the decay constant for A - and similarly for nuclide B. Solving this equation for NB gives:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              \n                \u03bb\n                \n                  B\n                \n              \n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    B\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}={\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right).}\n  In the case where B is a stable nuclide (\u03bbB = 0), this equation reduces to the previous solution:\n\n  \n    \n      \n        \n          lim\n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u2192\n            0\n          \n        \n        \n          [\n          \n            \n              \n                \n                  \n                    N\n                    \n                      A\n                      0\n                    \n                  \n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n                \n                  \n                    \u03bb\n                    \n                      B\n                    \n                  \n                  \u2212\n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n              \n            \n            \n              (\n              \n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        A\n                      \n                    \n                    t\n                  \n                \n                \u2212\n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    t\n                  \n                \n              \n              )\n            \n          \n          ]\n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              0\n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            1\n          \n          )\n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\lim _{\\lambda _{B}\\rightarrow 0}\\left[{\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right)\\right]={\\frac {N_{A0}\\lambda _{A}}{0-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-1\\right)=N_{A0}\\left(1-e^{-\\lambda _{A}t}\\right),}\n  as shown above for one decay. The solution can be found by the integration factor method, where the integrating factor is e\u03bbBt. This case is perhaps the most useful, since it can derive both the one-decay equation (above) and the equation for multi-decay chains (below) more directly.\nChain of any number of decays\nFor the general case of any number of consecutive decays in a decay chain, i.e. A1 \u2192 A2 \u00b7\u00b7\u00b7 \u2192 Ai \u00b7\u00b7\u00b7 \u2192 AD, where D is the number of decays and i is a dummy index (i = 1, 2, 3, ...D), each nuclide population can be found in terms of the previous population. In this case N2 = 0, N3 = 0,..., ND = 0. Using the above result in a recursive form:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  j\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            j\n          \n        \n        \n          N\n          \n            j\n          \n        \n        +\n        \n          \u03bb\n          \n            j\n            \u2212\n            1\n          \n        \n        \n          N\n          \n            (\n            j\n            \u2212\n            1\n            )\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n              \n                j\n                \u2212\n                1\n              \n            \n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{j}}{\\mathrm {d} t}}=-\\lambda _{j}N_{j}+\\lambda _{j-1}N_{(j-1)0}e^{-\\lambda _{j-1}t}.}\n  The general solution to the recursive problem is given by Bateman's equations:\n\n\n==== Alternative decay modes ====\nIn all of the above examples, the initial nuclide decays into just one product. Consider the case of one initial nuclide that can decay into either of two products, that is A \u2192 B and A \u2192 C in parallel. For example, in a sample of potassium-40, 89.3% of the nuclei decay to calcium-40 and 10.7% to argon-40. We have for all time t:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        +\n        \n          N\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle N=N_{A}+N_{B}+N_{C}}\n  which is constant, since the total number of nuclides remains constant. Differentiating with respect to time:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        N\n                        \n                          A\n                        \n                      \n                    \n                    \n                      \n                        d\n                      \n                      t\n                    \n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  (\n                  \n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              B\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                    +\n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              C\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n            \n              \n                \u2212\n                \u03bb\n                \n                  N\n                  \n                    A\n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  N\n                  \n                    A\n                  \n                \n                \n                  (\n                  \n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    +\n                    \n                      \u03bb\n                      \n                        C\n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}&=-\\left({\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}\\right)\\\\-\\lambda N_{A}&=-N_{A}\\left(\\lambda _{B}+\\lambda _{C}\\right)\\\\\\end{aligned}}}\n  defining the total decay constant \u03bb in terms of the sum of partial decay constants \u03bbB and \u03bbC:\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        .\n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}.}\n  Notice that \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  A\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        <\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  C\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0.\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}<0,{\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}>0,{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}>0.}\n  Solving this equation for NA:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \u03bb\n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-\\lambda t}.}\n  where NA0 is the initial number of nuclide A. When measuring the production of one nuclide, one can only observe the total decay constant \u03bb. The decay constants \u03bbB and \u03bbC determine the probability for the decay to result in products B or C as follows:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle N_{B}={\\frac {\\lambda _{B}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right),}\n  \n  \n    \n      \n        \n          N\n          \n            C\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                C\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{C}={\\frac {\\lambda _{C}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right).}\n  because the fraction \u03bbB/\u03bb of nuclei decay into B while the fraction \u03bbC/\u03bb of nuclei decay into C.\n\n\n=== Corollaries of the decay laws ===\nThe above equations can also be written using quantities related to the number of nuclide particles N in a sample;\n\nThe activity: A = \u03bbN.\nThe amount of substance: n = N/L.\nThe mass: M = Arn = ArN/L.where L = 6.022\u00d71023 is Avogadro's constant, Ar is the relative atomic mass number, and the amount of the substance is in moles.\n\n\n=== Decay timing: definitions and relations ===\n\n\n==== Time constant and mean-life ====\nFor the one-decay solution A \u2192 B:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the equation indicates that the decay constant \u03bb has units of t\u22121, and can thus also be represented as 1/\u03c4, where \u03c4 is a characteristic time of the process called the time constant.\nIn a radioactive decay process, this time constant is also the mean lifetime for decaying atoms. Each atom \"lives\" for a finite amount of time before it decays, and it may be shown that this mean lifetime is the arithmetic mean of all the atoms' lifetimes, and that it is \u03c4, which again is related to the decay constant as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            1\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau ={\\frac {1}{\\lambda }}.}\n  This form is also true for two-decay processes simultaneously A \u2192 B + C, inserting the equivalent values of decay constants (as given above)\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        \n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}\\,}\n  into the decay solution leads to:\n\n  \n    \n      \n        \n          \n            1\n            \u03c4\n          \n        \n        =\n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        =\n        \n          \n            1\n            \n              \u03c4\n              \n                B\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              \u03c4\n              \n                C\n              \n            \n          \n        \n        \n      \n    \n    {\\displaystyle {\\frac {1}{\\tau }}=\\lambda =\\lambda _{B}+\\lambda _{C}={\\frac {1}{\\tau _{B}}}+{\\frac {1}{\\tau _{C}}}\\,}\n  \n\n\n==== Half-life ====\nA more commonly used parameter is the half-life. Given a sample of a particular radionuclide, the half-life is the time taken for half the radionuclide's atoms to decay. For the case of one-decay nuclear reactions:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the half-life is related to the decay constant as follows: set N = N0/2 and t = T1/2 to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              2\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        2.\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln 2}{\\lambda }}=\\tau \\ln 2.}\n  This relationship between the half-life and the decay constant shows that highly radioactive substances are quickly spent, while those that radiate weakly endure longer. Half-lives of known radionuclides vary widely, from more than 1019 years, such as for the very nearly stable nuclide 209Bi, to 10\u221223 seconds for highly unstable ones.\nThe factor of ln(2) in the above relations results from the fact that the concept of \"half-life\" is merely a way of selecting a different base other than the natural base e for the lifetime expression. The time constant \u03c4 is the e -1 -life, the time until only 1/e remains, about 36.8%, rather than the 50% in the half-life of a radionuclide. Thus, \u03c4 is longer than t1/2. The following equation can be shown to be valid:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          2\n          \n            \u2212\n            t\n            \n              /\n            \n            \n              t\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        .\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-t/\\tau }=N_{0}\\,2^{-t/t_{1/2}}.\\,\\!}\n  Since radioactive decay is exponential with a constant probability, each process could as easily be described with a different constant time period that (for example) gave its \"(1/3)-life\" (how long until only 1/3 is left) or \"(1/10)-life\" (a time period until only 10% is left), and so on. Thus, the choice of \u03c4 and t1/2 for marker-times, are only for convenience, and from convention. They reflect a fundamental principle only in so much as they show that the same proportion of a given radioactive substance will decay, during any time-period that one chooses.\nMathematically, the nth life for the above situation would be found in the same way as above\u2014by setting N = N0/n, t = T1/n and substituting into the decay solution to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            n\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              n\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        n\n        .\n      \n    \n    {\\displaystyle t_{1/n}={\\frac {\\ln n}{\\lambda }}=\\tau \\ln n.}\n  \n\n\n=== Example ===\nA sample of 14C has a half-life of 5,730 years and a decay rate of 14 disintegration per minute (dpm) per gram of natural carbon.\nIf an artifact is found to have radioactivity of 4 dpm per gram of its present C, we can find the approximate age of the object using the above equation:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-t/\\tau },}\n  where: \n  \n    \n      \n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        =\n        4\n        \n          /\n        \n        14\n        \u2248\n        0.286\n        ,\n      \n    \n    {\\displaystyle {\\frac {N}{N_{0}}}=4/14\\approx 0.286,}\n  \n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            \n              T\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n            \n              ln\n              \u2061\n              2\n            \n          \n        \n        \u2248\n        8267\n      \n    \n    {\\displaystyle \\tau ={\\frac {T_{1/2}}{\\ln 2}}\\approx 8267}\n   years,\n\n  \n    \n      \n        t\n        =\n        \u2212\n        \u03c4\n        \n        ln\n        \u2061\n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        \u2248\n        10356\n      \n    \n    {\\displaystyle t=-\\tau \\,\\ln {\\frac {N}{N_{0}}}\\approx 10356}\n   years.\n\n\n== Changing decay rates ==\nThe radioactive decay modes of electron capture and internal conversion are known to be slightly sensitive to chemical and environmental effects that change the electronic structure of the atom, which in turn affects the presence of 1s and 2s electrons that participate in the decay process. A small number of mostly light nuclides are affected. For example, chemical bonds can affect the rate of electron capture to a small degree (in general, less than 1%) depending on the proximity of electrons to the nucleus. In 7Be, a difference of 0.9% has been observed between half-lives in metallic and insulating environments. This relatively large effect is because beryllium is a small atom whose valence electrons are in 2s atomic orbitals, which are subject to electron capture in 7Be because (like all s atomic orbitals in all atoms) they naturally penetrate into the nucleus.\nIn 1992, Jung et al. of the Darmstadt Heavy-Ion Research group observed an accelerated \u03b2\u2212 decay of 163Dy66+. Although neutral 163Dy is a stable isotope, the fully ionized 163Dy66+ undergoes \u03b2\u2212 decay into the K and L shells to 163Ho66+ with a half-life of 47 days.Rhenium-187 is another spectacular example. 187Re normally beta decays to 187Os with a half-life of 41.6 \u00d7 109 years, but studies using fully ionised 187Re atoms (bare nuclei) have found that this can decrease to only 33 years. This is attributed to \"bound-state \u03b2\u2212 decay\" of the fully ionised atom \u2013 the electron is emitted into the \"K-shell\" (1s atomic orbital), which cannot occur for neutral atoms in which all low-lying bound states are occupied.\n\nA number of experiments have found that decay rates of other modes of artificial and naturally occurring radioisotopes are, to a high degree of precision, unaffected by external conditions such as temperature, pressure, the chemical environment, and electric, magnetic, or gravitational fields. Comparison of laboratory experiments over the last century, studies of the Oklo natural nuclear reactor (which exemplified the effects of thermal neutrons on nuclear decay), and astrophysical observations of the luminosity decays of distant supernovae (which occurred far away so the light has taken a great deal of time to reach us), for example, strongly indicate that unperturbed decay rates have been constant (at least to within the limitations of small experimental errors) as a function of time as well.Recent results suggest the possibility that decay rates might have a weak dependence on environmental factors. It has been suggested that measurements of decay rates of silicon-32, manganese-54, and radium-226 exhibit small seasonal variations (of the order of 0.1%).  However, such measurements are highly susceptible to systematic errors, and a subsequent paper has found no evidence for such correlations in seven other isotopes (22Na, 44Ti, 108Ag, 121Sn, 133Ba, 241Am, 238Pu), and sets upper limits on the size of any such effects. The decay of radon-222 was once reported to exhibit large 4% peak-to-peak seasonal variations (see plot),  which were proposed to be related to either solar flare activity or the distance from the Sun, but detailed analysis of the experiment's design flaws, along with comparisons to other, much more stringent and systematically controlled, experiments refute this claim.\n\n\n=== GSI anomaly ===\n\nAn unexpected series of experimental results for the rate of decay of heavy highly charged radioactive ions circulating in a storage ring has provoked theoretical activity in an effort to find a convincing explanation. The rates of weak decay of two radioactive species with half lives of about 40 s and 200 s are found to have a significant oscillatory modulation, with a period of about 7 s.\nThe observed phenomenon is known as the GSI anomaly, as the storage ring is a facility at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany.  As the decay process produces an electron neutrino, some of the proposed explanations for the observed rate oscillation invoke neutrino properties. Initial ideas related to flavour oscillation met with skepticism.  A more recent proposal involves mass differences between neutrino mass eigenstates.\n\n\n== Theoretical basis of decay phenomena ==\nThe neutrons and protons that constitute nuclei, as well as other particles that approach close enough to them, are governed by several interactions. The strong nuclear force, not observed at the familiar macroscopic scale, is the most powerful force over subatomic distances. The electrostatic force is almost always significant, and, in the case of beta decay, the weak nuclear force is also involved.\nThe combined effects of these forces produces a number of different phenomena in which energy may be released by rearrangement of particles in the nucleus, or else the change of one type of particle into others. These rearrangements and transformations may be hindered energetically, so that they do not occur immediately. In certain cases, random quantum vacuum fluctuations are theorized to promote relaxation to a lower energy state (the \"decay\") in a phenomenon known as quantum tunneling. Radioactive decay half-life of nuclides has been measured over timescales of 55 orders of magnitude, from 2.3 \u00d7 10\u221223 seconds (for hydrogen-7) to 6.9 \u00d7 1031 seconds (for tellurium-128). The limits of these timescales are set by the sensitivity of instrumentation only, and there are no known natural limits to how brief or long a decay half-life for radioactive decay of a radionuclide may be.\nThe decay process, like all hindered energy transformations, may be analogized by a snowfield on a mountain. While friction between the ice crystals may be supporting the snow's weight, the system is inherently unstable with regard to a state of lower potential energy. A disturbance would thus facilitate the path to a state of greater entropy; the system will move towards the ground state, producing heat, and the total energy will be distributable over a larger number of quantum states thus resulting in an avalanche. The total energy does not change in this process, but, because of the second law of thermodynamics, avalanches have only been observed in one direction and that is toward the \"ground state\" \u2014 the state with the largest number of ways in which the available energy could be distributed.\nSuch a collapse (a gamma-ray decay event) requires a specific activation energy. For a snow avalanche, this energy comes as a disturbance from outside the system, although such disturbances can be arbitrarily small. In the case of an excited atomic nucleus decaying by gamma radiation in a spontaneous emission of electromagnetic radiation, the arbitrarily small disturbance comes from quantum vacuum fluctuations.A radioactive nucleus (or any excited system in quantum mechanics) is unstable, and can, thus, spontaneously stabilize to a less-excited system. The resulting transformation alters the structure of the nucleus and results in the emission of either a photon or a high-velocity particle that has mass (such as an electron, alpha particle, or other type).\n\n\n== Occurrence and applications ==\nAccording to the Big Bang theory, stable isotopes of the lightest five elements (H, He, and traces of Li, Be, and B) were produced very shortly after the emergence of the universe, in a process called Big Bang nucleosynthesis. These lightest stable nuclides (including deuterium) survive to today, but any radioactive isotopes of the light elements produced in the Big Bang (such as tritium) have long since decayed. Isotopes of elements heavier than boron were not produced at all in the Big Bang, and these first five elements do not have any long-lived radioisotopes. Thus, all radioactive nuclei are, therefore, relatively young with respect to the birth of the universe, having formed later in various other types of nucleosynthesis in stars (in particular, supernovae), and also during ongoing interactions between stable isotopes and energetic particles. For example, carbon-14, a radioactive nuclide with a half-life of only 5,730 years, is constantly produced in Earth's upper atmosphere due to interactions between cosmic rays and nitrogen.\nNuclides that are produced by radioactive decay are called radiogenic nuclides, whether they themselves are stable or not. There exist stable radiogenic nuclides that were formed from short-lived extinct radionuclides in the early solar system. The extra presence of these stable radiogenic nuclides (such as Xe-129 from primordial I-129) against the background of primordial stable nuclides can be inferred by various means.\nRadioactive decay has been put to use in the technique of radioisotopic labeling, which is used to track the passage of a chemical substance through a complex system (such as a living organism). A sample of the substance is synthesized with a high concentration of unstable atoms. The presence of the substance in one or another part of the system is determined by detecting the locations of decay events.\nOn the premise that radioactive decay is truly random (rather than merely chaotic), it has been used in hardware random-number generators. Because the process is not thought to vary significantly in mechanism over time, it is also a valuable tool in estimating the absolute ages of certain materials. For geological materials, the radioisotopes and some of their decay products become trapped when a rock solidifies, and can then later be used (subject to many well-known qualifications) to estimate the date of the solidification. These include checking the results of several simultaneous processes and their products against each other, within the same sample. In a similar fashion, and also subject to qualification, the rate of formation of carbon-14 in various eras, the date of formation of organic matter within a certain period related to the isotope's half-life may be estimated, because the carbon-14 becomes trapped when the organic matter grows and incorporates the new carbon-14 from the air. Thereafter, the amount of carbon-14 in organic matter decreases according to decay processes that may also be independently cross-checked by other means (such as checking the carbon-14 in individual tree rings, for example).\n\n\n=== Szilard\u2013Chalmers effect ===\nThe Szilard\u2013Chalmers effect is defined as the breaking of a chemical bond between an atom and the molecule that the atom is part of, as a result of a nuclear reaction of the atom. The effect can be used to separate isotopes by chemical means. The discovery of this effect is due to L. Szil\u00e1rd and T.A. Chalmers.\n\n\n== Origins of radioactive nuclides ==\n\nRadioactive primordial nuclides found in the Earth are residues from ancient supernova explosions that occurred before the formation of the solar system. They are the fraction of radionuclides that survived from that time, through the formation of the primordial solar nebula, through planet accretion, and up to the present time. The naturally occurring short-lived radiogenic radionuclides found in today's rocks, are the daughters of those radioactive primordial nuclides. Another minor source of naturally occurring radioactive nuclides are cosmogenic nuclides, that are formed by cosmic ray bombardment of material in the Earth's atmosphere or crust. The decay of the radionuclides in rocks of the Earth's mantle and crust contribute significantly to Earth's internal heat budget.\n\n\n== Decay chains and multiple modes ==\n\nThe daughter nuclide of a decay event may also be unstable (radioactive). In this case, it too will decay, producing radiation. The resulting second daughter nuclide may also be radioactive. This can lead to a sequence of several decay events called a decay chain (see this article for specific details of important natural decay chains). Eventually, a stable nuclide is produced.\n\nAn example is the natural decay chain of 238U:\n\nUranium-238 decays, through alpha-emission, with a half-life of 4.5 billion years to thorium-234\nwhich decays, through beta-emission, with a half-life of 24 days to protactinium-234\nwhich decays, through beta-emission, with a half-life of 1.2 minutes to uranium-234\nwhich decays, through alpha-emission, with a half-life of 240 thousand years to thorium-230\nwhich decays, through alpha-emission, with a half-life of 77 thousand years to radium-226\nwhich decays, through alpha-emission, with a half-life of 1.6 thousand years to radon-222\nwhich decays, through alpha-emission, with a half-life of 3.8 days to polonium-218\nwhich decays, through alpha-emission, with a half-life of 3.1 minutes to lead-214\nwhich decays, through beta-emission, with a half-life of 27 minutes to bismuth-214\nwhich decays, through beta-emission, with a half-life of 20 minutes to polonium-214\nwhich decays, through alpha-emission, with a half-life of 160 microseconds to lead-210\nwhich decays, through beta-emission, with a half-life of 22 years to bismuth-210\nwhich decays, through beta-emission, with a half-life of 5 days to polonium-210\nwhich decays, through alpha-emission, with a half-life of 140 days to lead-206, which is a stable nuclide.Some radionuclides may have several different paths of decay. For example, approximately 36% of bismuth-212 decays, through alpha-emission, to thallium-208 while approximately 64% of bismuth-212 decays, through beta-emission, to polonium-212. Both thallium-208 and polonium-212 are radioactive daughter products of bismuth-212, and both decay directly to stable lead-208.\n\n\n== Associated hazard warning signs ==\n\n\t\t\n\t\t\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Inline ===\n\n\n=== General ===\n\"Radioactivity\", Encyclop\u00e6dia Britannica. 2006. Encyclop\u00e6dia Britannica Online. December 18, 2006\nRadio-activity by Ernest Rutherford Phd, Encyclop\u00e6dia Britannica Eleventh Edition\n\n\n== External links ==\nThe Lund/LBNL Nuclear Data Search \u2013 Contains tabulated information on radioactive decay types and energies.\nNomenclature of nuclear chemistry\nSpecific activity and related topics.\nThe Live Chart of Nuclides \u2013 IAEA\nInteractive Chart of Nuclides\nHealth Physics Society Public Education Website\n Beach, Chandler B., ed. (1914). \"Becquerel Rays\". The New Student's Reference Work. Chicago: F. E. Compton and Co. \nAnnotated bibliography for radioactivity from the Alsos Digital Library for Nuclear Issues\nStochastic Java applet on the decay of radioactive atoms by Wolfgang Bauer\nStochastic Flash simulation on the decay of radioactive atoms by David M. Harrison\n\"Henri Becquerel: The Discovery of Radioactivity\", Becquerel's 1896 articles online and analyzed on BibNum [click '\u00e0 t\u00e9l\u00e9charger' for English version].\n\"Radioactive change\", Rutherford & Soddy article (1903), online and analyzed on Bibnum [click '\u00e0 t\u00e9l\u00e9charger' for English version].",
        "unit": "radioactivity",
        "url": "https://en.wikipedia.org/wiki/Radioactive_decay"
    },
    {
        "_id": "Inch",
        "clean": "Inch",
        "text": "The inch (abbreviation: in or \u2033) is a unit of length in the (British) imperial and United States customary systems of measurement now formally equal to \u200b1\u204436 yard but usually understood as \u200b1\u204412 of a foot. Derived from the Roman uncia (\"twelfth\"), inch is also sometimes used to translate related units in other measurement systems, usually understood as deriving from the width of the human thumb. Traditional standards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s it has been based on the metric system and defined as exactly 2.54 cm.\n\n\n== Name ==\nThe English word \"inch\" (Old English: ynce) was an early borrowing from Latin uncia (\"one-twelfth; Roman inch; Roman ounce\") not present in other Germanic languages. The vowel change from Latin /u/ to Old English /y/ (which became Modern English /\u026a/) is known as umlaut. The consonant change from the Latin /k/ (spelled c) to English /t\u0283/ is palatalisation. Both were features of Old English phonology; see Phonological history of Old English \u00a7 Palatalization and Germanic umlaut \u00a7 I-mutation in Old English for more information.\n\"Inch\" is cognate with \"ounce\" (Old English: ynse), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman unce and ounce.In many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). Examples include Afrikaans: duim; Catalan: polzada (\"inch\") and polze (\"thumb\"); Czech: palec; Danish and Norwegian: tomme (\"inch\") tommel (\"thumb\"); Dutch: duim; French: pouce; Hungarian: h\u00fcvelyk; Italian: pollice; Portuguese: polegada (\"inch\") and polegar (\"thumb\"); Slovak: palec; Spanish: pulgada (\"inch\") and pulgar (\"thumb\"); and Swedish: tum (\"inch\") and tumme (\"thumb\").\n\n\n== Usage ==\nThe inch is a commonly used customary unit of length in the United States, Canada, and the United Kingdom. It is also used in Japan for electronic parts, especially display screens. In most of continental Europe, the inch is also used informally as a measure for display screens. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.The international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example, three feet two inches can be written as 3\u2032 2\u2033. (This is akin to how the first and second \"cuts\" of the hour and degree are likewise indicated by prime and double prime symbols.) Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example, two and three eighths of an inch would be written as 2 3/8\u2033 and not as 2.375\u2033 nor as 2 6/16\u2033.\n\n\n=== Equivalences ===\n1 international inch is equal to:\n\n10,000 tenths\n1,000 thou or mil\n100 points or gries\n72 PostScript points\n10, 12, 16, or 40 lines\n6 computer picas\n3 barleycorns\n2.54 centimetres exactly (1 centimetre \u2248 0.3937008 inches.)\n0.999998 US Survey inches\n1/3 or 0.333 palms\n1/4 or 0.25 hands\n1/12 or 0.08333 feet\n1/36 or 0.02777 yards\n\n\n== History ==\n\nThe earliest known reference to the inch in England is from the Laws of \u00c6thelberht dating to the early 7th century, surviving in a single manuscript, the Textus Roffensis from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc.An Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".Similar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in Ancient Laws and Institutes of Wales (vol i., pp. 184, 187, 189), are that \"three lengths of a barleycorn is the inch\".King David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.In 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and that was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclop\u00e6dia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.Before the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre = 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realization of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.In 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known.In 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951, the United States on 1 July 1959, Australia in 1961, effective 1 January 1964, and the United Kingdom in 1963, effective on 1 January 1964. The new standards gave an inch of exactly 25.4 mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\n\n\n== Related units ==\n\n\n=== US Survey inches ===\nThe United States retains the 1/39.37-metre definition for survey purposes, producing a 2 millionth part difference between standard and US survey inches. This is approximately 1/8 inch per mile. In fact, 12.7 kilometres is exactly 500,000 standard inches and exactly 499,999 survey inches. This difference is significant when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\n\n\n=== Continental inches ===\n\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French pouce measured 2.70 cm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (voet) consisted of 11 Amsterdam inches (duim). The Amsterdam foot is about 8% shorter than an English foot.\n\n\n=== Scottish inch ===\nThe now obsolete Scottish inch (Scottish Gaelic: \u00f2irleach), 1/12 of a Scottish foot, was about 1.0016 imperial inches (about 2.5441 cm). It was used in the popular expression Gie 'im an inch, an he'll tak an ell, in English \"Give him an inch and he'll take an ell\", first published as \"For when I gave you an inch, you tooke an ell\" by John Heywood in 1546. (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.) Modern versions of the saying include \"Give him an inch and he'll take a mile\" and \"Give him and inch and he'll take a yard\".\n\n\n== See also ==\nEnglish units\nSquare inch, Cubic inch, and Metric inch\nInternational yard and pound\nAnthropic units\n\"Roman inch\" (uncia) and \"French inch\" (pouce)\nPyramid inch\nDigit and Line\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Bibliography ===\nAttenborough, F. L. (1922), The Laws of the Earliest English Kings (Llanerch Press Facsimile Reprint 2000 ed.), Cambridge: Cambridge University Press, ISBN 978-1-86143-101-1, retrieved 11 July 2018 \nCollins Encyclopedia of Scotland\nWeights and Measures, by D. Richard Torrance, SAFHS, Edinburgh, 1996, ISBN 1-874722-09-9 (NB book focusses on Scottish weights and measures exclusively)\nThis article incorporates text from \"Dwelly's [Scottish] Gaelic Dictionary\" (1911).\nScottish National Dictionary and Dictionary of the Older Scottish Tongue",
        "unit": "inch",
        "url": "https://en.wikipedia.org/wiki/Inch"
    },
    {
        "_id": "Gallon",
        "clean": "Gallon",
        "text": "The gallon () is a unit of measurement for fluid capacity in both the US customary units and the British imperial systems of measurement. Three significantly different sizes are in current use: the imperial gallon defined as 4.54609 litres (4 imperial quarts or 8 imperial pints), which is used in the United Kingdom, Canada, and some Caribbean nations; the US gallon defined as 231 cubic inches (4 US liquid quarts or 8 US liquid pints) or about 3.785 L, which is used in the US and some Latin American and Caribbean countries; and the least-used US dry gallon defined as 1/8 US bushel (4.405 L).\nThe IEEE standard symbol for the gallon is gal.\n\n\n== Definitions ==\nThe gallon currently has one definition in the imperial system, and two definitions (liquid and dry) in the US customary system. Historically, there were many definitions and redefinitions.\n\n\n=== English system gallons ===\nThere were more than a few systems of liquid measurements in the pre-1884 United Kingdom.\nWinchester or Corn Gallon was 272 in3 (157 fl oz) (1697 Act 8 & 9 Will III c22)\nHenry VII (Winchester) corn gallon from 1497 onwards was 154.80 fl oz\nElizabeth I corn gallon from 1601 onwards was 155.70 fl oz\nWilliam III corn gallon from 1697 onwards was 156.90 fl oz\nOld English (Elizabethan) Ale Gallon was 282 in3 (162 fl oz) (1700 Act 11 Will III c15)\nOld English (Queen Anne) Wine Gallon was standardized as 231 in3 (133 fl oz) in the 1706 Act 5 Anne c27, but it differed before that:\nLondon 'Guildhall' gallon (before 1688) was 129.19 fl oz\nJersey gallon (from 1562 onwards) was 139.20 fl oz\nGuernsey gallon (17th century origins till 1917) was 150.14 fl oz\nIrish Gallon was 217 in3 (125 fl oz) (1495 Irish Act 10 Hen VII c22 confirmed by 1736 Act Geo II c9)\n\n\n=== Imperial gallon ===\n\nThe imperial (UK) gallon, now defined as exactly 4.54609 litres (about 277.42 cubic inches), is used in some Commonwealth countries and was originally based on the volume of 10 pounds (approximately 4.54 kg) of water at 62 \u00b0F (17 \u00b0C). The imperial fluid ounce is defined as 1/160 of an imperial gallon; there are four quarts in a gallon, two pints in a quart, and 20 Imperial fluid ounces in an imperial pint.\n\n\n=== US liquid gallon ===\n\nThe US gallon is legally defined as 231 cubic inches, which is exactly 3.785411784 litres. A US liquid gallon of water weighs about 8.34 pounds or 3.78 kilograms at 62 \u00b0F (17 \u00b0C), making it about 16.6% lighter than the imperial gallon. There are four quarts in a gallon, two pints in a quart and 16 US fluid ounces in a US pint, which makes the US fluid ounce equal to 1/128 of a US gallon. In order to overcome the effects of expansion and contraction with temperature when using a gallon to specify a quantity of material for purposes of trade, it is common to define the temperature at which the material will occupy the specified volume. For example, the volume of petroleum products and alcoholic beverages are both referenced to 60 \u00b0F (15.6 \u00b0C) in government regulations.\n\n\n=== US dry gallon ===\n\nThis dry measure is one-eighth of a US Winchester bushel of 2150.42 cubic inches; it is therefore equal to exactly 268.8025 cubic inches or about 4.405 L. The US dry gallon is not used in commerce, and is not listed in the relevant statute, which jumps from the dry quart to the peck.\n\n\n== Worldwide usage of gallons ==\n\nGallons used in fuel economy expression in Canada and the United Kingdom are Imperial gallons.Despite its status as a U.S. territory, and unlike American Samoa, the Northern Mariana Islands, Guam, and the U.S. Virgin Islands, Puerto Rico ceased selling gasoline by the US gallon in 1980.The gallon was removed from the list of legally defined primary units of measure catalogued in the EU directive 80/181/EEC for trading and official purposes, with effect from 31 December 1994. Under the directive the gallon could still be used \u2013 but only as a supplementary or secondary unit. One of the effects of this directive was that the United Kingdom amended its own legislation to replace the gallon with the litre as a primary unit of measure in trade and in the conduct of public business, effective from 30 September 1995.Ireland also passed legislation in response to the EU directive, with the effective date being 31 December 1993. Though the gallon has ceased to be the legally defined primary unit, it can still be legally used in both the UK and Ireland as a supplementary unit.\nThe United Arab Emirates started selling gasoline by the litre in 2010, along with Guyana, and Panama in 2013.\nThe two former had used the Imperial gallon and the latter the US gallon until they switched.Myanmar (Burma) switched from Imperial gallon to litre sales before 2014.The Imperial gallon continues to be used as a unit of measure in Anguilla, Antigua and Barbuda, the Bahamas, the British Virgin Islands, the Cayman Islands, Dominica, Grenada, Montserrat,  St. Kitts & Nevis, St. Lucia, and St. Vincent & the Grenadines.Other than the United States, the US gallon is used in Liberia, Belize, Colombia, The Dominican Republic, Ecuador, El Salvador, Guatemala, Haiti, Honduras, Nicaragua, and Peru, but only for the sale of gasoline.  All other products are sold in litres and its multiples and submultiples.Antigua and Barbuda planned to switch over to using litres by 2015, but as of  2018 the switch-over had not been effected.\nIn the Turks & Caicos Islands, both the U.S. gallon and Imperial gallon are used, due to an increase in tax duties disguised by levying the same duty on the 3.79 L U.S. gallon as was previously levied on the 4.55 L Imperial gallon.\n\n\n== Relationship to other units ==\nBoth the US liquid and imperial gallon are divided into four quarts (quarter gallons), which in turn are divided into two pints. These pints are divided into two cups (though the imperial cup is rarely used now), which in turn are divided into two gills (gills are also rarely used). Thus a gallon is equal to four quarts, eight pints, sixteen cups or thirty-two gills. The imperial gill is further divided into five fluid ounces, whereas the US gill is divided into four fluid ounces. Thus an imperial fluid ounce is 1/20 of an imperial pint or 1/160 of an imperial gallon, while a US fluid ounce is 1/16 of a US pint or 1/128 of a US gallon.\nThe imperial gallon, quart, pint, cup and gill are approximately 20% larger than their US counterparts and are therefore not interchangeable. The imperial fluid ounce, on the other hand, is only 4% smaller than the US fluid ounce and therefore they are often used interchangeably.\nIn the US, liquor is often sold in \"fifths\", which are approximately one-fifth of a US gallon.\n\n\n== History ==\nThe term derives most immediately from galun, galon in Old Northern French, but the usage was common in several languages, for example jale in Old French and g\u0119llet (bowl) in Old English. This suggests a common origin in Romance Latin, but the ultimate source of the word is unknown. The gallon originated as the base of systems for measuring wine, and beer in England. The sizes of gallon used in these two systems were different from each other: the first was based on the wine gallon (equal in size to the US gallon), and the second on either the ale gallon or the larger imperial gallon.\nBy the end of the 18th century, three definitions of the gallon were in common use:\nThe corn gallon, or Winchester gallon, of about 268.8 cubic inches (\u2248 4.405 L),\nThe wine gallon, or Queen Anne's gallon, which was 231 cubic inches (\u2248 3.79 L), and\nThe ale gallon of 282 cubic inches (\u2248 4.62 L).The corn or dry gallon was used in the United States until recently for grain and other dry commodities. It is one-eighth of the (Winchester) bushel, originally a cylindrical measure of 18 1/2 inches in diameter and 8 inches in depth. That made the dry gallon (9 1/4)2 \u00d7 \u03c0 cubic inches \u2248 268.80252 in3. The bushel, which like dry quart and pint still sees some use, was later defined to be 2150.42 cubic inches exactly, making its gallon exactly 268.8025 in3 (4.40488377086 L).\nIn previous centuries, there had been a corn gallon of around 271 to 272 cubic inches.\nThe wine, fluid, or liquid gallon has been the standard US gallon since the early 19th century. The wine gallon, which some sources relate to the volume occupied by eight medieval merchant pounds of wine, was at one time defined as the volume of a cylinder 6 inches deep and 7 inches in diameter, i.e. 6 in \u00d7 (3 1/2 in)2 \u00d7 \u03c0 \u2248 230.907 06 cubic inches. It had been redefined during the reign of Queen Anne, in 1706, as 231 cubic inches exactly, which is the result of the earlier definition with \u03c0 approximated to 22/7. Although the wine gallon had been used for centuries for import duty purposes there was no legal standard of it in the Exchequer and a smaller gallon (224 cu in) was actually in use, so this statute became necessary. It remains the US definition today.\nIn 1824, Britain adopted a close approximation to the ale gallon known as the imperial gallon and abolished all other gallons in favour of it. Inspired by the kilogram-litre relationship, the imperial gallon was based on the volume of 10 pounds of distilled water weighed in air with brass weights with the barometer standing at 30 inches of mercury and at a temperature of 62 \u00b0F. In 1963, this definition was refined as the space occupied by 10 pounds of distilled water of density 0.998859 g/mL weighed in air of density 0.001217 g/mL against weights of density 8.136 g/mL (the original \"brass\" was refined as the density of brass alloys vary depending on metallurgical composition). This works out at approximately 4.5460903 L (277.41945 in3). The metric definition of exactly 4.54609 cubic decimetres (also 4.54609 L after the litre was redefined in 1964, \u2248 277.419433 in3) was adopted shortly afterwards in Canada, but from 1976 the conventional value of 4.546092 L was used in the United Kingdom until the Canadian convention was adopted in 1985.\nHistorically, gallons of various sizes were used in many parts of Western Europe. In these localities, it has been replaced as the unit of capacity by the litre.\n\n\n== References ==\n\n\n== External links ==",
        "unit": "gallon",
        "url": "https://en.wikipedia.org/wiki/Gallon"
    },
    {
        "_id": "Coulomb",
        "clean": "Coulomb",
        "text": "The coulomb (symbol: C) is the International System of Units (SI) unit of electric charge. It is the charge (symbol: Q or q) transported by a constant current of one ampere in one second:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          A\n        \n        \u22c5\n        1\n         \n        \n          s\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{A}}\\cdot 1~{\\text{s}}}\n  Thus, it is also the amount of excess charge on a capacitor of one farad charged to a potential difference of one volt:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          F\n        \n        \u22c5\n        1\n         \n        \n          V\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{F}}\\cdot 1~{\\text{V}}}\n  It is equivalent to the charge of approximately 6.242\u00d71018 (1.036\u00d710\u22125 mol) protons, and \u22121 C is equivalent to the charge of approximately 6.242\u00d71018 electrons.\n\n\n== Name and notation ==\nThis SI unit is named after Charles-Augustin de Coulomb. As with every International System of Units (SI) unit named for a person, the first letter of its symbol is upper case (C). However, when an SI unit is spelled out in English, it is treated as a common noun and should always begin with a lower case letter (coulomb)\u2014except in a situation where any word in that position would be capitalized, such as at the beginning of a sentence or in material using title case.\n\n\n== Definition ==\nThe SI system defines the coulomb in terms of the ampere and second: 1 C = 1 A \u00d7 1 s. The second is defined in terms of a frequency naturally emitted by caesium atoms. The ampere is defined using Amp\u00e8re's force law; the definition relies in part on the mass of the international prototype kilogram, a metal cylinder housed in France. In practice, the Kibble balance is used to measure amperes with the highest possible accuracy.Since the charge of one electron is known to be about 1.6021766208(98)\u00d710\u221219 C, 1 C can also be considered the charge of roughly 6.241509\u00d710^18 electrons or +1 C the charge of that many positrons or protons, where the number is the reciprocal of 1.602177\u00d710^\u221219.\nThe proposed redefinition of the ampere and other SI base units would have the effect of fixing the numerical value of the elementary charge to an explicit constant expressed in coulombs, and therefore it would implicitly fix the value of the coulomb when expressed as a multiple of the fundamental charge (the numerical values of those quantities are the multiplicative inverses of each other).\n\n\n== SI prefixes ==\nSee also Metric prefix.\n\n\n== Conversions ==\nOne coulomb is the magnitude (absolute value) of electrical charge in 6.24150934(14)\u00d710^18 protons or electrons.\nThe inverse of this number gives the elementary charge of 1.6021766208(98)\u00d710\u221219 C.\nThe magnitude of the electrical charge of one mole of elementary charges (approximately 6.022\u00d71023, or Avogadro's number) is known as a faraday unit of charge (closely related to the Faraday constant). One faraday equals 96485.3399 coulombs. In terms of Avogadro's number (NA), one coulomb is equal to approximately 1.036 \u00d7 NA\u00d710\u22125 elementary charges.\nOne ampere hour = 3600 C \u2234 1 mA\u22c5h = 3.6 C.\nOne statcoulomb (statC), the obsolete CGS electrostatic unit of charge (esu), is approximately 3.3356\u00d710\u221210 C or about one-third of a nanocoulomb.\n\n\n== Relation to elementary charge ==\nThe elementary charge, the charge of a proton (equivalently, the negative of the charge of an electron), is approximately 1.6021766208(98)\u00d710\u221219 C. In SI, the elementary charge in coulombs is an approximate value: no experiment can be infinitely accurate. However, in other unit systems, the elementary charge has an exact value by definition, and other charges are ultimately measured relative to the elementary charge. For example, in conventional electrical units, the values of the Josephson constant KJ and von Klitzing constant RK are exact defined values (written KJ-90 and RK-90), and it follows that the elementary charge e = 2/(KJRK) is also an exact defined value in this unit system. Specifically, e90 = (2\u00d710\u22129)/(25812.807 \u00d7 483597.9) C exactly. SI itself may someday change its definitions in a similar way. For example, one possible proposed redefinition is \"the ampere...is [defined] such that the value of the elementary charge e (charge on a proton) is exactly 1.602176487\u00d710\u221219 coulombs\", (in which the numeric value is the 2006 CODATA recommended value, since superseded). This proposal is not yet accepted as part of the SI.\n\n\n== In everyday terms ==\nThe charges in static electricity from rubbing materials together are typically a few microcoulombs.\nThe amount of charge that travels through a lightning bolt is typically around 15 C, although large bolts can be up to 350 C.\nThe amount of charge that travels through a typical alkaline AA battery from being fully charged to discharged is about 5 kC = 5000 C \u2248 1400 mA\u22c5h.\nThe hydraulic analogy uses everyday terms to illustrate movement of charge and the transfer of energy. The analogy equates charge to a volume of water, and voltage to pressure. One coulomb equals (the negative of) the charge of 6.24\u00d71018 electrons. The amount of energy transferred by the flow of 1 coulomb can vary; for example, 300 times fewer electrons flow through a lightning bolt than in the discharge of an AA battery, but the total energy transferred by the flow of the lightning's electrons is 300 million times greater.\n\n\n== See also ==\nAbcoulomb, a cgs unit of charge\nAmp\u00e8re's circuital law\nCoulomb's law\nElectrostatics\nElementary charge\nFaraday constant, the number of coulombs per mole\n\n\n== Notes and references ==",
        "unit": "milliampere-hour",
        "url": "https://en.wikipedia.org/wiki/Coulomb"
    },
    {
        "_id": "Jansky",
        "clean": "Jansky",
        "text": "The jansky (symbol Jy) is a non-SI unit of spectral flux density, or spectral irradiance, used especially in radio astronomy. It is equivalent to 10\u221226 watts per square metre per hertz.\nThe flux density or monochromatic flux, \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  , of a source is the integral of the spectral radiance, \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , over the source solid angle:\n\n  \n    \n      \n        S\n        =\n        \n          \u222c\n          \n            source\n          \n        \n        B\n        (\n        \u03b8\n        ,\n        \u03d5\n        )\n        \n        \n          d\n        \n        \u03a9\n        .\n      \n    \n    {\\displaystyle S=\\iint \\limits _{\\text{source}}B(\\theta ,\\phi )\\,\\mathrm {d} \\Omega .}\n  The unit is named after pioneering US radio astronomer Karl Guthe Jansky and is defined as\n\n  \n    \n      \n        1\n         \n        \n          Jy\n        \n        =\n        \n          10\n          \n            \u2212\n            26\n          \n        \n        \n          \n            W\n            \n              \n                \n                  m\n                \n                \n                  2\n                \n              \n              \n                \u22c5\n              \n              \n                Hz\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 1~{\\text{Jy}}=10^{-26}{\\frac {\\text{W}}{{\\text{m}}^{2}{\\cdot }{\\text{Hz}}}}}\n   (SI) \n  \n    \n      \n        =\n        \n          10\n          \n            \u2212\n            23\n          \n        \n        \n          \n            erg\n            \n              \n                s\n              \n              \n                \u22c5\n              \n              \n                \n                  cm\n                \n                \n                  2\n                \n              \n              \n                \u22c5\n              \n              \n                Hz\n              \n            \n          \n        \n      \n    \n    {\\displaystyle =10^{-23}{\\frac {\\text{erg}}{{\\text{s}}{\\cdot }{\\text{cm}}^{2}{\\cdot }{\\text{Hz}}}}}\n   (cgs).Since the jansky is obtained by integrating over the whole source solid angle, it is most simply used to describe point sources; for example, the Third Cambridge Catalogue of Radio Sources (3C) reports results in Jy.\n\nFor extended sources, the surface brightness is often described with units of Jy per solid angle; for example, far-infrared (FIR) maps from the IRAS satellite are in MJy/sr.\nAlthough extended sources at all wavelengths can be reported with these units, for radio-frequency maps, extended sources have traditionally been described in terms of a brightness temperature; for example the Haslam et al. 408 MHz all-sky continuum survey is reported in terms of a brightness temperature in K.\n\n\n== Unit conversions ==\nJansky units are not a standard SI Unit, so it may be necessary to convert the measurements made in the unit to the SI equivalent in terms of watts per square metre per hertz (W/(m2\u00b7Hz)). However, other unit conversions are possible with respect to measuring this unit.\n\n\n=== AB magnitude ===\nThe flux density in Jy can be converted to a magnitude basis, for suitable assumptions about the spectrum. For instance, converting an AB magnitude to a flux-density in microjanskys is straightforward:\n\n  \n    \n      \n        \n          S\n          \n            v\n          \n        \n         \n        [\n        \u03bc\n        \n          Jy\n        \n        ]\n        =\n        \n          10\n          \n            6\n          \n        \n        \u22c5\n        \n          10\n          \n            23\n          \n        \n        \u22c5\n        \n          10\n          \n            \u2212\n            (\n            \n              AB\n            \n            +\n            48.6\n            )\n            \n              /\n            \n            2.5\n          \n        \n        =\n        \n          10\n          \n            (\n            23.9\n            \u2212\n            \n              AB\n            \n            )\n            \n              /\n            \n            2.5\n          \n        \n        .\n      \n    \n    {\\displaystyle S_{v}~[\\mu {\\text{Jy}}]=10^{6}\\cdot 10^{23}\\cdot 10^{-({\\text{AB}}+48.6)/2.5}=10^{(23.9-{\\text{AB}})/2.5}.}\n  \n\n\n=== dBW/(m2\u22c5Hz) ===\nThe linear flux density in Jy can be converted to a decibel basis, suitable for use in fields of telecommunication and radio engineering.\n1 jansky is equal to \u2212260 dBW/(m2\u00b7Hz), or \u2212230 dBm/(m2\u00b7Hz):\n\n  \n    \n      \n        \n          P\n          \n            \n              dBW\n            \n            \n              /\n            \n            (\n            \n              \n                m\n              \n              \n                2\n              \n            \n            \u22c5\n            \n              Hz\n            \n            )\n          \n        \n        =\n        10\n        \n          log\n          \n            10\n          \n        \n        \u2061\n        (\n        \n          P\n          \n            Jy\n          \n        \n        )\n        \u2212\n        260\n        ,\n      \n    \n    {\\displaystyle P_{{\\text{dBW}}/({\\text{m}}^{2}\\cdot {\\text{Hz}})}=10\\log _{10}(P_{\\text{Jy}})-260,}\n  \n  \n    \n      \n        \n          P\n          \n            \n              dBm\n            \n            \n              /\n            \n            (\n            \n              \n                m\n              \n              \n                2\n              \n            \n            \u22c5\n            \n              Hz\n            \n            )\n          \n        \n        =\n        10\n        \n          log\n          \n            10\n          \n        \n        \u2061\n        (\n        \n          P\n          \n            Jy\n          \n        \n        )\n        \u2212\n        230.\n      \n    \n    {\\displaystyle P_{{\\text{dBm}}/({\\text{m}}^{2}\\cdot {\\text{Hz}})}=10\\log _{10}(P_{\\text{Jy}})-230.}\n  \n\n\n== Usage ==\nThe flux to which the jansky refers can be in any form of energy.\nIt was created for and is still most frequently used in reference to electromagnetic energy, especially in the context of radio astronomy.\nThe brightest astronomical radio sources have flux densities of the order of 1\u2013100 janskys.  For example, the Third Cambridge Catalogue of Radio Sources lists some 300 to 400 radio sources in the Northern Hemisphere brighter than 9 Jy at 159 MHz.  This range makes the jansky a suitable unit for radio astronomy.\nGravitational waves also carry energy, so their flux density can also be expressed in terms of janskys.  Typical signals on Earth are expected to be 1020 Jy or more.  However, because of the poor coupling of gravitational waves to matter, such signals are difficult to detect.\nWhen measuring broadband continuum emissions, where the energy is roughly evenly distributed across the detector bandwidth, the detected signal will increase in proportion to the bandwidth of the detector (as opposed to signals with bandwidth narrower than the detector bandpass). To calculate the flux density in janskys, the total power detected (in watts) is divided by the receiver collecting area (in square meters), and then divided by the detector bandwidth (in hertz).  The flux density of astronomical sources is many orders of magnitude below 1 W/(m2\u00b7Hz), so the result is multiplied by 1026 to get a more appropriate unit for natural astrophysical phenomena.The millijansky, mJy, was sometimes referred to as a milli flux unit (m.f.u.) in the astronomical literature.\n\n\n== Orders of magnitude ==\nNote: Unless noted, all values are as seen from the Earth's surface.\n\n\n== References ==",
        "unit": "millijansky",
        "url": "https://en.wikipedia.org/wiki/Jansky"
    },
    {
        "_id": "Chinese_yuan",
        "clean": "Chinese yuan",
        "text": "The renminbi (Ab.: RMB; simplified Chinese: \u4eba\u6c11\u5e01; traditional Chinese: \u4eba\u6c11\u5e63; pinyin:  r\u00e9nm\u00ednb\u00ec; literally: \"people's currency\"; sign: \u5143; code: CNY) is the official currency of the People's Republic of China. The yuan (Chinese: \u5143; pinyin: yu\u00e1n) is the basic unit of the renminbi, but is also used to refer to the Chinese currency generally, especially in international contexts where \"Chinese yuan\" is widely used to refer to the renminbi. The distinction between the terms renminbi and yuan is similar to that between sterling and pound, which respectively refer to the British currency and its primary unit. One yuan is subdivided into 10 jiao (Chinese: \u89d2; pinyin: ji\u01ceo), and a jiao in turn is subdivided into 10 fen (Chinese: \u5206; pinyin: f\u0113n). The renminbi is issued by the People's Bank of China, the monetary authority of China.Until 2005, the value of the renminbi was pegged to the US dollar. As China pursued its transition from central planning to a market economy, and increased its participation in foreign trade, the renminbi was devalued to increase the competitiveness of Chinese industry. It has previously been claimed that the renminbi's official exchange rate was undervalued by as much as 37.5% against its purchasing power parity. More recently, however, appreciation actions by the Chinese government, as well as quantitative easing measures taken by the American Federal Reserve and other major central banks, have caused the renminbi to be within as little as 8% of its equilibrium value by the second half of 2012. Since 2006, the renminbi exchange rate has been allowed to float in a narrow margin around a fixed base rate determined with reference to a basket of world currencies. The Chinese government has announced that it will gradually increase the flexibility of the exchange rate. As a result of the rapid internationalization of the renminbi, it became the world's 8th most traded currency in 2013, and 5th by 2015.On 1 October 2016, the RMB became the first emerging market currency to be included in the IMF's special drawing rights basket, the basket of currencies used by the IMF (reserve currency).\n\n\n== Terminology ==\nThe ISO code for renminbi (which may also be used for the yuan) is CNY (an abbreviation for \"Chinese yuan\"), or also CNH when traded in off-shore markets such as Hong Kong. The currency is often abbreviated RMB, or indicated by the yuan sign \u00a5. The latter may be written CN\u00a5 to distinguish it from other currencies with the same symbol (such as the Japanese yen).  In Chinese texts the currency may also be indicated with the Chinese character for the yuan, \u5706 (or \u5143 informally). The renminbi is legal tender in mainland China, but not in Hong Kong or Macau. However, Renminbi is widely accepted in Hong Kong and Macau, and are easily exchanged in the two territories, with banks in Hong Kong allowing people to maintain accounts in RMB and withdraw RMB banknotes from ATM terminals.\n\n\n== History ==\n\nA variety of currencies circulated in China during the Republic of China (ROC) era, most of which were denominated in the unit yu\u00e1n (Mandarin pronunciation in IPA: [\u0265\u00e6\u030cn\u02e7\u02e5]). Each was distinguished by a currency name, such as the fabi (\"legal tender\"), the \"gold yuan\", and the \"silver yuan\".\nThe renminbi was introduced by the People's Bank of China in December 1948, about a year before the establishment of the People's Republic of China. It was issued only in paper money form at first, and replaced the various currencies circulating in the areas controlled by the Communists. One of the first tasks of the new government was to end the hyperinflation that had plagued China in the final years of the Kuomintang (KMT) era. That achieved, a revaluation occurred in 1955 at the rate of 1 new yuan = 10,000 old yuan.\nAs the Communist Party of China took control of ever larger territories in the latter part of the Chinese Civil War, its People's Bank of China began in 1948 to issue a unified currency for use in Communist-controlled territories. Also denominated in yuan, this currency was identified by different names, including \"People's Bank of China banknotes\" (simplified Chinese: \u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u949e\u7968; traditional Chinese: \u4e2d\u570b\u4eba\u6c11\u9280\u884c\u9214\u7968; from November 1948), \"New Currency\" (simplified Chinese: \u65b0\u5e01; traditional Chinese: \u65b0\u5e63; from December 1948), \"People's Bank of China notes\" (simplified Chinese: \u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u5238; traditional Chinese: \u4e2d\u570b\u4eba\u6c11\u9280\u884c\u5238; from January 1949), \"People's Notes\" (\u4eba\u6c11\u5238, as an abbreviation of the last name), and finally \"People's Currency\", or \"renminbi\", from June 1949.\n\n\n=== Era of the planned economy ===\n\nFrom 1949 until the late 1970s, the state fixed China's exchange rate at a highly overvalued level as part of the country's import-substitution strategy. During this time frame, the focus of the state's central planning was to accelerate industrial development and reduce China's dependence on imported manufactured goods. The overvaluation allowed the government to provide imported machinery and equipment to priority industries at a relatively lower domestic currency cost than otherwise would have been possible.\n\n\n=== Transition to an equilibrium exchange rate ===\nChina's transition by the mid-1990s to a system in which the value of its currency was determined by supply and demand in a foreign exchange market was a gradual process spanning 15 years that involved changes in the official exchange rate, the use of a dual exchange rate system, and the introduction and gradual expansion of markets for foreign exchange.\nThe most important move to a market-oriented exchange rate was an easing of controls on trade and other current account transactions, as occurred in several very early steps. In 1979 the State Council approved a system allowing exporters and their provincial and local government owners to retain a share of their foreign exchange earnings, referred to as foreign exchange quotas. At the same time, the government introduced measures to allow retention of part of the foreign exchange earnings from non-trade sources, such as overseas remittances, port fees paid by foreign vessels, and tourism.\nAs early as October 1980, exporting firms that retained foreign exchange above their own import needs were allowed to sell the excess through the state agency responsible for the management of China's exchange controls and its foreign exchange reserves, the State Administration of Exchange Control. Beginning in the mid-1980s, the government sanctioned foreign exchange markets, known as swap centers eventually in most large cities.\nThe government also gradually allowed market force to take the dominant role by introducing an \"internal settlement rate\" of RMB 2.8 to 1 US dollar which was a devaluation of almost 100 percent.\n\n\n=== Evolution of exchange policy since 1994 ===\nIn November 1993 the Third Plenum of the Fourteenth CPC Central Committee approved a comprehensive reform strategy in which foreign exchange management reforms were highlighted as a key element for a market-oriented economy. A floating exchange rate regime and convertibility for RMB were seen as the ultimate goal of the reform. Conditional convertibility under current account was achieved by allowing firms to surrender their foreign exchange earning from current account transactions and purchase foreign exchange as needed. Restrictions on Foreign Direct Investment (FDI) was also loosened and capital inflows to China surged.\n\n\n=== Convertibility ===\nDuring the era of the command economy, the value of the renminbi  was set to unrealistic values in exchange with western currency and severe currency exchange rules were put in place. With the opening of the mainland Chinese economy in 1978, a dual-track currency system was instituted, with renminbi usable only domestically, and with foreign visitors to China forced to use foreign exchange certificates. The unrealistic levels at which exchange rates were pegged led to a strong black market in currency transactions.\nIn the late 1980s and early 1990s, China worked to make the RMB more convertible. Through the use of swap centres, the exchange rate was brought to realistic levels and the dual track currency system was abolished.\nAs of 2013, the renminbi is convertible on current accounts but not capital accounts. The ultimate goal has been to make the RMB fully convertible. However, partly in response to the Asian financial crisis in 1998, China has been concerned that the mainland Chinese financial system would not be able to handle the potential rapid cross-border movements of hot money, and as a result, as of 2012, the currency trades within a narrow band specified by the Chinese central government.\nFollowing the Internationalization of the renminbi, on 30 November 2015, the IMF voted to designate the renminbi as one of several main world currencies, thus including it in the basket of special drawing rights. The RMB became the first emerging market currency to be included in the IMF\u2019s SDR basket on 1 October 2016. The other main world currencies are the United States dollar, euro, British pound, and Japanese yen.\n\n\n== Issuance ==\nAs of 2016, renminbi banknotes are available in denominations from \u00a50.1, \u00a50.2, \u00a50.5 (1, 2, and 5 jiao), \u00a51, \u00a52, \u00a55, \u00a510, \u00a520, \u00a550 and \u00a5100 yuan. These denominations have been available since 1955, except for the 50 and 100 yuan notes (added in 1980) and 20 yuan notes (added in or after 1999). Coins are available in denominations from 1 fen to 1 yuan (\u00a50.01\u20131). Thus some denominations exist in both coins and banknotes. On rare occasions larger yuan coin denominations such as \u00a55 have been issued to commemorate events but use of these outside of collecting has never been widespread.\nThe denomination of each banknote is printed in Chinese. The numbers themselves are printed in financial Chinese numeral characters, as well as Arabic numerals. The denomination and the words \"People's Bank of China\" are also printed in Mongolian, Tibetan, Uyghur and Zhuang on the back of each banknote, in addition to the boldface Hanyu Pinyin \"Zhongguo Renmin Yinhang\" (without tones). The right front of the note has a tactile representation of the denomination in Chinese Braille starting from the fourth series. See corresponding section for detailed information.\nThe fen and jiao denominations have become increasingly unnecessary as prices have increased. Coins under \u00a50.1 are used infrequently. Chinese retailers tend to avoid decimal values (such as \u00a59.99), opting instead for integer values of yuan (such as \u00a59 or \u00a510).\n\n\n=== Coins ===\nIn 1953, aluminium 1-, 2-, and 5-fen coins began being struck for circulation, and were first introduced in 1955. These depict the national emblem on the obverse (front) and the name and denomination framed by wheat stocks on the reverse (back). In 1980, brass 1-, 2-, and 5-jiao and cupro-nickel 1-yuan coins were added, although the 1 and 2 jiao were only produced until 1981, with the last 5 jiao and 1 yuan issued in 1985. All jiao coins depicted similar designs to the fen coins while the yuan depicted the Great Wall of China. In 1991, a new coinage was introduced, consisting of an aluminium 1 jiao, brass 5 jiao and nickel-clad-steel 1 yuan. These were smaller than the previous jiao and yuan coins and depicted flowers on the obverse and the national emblem on the reverse. Issuance of the aluminum 1- and 2-fen coins ceased in 1991, with that of the 5 fen halting in 1994. The small coins were still made for annual uncirculated mint sets in limited quantities, and from the beginning of 2005 the 1-fen coin got a new lease on life by being issued again every year since then up to present. New designs of the 1 and 5 jiao and 1 yuan were again introduced in between 1999 and 2002, with the 1 jiao being significantly reduced in size. In 2005, the metallic composition of the 1 jiao was changed from aluminum to more durable nickel-plated steel. The frequency of usage of coins varies between different parts of China, with coins typically being more popular in urban areas, and small notes being more popular in rural areas. Older fen and large jiao coins are uncommonly still seen in circulation but are still valid in exchange.\n\n\n=== Banknotes ===\n\nAs of 2018, there have been five series of renminbi banknotes issued by the People's Republic of China:\n\nThe first series of renminbi banknotes was issued on 1 December 1948, by the newly founded People's Bank of China.  It introduced notes in denominations of 1, 5, 10, 20, 50, 100 and 1000 yuan. Notes for 200, 500, 5000 and 10,000 yuan followed in 1949, with 50,000 yuan notes added in 1950. A total of 62 different designs were issued. The notes were officially withdrawn on various dates between 1 April and 10 May 1955. The name \"first series\" was given retroactively in 1950, after work began to design a new series.These first renminbi notes were printed with the words \"People's Bank of China\", \"Republic of China\", and the denomination, written in Chinese characters by Dong Biwu.The second series of renminbi banknotes was introduced on 1 March 1955 (but dated 1953). Each note has the words \"People's Bank of China\" as well as the denomination in the Uyghur, Tibetan, Mongolian and Zhuang languages on the back, which has since appeared in each series of renminbi notes. The denominations available in banknotes were \u00a50.01, \u00a50.02, \u00a50.05, \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a53, \u00a55 and \u00a510. Except for the three fen denominations and the 3 yuan which were withdrawn, notes in these denominations continued to circulate. Good examples of this series have gained high status with banknote collectors.\nThe third series of renminbi banknotes was introduced on 15 April 1962, though many denominations were dated 1960. New dates would be issued as stocks of older dates were gradually depleted. The sizes and design layout of the notes had changed but not the order of colors for each denomination. For the next two decades, the second and third series banknotes were used concurrently. The denominations were of \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a55 and \u00a510. The third series was phased out during the 1990s and then was recalled completely on 1 July 2000.\nThe fourth series of renminbi banknotes was introduced between 1987 and 1997, although the banknotes were dated 1980, 1990, or 1996. They are still legal tender. Banknotes are available in denominations of \u00a50.1, \u00a50.2, \u00a50.5, \u00a51, \u00a52, \u00a55, \u00a510, \u00a550 and \u00a5100. Like previous issues, the color designation for already existing denominations remained in effect.\nThe fifth series of renminbi banknotes and coins was progressively introduced from 1999. This series also bears the years 2005 (all except \u00a51) and 2015 (\u00a5100 only). As of 2016, it includes banknotes for \u00a51, \u00a55, \u00a510, \u00a520, \u00a550 and \u00a5100. Significantly, the fifth series uses the portrait of Mao Zedong on all banknotes, in place of the various leaders and workers which had been featured previously. During this series new security features were added, the \u00a52 denomination was discontinued, and the color pattern for each note was changed.\n\n\n=== Commemorative issues of the renminbi ===\nIn 1999, a commemorative red \u00a550 note was issued in honor of the 50th anniversary of the establishment of the People's Republic of China. This note features Mao Zedong on the front and various animals on the back.\nAn orange polymer note, and so far, China's only polymer note, commemorating the new millennium was issued in 2000 with a face value of \u00a5100. This features a dragon on the obverse and the reverse features the China Millennium monument (at the Center for Cultural and Scientific Fairs).\nFor the 2008 Beijing Olympics, a green \u00a510 note was issued featuring the Bird's Nest Stadium on the front with the back showing a classical Olympic discus thrower and various other athletes.\nOn 26 November 2015, the People's Bank of China issued a blue \u00a5100 commemorative note to commemorate aerospace science and technology.\n\n\n=== Use in minority regions ===\n\nThe renminbi yuan has different names when used in minority regions. \n\nWhen used in Inner Mongolia and other Mongol autonomies, a yuan is called a tugreg (Mongolian: \u1832\u1826\u182d\u1826\u1837\u1822\u182d\u180c t\u00fcg\u00fcrig). However, when used in the republic of Mongolia, it is still named yuani (Mongolian: \u044e\u0430\u043d\u044c) to differentiate it from Mongolian t\u00f6gr\u00f6g (Mongolian: \u0442\u04e9\u0433\u0440\u04e9\u0433). One Chinese t\u00fcg\u00fcrig (tugreg) is divided into 100 m\u00f6ngg\u00fc (Mongolian: \u182e\u1825\u1829\u182d\u1826), one Chinese jiao is labeled \"10 m\u00f6ngg\u00fc\". In Mongolian, renminbi is called aradin jogos or arad-un jogos (Mongolian: \u1820\u1837\u1820\u1833\u202f\u1824\u1828 \u1835\u1823\u182d\u1823\u1830 arad-un \u01f0o\u03b3os).\nWhen used in Tibet and other Tibetan autonomies, a yuan is called a gor (Tibetan: \u0f66\u0f92\u0f7c\u0f62\u0f0b, ZYPY: Gor). One gor is divided into 10 gorsur (Tibetan: \u0f66\u0f92\u0f7c\u0f62\u0f0b\u0f5f\u0f74\u0f62\u0f0b, ZYPY: Gorsur) or 100 gar (Tibetan: \u0f66\u0f90\u0f62\u0f0b, ZYPY: gar). In Tibetan, renminbi is called mimangxogng\u00fc (Tibetan: \u0f58\u0f72\u0f0b\u0f51\u0f58\u0f44\u0f66\u0f0b\u0f64\u0f7c\u0f42\u0f0b\u0f51\u0f44\u0f74\u0f63\u0f0d, ZYPY: Mimang Xogng\u00fc) or mimang shog ngul.\nWhen used in the Uyghur autonomy region of Xinjiang, the renminbi is called Xelq puli (Uyghur: \u062e\u06d5\u0644\u0642 \u067e\u06c7\u0644\u0649\u200e)\n\n\n=== Production and minting ===\nRenminbi currency production is carried out by a state owned corporation, China Banknote Printing and Minting Corporation (CBPMC; \u4e2d\u56fd\u5370\u949e\u9020\u5e01\u603b\u516c\u53f8) headquartered in Beijing. CBPMC uses several printing, engraving and minting facilities around the country to produce banknotes and coins for subsequent distribution. Banknote printing facilities are based in Beijing, Shanghai, Chengdu, Xi'an, Shijiazhuang, and Nanchang. Mints are located in Nanjing, Shanghai, and Shenyang. Also, high grade paper for the banknotes is produced at two facilities in Baoding and Kunshan. The Baoding facility is the largest facility in the world dedicated to developing banknote material according to its website. In addition, the People's Bank of China has its own printing technology research division that researches new techniques for creating banknotes and making counterfeiting more difficult.\n\n\n=== Suggested future design ===\nOn 13 March 2006, some delegates to an advisory body at the National People's Congress proposed to include Sun Yat-sen and Deng Xiaoping on the renminbi banknotes. However, the proposal was not adopted.\n\n\n== Economics ==\n\n\n=== Value ===\n\nFor most of its early history, the RMB was pegged to the U.S. dollar at \u00a52.46 per USD (note: during the 1970s, it was revalued until it reached \u00a51.50 per USD in 1980). When China's economy gradually opened in the 1980s, the RMB was devalued in order to improve the competitiveness of Chinese exports. Thus, the official exchange rate increased from \u00a51.50 in 1980 to \u00a58.62 by 1994 (the lowest rate on record). Improving current account balance during the latter half of the 1990s enabled the Chinese government to maintain a peg of \u00a58.27 per USD from 1997 to 2005.\nThe RMB reached a record high exchange value of \u00a56.0395 to the U.S. dollar on 14 January 2014. Chinese leadership have been raising the yuan to tame inflation, a step U.S. officials have pushed for years to lower the massive trade deficit with China. Strengthening the value of the RMB also fits with the Chinese transition to a more consumer-led economic growth model.In 2015 the Chinese Central Bank again devalued their country's currency. As of  1 September 2015, the exchange rate for 1 USD is \u00a56.37.\n\n\n=== Depegged from the U.S. dollar ===\nOn 21 July 2005, the peg was finally lifted, which saw an immediate one-time RMB revaluation to \u00a58.11 per USD. The exchange rate against the euro stood at \u00a510.07060 yuan per euro.\nHowever the peg was reinstituted unofficially when the financial crisis hit: \"Under intense pressure from Washington, China took small steps to allow its currency to strengthen for three years starting in July 2005. But China 're-pegged' its currency to the dollar as the financial crisis intensified in July 2008.\"On 19 June 2010, the People\u2019s Bank of China released a statement simultaneously in Chinese and English indicating that they would \"proceed further with reform of the RMB exchange rate regime and increase the RMB exchange rate flexibility\". The news was greeted with praise by world leaders including Barack Obama, Nicolas Sarkozy and Stephen Harper. The PBoC maintained there would be no \"large swings\" in the currency. The RMB rose to its highest level in five years and markets worldwide surged on Monday, 21 June following China's announcement.In August 2015, Joseph Adinolfi, a reporter for MarketWatch, reported that China had re-pegged the RMB. In his article, he narrated that \"Weak trade data out of China, released over the weekend, weighed on the currencies of Australia and New Zealand on Monday. But the yuan didn\u2019t budge. Indeed, the Chinese currency, also known as the renminbi, has been remarkably steady over the past month despite the huge selloff in China\u2019s stock market and a spate of disappointing economic data. Market strategists, including Simon Derrick, chief currency strategist at BNY Mellon, and Marc Chandler, head currency strategist at Brown Brothers Harriman, said that\u2019s because China\u2019s policy makers have effectively re-pegged the yuan. \u201cWhen I look at the dollar-renminbi right now, that looks like a fixed exchange rate again. They\u2019ve re-pegged it,\u201d Chandler said.\"\n\n\n=== Managed float ===\nThe RMB has now moved to a managed floating exchange rate based on market supply and demand with reference to a basket of foreign currencies. In July 2005, the daily trading price of the U.S. dollar against the RMB in the inter-bank foreign exchange market was allowed to float within a narrow band of 0.3% around the central parity  published by the People's Bank of China; in a later announcement published on 18 May 2007, the band was extended to 0.5%. On 14 April 2012, the band was extended to 1.0%. On 17 March 2014, the band was extended to 2%.  China has stated that the basket is dominated by the United States dollar, euro, Japanese yen and South Korean won, with a smaller proportion made up of the British pound, Thai baht, Russian ruble, Australian dollar, Canadian dollar and Singapore dollar.On 10 April 2008, it traded at \u00a56.9920 per US dollar, which was the first time in more than a decade that a dollar had bought less than seven yuan, and at 11.03630 yuan per euro.\nBeginning in January 2010, Chinese and non-Chinese citizens have an annual exchange limit of a maximum of US$50,000. Exchange will only proceed if the applicant appears in person at the relevant bank, and presents their passport or Chinese ID; these deals are being centrally registered. The maximum dollar withdrawal is $10,000 per day, the maximum purchase limit of USD is $500 per day. This stringent management of the currency leads to a bottled-up demand for exchange in both directions. It is viewed as a major tool to keep the currency peg, preventing inflows of 'hot money'.\nA shift of Chinese reserves into the currencies of their other trading partners has caused these nations to shift more of their reserves into dollars, leading to no great change in the value of the renminbi against the dollar.\n\n\n=== Futures market ===\nRenminbi futures are traded at the Chicago Mercantile Exchange. The futures are cash-settled at the exchange rate published by the People's Bank of China.\n\n\n=== Purchasing power parity ===\nScholarly studies suggest that the yuan is undervalued on the basis of purchasing power parity analysis. One 2011 study suggests a 37.5% undervaluation.\nThe World Bank estimated that, by purchasing power parity, one International dollar was equivalent to approximately \u00a51.9 in 2004.\nThe International Monetary Fund estimated that, by purchasing power parity, one International dollar was equivalent to approximately \u00a53.462 in 2006, \u00a53.621 in 2007, \u00a53.798 in 2008, \u00a53.872 in 2009, \u00a53.922 in 2010, \u00a53.946 in 2011, \u00a53.952 in 2012, \u00a53.944 in 2013 and \u00a53.937 in 2014.The People\u2019s Bank of China lowered the renminbi\u2019s daily fix to the US dollar by 1.9 per cent to \u00a56.2298 on 11 August 2015. The People\u2019s Bank of China again lowered the renminbi\u2019s daily fix to the US dollar from \u00a56.620 to \u00a56.6375 after the Brexit on 27 June 2016. It had not been this low since December 2010.\n\n\n=== Internationalization ===\n\nBefore 2009, the Chinese renminbi had little to no exposure in the international markets because of strict government controls by the central Chinese government that prohibited almost all export of the currency, or use of it in international transactions. Transactions between Chinese companies and a foreign entity were generally denominated in US dollars. With Chinese companies unable to hold US dollars and foreign companies unable to hold Chinese yuan, all transactions would go through the People's Bank of China. Once the sum was paid by the foreign party in dollars, the central bank would pass the settlement in renminbi to the Chinese company at the state-controlled exchange rate.\nIn June 2009 the Chinese officials announced a pilot scheme where business and trade transactions were allowed between limited businesses in Guangdong province and Shanghai, and only counterparties in Hong Kong, Macau, and select ASEAN nations. Proving a success, the program was further extended to 20 Chinese provinces and counterparties internationally in July 2010, and in September 2011 it was announced that the remaining 11 Chinese provinces would be included.\nIn steps intended to establish the renminbi as an international reserve currency, China has agreements with Russia, Vietnam, Sri Lanka, Thailand, and Japan, allowing trade with those countries to be settled directly in renminbi instead of requiring conversion to US dollars, with Australia and South Africa to follow soon.\n\n\n=== International reserve currency ===\nCurrency restrictions regarding renminbi-denominated bank deposits and financial products were greatly liberalized in July 2010. In 2010 renminbi-denominated bonds were reported to have been purchased by Malaysia's central bank and that McDonald's had issued renminbi denominated corporate bonds through Standard Chartered Bank of Hong Kong. Such liberalization allows the yuan to look more attractive as it can be held with higher return on investment yields, whereas previously that yield was virtually none.  Nevertheless, some national banks such as Bank of Thailand (BOT) have expressed a serious concern about RMB since BOT cannot substitute the deprecated US dollars in its US$200 billion foreign exchange reserves for renminbi as much as it wishes because:\n\nThe Chinese government has not taken full responsibilities and commitments on economic affairs at global levels.\nRenminbi still has not become well-liquidated (fully convertible) yet.\nThe Chinese government still lacks deep and wide vision about how to perform fund-raising to handle international loans at global levels.To meet IMF requirements, China gave up some of its tight control over the currency.Countries that are left-leaning in the political spectrum had already begun to use the renminbi as an alternative reserve currency to the United States dollar; the Central Bank of Chile reported in 2011 to have US$91 million worth of renminbi in reserves, and the president of the Central Bank of Venezuela, Nelson Merentes, made statements in favour of the renminbi following the announcement of reserve withdrawals from Europe and the United States.\n\n\n=== Use as a currency outside mainland China ===\nThe two special administrative regions, Hong Kong and Macau, have their own respective currencies, according to the \"one country, two systems\" principle and the basic laws of the two territories.  Therefore, the Hong Kong dollar and the Macanese pataca remain the legal tenders in the two territories, and renminbi, although sometimes accepted, is not legal tender.  Banks in Hong Kong allow people to maintain accounts in RMB. Because of changes in legislation in July 2010, many banks around the world are now slowly offering individuals the chance to hold deposits in Chinese renminbi.\nThe RMB had a presence in Macau even before the 1999 return to the People's Republic of China from Portugal. Banks in Macau can issue credit cards based on the renminbi, but not loans. Renminbi-based credit cards cannot be used in Macau's casinos.The Republic of China, which governs Taiwan, believes wide usage of the renminbi would create an underground economy and undermine its sovereignty. Tourists are allowed to bring in up to \u00a520,000 when visiting Taiwan. These renminbi must be converted to the New Taiwan dollar at trial exchange sites in Matsu and Kinmen.  The Chen Shui-bian administration insisted that it would not allow full convertibility until the mainland signs a bilateral foreign exchange settlement agreement, though president Ma Ying-jeou has pledged to allow full convertibility as soon as possible.\nThe renminbi circulates in some of China's neighbors, such as Pakistan, Mongolia and northern Thailand. Cambodia welcomes the renminbi as an official currency and Laos and Myanmar allow it in border provinces such as Wa and Kokang and economic zones like Mandalay. Though unofficial, Vietnam recognizes the exchange of the renminbi to the \u0111\u1ed3ng.Since 2007, RMB-nominated bonds are issued outside mainland China; these are colloquially called \"dim sum bonds\". In April 2011, the first initial public offering denominated in renminbi occurred in Hong Kong, when the Chinese property investment trust Hui Xian raised \u00a510.48 billion ($1.6 billion) in its IPO. Beijing has allowed renminbi-denominated financial markets to develop in Hong Kong as part of the effort to internationalise the renminbi.\n\n\n=== Other markets ===\n\nSince currency flows in and out of mainland China are still restricted, RMB traded in off-shore markets, such as the Hong Kong market, can have a different value to RMB traded on the mainland. The offshore RMB market is usually denoted as CNH, but there is another RMB interbank and spot market in Taiwan for domestic trading known as CNT.\nOther RMB markets include the dollar-settled non-deliverable forward (NDF), and the trade-settlement exchange rate (CNT).Note that the two CNT mentioned above are different from each other.\n\n\n=== Current exchange rates ===\n\n\n== See also ==\nChina Banknote Printing and Minting Corporation (CBPMC)\nChinese lunar coins\nEconomy of China\nList of renminbi exchange rates\nTibetan coins and currency\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nPhotographs of all Chinese currency and sound of pronunciation in Chinese\nStephen Mulvey, Why China's currency has two names - BBC News, 2010-06-26\nHistorical and current banknotes of the People's Republic of China (in English) (in German)\nForeign exchange certificates (FEC) of the People's Republic of China (in English) (in German)",
        "unit": "chinese yuan",
        "url": "https://en.wikipedia.org/wiki/Chinese_yuan"
    },
    {
        "_id": "Knot_(unit)",
        "clean": "Knot (unit)",
        "text": "The knot () is a unit of speed equal to one nautical mile per hour, exactly 1.852 km/h (approximately 1.15078 mph). The ISO standard symbol for the knot is kn. The same symbol is preferred by the Institute of Electrical and Electronics Engineers (IEEE); kt is also common. The knot is a non-SI unit. Worldwide, the knot is used in meteorology, and in maritime and air navigation\u2014for example, a vessel travelling at 1 knot along a meridian travels approximately one minute of geographic latitude in one hour.\nEtymologically, the term derives from counting the number of knots in the line that unspooled from the reel of a chip log in a specific time.\n\n\n== Definitions ==\n1 international knot =\n1 nautical mile per hour (by definition),\n1.852 kilometres per hour (exactly),\n0.51444 metres per second (approximately),\n1.15078 miles per hour (approximately),\n20.25372 inches per second (approximately)\n1.68781 feet per second (approximately).1852 m is the length of the internationally agreed nautical mile. The US adopted the international definition in 1954, having previously used the US nautical mile (1853.248 m). The UK adopted the international nautical mile definition in 1970, having previously used the UK Admiralty nautical mile (6080 ft or 1853.184 m).\n\n (Values in bold face are exact.)\n\n\n== Usage ==\nThe speeds of vessels relative to the fluids in which they travel (boat speeds and air speeds) are measured in knots. For consistency, the speeds of navigational fluids (tidal streams, river currents and wind speeds) are also measured in knots. Thus, speed over the ground (SOG) (ground speed (GS) in aircraft) and rate of progress towards a distant point (\"velocity made good\", VMG) are also given in knots.\n\n\n== Origin ==\nUntil the mid-19th century, vessel speed at sea was measured using a chip log. This consisted of a wooden panel, attached by line to a reel, and weighted on one edge to float perpendicularly to the water surface and thus present substantial resistance to the water moving around it. The chip log was cast over the stern of the moving vessel and the line allowed to pay out. Knots placed at a distance of 47 feet 3 inches (14.4018 m) from each other, passed through a sailor's fingers, while another sailor used a 30-second sand-glass (28-second sand-glass is the currently accepted timing) to time the operation. The knot count would be reported and used in the sailing master's dead reckoning and navigation. This method gives a value for the knot of 20.25 in/s, or 1.85166 km/h. The difference from the modern definition is less than 0.02%.\nDerivation of knots spacing:\n\n  \n    \n      \n        1\n        \n          \n            kn\n          \n        \n        =\n        1852\n        \n          \n            m/h\n          \n        \n        =\n        0.5144\n        \n          \n            m/s\n          \n        \n      \n    \n    {\\displaystyle 1{\\textrm {kn}}=1852{\\textrm {m/h}}=0.5144{\\textrm {m/s}}}\n  , so in \n  \n    \n      \n        28\n      \n    \n    {\\displaystyle 28}\n   seconds that is \n  \n    \n      \n        14.40\n      \n    \n    {\\displaystyle 14.40}\n   meters per knot.\n\n\n== Modern use ==\n\nAlthough the unit knot does not fit within the SI system, its retention for nautical and aviation use is important because the length of a Nautical Mile, upon which the knot is based, is closely related to the size of the Earth. As a result, nautical miles and knots are convenient units to use when navigating an aircraft or ship.\nStandard nautical charts are on the Mercator projection and the horizontal (East-West) scale varies with latitude. On a chart of the North Atlantic, the scale varies by a factor of two from Florida to Greenland. A single graphic scale, of the sort on many maps, would therefore be useless on such a chart. Since the length of a nautical mile, for practical purposes, is equivalent to about a minute of latitude, a distance in nautical miles on a chart can easily be measured by using dividers and the latitude scales on the sides of the chart. Recent British Admiralty charts have a latitude scale down the middle to make this even easier.Speed is sometimes incorrectly expressed as \"knots per hour\", which is in fact a measure of acceleration.\n\n\n=== Aeronautical terms ===\nPrior to 1969, airworthiness standards for civil aircraft in the United States Federal Aviation Regulations specified that distances were to be in statute miles, and speeds in miles per hour. In 1969, these standards were progressively amended to specify that distances were to be in nautical miles, and speeds in knots.The following abbreviations are used to distinguish between various measurements of airspeed:\nKTAS is \"knots true airspeed\", the airspeed of an aircraft relative to undisturbed air\nKIAS is \"knots indicated airspeed\", the speed shown on an aircraft's pitot-static airspeed indicator\nKCAS is \"knots calibrated airspeed\", the indicated airspeed corrected for position error and instrument error\nKEAS is \"knots equivalent airspeed\", the calibrated airspeed corrected for adiabatic compressible flow for the particular altitudeThe indicated airspeed is close to the true airspeed only at sea level in standard conditions and at low speeds. At 11000 m (36000 ft), an indicated airspeed of 300 kn may correspond to a true airspeed of 500 kn in standard conditions.\n\n\n== See also ==\n\nBeaufort scale\nHull speed, which deals with theoretical estimates of practical maximum speed of displacement hulls\nKnot count\nKnotted cord\nMetre per second\nOrders of magnitude (speed)\nRope (unit)\n\n\n== References ==\n\n\n== Further reading ==\nKemp, Peter (editor). The Oxford Companion to Ships and the Sea. Oxford university Press, 1976. ISBN 0-19-282084-2",
        "unit": "knot",
        "url": "https://en.wikipedia.org/wiki/Knot_(unit)"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Dynamic (shear) viscosity ===\n\nThe dynamic viscosity of a fluid expresses its resistance to shearing flows, where adjacent layers move parallel to each other with different speeds. It can be defined through the idealized situation known as a Couette flow, where a layer of fluid is trapped between two horizontal plates, one fixed and one moving horizontally at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  . This fluid has to be homogeneous in the layer and at different shear stresses. (The plates are assumed to be very large so that one need not consider what happens near their edges.)\nIf the speed of the top plate is low enough, the fluid particles will move parallel to it, and their speed will vary linearly from zero at the bottom to u at the top. Each layer of fluid will move faster than the one just below it, and friction between them will give rise to a force resisting their relative motion. In particular, the fluid will apply on the top plate a force in the direction opposite to its motion, and an equal but opposite one to the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nThe magnitude F of this force is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc in this formula is the viscosity (specifically, the dynamic viscosity) of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second).\nThe ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). Isaac Newton expressed the viscous forces by the differential equation\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This formula assumes that the flow is moving along parallel lines to x-axis. Furthermore, it assumes that the y-axis, perpendicular to the flow, points in the direction of maximum shear velocity. This equation can be used where the velocity does not vary linearly with y, such as in fluid flowing through a pipe. This equation is called the defining equation for shear viscosity. The viscosity is not a material constant, but a material property that depends on physical properties like temperature. The functional relationship between viscosity and other physical properties is described by a mathematical viscosity model called a constitutive equation which is usually more complex than the defining equation for viscosity. There exist  many viscosity models, and based on type of development-reasoning, some viscosity models are selected and presented in the article Viscosity models for mixtures.\nUse of the Greek letter mu (\u03bc) for the dynamic stress viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC.\n\n\n=== Kinematic viscosity ===\nThe kinematic viscosity (also called \"momentum diffusivity\") is the ratio of the dynamic viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {m^{2}/s} }\n  . \n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  A convenient concept when analyzing the Reynolds number, which expresses the ratio of the inertial forces to the viscous forces, is:\n\n  \n    \n      \n        \n          R\n          e\n        \n        =\n        \n          \n            \n              \u03c1\n              V\n              D\n            \n            \u03bc\n          \n        \n        =\n        \n          \n            \n              V\n              D\n            \n            \u03bd\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathrm {Re} ={\\frac {\\rho VD}{\\mu }}={\\frac {VD}{\\nu }},}\n  where D is a diameter in the system, and V is the velocity of the fluid with respect to the object (m/s).\n\n\n=== Bulk viscosity ===\n\nWhen a compressible fluid is compressed or expanded evenly, without shear, it may still exhibit a form of internal friction that resists its flow. These forces are related to the rate of compression or expansion by a factor called the volume viscosity, bulk viscosity or second viscosity.\nThe bulk viscosity is important only when the fluid is being rapidly compressed or expanded, such as in sound and shock waves. Bulk viscosity explains the loss of energy in those waves, as described by Stokes' law of sound attenuation.\n\n\n=== Viscosity tensor ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure.\nIn very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model, the relationship is by definition a linear map, described by a viscosity tensor that, multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor.\nThe viscosity tensor has nine independent degrees of freedom in general. For isotropic Newtonian fluids, these can be reduced to two independent parameters. The most usual decomposition yields the dynamic viscosity \u03bc and the bulk viscosity \u03c3.\n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes.  It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nThe viscosity of a system is determined by how molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the Transient Time Correlation Function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, in order to calculate the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations.\n\n\n=== Gases ===\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. The kinetic theory of gases allows accurate prediction of the behavior of gaseous viscosity.\nWithin the regime where the theory is applicable:\n\nViscosity is independent of pressure and\nViscosity increases as temperature increases.James Clerk Maxwell published a famous paper in 1866 using the kinetic theory of gases to study gaseous viscosity. To understand why the viscosity is independent of pressure, consider two adjacent boundary layers (A and B) moving with respect to each other. The internal friction (the viscosity) of the gas is determined by the probability a particle of layer A enters layer B with a corresponding transfer of momentum. Maxwell's calculations show that the viscosity coefficient is proportional to the density, the mean free path, and the mean velocity of the atoms. On the other hand, the mean free path is inversely proportional to the density. So an increase in density due to an increase in pressure doesn't result in any change in viscosity.\n\n\n==== Relation to mean free path of diffusing particles ====\nIn relation to diffusion, the kinematic viscosity provides a better understanding of the behavior of mass transport of a dilute species. Viscosity is related to shear stress and the rate of shear in a fluid, which illustrates its dependence on the mean free path, \u03bb, of the diffusing particles.\nFrom fluid mechanics, for a Newtonian fluid, the shear stress, \u03c4, on a unit area moving parallel to itself, is found to be proportional to the rate of change of velocity with distance perpendicular to the unit area:\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \n                d\n              \n              \n                u\n                \n                  x\n                \n              \n            \n            \n              \n                d\n              \n              y\n            \n          \n        \n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}}\n  for a unit area parallel to the xz-plane, moving along the x axis. We will derive this formula and show how \u03bc is related to \u03bb.\nInterpreting shear stress as the time rate of change of momentum, p, per unit area A (rate of momentum flux) of an arbitrary control surface gives\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            \n              \n                p\n                \u02d9\n              \n            \n            A\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    m\n                    \u02d9\n                  \n                \n              \n              \n                \u27e8\n                \n                  u\n                  \n                    x\n                  \n                \n                \u27e9\n              \n            \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau ={\\frac {\\dot {p}}{A}}={\\frac {{\\dot {m}}\\left\\langle u_{x}\\right\\rangle }{A}}.}\n  where \u27e8ux\u27e9 is the average velocity, along the x-axis, of fluid molecules hitting the unit area, with respect to the unit area and \u1e41 is the rate of fluid mass hitting the surface.\nBy making simplified assumption that the velocity of the molecules depends linearly on the distance they are coming from, the mean velocity depends linearly on the mean distance:\n\n  \n    \n      \n        \n          \u27e8\n          \n            u\n            \n              x\n            \n          \n          \u27e9\n        \n        =\n        \u03bb\n        \n          \n            \n              \n                d\n              \n              \n                u\n                \n                  x\n                \n              \n            \n            \n              \n                d\n              \n              y\n            \n          \n        \n      \n    \n    {\\displaystyle \\left\\langle u_{x}\\right\\rangle =\\lambda {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}}\n  .\nFurther manipulation will show,\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      m\n                      \u02d9\n                    \n                  \n                \n              \n              \n                \n                =\n                \u03c1\n                \n                  \n                    \n                      u\n                      \u00af\n                    \n                  \n                \n                A\n              \n            \n            \n              \n                \u03c4\n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        \u03c1\n                        \n                          \n                            \n                              u\n                              \u00af\n                            \n                          \n                        \n                        \u03bb\n                      \n                      \u23df\n                    \n                  \n                  \n                    \u03bc\n                  \n                \n                \u22c5\n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        u\n                        \n                          x\n                        \n                      \n                    \n                    \n                      \n                        d\n                      \n                      y\n                    \n                  \n                \n                \n                \u21d2\n                \n                \u03bd\n                =\n                \n                  \n                    \u03bc\n                    \u03c1\n                  \n                \n                =\n                \n                  \n                    \n                      u\n                      \u00af\n                    \n                  \n                \n                \u03bb\n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\dot {m}}&=\\rho {\\bar {u}}A\\\\\\tau &=\\underbrace {\\rho {\\bar {u}}\\lambda } _{\\mu }\\cdot {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}\\quad \\Rightarrow \\quad \\nu ={\\frac {\\mu }{\\rho }}={\\bar {u}}\\lambda ,\\end{aligned}}}\n  where\n\n\u03c1 is the density of the fluid,\n\u016b is the root mean square molecular speed: \u016b = \u221a\u27e8u2\u27e9,\n\u03bb is the mean free path,\n\u03bc is the dynamic viscosity.Note, that the mean free path itself typically depends (inversely) on the density.\n\n\n==== Effect of temperature on the viscosity of a gas ====\nSutherland's formula can be used to derive the dynamic viscosity of an ideal gas as a function of the temperature:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              C\n            \n            \n              T\n              +\n              C\n            \n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            \n              3\n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}{\\frac {T_{0}+C}{T+C}}\\left({\\frac {T}{T_{0}}}\\right)^{\\frac {3}{2}}.}\n  This, in turn, is equal to\n\n  \n    \n      \n        \u03bc\n        =\n        \u03bb\n        \n          \n            \n              T\n              \n                \n                  3\n                  2\n                \n              \n            \n            \n              T\n              +\n              C\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\lambda {\\frac {T^{\\frac {3}{2}}}{T+C}},}\n  where\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              \n                (\n                \n                  \n                    T\n                    \n                      0\n                    \n                  \n                  +\n                  C\n                \n                )\n              \n            \n            \n              T\n              \n                0\n              \n              \n                \n                  3\n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda ={\\frac {\\mu _{0}\\left(T_{0}+C\\right)}{T_{0}^{\\frac {3}{2}}}}}\n  is a constant for the gas.\nin Sutherland's formula:\n\n\u03bc = dynamic viscosity (Pa\u00b7s or \u03bcPa\u00b7s) at input temperature T,\n\u03bc0 = reference viscosity (in the same units as \u03bc) at reference temperature T0,\nT = input temperature (K),\nT0 = reference temperature (K),\nC = Sutherland's constant for the gaseous material in question.Valid for temperatures between 0 < T < 555 K with an error due to pressure less than 10% below 3.45 MPa.\nAccording to Sutherland's formula, if the absolute temperature is less than C, the relative change in viscosity for a small change in temperature is greater than the relative change in the absolute temperature, but it is smaller when T is above C. The kinematic viscosity though always increases faster than the temperature (that is, d log(\u03bd)/d log(T) is greater than 1).\nSutherland's constant, reference values and \u03bb values for some gases:\n\n\n==== Viscosity of a dilute gas ====\nThe Chapman\u2013Enskog equation may be used to estimate viscosity for a dilute gas. This equation is based on a semi-theoretical assumption by Chapman and Enskog. The equation requires three empirically determined parameters: the collision diameter (\u03c3), the maximum energy of attraction divided by the Boltzmann constant (\u03b5/\u043a) and the collision integral (\u03c9(T*)).\n\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n        \u00d7\n        \n          10\n          \n            6\n          \n        \n        =\n        \n          2.6693\n        \n        \n          \n            \n              M\n              T\n            \n            \n              \n                \u03c3\n                \n                  2\n                \n              \n              \u03c9\n              (\n              \n                T\n                \n                  \u2217\n                \n              \n              )\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{0}\\times 10^{6}={2.6693}{\\frac {\\sqrt {MT}}{\\sigma ^{2}\\omega (T^{*})}},}\n  with\n\nT* = \u03baT/\u03b5 is reduced temperature (dimensionless),\n\u03bc0 is viscosity for dilute gas (\u03bcPa\u00b7s),\nM is molecular mass (g/mol),\nT is temperature (K),\n\u03c3 is the collision diameter (\u00c5),\n\u03b5/\u043a is the maximum energy of attraction divided by the Boltzmann constant (K),\n\u03c9\u03bc is the collision integral.\n\n\n=== Liquids ===\n\nIn liquids, the additional forces between molecules become important. This leads to an additional contribution to the shear stress though the exact mechanics of this are still controversial. Thus, in liquids:\n\nViscosity is independent of pressure (except at very high pressure); and\nViscosity tends to fall as temperature increases (for example, water viscosity goes from 1.79 cP to 0.28 cP in the temperature range from 0 \u00b0C to 100 \u00b0C); see temperature dependence of liquid viscosity for more details.The dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n==== Viscosity of blends of liquids ====\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b1\n            \n          \n        \n        +\n        \n          \n            \n              \u03b1\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b1\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\alpha }}+{\\frac {\\alpha x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\alpha }}}\n  \n\n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\nx[i]=mole_fraction[i]\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464. \nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654. \n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity and other physical properties of frequent used pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "fluidity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "Celsius",
        "clean": "Celsius",
        "text": "The Celsius scale, previously known as the centigrade scale, is a temperature scale used by the International System of Units (SI). As an SI derived unit, it is used by all countries except the United States and Liberia. It is named after the Swedish astronomer Anders Celsius (1701\u20131744), who developed a similar temperature scale. The degree Celsius (symbol: \u00b0C) can refer to a specific temperature on the Celsius scale or a unit to indicate a difference between two temperatures or an uncertainty. Before being renamed to honor Anders Celsius in 1948, the unit was called centigrade, from the Latin centum, which means 100, and gradus, which means steps.\nBefore 1954, the Celsius scale was based on 0 \u00b0C for the freezing point of water and 100 \u00b0C for the boiling point of water at 1 atm pressure following a change introduced in 1743 by Jean-Pierre Christin to reverse the Celsius thermometer scale (from water boiling at 0 degrees and ice melting at 100 degrees). This scale is widely taught in schools today. \nBy international agreement, since 1954 the unit \"degree Celsius\" and the Celsius scale are defined by absolute zero and the triple point of Vienna Standard Mean Ocean Water (VSMOW), a specially purified water. This definition also precisely relates the Celsius scale to the Kelvin scale, which defines the SI base unit of thermodynamic temperature with symbol K. Absolute zero, the lowest temperature possible, is defined as being exactly 0 K and \u2212273.15 \u00b0C. The temperature of the triple point of water is defined as exactly 273.16 K (0.01 \u00b0C). This means that a temperature difference of one degree Celsius and that of one kelvin are exactly the same.\n\n\n== History ==\n\nIn 1742, Swedish astronomer Anders Celsius (1701\u20131744) created a temperature scale that reversed the scale now known as \"Celsius\": 0 represented the boiling point of water, while 100 represented the freezing point of water. In his paper Observations of two persistent degrees on a thermometer, he recounted his experiments showing that the melting point of ice is essentially unaffected by pressure. He also determined with remarkable precision how the boiling point of water varied as a function of atmospheric pressure. He proposed that the zero point of his temperature scale, being the boiling point, would be calibrated at the mean barometric pressure at mean sea level. This pressure is known as one standard atmosphere. The BIPM's 10th General Conference on Weights and Measures (CGPM) later defined one standard atmosphere to equal precisely 1,013,250 dynes per square centimetre (101.325 kPa).In 1743, the Lyonnais physicist Jean-Pierre Christin, permanent secretary of the Acad\u00e9mie des sciences, belles-lettres et arts de LyonFR, working independently of Celsius, developed a scale where zero represented the freezing point of water and 100 represented the boiling point of water. On 19 May 1743 he published the design of a mercury thermometer, the \"Thermometer of Lyon\" built by the craftsman Pierre Casati that used this scale.In 1744, coincident with the death of Anders Celsius, the Swedish botanist Carl Linnaeus (1707\u20131778) reversed Celsius's scale. His custom-made \"linnaeus-thermometer\", for use in his greenhouses, was made by Daniel Ekstr\u00f6m, Sweden's leading maker of scientific instruments at the time, whose workshop was located in the basement of the Stockholm observatory. As often happened in this age before modern communications, numerous physicists, scientists, and instrument makers are credited with having independently developed this same scale; among them were Pehr Elvius, the secretary of the Royal Swedish Academy of Sciences (which had an instrument workshop) and with whom Linnaeus had been corresponding; Daniel Ekstr\u00f6m[SV], the instrument maker; and M\u00e5rten Str\u00f6mer (1707\u20131770) who had studied astronomy under Anders Celsius.\nThe first known Swedish document reporting temperatures in this modern \"forward\" Celsius scale is the paper Hortus Upsaliensis dated 16 December 1745 that Linnaeus wrote to a student of his, Samuel Naucl\u00e9r. In it, Linnaeus recounted the temperatures inside the orangery at the University of Uppsala Botanical Garden:\n\n...since the caldarium (the hot part of the greenhouse) by the angle of the windows, merely from the rays of the sun, obtains such heat that the thermometer often reaches 30 degrees, although the keen gardener usually takes care not to let it rise to more than 20 to 25 degrees, and in winter not under 15 degrees...\n\n\n=== Centigrade, hectograde and Celsius ===\nSince the 19th century, the scientific and thermometry communities worldwide have used the phrase \"centigrade scale\". Temperatures on the centigrade scale were often reported simply as degrees or, when greater specificity was desired, as degrees centigrade (symbol: \u00b0C). Because the term centigrade was also the Spanish and French language name for a unit of angular measurement (1/10000 of a right angle) and had a similar connotation in other languages, the term centesimal degree (known as the gradian, \"grad\" or \"gon\": 1\u1d4d = 0.9\u00b0, 100\u1d4d = 90\u00b0) was used when very precise, unambiguous language was required by international standards bodies such as the BIPM. More properly, what was defined as \"centigrade\" then would now be \"hectograde\". \nTo eliminate any confusion, the 9th CGPM and the CIPM (Comit\u00e9 international des poids et mesures) formally adopted \"degree Celsius\" in 1948, formally keeping the recognized degree symbol, rather than adopting the gradian/centesimal degree symbol.\nFor scientific use, \"Celsius\" is the term usually used, with \"centigrade\" remaining in common but decreasing use, especially in informal contexts in English-speaking countries. It was not until February 1985 that the forecasts issued by the BBC switched from \"centigrade\" to \"Celsius\".\n\n\n=== Common temperatures ===\nSome key temperatures relating the Celsius scale to other temperature scales are shown in the table below.\n\n\n== Name and symbol typesetting ==\nThe \"degree Celsius\" has been the only SI unit whose full unit name contains an uppercase letter since the SI base unit for temperature, the kelvin, became the proper name in 1967 replacing the term degrees Kelvin. The plural form is degrees Celsius.The general rule of the International Bureau of Weights and Measures (BIPM) is that the numerical value always precedes the unit, and a space is always used to separate the unit from the number, e.g. \"30.2 \u00b0C\" (not \"30.2\u00b0C\" or \"30.2\u00b0 C\"). The only exceptions to this rule are for the unit symbols for degree, minute, and second for plane angle (\u00b0, \u2032, and \u2033, respectively), for which no space is left between the numerical value and the unit symbol. Other languages, and various publishing houses, may follow different typographical rules.\n\n\n=== Unicode character ===\nUnicode provides the Celsius symbol at code point U+2103 \u2103 degree celsius. However, this is a compatibility character provided for roundtrip compatibility with legacy encodings. It easily allows correct rendering for vertically written East Asian scripts, such as Chinese. The Unicode standard explicitly discourages the use of this character: \"In normal use, it is better to represent degrees Celsius \"\u00b0C\" with a sequence of U+00B0 \u00b0 degree sign + U+0043 C latin capital letter c, rather than U+2103 \u2103 degree celsius. For searching, treat these two sequences as identical.\"Shown below is the degree Celsius character followed immediately by the two-component version:\n\n\u2103 \u00b0CWhen viewed on computers that properly support Unicode, the above line may be similar to the image in the line below (enlarged for clarity):\n\nThe canonical decomposition is simply an ordinary degree sign and \"C\", so some browsers may simply display \"\u00b0C\" in its place due to Unicode normalization.\n\n\n== Temperatures and intervals ==\nThe degree Celsius is subject to the same rules as the kelvin with regard to the use of its unit name and symbol. Thus, besides expressing specific temperatures along its scale (e.g. \"Gallium melts at 29.7646 \u00b0C\" and \"The temperature outside is 23 degrees Celsius\"), the degree Celsius is also suitable for expressing temperature intervals: differences between temperatures or their uncertainties (e.g. \"The output of the heat exchanger is hotter by 40 degrees Celsius\", and \"Our standard uncertainty is \u00b13 \u00b0C\"). Because of this dual usage, one must not rely upon the unit name or its symbol to denote that a quantity is a temperature interval; it must be unambiguous through context or explicit statement that the quantity is an interval. This is sometimes solved by using the symbol \u00b0C (pronounced \"degrees Celsius\") for a temperature, and C\u00b0 (pronounced \"Celsius degrees\") for a temperature interval, although this usage is non-standard.Celsius measurement follows an interval system but not a ratio system; and it follows a relative scale not an absolute scale. For example, 20 \u00b0C is not twice the heat energy of 10 \u00b0C; and 0 \u00b0C is not the lowest Celsius value. Thus, degrees Celsius is a useful interval measurement but does not possess the characteristics of ratio measures like weight or distance.\n\n\n== Coexistence of Kelvin and Celsius scales ==\nIn science and in engineering, the Celsius scale and the Kelvin scale are often used in combination in close contexts, e.g. \"a measured value was 0.01023 \u00b0C with an uncertainty of 70 \u00b5K\". This practice is permissible because the magnitude of the degree Celsius is equal to that of the kelvin. Notwithstanding the official endorsement provided by decision #3 of Resolution 3 of the 13th CGPM, which stated \"a temperature interval may also be expressed in degrees Celsius\", the practice of simultaneously using both \u00b0C and K remains widespread throughout the scientific world as the use of SI-prefixed forms of the degree Celsius (such as \"\u00b5\u00b0C\" or \"microdegrees Celsius\") to express a temperature interval has not been well-adopted.\n\n\n== Melting and boiling points of water ==\nOne effect of defining the Celsius scale at the triple point of Vienna Standard Mean Ocean Water (VSMOW, 273.16 K and 0.01 \u00b0C), and at absolute zero (0 K and \u2212273.15 \u00b0C), is that neither the melting nor boiling point of water under one standard atmosphere (101.325 kPa) remains a defining point for the Celsius scale. In 1948 when the 9th General Conference on Weights and Measures (CGPM) in Resolution 3 first considered using the triple point of water as a defining point, the triple point was so close to being 0.01 \u00b0C greater than water's known melting point, it was simply defined as precisely 0.01 \u00b0C. However, current measurements show that the difference between the triple and melting points of VSMOW is actually very slightly (<0.001 \u00b0C) greater than 0.01 \u00b0C. Thus, the actual melting point of ice is very slightly (less than a thousandth of a degree) below 0 \u00b0C. Also, defining water's triple point at 273.16 K precisely defined the magnitude of each 1 \u00b0C increment in terms of the absolute thermodynamic temperature scale (referencing absolute zero). Now decoupled from the actual boiling point of water, the value \"100 \u00b0C\" is hotter than 0 \u00b0C \u2013 in absolute terms \u2013 by a factor of precisely 373.15/273.15 (approximately 36.61% thermodynamically hotter). When adhering strictly to the two-point definition for calibration, the boiling point of VSMOW under one standard atmosphere of pressure is actually 373.1339 K (99.9839 \u00b0C). When calibrated to ITS-90 (a calibration standard comprising many definition points and commonly used for high-precision instrumentation), the boiling point of VSMOW is slightly less, about 99.974 \u00b0C.This boiling-point difference of 16.1 millikelvin between the Celsius scale's original definition and the current one (based on absolute zero and the triple point) has little practical meaning in common daily applications because water's boiling point is very sensitive to variations in barometric pressure. For example, an altitude change of only 28 cm (11 in) causes the boiling point to change by one millikelvin.\n\n\n== See also ==\nComparison of temperature scales\nDegrees of frost\nITS-90\nR\u00e9aumur scale\nThermodynamic temperature\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNIST, Basic unit definitions: Kelvin\nThe Uppsala Astronomical Observatory, History of the Celsius temperature scale\nLondon South Bank University, Water, scientific data\nBIPM, SI brochure, section 2.1.1.5, Unit of thermodynamic temperature\nTAMPILE, Comparison of temperature scales\nC to F converter, Celsius to Fahrenheit Converter",
        "unit": "degree celsius",
        "url": "https://en.wikipedia.org/wiki/Celsius"
    },
    {
        "_id": "Gal_(unit)",
        "clean": "Gal (unit)",
        "text": "The gal (symbol: Gal), sometimes called galileo after Galileo Galilei, is a unit of acceleration used extensively in the science of gravimetry. The gal is defined as 1 centimeter per second squared (1 cm/s2). The milligal (mGal) and microgal (\u00b5Gal) refer respectively to one thousandth and one millionth of a gal.\nThe gal is not part of the International System of Units (known by its French-language initials \"SI\"). In 1978 the CIPM decided that it was permissible to use the gal \"with the SI until the CIPM considers that [its] use is no longer necessary\".  However, use of the gal is deprecated by ISO 80000-3:2006.\nThe gal is a derived unit, defined in terms of the centimeter\u2013gram\u2013second (CGS) base unit of length, the centimeter, and the second, which is the base unit of time in both the CGS and the modern SI system. In SI base units, 1 Gal is equal to 0.01 m/s2.\nThe acceleration due to Earth\u2019s gravity (see standard gravity) at its surface is 976 to 983 Gal, the variation being due mainly to differences in latitude and elevation.  Mountains and masses of lesser density within the Earth's crust typically cause variations in gravitational acceleration of tens to hundreds of milligals (mGal). The gravity gradient (variation with height) above Earth's surface is about 3.1 \u00b5Gal per centimeter of height (3.1\u00d710\u22126 s\u22122), resulting in a maximal difference of about 2 Gal (0.02 m/s2) from the top of Mount Everest to sea level.Unless it is being used at the beginning of a sentence or in paragraph or section titles, the unit name gal is properly spelled with a lowercase g. As with the torr and its symbol, the unit name (gal) and its symbol (Gal) are spelled identically except that the latter is capitalized.\n\n\n== Conversions ==\n\n\n== See also ==\nUnits of acceleration\ng-force (g) (related to standard gravity and Earth\u2019s gravity)\nMeter per second squared (m/s2)\nFoot per second squared (ft/s2)\nRelated articles\nGravimeter\nGravimetry\nGravitation\nGravitational acceleration\nGravitational constant (G)\nGravitational field\nGravity gradiometry\n\n\n== References ==",
        "unit": "gal",
        "url": "https://en.wikipedia.org/wiki/Gal_(unit)"
    },
    {
        "_id": "Second",
        "clean": "Second",
        "text": "The second is the SI base unit of time, commonly understood and historically defined as \u200b1\u204486400 of a day \u2013 this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Another intuitive understanding is that it is about the time between beats of a human heart.  Mechanical and electric clocks and watches usually have a face with 60 tickmarks representing seconds and minutes, traversed by a second hand and minute hand.  Digital clocks and watches often have a two-digit counter that cycles through seconds.  In common parlance, a \"clock tick\" is a second, though most modern clocks are digital electronic, and do not actually tick.  The second is also part of several other units of measurement like velocity, acceleration, and frequency.\nThough the historical definition of the unit was based upon this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is  a much steadier timekeeper: 1 second is defined to be exactly 9 192 631 770 cycles of a Caesium atomic clock.\nBecause the Earth's rotation varies and is also slowing ever so slightly, a leap second is added to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths.  In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second.\nAn everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond.  Camera shutter speeds usually range from \u200b1\u204460 second to \u200b1\u2044250 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today.  Small divisions of time could not be counted back then, so such divisions were figurative.  The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century.  Starting in the 1950s, atomic clocks became better timekeepers than earth's rotation, and they continue to set the standard today.\n\n\n== Clocks and solar time ==\nA mechanical clock, one which does not depend on measuring the relative rotational position of the earth, keeps uniform time called mean time, within whatever accuracy is intrinsic to it. That means that every second, minute and every other division of time counted by the clock will be the same duration as any other identical division of time. But a sundial which measures the relative position of the sun in the sky called apparent time, does not keep uniform time.  The time kept by a sundial varies by time of year, meaning that seconds, minutes and every other division of time is a different duration at different times of the year. The time of day measured with mean time versus apparent time may differ by as much as 15 minutes, but a single day will differ from the next by only a small amount; 15 minutes is a cumulative difference over a part of the year. The effect is due chiefly to the obliqueness of earth's axis with respect to its orbit around the sun.\nThe difference between apparent solar time and mean time was recognized by astronomers since antiquity, but prior to the invention of accurate mechanical clocks in the mid-17th century, sundials were the only reliable timepieces, and apparent solar time was the generally accepted standard.\n\n\n== Events and units of time in seconds ==\nFractions of a second are usually denoted in decimal notation, i.e. 2.01 seconds, or two and one hundredth seconds. Multiples of seconds are usually expressed as minutes and seconds, or hours, minutes and seconds of clock time, separated by colons, such as 11:23:24, or 45:23 (the latter notation can give rise to ambiguity, because the same notation is used to denote hours and minutes).  It rarely makes sense to express longer periods of time like hours or days in seconds, because they are awkwardly large numbers.  For the metric unit of second, there are decimal prefixes representing 10\u221224 to 1024 seconds.\nSome common units of time in seconds are: an hour is 3,600 seconds; a day is 86,400 seconds, a week is 604,800 seconds; a year is 31,536,000 seconds; and a century is 3,153,600,000 seconds.\nSome common events in seconds are: a stone falls about 4.9 meters from rest in one second; a pendulum of length about one meter has a swing of one second, so pendulum clocks have pendulums about a meter long; the fastest human sprinters run 10 meters in a second; an ocean wave in deep water travels about 23 meters in one second; sound travels about 343 meters in one second in air; light takes 1.3 seconds to reach Earth from the surface of the Moon, a distance of 384,400 kilometers.\n\n\n== Other units incorporating seconds ==\nA second is part of other units, such as frequency measured in hertz (inverse seconds or second\u22121), speed (meters per second) and acceleration (meters per second squared).  The metric system unit becquerel, a measure of radioactive decay, is measured in inverse seconds.  The meter is defined in terms of the speed of light and the second; definitions of the metric base units ampere and candela also depend on the second. Of the 22 named derived units of the SI, only three: degree Celsius, radian, and steradian, do not depend on the second.  Many derivative units for everyday things are reported in terms of larger units of time, not seconds, such as clock time in hours and minutes, velocity of a car in miles per hour or kilometers per hour, kilowatt hours of electricity usage, and speed of a turntable in rotations per minute.\n\n\n== Timekeeping standards ==\nA set of atomic clocks throughout the world keeps time by consensus: the clocks \"vote\" on the correct time, and all voting clocks are steered to agree with the consensus, which is called International Atomic Time (TAI). TAI \"ticks\" atomic seconds.Civil time is defined to agree with the rotation of the earth. The international standard for timekeeping is Coordinated Universal Time (UTC). This time scale \"ticks\" the same atomic seconds as TAI, but inserts or omits leap seconds as necessary to correct for variations in the rate of rotation of the earth.A time scale in which the seconds are not exactly equal to atomic seconds is UT1, a form of universal time. UT1 is defined by the rotation of the earth with respect to the sun, and does not contain any leap seconds. UT1 always differs from UTC by less than a second.\n\n\n== Optical lattice clock ==\nWhile they are not yet part of any timekeeping standard, optical lattice clocks with frequencies in the visible light spectrum now exist and are the most accurate timekeepers of all.  A strontium clock with frequency 430 THz, in the red range of visible light, now holds the accuracy record: it will gain or lose less than a second in 15 billion years, which is longer than the estimated age of the universe. Such a clock can measure a change in its height of as little as 2 cm by the change in its rate due to gravitational time dilation.\n\n\n== History of definition ==\n\nThere have only ever been three definitions of the second: as a fraction of the day, as a fraction of an extrapolated year, and as the microwave frequency of a caesium atomic clock, and they have realized a sexagesimal division of the day from ancient astronomical calendars.\n\n\n=== Sexagesimal divisions of calendar time and day ===\nCivilizations in the classic period and before constructed divisions of the calendar as well as arcs according to a sexagesimal system of counting, but none used the term second, and none was a precursor to the modern second.  Sundials and water clocks were among the earliest timekeeping devices, and units of time were measured in degrees of arc.  Conceptual units of time smaller than realizable on sundials were also used.\nThere are references to 'second' as part of a lunar month in the writings of natural philosophers of the Middle Ages, but no evidence that 'seconds' were ever realizable or adopted as part of timekeeping based on the lunar calendar.\n\n\n=== Fraction of solar day ===\nThe earliest mechanical clocks which appeared starting in the 14th century had displays that divided the hour into halves, thirds, quarters and sometimes even 12 parts, but never by 60. In fact, the hour was not commonly understood to be the duration of 60 minutes. It was not practical for timekeepers to consider minutes until the first mechanical clocks that displayed minutes appeared near the end of the 16th century. By that time, sexagesimal divisions of time were well established in Europe.The earliest clocks to display seconds appeared during the last half of the 16th century. The second became accurately measurable with the development of mechanical clocks keeping mean time, as opposed to the apparent time displayed by sundials. The earliest spring-driven timepiece with a second hand which marked seconds is an unsigned clock depicting Orpheus in the Fremersdorf collection, dated between 1560 and 1570. During the 3rd quarter of the 16th century, Taqi al-Din built a clock with marks every 1/5 minute.\nIn 1579, Jost B\u00fcrgi built a clock for William of Hesse that marked seconds. In 1581, Tycho Brahe redesigned clocks that displayed minutes at his observatory so they also displayed seconds. However, they were not yet accurate enough for seconds. In 1587, Tycho complained that his four clocks disagreed by plus or minus four seconds.\nIn 1656, Dutch scientist Christiaan Huygens invented the first pendulum clock. It had a pendulum length of just under a meter which gave it a swing of one second, and an escapement that ticked every second. It was the first clock that could accurately keep time in seconds. By the 1730s, 80 years later, John Harrison's maritime chronometers could keep time accurate to within one second in 100 days.\nIn 1832, Gauss proposed using the second as the base unit of time in his millimeter-milligram-second system of units. The British Association for the Advancement of Science (BAAS) in 1862 stated that \"All men of science are agreed to use the second of mean solar time as the unit of time.\" BAAS formally proposed the CGS system in 1874, although this system was gradually replaced over the next 70 years by MKS units. Both the CGS and MKS systems used the same second as their base unit of time. MKS was adopted internationally during the 1940s, defining the second as \u200b1\u204486,400 of a mean solar day.\n\n\n=== Fraction of an ephemeris year ===\n\nSome time in the late 1940s, quartz crystal oscillator clocks with an operating frequency of ~100 kHz advanced to keep time with accuracy better than 1 part in 108 over an operating period of a day.  It became apparent that a consensus of such clocks kept better time than the rotation of the Earth. Metrologists also knew that Earth's orbit around the Sun (a year) was much more stable than earth's rotation. This led to proposals as early as 1950 to define the second as a fraction of a year.\nThe Earth's motion was described in Newcomb's Tables of the Sun (1895), which provided a formula for estimating the motion of the Sun relative to the epoch 1900 based on astronomical observations made between 1750 and 1892. This resulted in adoption of an ephemeris time scale expressed in units of the sidereal year at that epoch by the IAU in 1952. This extrapolated timescale brings the observed positions of the celestial bodies into accord with Newtonian dynamical theories of their motion. In 1955, the tropical year, considered more fundamental than the sidereal year, was chosen by the IAU as the unit of time. The tropical year in the definition was not measured but calculated from a formula describing a mean tropical year that decreased linearly over time.\nIn 1956, the second was redefined in terms of a year relative to that epoch. The second was thus defined as \"the fraction \u200b1\u204431,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time\". This definition was adopted as part of the International System of Units in 1960.\n\n\n=== \"Atomic\" second ===\nBut even the best mechanical, electric motorized and quartz crystal-based clocks develop discrepancies, and virtually none are good enough to realize an ephemeris second. Far better for timekeeping is the natural and exact \"vibration\" in an energized atom. The frequency of vibration (i.e., radiation) is very specific depending on the type of atom and how it is excited. Since 1967, the second has been defined as exactly 9,192,631,770 times the period of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom. This length of a second was selected to correspond exactly to the length of the ephemeris second previously defined. Atomic clocks use such a frequency to measure seconds by counting cycles per second at that frequency. Radiation of this kind is one of the most stable and reproducible phenomena of nature. The current generation of atomic clocks is accurate to within one second in a few hundred million years.\nAtomic clocks now set the length of a second and the time standard for the world.\n\n\n== SI multiples ==\nSI prefixes are commonly used to measure time less than a second, but rarely for multiples of a second (which is known as metric time). Instead, the non-SI units minutes, hours, days, Julian years, Julian centuries, and Julian millennia are used.\n\n\n== See also ==\n\nOrders of magnitude (time)\nTime standard\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNational Physical Laboratory: Trapped ion optical frequency standards \nHigh-accuracy strontium ion optical clock; National Physical Laboratory (2005)\nNational Research Council of Canada: Optical frequency standard based on a single trapped ion\nNIST: Definition of the second; notice the cesium atom must be in its ground state at 0 K\nOfficial BIPM definition of the second\nThe leap second: its history and possible future\nWhat is a Cesium atom clock?\nAccuracy of the time \u2014 Astronoo",
        "unit": "second",
        "url": "https://en.wikipedia.org/wiki/Second"
    },
    {
        "_id": "Rad_(unit)",
        "clean": "Rad (unit)",
        "text": "The rad is a unit of absorbed radiation dose, defined as 1 rad = 0.01 Gy = 0.01 J/kg. It was originally defined in CGS units in 1953 as the dose causing 100 ergs of energy to be absorbed by one gram of matter. It has been replaced by the gray (Gy) in SI derived units but is still used in the United States, though \"strongly discouraged\" in the chapter 5.2 of style guide for U.S. National Institute of Standards and Technology authors. A related unit, the roentgen, is used to quantify the radiation exposure. The F-factor can be used to convert between rads and roentgens.\nThe material absorbing the radiation can be human tissue or silicon microchips or any other medium (for example, air, water, lead shielding, etc.).\n\n\n== Health effects ==\n\nA dose of under 100 rad will typically produce no immediate symptoms other than blood changes. 100 to 200 rad delivered to the entire body in less than a day may cause acute radiation syndrome, (ARS) but is usually not fatal. Doses of 200 to 1,000 rad delivered in a few hours will cause serious illness with poor outlook at the upper end of the range. Whole body doses of more than 1,000 rad are almost invariably fatal. Therapeutic doses of radiation therapy are often given and well tolerated even at higher doses to treat discrete and well defined anatomical structures.  The same dose given over a longer period of time is less likely to cause ARS. Dose thresholds are about 50% higher for dose rates of 20 rad/h, and even higher for lower dose rates.Radiation increases the risk of cancer and other stochastic effects at any dose. The International Commission on Radiological Protection maintains a model of these risks as a function of absorbed dose and other factors. That model calculates an effective radiation dose, measured units of rem, which is more representative of the stochastic risk than the absorbed dose in rad. In most power plant scenarios, where the radiation environment is dominated by gamma or x rays applied uniformly to the whole body, 1 rad of absorbed dose gives 1 rem of effective dose. In other situations, the effective dose in rem might be thirty times higher or thousands of time lower than the absorbed dose in rad.\n\n\n== Material effects ==\nSilicon-based microelectronics break down under exposure to radiation. Radiation-hardened components designed for military or nuclear applications can survive up to 100 Mrad (1 MGy).Metals creep, harden, and become brittle under the effect of radiation.\nFoods and medical equipment can be sterilized with radiation.\n\n\n== Dose examples ==\n\n\n== History ==\nIn the 1930s the roentgen was the most commonly used unit of radiation exposure. This unit is obsolete and no longer clearly defined. One roentgen deposits 0.877 rad in dry air, 0.96 rad in soft tissue, or anywhere from 1 to more than 4 rad in bone depending on the beam energy.  These conversions to absorbed energy all depend on the ionizing energy of a standard medium, which is ambiguous in the latest NIST definition. Even where the standard medium is fully defined, the ionizing energy is often not precisely known.\nIn 1940, British physicist Louis Harold Gray, who had been studying the effect of neutron damage on human tissue, together with William Valentine Mayneord and John Read published a paper in which a unit of measure, dubbed the \"gram roentgen\" (symbol: gr) defined as \"that amount of neutron radiation which produces an increment in energy in unit volume of tissue equal to the increment of energy produced in unit volume of water by one roentgen of radiation\" was proposed. This unit was found to be equivalent to 88 ergs in air. It marked a shift towards measurements based on energy rather than charge.\nThe R\u00f6ntgen equivalent physical (rep), introduced by Herbert Parker in 1945, was the absorbed energetic dose to tissue before factoring in relative biological effectiveness. The rep has variously been defined as 83 or 93 ergs per gram of tissue (8.3/9.3 mGy) or per cc of tissue.In 1953 the ICRU recommended the rad, equal to 100 erg/g as a new unit of absorbed radiation, but then promoted a switch to the gray in the 1970s.\nThe International Committee for Weights and Measures (CIPM) has not accepted the use of the rad. From 1977 to 1998, the US NIST's translations of the SI brochure stated that the CIPM had temporarily accepted the use of the rad (and other radiology units) with SI units since 1969. However, the only related CIPM decisions shown in the appendix are with regards to the curie in 1964 and the radian (symbol: rad) in 1960. The NIST brochures redefined the rad as 0.01 Gy. The CIPM's current SI brochure excludes the rad from the tables of non-SI units accepted for use with the SI. The US NIST clarified in 1998 that it was providing its own interpretations of the SI system, whereby it accepted the rad for use in the US with the SI, while recognizing that the CIPM did not. NIST recommends defining the rad in relation to SI units in every document where this unit is used. Nevertheless, use of the rad remains widespread in the US, where it is still an industry standard. Although the United States Nuclear Regulatory Commission still permits the use of the units curie, rad, and rem alongside SI units, the European Union required that its use for \"public health ... purposes\" be phased out by 31 December 1985.\n\n\n== Radiation-related quantities ==\nThe following table shows radiation quantities in SI and non-SI units:\n\n\n== See also ==\nBecquerel\nCurie (unit)\nRadiation\nGray (unit)\nRoentgen (unit)\nRoentgen equivalent man (rem)\nSievert\nOrder of magnitude (unit)\n\n\n== References ==",
        "unit": "rad",
        "url": "https://en.wikipedia.org/wiki/Rad_(unit)"
    },
    {
        "_id": "Torque",
        "clean": "Torque",
        "text": "Torque, moment, or moment of force is rotational force. Just as a linear force is a push or a pull, a torque can be thought of as a twist to an object. In three dimensions, the torque is a pseudovector; for point particles, it is given by the cross product of the position vector (distance vector) and the force vector.\nThe symbol for torque is typically \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n  , the lowercase Greek letter tau. When it is called moment of force, it is commonly denoted by M.\nThe magnitude of torque of a rigid body depends on three quantities: the force applied, the lever arm vector connecting the origin to the point of force application, and the angle between the force and lever arm vectors. In symbols:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} \\,\\!}\n  \n  \n    \n      \n        \u03c4\n        =\n        \u2016\n        \n          r\n        \n        \u2016\n        \n        \u2016\n        \n          F\n        \n        \u2016\n        sin\n        \u2061\n        \u03b8\n        \n        \n      \n    \n    {\\displaystyle \\tau =\\|\\mathbf {r} \\|\\,\\|\\mathbf {F} \\|\\sin \\theta \\,\\!}\n  where\n\n  \n    \n      \n        \n          \u03c4\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n   is the torque vector and \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is the magnitude of the torque,\nr is the position vector (a vector from the origin of the coordinate system defined to the point where the force is applied)\nF is the force vector,\n\u00d7 denotes the cross product, which is defined as magnitudes of the respective vectors times sin \u03b8.\n\u03b8 is the angle between the force vector and the lever arm vector.The SI unit for torque is N\u22c5m. For more on the units of torque, see Units.\n\n\n== Defining terminology ==\n\nTorque is referred to using different vocabulary depending on geographical location and field of study. This article refers to the definition used in US physics in its usage of the word torque. In the UK and in US mechanical engineering, torque is referred to as moment of force, usually shortened to moment. In US physics and UK physics terminology these terms are interchangeable, unlike in US mechanical engineering, where the term torque is used for the closely related \"resultant moment of a couple\".Torque is defined mathematically as the rate of change of angular momentum of an object. The definition of torque states that one or both of the angular velocity or the moment of inertia of an object are changing. Moment is the general term used for the tendency of one or more applied forces to rotate an object about an axis, but not necessarily to change the angular momentum of the object (the concept which is called torque in physics). For example, a rotational force applied to a shaft causing acceleration, such as a drill bit accelerating from rest, results in a moment called a torque. By contrast, a lateral force on a beam produces a moment (called a bending moment), but since the angular momentum of the beam is not changing, this bending moment is not called a torque. Similarly with any force couple on an object that has no change to its angular momentum, such moment is also not called a torque.\nThis article follows the US physics terminology by calling all moments by the term torque, whether or not they cause the angular momentum of an object to change.\n\n\n== History ==\nThe concept of torque, also called moment or couple, originated with the studies of Archimedes on levers. The term torque was apparently introduced into English scientific literature by James Thomson, the brother of Lord Kelvin, in 1884.\n\n\n== Definition and relation to angular momentum ==\n\nA force applied at a right angle to a lever multiplied by its distance from the lever's fulcrum (the length of the lever arm) is its torque. A force of three newtons applied two metres from the fulcrum, for example, exerts the same torque as a force of one newton applied six metres from the fulcrum. The direction of the torque can be determined by using the right hand grip rule: if the fingers of the right hand are curled from the direction of the lever arm to the direction of the force, then the thumb points in the direction of the torque.More generally, the torque on a particle (which has the position r in some reference frame) can be defined as the cross product:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} ,}\n  where r is the particle's position vector relative to the fulcrum, and F is the force acting on the particle. The magnitude \u03c4 of the torque is given by\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        F\n        sin\n        \u2061\n        \u03b8\n        ,\n        \n      \n    \n    {\\displaystyle \\tau =rF\\sin \\theta ,\\!}\n  where r is the distance from the axis of rotation to the particle, F is the magnitude of the force applied, and \u03b8 is the angle between the position and force vectors. Alternatively,\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        \n          F\n          \n            \u22a5\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =rF_{\\perp },}\n  where F\u22a5 is the amount of force directed perpendicularly to the position of the particle. Any force directed parallel to the particle's position vector does not produce a torque.It follows from the properties of the cross product that the torque vector is perpendicular to both the position and force vectors. The torque vector points along the axis of the rotation that the force vector (starting from rest) would initiate. The resulting torque vector direction is determined by the right-hand rule.The unbalanced torque on a body along axis of rotation determines the rate of change of the body's angular momentum,\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}}\n  where L is the angular momentum vector and t is time. If multiple torques are acting on the body, it is instead the net torque which determines the rate of change of the angular momentum:\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        \u22ef\n        +\n        \n          \n            \u03c4\n          \n          \n            n\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}+\\cdots +{\\boldsymbol {\\tau }}_{n}={\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}.}\n  For the motion of a point particle,\n\n  \n    \n      \n        \n          L\n        \n        =\n        I\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {L} =I{\\boldsymbol {\\omega }},}\n  where I is the moment of inertia and \u03c9 is the angular velocity. It follows that\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              (\n              I\n              \n                \u03c9\n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        I\n        \n          \n            \n              \n                d\n              \n              \n                \u03c9\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              I\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        \n          \n            \n              \n                d\n              \n              (\n              m\n              \n                r\n                \n                  2\n                \n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        2\n        r\n        \n          p\n          \n            \n              |\n            \n            \n              |\n            \n          \n        \n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} (I{\\boldsymbol {\\omega }})}{\\mathrm {d} t}}=I{\\frac {\\mathrm {d} {\\boldsymbol {\\omega }}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} I}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+{\\frac {\\mathrm {d} (mr^{2})}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+2rp_{||}{\\boldsymbol {\\omega }},}\n  where \u03b1 is the angular acceleration of the particle, and p|| is the radial component of its linear momentum. This equation is the rotational analogue of Newton's Second Law for point particles, and is valid for any type of trajectory. Note that although force and acceleration are always parallel and directly proportional, the torque \u03c4 need not be parallel or directly proportional to the angular acceleration \u03b1. This arises from the fact that although mass is always conserved, the moment of inertia in general is not.\n\n\n=== Proof of the equivalence of definitions ===\nThe definition of angular momentum for a single particle is:\n\n  \n    \n      \n        \n          L\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          p\n        \n      \n    \n    {\\displaystyle \\mathbf {L} =\\mathbf {r} \\times {\\boldsymbol {p}}}\n  where \"\u00d7\" indicates the vector cross product, p is the particle's linear momentum, and r is the displacement vector from the origin (the origin is assumed to be a fixed location anywhere in space). The time-derivative of this is:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times {\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}\\times {\\boldsymbol {p}}.}\n  This result can easily be proven by splitting the vectors into components and applying the product rule. Now using the definition of force \n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} ={\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}}\n   (whether or not mass is constant) and the definition of velocity \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          v\n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}=\\mathbf {v} }\n  \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} +\\mathbf {v} \\times {\\boldsymbol {p}}.}\n  The cross product of momentum \n  \n    \n      \n        \n          p\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {p}}}\n   with its associated velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is zero because velocity and momentum are parallel, so the second term vanishes.\nBy definition, torque \u03c4 = r \u00d7 F. Therefore, torque on a particle is equal to the\nfirst derivative of its angular momentum with respect to time.\nIf multiple forces are applied, Newton's second law instead reads Fnet = ma, and it follows that\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} _{\\mathrm {net} }={\\boldsymbol {\\tau }}_{\\mathrm {net} }.}\n  This is a general proof.\n\n\n== Units ==\nTorque has dimension force times distance, symbolically L2MT\u22122. Official SI literature suggests using the unit newton metre (N\u22c5m) or the unit joule per radian. The unit newton metre is properly denoted N\u22c5m or N m. This avoids ambiguity with mN, millinewtons.\nThe SI unit for energy or work is the joule. It is dimensionally equivalent to a force of one newton acting over a distance of one metre, but it is not used for torque. Energy and torque are entirely different concepts, so the practice of using different unit names (i.e., reserving newton metres for torque and using only joules for energy) helps avoid mistakes and misunderstandings. The dimensional equivalence of these units is not simply a coincidence: a torque of 1 N\u22c5m applied through a full revolution will require an energy of exactly 2\u03c0 joules. Mathematically,\n\n  \n    \n      \n        E\n        =\n        \u03c4\n        \u03b8\n         \n      \n    \n    {\\displaystyle E=\\tau \\theta \\ }\n  where E is the energy, \u03c4 is magnitude of the torque, and \u03b8 is the angle moved (in radians). This equation motivates the alternate unit name joules per radian.In Imperial units, \"pound-force-feet\" (lbf\u22c5ft), \"foot-pounds-force\", \"inch-pounds-force\", \"ounce-force-inches\" (ozf\u22c5in) are used, and other non-SI units of torque includes \"metre-kilograms-force\". For all these units, the word \"force\" is often left out. For example, abbreviating \"pound-force-foot\" to simply \"pound-foot\" (in this case, it would be implicit that the \"pound\" is pound-force and not pound-mass). This is an example of the confusion caused by the use of English units that may be avoided with SI units because of the careful distinction in SI between force (in newtons) and mass (in kilograms).\nTorque is sometimes listed with units that do not make dimensional sense, such as the gram-centimeter. In this case, \"gram\" should be understood as the force given by the weight of 1 gram on the surface of the Earth (i.e. 0.00980665 N). The surface of the Earth has a standard gravitational field strength of 9.80665 N/kg.\n\n\n== Special cases and other facts ==\n\n\n=== Moment arm formula ===\n\nA very useful special case, often given as the definition of torque in fields other than physics, is as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          moment arm\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{moment arm}})({\\text{force}}).}\n  The construction of the \"moment arm\" is shown in the figure to the right, along with the vectors r and F mentioned above. The problem with this definition is that it does not give the direction of the torque but only the magnitude, and hence it is difficult to use in three-dimensional cases. If the force is perpendicular to the displacement vector r, the moment arm will be equal to the distance to the centre, and torque will be a maximum for the given force. The equation for the magnitude of a torque, arising from a perpendicular force:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          distance to centre\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{distance to centre}})({\\text{force}}).}\n  For example, if a person places a force of 10 N at the terminal end of a wrench that is 0.5 m long (or a force of 10 N exactly 0.5 m from the twist point of a wrench of any length), the torque will be 5 N.m \u2013 assuming that the person moves the wrench by applying force in the plane of movement and perpendicular to the wrench.\n\n\n=== Static equilibrium ===\nFor an object to be in static equilibrium, not only must the sum of the forces be zero, but also the sum of the torques (moments) about any point. For a two-dimensional situation with horizontal and vertical forces, the sum of the forces requirement is two equations: \u03a3H = 0 and \u03a3V = 0, and the torque a third equation: \u03a3\u03c4 = 0. That is, to solve statically determinate equilibrium problems in two-dimensions, three equations are used.\n\n\n=== Net force versus torque ===\nWhen the net force on the system is zero, the torque measured from any point in space is the same. For example, the torque on a current-carrying loop in a uniform magnetic field is the same regardless of your point of reference. If the net force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   is not zero, and \n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}}\n   is the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}}\n  , then the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}}\n   is \u2026\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        (\n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u2212\n        \n          \n            r\n          \n          \n            2\n          \n        \n        )\n        \u00d7\n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{2}={\\boldsymbol {\\tau }}_{1}+(\\mathbf {r} _{1}-\\mathbf {r} _{2})\\times \\mathbf {F} }\n  \n\n\n== Machine torque ==\n\nTorque is part of the basic specification of an engine: the power output of an engine is expressed as its torque multiplied by its rotational speed of the axis. Internal-combustion engines produce useful torque only over a limited range of rotational speeds (typically from around 1,000\u20136,000 rpm for a small car). The varying torque output over that range can be  measured with a dynamometer, and shown as a torque curve.\nSteam engines and electric motors tend to produce maximum torque close to zero rpm, with the torque diminishing as rotational speed rises (due to increasing friction and other constraints). Reciprocating steam engines and electric motors can start heavy loads from zero RPM without a clutch.\n\n\n== Relationship between torque, power, and energy ==\nIf a force is allowed to act through a distance, it is doing mechanical work. Similarly, if torque is allowed to act through a rotational distance, it is doing work. Mathematically, for rotation about a fixed axis through the center of mass,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n         \n        \n          d\n        \n        \u03b8\n        ,\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\ \\mathrm {d} \\theta ,}\n  where W is work, \u03c4 is torque, and \u03b81 and \u03b82 represent (respectively) the initial and final angular positions of the body.\n\n\n=== Proof ===\nThe work done by a variable force acting over a finite linear displacement \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is given by integrating the force with respect to an elemental linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n  \n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {s}}}\n  However, the infinitesimal linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n   is related to a corresponding angular displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {\\theta }}}\n   and the radius vector \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   as \n\n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n        =\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}=\\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  Substitution in the above expression for work gives\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  The expression \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n   is a scalar triple product given by \n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]}\n  . An alternate expression for the same scalar triple product is\n\n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]={\\vec {r}}\\times {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  But as per the definition of torque,\n\n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\tau }}={\\vec {r}}\\times {\\vec {F}}}\n  Corresponding substitution in the expression of work gives,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  Since the parameter of integration has been changed from linear displacement to angular displacement, the limits of the integration also change correspondingly, giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  If the torque and the angular displacement are in the same direction, then the scalar product reduces to a product of magnitudes; i.e., \n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        =\n        \n          |\n          \n            \n              \n                \u03c4\n                \u2192\n              \n            \n          \n          |\n        \n        \n          |\n          \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n          \n          |\n        \n        cos\n        \u2061\n        0\n        =\n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle {\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}=\\left|{\\vec {\\tau }}\\right|\\left|\\,\\mathrm {d} {\\vec {\\theta }}\\right|\\cos 0=\\tau \\,\\mathrm {d} \\theta }\n   giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\,\\mathrm {d} \\theta }\n  It follows from the work-energy theorem that W also represents the change in the rotational kinetic energy Er of the body, given by\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        I\n        \n          \u03c9\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle E_{\\mathrm {r} }={\\tfrac {1}{2}}I\\omega ^{2},}\n  where I is the moment of inertia of the body and \u03c9 is its angular speed.Power is the work per unit time, given by\n\n  \n    \n      \n        P\n        =\n        \n          \u03c4\n        \n        \u22c5\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle P={\\boldsymbol {\\tau }}\\cdot {\\boldsymbol {\\omega }},}\n  where P is power, \u03c4 is torque, \u03c9 is the angular velocity, and \u22c5 represents the scalar product.\nAlgebraically, the equation may be rearranged to compute torque for a given angular speed and power output. Note that the power injected by the torque depends only on the instantaneous angular speed \u2013 not on whether the angular speed increases, decreases, or remains constant while the torque is being applied (this is equivalent to the linear case where the power injected by a force depends only on the instantaneous speed \u2013 not on the resulting acceleration, if any).\nIn practice, this relationship can be observed in bicycles: Bicycles are typically composed of two road wheels, front and rear gears (referred to as sprockets) meshing with a circular chain, and a derailleur mechanism if the bicycle's transmission system allows multiple gear ratios to be used (i.e. multi-speed bicycle), all of which attached to the frame. A cyclist, the person who rides the bicycle, provides the input power by turning pedals, thereby cranking the front sprocket (commonly referred to as chainring). The input power provided by the cyclist is equal to the product of cadence (i.e. the number of pedal revolutions per minute) and the torque on spindle of the bicycle's crankset. The bicycle's drivetrain transmits the input power to the road wheel, which in turn conveys the received power to the road as the output power of the bicycle. Depending on the gear ratio of the bicycle, a (torque, rpm)input pair is converted to a (torque, rpm)output pair. By using a larger rear gear, or by switching to a lower gear in multi-speed bicycles, angular speed of the road wheels is decreased while the torque is increased, product of which (i.e. power) does not change.\nConsistent units must be used. For metric SI units, power is watts, torque is newton metres and angular speed is radians per second (not rpm and not revolutions per second).\nAlso, the unit newton metre is dimensionally equivalent to the joule, which is the unit of energy. However, in the case of torque, the unit is assigned to a vector, whereas for energy, it is assigned to a scalar.\n\n\n=== Conversion to other units ===\nA conversion factor may be necessary when using different units of power or torque.  For example, if rotational speed (revolutions per time) is used in place of angular speed (radians per time), we multiply by a factor of 2\u03c0 radians per revolution. In the following formulas, P is power, \u03c4 is torque, and \u03bd (Greek letter nu) is rotational speed.\n\n  \n    \n      \n        P\n        =\n        \u03c4\n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \u03bd\n      \n    \n    {\\displaystyle P=\\tau \\cdot 2\\pi \\cdot \\nu }\n  Showing units:\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \u03c4\n        \n          \n            (\n            N\n            \u22c5\n            m\n            )\n          \n        \n        \u22c5\n        2\n        \u03c0\n        \n          \n            (\n            r\n            a\n            d\n            \n              /\n            \n            r\n            e\n            v\n            )\n          \n        \n        \u22c5\n        \u03bd\n        \n          \n            (\n            r\n            e\n            v\n            \n              /\n            \n            s\n            e\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})=\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rev/sec)}}}\n  Dividing by 60 seconds per minute gives us the following.\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  N\n                  \u22c5\n                  m\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              \n                \n                  (\n                  r\n                  p\n                  m\n                  )\n                \n              \n            \n            60\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})={\\frac {\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rpm)}}}{60}}}\n  where rotational speed is in revolutions per minute (rpm).\nSome people (e.g., American automotive engineers) use horsepower (imperial mechanical) for power, foot-pounds (lbf\u22c5ft) for torque and rpm for rotational speed. This results in the formula changing to:\n\n  \n    \n      \n        P\n        (\n        \n          \n            h\n            p\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  l\n                  b\n                  f\n                  \u22c5\n                  f\n                  t\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              (\n              \n                \n                  r\n                  p\n                  m\n                \n              \n              )\n            \n            \n              33\n              ,\n              000\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P({\\rm {hp}})={\\frac {\\tau {\\rm {(lbf\\cdot ft)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu ({\\rm {rpm}})}{33,000}}.}\n  The constant below (in foot pounds per minute) changes with the definition of the horsepower; for example, using metric horsepower, it becomes approximately 32,550.\nUse of other units (e.g., BTU per hour for power) would require a different custom conversion factor.\n\n\n=== Derivation ===\nFor a rotating object, the linear distance covered at the circumference of rotation is the product of the radius with the angle covered.  That is:  linear distance = radius \u00d7 angular distance.   And by definition, linear distance = linear speed \u00d7 time = radius \u00d7 angular speed \u00d7 time.\nBy the definition of torque: torque = radius \u00d7 force. We can rearrange this to determine force = torque \u00f7 radius. These two values can be substituted into the definition of power:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        force\n                      \n                      \u22c5\n                      \n                        linear distance\n                      \n                    \n                    time\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        (\n                        \n                          \n                            \n                              torque\n                              r\n                            \n                          \n                        \n                        )\n                      \n                      \u22c5\n                      (\n                      r\n                      \u22c5\n                      \n                        angular speed\n                      \n                      \u22c5\n                      t\n                      )\n                    \n                    t\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                \n                  angular speed\n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\frac {{\\text{force}}\\cdot {\\text{linear distance}}}{\\text{time}}}\\\\[6pt]&={\\frac {\\left({\\dfrac {\\text{torque}}{r}}\\right)\\cdot (r\\cdot {\\text{angular speed}}\\cdot t)}{t}}\\\\[6pt]&={\\text{torque}}\\cdot {\\text{angular speed}}.\\end{aligned}}}\n  The radius r and time t have dropped out of the equation.  However, angular speed must be in radians, by the assumed direct relationship between linear speed and angular speed at the beginning of the derivation.  If the rotational speed is measured in revolutions per unit of time, the linear speed and distance are increased proportionately by 2\u03c0 in the above derivation to give:\n\n  \n    \n      \n        \n          power\n        \n        =\n        \n          torque\n        \n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \n          rotational speed\n        \n        .\n        \n      \n    \n    {\\displaystyle {\\text{power}}={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}.\\,}\n  If torque is in newton metres and rotational speed in revolutions per second, the above equation gives power in newton metres per second or watts.  If Imperial units are used, and if torque is in pounds-force feet and rotational speed in revolutions per minute, the above equation gives power in foot pounds-force per minute.  The horsepower form of the equation is then derived by applying the conversion factor 33,000 ft\u22c5lbf/min per horsepower:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                2\n                \u03c0\n                \u22c5\n                \n                  rotational speed\n                \n                \u22c5\n                \n                  \n                    \n                      \n                        ft\n                      \n                      \u22c5\n                      \n                        lbf\n                      \n                    \n                    min\n                  \n                \n                \u22c5\n                \n                  \n                    horsepower\n                    \n                      33\n                      ,\n                      000\n                      \u22c5\n                      \n                        \n                          \n                            \n                              ft\n                            \n                            \u22c5\n                            \n                              lbf\n                            \n                          \n                          min\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2248\n                \n                  \n                    \n                      \n                        torque\n                      \n                      \u22c5\n                      \n                        RPM\n                      \n                    \n                    \n                      5\n                      ,\n                      252\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}\\cdot {\\frac {\\text{horsepower}}{33,000\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}}}\\\\[6pt]&\\approx {\\frac {{\\text{torque}}\\cdot {\\text{RPM}}}{5,252}}\\end{aligned}}}\n  because \n  \n    \n      \n        5252.113122\n        \u2248\n        \n          \n            \n              33\n              ,\n              000\n            \n            \n              2\n              \u03c0\n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle 5252.113122\\approx {\\frac {33,000}{2\\pi }}.\\,}\n  \n\n\n== Principle of moments ==\nThe Principle of Moments, also known as Varignon's theorem (not to be confused with the geometrical theorem of the same name) states that the sum of torques due to several forces applied to a single point is equal to the torque due to the sum (resultant) of the forces. Mathematically, this follows from:\n\n  \n    \n      \n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            1\n          \n        \n        )\n        +\n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            2\n          \n        \n        )\n        +\n        \u22ef\n        =\n        \n          r\n        \n        \u00d7\n        (\n        \n          \n            F\n          \n          \n            1\n          \n        \n        +\n        \n          \n            F\n          \n          \n            2\n          \n        \n        +\n        \u22ef\n        )\n        .\n      \n    \n    {\\displaystyle (\\mathbf {r} \\times \\mathbf {F} _{1})+(\\mathbf {r} \\times \\mathbf {F} _{2})+\\cdots =\\mathbf {r} \\times (\\mathbf {F} _{1}+\\mathbf {F} _{2}+\\cdots ).}\n  \n\n\n== Torque multiplier ==\n\nTorque can be multiplied via three methods:  by locating the fulcrum such that the length of a lever is increased; by using a longer lever; or by the use of a speed reducing gearset or gear box.  Such a mechanism multiplies torque, as rotation rate is reduced.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\"Horsepower and Torque\" An article showing how power, torque, and gearing affect a vehicle's performance.\n\"Torque vs. Horsepower: Yet Another Argument\" An automotive perspective\nTorque and Angular Momentum in Circular Motion  on Project PHYSNET.\nAn interactive simulation of torque\nTorque Unit Converter\nA feel for torque An order-of-magnitude interactive.",
        "unit": "torque",
        "url": "https://en.wikipedia.org/wiki/Torque"
    },
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "minute of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Frequency",
        "clean": "Frequency",
        "text": "Frequency is the number of occurrences of a repeating event per unit of time. It is also referred to as temporal frequency, which emphasizes the contrast to spatial frequency and angular frequency. The period is the duration of time of one cycle in a repeating event, so the period is the reciprocal of the frequency.  For example, if a newborn baby's heart beats at a frequency of 120 times a minute, its period\u2014the time interval between beats\u2014is half a second (that is, 60 seconds divided by 120 beats).  Frequency is an important parameter used in science and engineering to specify the rate of oscillatory and vibratory phenomena, such as mechanical vibrations, audio signals (sound), radio waves, and light.\n\n\n== Definitions ==\n\nFor cyclical processes, such as rotation, oscillations, or waves, frequency is defined as a number of cycles per unit time. In physics and engineering disciplines, such as optics, acoustics, and radio, frequency is usually denoted by a Latin letter f or by the Greek letter \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   or \u03bd (nu) (see e.g. Planck's formula).\nThe relation between the frequency and the period \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   of a repeating event or oscillation is given by\n\n  \n    \n      \n        f\n        =\n        \n          \n            1\n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {1}{T}}.}\n  \n\n\n== Units ==\nThe SI derived unit of frequency is the hertz (Hz), named after the German physicist Heinrich Hertz. One hertz means that an event repeats once per second. A previous name for this unit was cycles per second (cps). The SI unit for period is the second.\nA traditional unit of measure used with rotating mechanical devices is revolutions per minute, abbreviated r/min or rpm. 60 rpm equals one hertz.\n\n\n== Period versus frequency ==\nAs a matter of convenience, longer and slower waves, such as ocean surface waves, tend to be described by wave period rather than frequency. Short and fast waves, like audio and radio, are usually described by their frequency instead of period. These commonly used conversions are listed below:\n\n\n== Related types of frequency ==\n\nAngular frequency, usually denoted by the Greek letter \u03c9 (omega), is defined as the rate of change of angular displacement, \u03b8, (during rotation), or the rate of change of the phase of a sinusoidal waveform (notably in oscillations and waves), or as the rate of change of the argument to the sine function:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        =\n        sin\n        \u2061\n        (\n        2\n        \n          \u03c0\n        \n        f\n        t\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t)\\right)=\\sin(\\omega t)=\\sin(2\\mathrm {\\pi } ft)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03c9\n        =\n        2\n        \n          \u03c0\n        \n        f\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} t}}=\\omega =2\\mathrm {\\pi } f}\n  Angular frequency is commonly measured in radians per second (rad/s) but, for discrete-time signals, can also be expressed as radians per sampling interval, which is a dimensionless quantity.  Angular frequency (in radians) is larger than regular frequency (in Hz) by a factor of 2\u03c0.Spatial frequency is analogous to temporal frequency, but the time axis is replaced by one or more spatial displacement axes. E.g.:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            ,\n            x\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        +\n        k\n        x\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t,x)\\right)=\\sin(\\omega t+kx)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              x\n            \n          \n        \n        =\n        k\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} x}}=k}\n  Wavenumber, k, is the spatial frequency analogue of angular temporal frequency and is measured in radians per meter. In the case of more than one spatial dimension, wavenumber is a vector quantity.\n\n\n== In wave propagation ==\n\nFor periodic waves in nondispersive media (that is, media in which the wave speed is independent of frequency), frequency has an inverse relationship to the wavelength, \u03bb (lambda). Even in dispersive media, the frequency f of a sinusoidal wave is equal to the phase velocity v of the wave divided by the wavelength \u03bb of the wave:\n\n  \n    \n      \n        f\n        =\n        \n          \n            v\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {v}{\\lambda }}.}\n  In the special case of electromagnetic waves moving through a vacuum, then v = c, where c is the speed of light in a vacuum, and this expression becomes:\n\n  \n    \n      \n        f\n        =\n        \n          \n            c\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {c}{\\lambda }}.}\n  When waves from a monochrome source travel from one medium to another, their frequency remains the same\u2014only their wavelength and speed change.\n\n\n== Measurement ==\n\nMeasurement of frequency can done in the following ways,\n\n\n=== Counting ===\nCalculating the frequency of a repeating event is accomplished by counting the number of times that event occurs within a specific time period, then dividing the count by the length of the time period. For example, if 71 events occur within 15 seconds the frequency is:\n\n  \n    \n      \n        f\n        =\n        \n          \n            71\n            \n              15\n              \n              \n                s\n              \n            \n          \n        \n        \u2248\n        4.73\n        \n        \n          Hz\n        \n      \n    \n    {\\displaystyle f={\\frac {71}{15\\,{\\text{s}}}}\\approx 4.73\\,{\\text{Hz}}}\n  If the number of counts is not very large, it is more accurate to measure the time interval for a predetermined number of occurrences, rather than the number of occurrences within a specified time.  The latter method introduces a random error into the count of between zero and one count, so on average half a count. This is called gating error and causes an average error in the calculated frequency of \n  \n    \n      \n        \u0394\n        f\n        =\n        \n          \n            1\n            \n              2\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta f={\\frac {1}{2T_{m}}}}\n  , or a fractional error of \n  \n    \n      \n        \n          \n            \n              \u0394\n              f\n            \n            f\n          \n        \n        =\n        \n          \n            1\n            \n              2\n              f\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta f}{f}}={\\frac {1}{2fT_{m}}}}\n   where \n  \n    \n      \n        \n          T\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle T_{m}}\n   is the timing interval and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the measured frequency. This error decreases with frequency, so it is generally a problem at low frequencies where the number of counts N is small.\n\n\n=== Stroboscope ===\nAn older method of measuring the frequency of rotating or vibrating objects is to use a stroboscope. This is an intense repetitively flashing light (strobe light) whose frequency can be adjusted with a calibrated timing circuit. The strobe light is pointed at the rotating object and the frequency adjusted up and down. When the frequency of the strobe equals the frequency of the rotating or vibrating object, the object completes one cycle of oscillation and returns to its original position between the flashes of light, so when illuminated by the strobe the object appears stationary. Then the frequency can be read from the calibrated readout on the stroboscope. A downside of this method is that an object rotating at an integral multiple of the strobing frequency will also appear stationary.\n\n\n=== Frequency counter ===\n\nHigher frequencies are usually measured with a frequency counter. This is an electronic instrument which measures the frequency of an applied repetitive electronic signal and displays the result in hertz on a digital display. It uses digital logic to count the number of cycles during a time interval established by a precision quartz time base. Cyclic processes that are not electrical in nature, such as the rotation rate of a shaft, mechanical vibrations, or sound waves, can be converted to a repetitive electronic signal by transducers and the signal applied to a frequency counter. Frequency counters can currently cover the range up to about 100 GHz. This represents the limit of direct counting methods; frequencies above this must be measured by indirect methods.\n\n\n=== Heterodyne methods ===\nAbove the range of frequency counters, frequencies of electromagnetic signals are often measured indirectly by means of heterodyning (frequency conversion). A reference signal of a known frequency near the unknown frequency is mixed with the unknown frequency in a nonlinear mixing device such as a diode. This creates a heterodyne or \"beat\" signal at the difference between the two frequencies.  If the two signals are close together in frequency the heterodyne is low enough to be measured by a frequency counter. This process only measures the difference between the unknown frequency and the reference frequency. To reach higher frequencies, several stages of heterodyning can be used. Current research is extending this method to infrared and light frequencies (optical heterodyne detection).\n\n\n== Examples ==\n\n\n=== Light ===\n\nVisible light is an electromagnetic wave, consisting of oscillating electric and magnetic fields traveling through space. The frequency of the wave determines its color: 4\u00d71014 Hz is red light, 8\u00d71014 Hz is violet light, and between these (in the range 4-8\u00d71014 Hz) are all the other colors of the visible spectrum. An electromagnetic wave can have a frequency less than 4\u00d71014 Hz, but it will be invisible to the human eye; such waves are called infrared (IR) radiation. At even lower frequency, the wave is called a microwave, and at still lower frequencies it is called a radio wave. Likewise, an electromagnetic wave can have a frequency higher than 8\u00d71014 Hz, but it will be invisible to the human eye; such waves are called ultraviolet (UV) radiation. Even higher-frequency waves are called X-rays, and higher still are gamma rays.\nAll of these waves, from the lowest-frequency radio waves to the highest-frequency gamma rays, are fundamentally the same, and they are all called electromagnetic radiation. They all travel through a vacuum at the same speed (the speed of light), giving them wavelengths inversely proportional to their frequencies.\n\n  \n    \n      \n        \n          c\n          =\n          f\n          \u03bb\n        \n      \n    \n    {\\displaystyle \\displaystyle c=f\\lambda }\n  where c is the speed of light (c in a vacuum, or less in other media), f is the frequency and \u03bb is the wavelength.\nIn dispersive media, such as glass, the speed depends somewhat on frequency, so the wavelength is not quite inversely proportional to frequency.\n\n\n=== Sound ===\n\nSound propagates as mechanical vibration waves of pressure and displacement, in air or other substances.. In general, frequency components of a sound determine its \"color\", its timbre. When speaking about the frequency (in singular) of a sound, it means the property that most determines pitch.The frequencies an ear can hear are limited to a specific range of frequencies.  The audible frequency range for humans is typically given as being between about 20 Hz and 20,000 Hz (20 kHz), though the high frequency limit usually reduces with age. Other species have different hearing ranges. For example, some dog breeds can perceive vibrations up to 60,000 Hz.In many media, such as air, the speed of sound is approximately independent of frequency, so the wavelength of the sound waves (distance between repetitions) is approximately inversely proportional to frequency.\n\n\n=== Line current ===\n\nIn Europe, Africa, Australia, Southern South America, most of Asia, and Russia, the frequency of the alternating current in household electrical outlets is 50 Hz (close to the tone G), whereas in North America and Northern South America, the frequency of the alternating current in household electrical outlets is 60 Hz (between the tones B\u266d and B; that is, a minor third above the European frequency). The frequency of the 'hum' in an audio recording can show where the recording was made, in countries using a European, or an American, grid frequency.\n\n\n== See also ==\n\n\n== Notes and references ==\n\n\n== Further reading ==\nGiancoli, D.C. (1988). Physics for Scientists and Engineers (2nd ed.). Prentice Hall. ISBN 0-13-669201-X. \n\n\n== External links ==\nConversion: frequency to wavelength and back\nConversion: period, cycle duration, periodic time to frequency\nKeyboard frequencies = naming of notes - The English and American system versus the German system\nTeaching resource for 14-16yrs on sound including frequency\nA simple tutorial on how to build a frequency meter\nFrequency - diracdelta.co.uk \u2013 JavaScript calculation.\nA frequency generator with sound, useful for hearing tests",
        "unit": "frequency",
        "url": "https://en.wikipedia.org/wiki/Frequency"
    },
    {
        "_id": "Magnetic_field",
        "clean": "Magnetic field",
        "text": "A magnetic field is a vector field that describes the magnetic influence of electrical currents and magnetized materials. In everyday life, the effects of magnetic fields are most readily encountered with nearby permanent magnets, which pull on magnetic materials (such as iron) and attract or repel other magnets. Magnetic fields surround and are created by magnetized material and by moving electric charges (electric currents) such as those used in electromagnets. Magnetic fields exert forces on nearby moving electrical charges and torques on nearby magnets. In addition, a magnetic field that varies with location exerts a force on magnetic materials. Both the strength and direction of a magnetic field varies with location. As such, it is an example of a vector field.\nThe term 'magnetic field' is used for two distinct but closely related fields denoted by the symbols B and H. In the International System of Units, H is measured in units of amperes per meter and B is measured in teslas or newtons per meter per ampere.  H and B differ in how they account for magnetization. In a vacuum, B and H are the same aside from units; but in a magnetized material, B/\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   and H differ by the magnetization M of the material at that point in the material.\nMagnetic fields are produced by moving electric charges and the intrinsic magnetic moments of elementary particles associated with a fundamental quantum property, their spin. Magnetic fields and electric fields are interrelated, and are both components of the electromagnetic force, one of the four fundamental forces of nature.\nMagnetic fields are widely used throughout modern technology, particularly in electrical engineering and electromechanics. Rotating magnetic fields are used in both electric motors and generators. The interaction of magnetic fields in electric devices such as transformers is studied in the discipline of magnetic circuits. Magnetic forces give information about the charge carriers in a material through the Hall effect. The Earth produces its own magnetic field, which shields the Earth's ozone layer from the solar wind and is important in navigation using a compass.\n\n\n== History ==\n\nAlthough magnets and magnetism were studied much earlier, the research of magnetic fields began in 1269 when French scholar Petrus Peregrinus de Maricourt mapped out the magnetic field on the surface of a spherical magnet using iron needles. Noting that the resulting field lines crossed at two points he named those points 'poles' in analogy to Earth's poles. He also clearly articulated the principle that magnets always have both a north and south pole, no matter how finely one slices them.\nAlmost three centuries later, William Gilbert of Colchester replicated Petrus Peregrinus' work and was the first to state explicitly that Earth is a magnet. Published in 1600, Gilbert's work, De Magnete, helped to establish magnetism as a science.\nIn 1750, John Michell stated that magnetic poles attract and repel in accordance with an inverse square law. Charles-Augustin de Coulomb experimentally verified this in 1785 and stated explicitly that the north and south poles cannot be separated. Building on this force between poles, Sim\u00e9on Denis Poisson (1781\u20131840) created the first successful model of the magnetic field, which he presented in 1824. In this model, a magnetic H-field is produced by 'magnetic poles' and magnetism is due to small pairs of north/south magnetic poles.\n\nThree discoveries challenged this foundation of magnetism, though. First, in 1819, Hans Christian \u00d8rsted discovered that an electric current generates a magnetic field encircling it. Then in 1820, Andr\u00e9-Marie Amp\u00e8re showed that parallel wires with currents attract one another if the currents are in the same direction and repel if they are in opposite directions. Finally, Jean-Baptiste Biot and F\u00e9lix Savart discovered the Biot\u2013Savart law in 1820, which correctly predicts the magnetic field around any current-carrying wire.\nExtending these experiments, Amp\u00e8re published his own successful model of magnetism in 1825. In it, he showed the equivalence of electrical currents to magnets and proposed that magnetism is due to perpetually flowing loops of current instead of the dipoles of magnetic charge in Poisson's model. This has the additional benefit of explaining why magnetic charge can not be isolated. Further, Amp\u00e8re derived both Amp\u00e8re's force law describing the force between two currents and Amp\u00e8re's law, which, like the Biot\u2013Savart law, correctly described the magnetic field generated by a steady current. Also in this work, Amp\u00e8re introduced the term electrodynamics to describe the relationship between electricity and magnetism.\nIn 1831, Michael Faraday discovered electromagnetic induction when he found that a changing magnetic field generates an encircling electric field. He described this phenomenon in what is known as Faraday's law of induction. Later, Franz Ernst Neumann proved that, for a moving conductor in a magnetic field, induction is a consequence of Amp\u00e8re's force law. In the process, he introduced the magnetic vector potential, which was later shown to be equivalent to the underlying mechanism proposed by Faraday.\nIn 1850, Lord Kelvin, then known as William Thomson, distinguished between two magnetic fields now denoted H and B. The former applied to Poisson's model and the latter to Amp\u00e8re's model and induction. Further, he derived how H and B relate to each other.\nThe reason H and B are used for the two magnetic fields has been a source of some debate among science historians. Most agree that Kelvin avoided M to prevent confusion with the SI fundamental unit of length, the Metre, abbreviated \"m\". Others believe the choices were purely random.Between 1861 and 1865, James Clerk Maxwell developed and published Maxwell's equations, which explained and united all of classical electricity and magnetism. The first set of these equations was published in a paper entitled On Physical Lines of Force in 1861. These equations were valid although incomplete. Maxwell completed his set of equations in his later 1865 paper A Dynamical Theory of the Electromagnetic Field and demonstrated the fact that light is an electromagnetic wave. Heinrich Hertz experimentally confirmed this fact in 1887.\nThe twentieth century extended electrodynamics to include relativity and quantum mechanics. Albert Einstein, in his paper of 1905 that established relativity, showed that both the electric and magnetic fields are part of the same phenomena viewed from different reference frames. (See moving magnet and conductor problem for details about the thought experiment that eventually helped Albert Einstein to develop special relativity.) Finally, the emergent field of quantum mechanics was merged with electrodynamics to form quantum electrodynamics (QED).\n\n\n== Definitions, units and measurement ==\n\n\n=== The B-field ===\nThe magnetic field can be defined in several equivalent ways based on the effects it has on its environment.\nOften the magnetic field is defined by the force it exerts on a moving charged particle. It is known from experiments in electrostatics that a particle of charge q in an electric field E experiences a force F = qE. However, in other situations, such as when a charged particle moves in the vicinity of a current-carrying wire, the force also depends on the velocity of that particle. Fortunately, the velocity dependent portion can be separated out such that the force on the particle satisfies the Lorentz force law,\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        (\n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {F} =q(\\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} ).}\n  Here v is the particle's velocity and \u00d7 denotes the cross product. The vector B is termed the magnetic field, and it is defined as the vector field necessary to make the Lorentz force law correctly describe the motion of a charged particle. This definition allows the determination of B in the following way\n[T]he command, \"Measure the direction and magnitude of the vector B at such and such a place,\" calls for the following operations: Take a particle of known charge q. Measure the force on q at rest, to determine E. Then measure the force on the particle when its velocity is v; repeat with v in some other direction. Now find a B that makes the Lorentz force law fit all these results\u2014that is the magnetic field at the place in question.\n\nAlternatively, the magnetic field can be defined in terms of the torque it produces on a magnetic dipole (see magnetic torque on permanent magnets below).\n\n\n=== The H-field ===\nIn addition to B, there is a quantity H, which is often called the magnetic field. In a vacuum, B and H are proportional to each other, with the multiplicative constant depending on the physical units. Inside a material they are different (see H and B inside and outside magnetic materials). The term \"magnetic field\" is historically reserved for H while using other terms for B. Informally, though, and formally for some recent textbooks mostly in physics, the term 'magnetic field' is used to describe B as well as or in place of H.\nThere are many alternative names for both (see sidebar).\n\n\n=== Units ===\nIn SI units, B is measured in teslas (symbol: T) and correspondingly \u03a6B (magnetic flux) is measured in webers (symbol: Wb) so that a flux density of 1 Wb/m2 is 1 tesla. The SI unit of tesla is equivalent to (newton\u00b7second)/(coulomb\u00b7metre). In Gaussian-cgs units, B is measured in gauss (symbol: G). (The conversion is 1 T = 10000 G.) One nanotesla is equivalent to 1 gamma (symbol: \u03b3). The H-field is measured in amperes per metre (A/m) in SI units, and in oersteds (Oe) in cgs units.\n\n\n=== Measurement ===\nThe precision attained for a magnetic field measurement for Gravity Probe B experiment is 5 attoteslas (5\u00d710\u221218 T); the largest magnetic field produced in a laboratory is 2.8 kT (VNIIEF in Sarov, Russia, 1998). The magnetic field of some astronomical objects such as magnetars are much higher; magnetars range from 0.1 to 100 GT (108 to 1011 T).  See orders of magnitude (magnetic field).\nDevices used to measure the local magnetic field are called magnetometers. Important classes of magnetometers include using induction magnetometer (or search-coil magnetometer) which measure only varying magnetic field, rotating coil magnetometer, Hall effect magnetometers, NMR magnetometers, SQUID magnetometers, and fluxgate magnetometers. The magnetic fields of distant astronomical objects are measured through their effects on local charged particles. For instance, electrons spiraling around a field line produce synchrotron radiation that is detectable in radio waves.\n\n\n== Magnetic field lines ==\n\nMapping the magnetic field of an object is simple in principle. First, measure the strength and direction of the magnetic field at a large number of locations (or at every point in space). Then, mark each location with an arrow (called a vector) pointing in the direction of the local magnetic field with its magnitude proportional to the strength of the magnetic field.\nAn alternative method to map the magnetic field is to 'connect' the arrows to form magnetic field lines. The direction of the magnetic field at any point is parallel to the direction of nearby field lines, and the local density of field lines can be made proportional to its strength. Magnetic field lines are like streamlines in fluid flow, in that they represent something continuous, and a different resolution would show more or fewer lines.\nAn advantage of using magnetic field lines as a representation is that many laws of magnetism (and electromagnetism) can be stated completely and concisely using simple concepts such as the 'number' of field lines through a surface. These concepts can be quickly 'translated' to their mathematical form. For example, the number of field lines through a given surface is the surface integral of the magnetic field.\nVarious phenomena have the effect of \"displaying\" magnetic field lines as though the field lines were physical phenomena. For example, iron filings placed in a magnetic field, form lines that correspond to 'field lines'. Magnetic field \"lines\" are also visually displayed in polar auroras, in which plasma particle dipole interactions create visible streaks of light that line up with the local direction of Earth's magnetic field.\nField lines can be used as a qualitative tool to visualize magnetic forces. In ferromagnetic substances like iron and in plasmas, magnetic forces can be understood by imagining that the field lines exert a tension, (like a rubber band) along their length, and a pressure perpendicular to their length on neighboring field lines.  'Unlike' poles of magnets attract because they are linked by many field lines; 'like' poles repel because their field lines do not meet, but run parallel, pushing on each other. The rigorous form of this concept is the electromagnetic stress\u2013energy tensor.\n\n\n== Magnetic field and permanent magnets ==\n\nPermanent magnets are objects that produce their own persistent magnetic fields. They are made of ferromagnetic materials, such as iron and nickel, that have been magnetized, and they have both a north and a south pole.\n\n\n=== Magnetic field of permanent magnets ===\n\nThe magnetic field of permanent magnets can be quite complicated, especially near the magnet. The magnetic field of a small straight magnet is proportional to the magnet's strength (called its magnetic dipole moment m). The equations are non-trivial and also depend on the distance from the magnet and the orientation of the magnet. For simple magnets, m points in the direction of a line drawn from the south to the north pole of the magnet. Flipping a bar magnet is equivalent to rotating its m by 180 degrees.\nThe magnetic field of larger magnets can be obtained by modeling them as a collection of a large number of small magnets called dipoles each having their own m. The magnetic field produced by the magnet then is the net magnetic field of these dipoles. And, any net force on the magnet is a result of adding up the forces on the individual dipoles.\nThere are two competing models for the nature of these dipoles. These two models produce two different magnetic fields, H and B. Outside a material, though, the two are identical (to a multiplicative constant) so that in many cases the distinction can be ignored. This is particularly true for magnetic fields, such as those due to electric currents, that are not generated by magnetic materials.\n\n\n=== Magnetic pole model and the H-field ===\n\nIt is sometimes useful to model the force and torques between two magnets as due to magnetic poles repelling or attracting each other in the same manner as the Coulomb force between electric charges. This is called the Gilbert model of magnetism, after William Gilbert. In this model, a magnetic H-field is produced by magnetic charges that are 'smeared' around each pole. These magnetic charges are in fact related to the magnetization field M.\nThe H-field, therefore, is analogous to the electric field E, which starts at a positive electric charge and ends at a negative electric charge. Near the north pole, therefore, all H-field lines point away from the north pole (whether inside the magnet or out) while near the south pole all H-field lines point toward the south pole (whether inside the magnet or out). Too, a north pole feels a force in the direction of the H-field while the force on the south pole is opposite to the H-field.\nIn the magnetic pole model, the elementary magnetic dipole m is formed by two opposite magnetic poles of pole strength qm separated by a small distance vector d, such that m = qm\u2009d. The magnetic pole model predicts correctly the field H both inside and outside magnetic materials, in particular the fact that  H is opposite to the magnetization field M inside a permanent magnet.\nSince it is based on the fictitious idea of a magnetic charge density, the Gilbert model has limitations. Magnetic poles cannot exist apart from each other as electric charges can, but always come in north/south pairs. If a magnetized object is divided in half, a new pole appears on the surface of each piece, so each has a pair of complementary poles. The magnetic pole model does not account for magnetism that is produced by electric currents.\n\n\n=== Amperian loop model and the B-field ===\n\nAfter \u00d8rsted discovered that electric currents produce a magnetic field and Ampere discovered that electric currents attracted and repelled each other similar to magnets, it was natural to hypothesize that all magnetic fields are due to electric current loops. In this model developed by Ampere, the elementary magnetic dipole that makes up all magnets is a sufficiently small Amperian loop of current I. The dipole moment of this loop is m = IA where A is the area of the loop.\nThese magnetic dipoles produce a magnetic B-field. One important property of the B-field produced this way is that magnetic B-field lines neither start nor end (mathematically, B is a solenoidal vector field); a field line either extends to infinity or wraps around to form a closed curve. To date, no exception to this rule has been found. (See magnetic monopole below.) Magnetic field lines exit a magnet near its north pole and enter near its south pole, but inside the magnet B-field lines continue through the magnet from the south pole back to the north. If a B-field line enters a magnet somewhere it has to leave somewhere else; it is not allowed to have an end point. Magnetic poles, therefore, always come in N and S pairs.\nMore formally, since all the magnetic field lines that enter any given region must also leave that region, subtracting the 'number' of field lines that enter the region from the number that exit gives identically zero. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} =0,}\n  where the integral is a surface integral over the closed surface S (a closed surface is one that completely surrounds a region with no holes to let any field lines escape). Since dA points outward, the dot product in the integral is positive for B-field pointing out and negative for B-field pointing in.\nThere is also a corresponding differential form of this equation covered in Maxwell's equations below.\n\n\n=== Force between magnets ===\n\nThe force between two small magnets is quite complicated and depends on the strength and orientation of both magnets and the distance and direction of the magnets relative to each other. The force is particularly sensitive to rotations of the magnets due to magnetic torque. The force on each magnet depends on its magnetic moment and the magnetic field of the other.\nTo understand the force between magnets, it is useful to examine the magnetic pole model given above. In this model, the H-field of one magnet pushes and pulls on both poles of a second magnet. If this H-field is the same at both poles of the second magnet then there is no net force on that magnet since the force is opposite for opposite poles. If, however, the magnetic field of the first magnet is nonuniform (such as the H near one of its poles), each pole of the second magnet sees a different field and is subject to a different force. This difference in the two forces moves the magnet in the direction of increasing magnetic field and may also cause a net torque.\nThis is a specific example of a general rule that magnets are attracted (or repulsed depending on the orientation of the magnet) into regions of higher magnetic field. Any non-uniform magnetic field, whether caused by permanent magnets or electric currents, exerts a force on a small magnet in this way.\nThe details of the Amperian loop model are different and more complicated but yield the same result: that magnetic dipoles are attracted/repelled into regions of higher magnetic field.\nMathematically, the force on a small magnet having a magnetic moment m due to a magnetic field B is:\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \u2207\n        \n        \n          (\n          \n            \n              m\n            \n            \u22c5\n            \n              B\n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =\\mathbf {\\nabla } \\left(\\mathbf {m} \\cdot \\mathbf {B} \\right),}\n  where the gradient \u2207 is the change of the quantity m \u00b7 B per unit distance and the direction is that of maximum increase of m \u00b7 B. To understand this equation, note that the dot product m \u00b7 B = mBcos(\u03b8), where m and B represent the magnitude of the m and B vectors and \u03b8 is the angle between them. If m is in the same direction as B then the dot product is positive and the gradient points 'uphill' pulling the magnet into regions of higher B-field (more strictly larger m \u00b7 B). This equation is strictly only valid for magnets of zero size, but is often a good approximation for not too large magnets. The magnetic force on larger magnets is determined by dividing them into smaller regions each having their own m then summing up the forces on each of these very small regions.\n\n\n=== Magnetic torque on permanent magnets ===\n\nIf two like poles of two separate magnets are brought near each other, and one of the magnets is allowed to turn, it promptly rotates to align itself with the first. In this example, the magnetic field of the stationary magnet creates a magnetic torque on the magnet that is free to rotate. This magnetic torque \u03c4 tends to align a magnet's poles with the magnetic field lines. A compass, therefore, turns to align itself with Earth's magnetic field.\nMagnetic torque is used to drive electric motors. In one simple motor design, a magnet is fixed to a freely rotating shaft and subjected to a magnetic field from an array of electromagnets. By continuously switching the electric current through each of the electromagnets, thereby flipping the polarity of their magnetic fields, like poles are kept next to the rotor; the resultant torque is transferred to the shaft. See Rotating magnetic fields below.\n\nAs is the case for the force between magnets, the magnetic pole model leads more readily to the correct equation. Here, two equal and opposite magnetic charges experiencing the same H also experience equal and opposite forces. Since these equal and opposite forces are in different locations, this produces a torque proportional to the distance (perpendicular to the force) between them. With the definition of m as the pole strength times the distance between the poles, this leads to \u03c4 = \u03bc0mHsin\u03b8, where \u03bc0 is a constant called the vacuum permeability, measuring 4\u03c0\u00d710\u22127 V\u00b7s/(A\u00b7m) and \u03b8 is the angle between H and m.\nThe Amperian loop model also predicts the same magnetic torque. Here, it is the B field interacting with the Amperian current loop through a Lorentz force described below. Again, the results are the same although the models are completely different.\n\nMathematically, the torque \u03c4 on a small magnet is proportional both to the applied magnetic field and to the magnetic moment m of the magnet:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          m\n        \n        \u00d7\n        \n          B\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          m\n        \n        \u00d7\n        \n          H\n        \n        ,\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {m} \\times \\mathbf {B} =\\mu _{0}\\mathbf {m} \\times \\mathbf {H} ,\\,}\n  where \u00d7 represents the vector cross product. Note that this equation includes all of the qualitative information included above. There is no torque on a magnet if m is in the same direction as the magnetic field. (The cross product is zero for two vectors that are in the same direction.) Further, all other orientations feel a torque that twists them toward the direction of magnetic field.\n\n\n== Magnetic field and electric currents ==\nCurrents of electric charges both generate a magnetic field and feel a force due to magnetic B-fields.\n\n\n=== Magnetic field due to moving charges and electric currents ===\n\nAll moving charged particles produce magnetic fields. Moving point charges, such as electrons, produce complicated but well known magnetic fields that depend on the charge, velocity, and acceleration of the particles.Magnetic field lines form in concentric circles around a cylindrical current-carrying conductor, such as a length of wire. The direction of such a magnetic field can be determined by using the \"right hand grip rule\" (see figure at right). The strength of the magnetic field decreases with distance from the wire. (For an infinite length wire the strength is inversely proportional to the distance.)\n\nBending a current-carrying wire into a loop concentrates the magnetic field inside the loop while weakening it outside. Bending a wire into multiple closely spaced loops to form a coil or \"solenoid\" enhances this effect. A device so formed around an iron core may act as an electromagnet, generating a strong, well-controlled magnetic field. An infinitely long cylindrical electromagnet has a uniform magnetic field inside, and no magnetic field outside. A finite length electromagnet produces a magnetic field that looks similar to that produced by a uniform permanent magnet, with its strength and polarity determined by the current flowing through the coil.\nThe magnetic field generated by a steady current I (a constant flow of electric charges, in which charge neither accumulates nor is depleted at any point) is described by the Biot\u2013Savart law:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \n          \u222b\n          \n            \n              w\n              i\n              r\n              e\n            \n          \n        \n        \n          \n            \n              \n                d\n              \n              \n                \u2113\n              \n              \u00d7\n              \n                \n                  \n                    r\n                    ^\n                  \n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{4\\pi }}\\int _{\\mathrm {wire} }{\\frac {\\mathrm {d} {\\boldsymbol {\\ell }}\\times \\mathbf {\\hat {r}} }{r^{2}}},}\n  where the integral sums over the wire length where vector d\u2113 is the vector line element with direction in the same sense as the current I, \u03bc0 is the magnetic constant, r is the distance between the location of d\u2113 and the location where the magnetic field is calculated, and r\u0302 is a unit vector in the direction of r.  In the case of a sufficiently long wire, this becomes:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              2\n              \u03c0\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{2\\pi r}}}\n  where r is the distance from the wire.A slightly more general way of relating the current \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n   to the B-field is through Amp\u00e8re's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          I\n          \n            \n              e\n              n\n              c\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {B} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\mu _{0}I_{\\mathrm {enc} },}\n  where the line integral is over any arbitrary loop and \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n  enc is the current enclosed by that loop. Amp\u00e8re's law is always valid for steady currents and can be used to calculate the B-field for certain highly symmetric situations such as an infinite wire or an infinite solenoid.\nIn a modified form that accounts for time varying electric fields, Amp\u00e8re's law is one of four Maxwell's equations that describe electricity and magnetism.\n\n\n=== Force on moving charges and current ===\n\n\n==== Force on a charged particle ====\n\nA charged particle moving in a B-field experiences a sideways force that is proportional to the strength of the magnetic field, the component of the velocity that is perpendicular to the magnetic field and the charge of the particle. This force is known as the Lorentz force, and is given by\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        \n          E\n        \n        +\n        q\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =q\\mathbf {E} +q\\mathbf {v} \\times \\mathbf {B} ,}\n  where\nF is the force, q is the electric charge of the particle, v is the instantaneous velocity  of the particle, and B is the magnetic field (in teslas).\nThe Lorentz force is always perpendicular to both the velocity of the particle and the magnetic field that created it. When a charged particle moves in a static magnetic field, it traces a helical path in which the helix axis is parallel to the magnetic field, and in which the speed of the particle remains constant. Because the magnetic force is always perpendicular to the motion, the magnetic field can do no work on an isolated charge. It can only do work indirectly, via the electric field generated by a changing magnetic field. It is often claimed that the magnetic force can do work to a non-elementary magnetic dipole, or to charged particles whose motion is constrained by other forces, but this is incorrect because the work in those cases is performed by the electric forces of the charges deflected by the magnetic field.\n\n\n==== Force on current-carrying wire ====\n\nThe force on a current carrying wire is similar to that of a moving charge as expected since a current carrying wire is a collection of moving charges. A current-carrying wire feels a force in the presence of a magnetic field. The Lorentz force on a macroscopic current is often referred to as the Laplace force.\nConsider a conductor of length \u2113, cross section A, and charge q due to electric current i. If this conductor is placed in a magnetic field of magnitude B that makes an angle \u03b8 with the velocity of charges in the conductor, the force exerted on a single charge q is\n\n  \n    \n      \n        F\n        =\n        q\n        v\n        B\n        sin\n        \u2061\n        \u03b8\n        ,\n      \n    \n    {\\displaystyle F=qvB\\sin \\theta ,}\n  so, for N charges where \n\n  \n    \n      \n        N\n        =\n        n\n        \u2113\n        A\n      \n    \n    {\\displaystyle N=n\\ell A}\n  ,the force exerted on the conductor is\n\n  \n    \n      \n        f\n        =\n        F\n        N\n        =\n        q\n        v\n        B\n        n\n        \u2113\n        A\n        sin\n        \u2061\n        \u03b8\n        =\n        B\n        i\n        \u2113\n        sin\n        \u2061\n        \u03b8\n      \n    \n    {\\displaystyle f=FN=qvBn\\ell A\\sin \\theta =Bi\\ell \\sin \\theta }\n  ,where i = nqvA.\n\n\n==== Direction of force ====\n\nThe direction of force on a charge or a current can be determined by a mnemonic known as the right-hand rule (see the figure). Using the right hand, pointing the thumb in the direction of the current, and the fingers in the direction of the magnetic field, the resulting force on the charge points outwards from the palm. The force on a negatively charged particle is in the opposite direction. If both the speed and the charge are reversed then the direction of the force remains the same. For that reason a magnetic field measurement (by itself) cannot distinguish whether there is a positive charge moving to the right or a negative charge moving to the left. (Both of these cases produce the same current.)  On the other hand, a magnetic field combined with an electric field can distinguish between these, see Hall effect below.\nAn alternative mnemonic to the right hand rule is Flemings's left hand rule.\n\n\n== Relation between H and B ==\nThe formulas derived for the magnetic field above are correct when dealing with the entire current. A magnetic material placed inside a magnetic field, though, generates its own bound current, which can be a challenge to calculate.  (This bound current is due to the sum of atomic sized current loops and the spin of the subatomic particles such as electrons that make up the material.)  The H-field as defined above helps factor out this bound current; but to see how, it helps to introduce the concept of magnetization first.\n\n\n=== Magnetization ===\n\nThe magnetization vector field M represents how strongly a region of material is magnetized. It is defined as the net magnetic dipole moment per unit volume of that region. The magnetization of a uniform magnet is therefore a material constant, equal to the magnetic moment m of the magnet divided by its volume. Since the SI unit of magnetic moment is A\u22c5m2, the SI unit of magnetization M is ampere per meter, identical to that of the H-field.\nThe magnetization M field of a region points in the direction of the average magnetic dipole moment in that region. Magnetization field lines, therefore, begin near the magnetic south pole and ends near the magnetic north pole. (Magnetization does not exist outside the magnet.)\nIn the Amperian loop model, the magnetization is due to combining many tiny Amperian loops to form a resultant current called bound current. This bound current, then, is the source of the magnetic B field due to the magnet. (See Magnetic dipoles below and magnetic poles vs. atomic currents for more information.) Given the definition of the magnetic dipole, the magnetization field follows a similar law to that of Ampere's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              b\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {M} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {b} },}\n  where the integral is a line integral over any closed loop and Ib is the 'bound current' enclosed by that closed loop.\nIn the magnetic pole model, magnetization begins at and ends at magnetic poles. If a given region, therefore, has a net positive 'magnetic pole strength' (corresponding to a north pole) then it has more magnetization field lines entering it than leaving it. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {M} \\cdot \\mathrm {d} \\mathbf {A} =-q_{\\mathrm {M} }}\n  ,where the integral is a closed surface integral over the closed surface S and qM is the 'magnetic charge' (in units of magnetic flux) enclosed by S. (A closed surface completely surrounds a region with no holes to let any field lines escape.) The negative sign occurs because the magnetization field moves from south to north.\n\n\n=== H-field and magnetic materials ===\n\nIn SI units, the H-field is related to the B-field by\n\n  \n    \n      \n        \n          H\n        \n         \n        \u2261\n         \n        \n          \n            \n              B\n            \n            \n              \u03bc\n              \n                0\n              \n            \n          \n        \n        \u2212\n        \n          M\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {H} \\ \\equiv \\ {\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} .}\n  In terms of the H-field, Ampere's law is\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \n                  B\n                \n                \n                  \u03bc\n                  \n                    0\n                  \n                \n              \n            \n            \u2212\n            \n              M\n            \n          \n          )\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              t\n              o\n              t\n            \n          \n        \n        \u2212\n        \n          I\n          \n            \n              b\n            \n          \n        \n        =\n        \n          I\n          \n            \n              f\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\oint \\left({\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} \\right)\\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {tot} }-I_{\\mathrm {b} }=I_{\\mathrm {f} },}\n  where If represents the 'free current' enclosed by the loop so that the line integral of H does not depend at all on the bound currents.For the differential equivalent of this equation see Maxwell's equations. Ampere's law leads to the boundary condition \n\n  \n    \n      \n        \n          (\n          \n            \n              \n                H\n                \n                  1\n                \n                \n                  \u2225\n                \n              \n            \n            \u2212\n            \n              \n                H\n                \n                  2\n                \n                \n                  \u2225\n                \n              \n            \n          \n          )\n        \n        =\n        \n          \n            K\n          \n          \n            \n              f\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\left(\\mathbf {H_{1}^{\\parallel }} -\\mathbf {H_{2}^{\\parallel }} \\right)=\\mathbf {K} _{\\mathrm {f} }\\times {\\hat {\\mathbf {n} }},}\n  where Kf is the surface free current density and the unit normal \n  \n    \n      \n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {n} }}}\n   points in the direction from medium 2 to medium 1.Similarly, a surface integral of H over any closed surface is independent of the free currents and picks out the \"magnetic charges\" within that closed surface:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        (\n        \n          B\n        \n        \u2212\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        )\n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        \u2212\n        (\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n        )\n        =\n        \n          q\n          \n            \n              M\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {H} \\cdot \\mathrm {d} \\mathbf {A} =\\oint _{S}(\\mathbf {B} -\\mu _{0}\\mathbf {M} )\\cdot \\mathrm {d} \\mathbf {A} =0-(-q_{\\mathrm {M} })=q_{\\mathrm {M} },}\n  which does not depend on the free currents.\nThe H-field, therefore, can be separated into two independent parts:\n\n  \n    \n      \n        \n          H\n        \n        =\n        \n          \n            H\n          \n          \n            0\n          \n        \n        +\n        \n          \n            H\n          \n          \n            \n              d\n            \n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle \\mathbf {H} =\\mathbf {H} _{0}+\\mathbf {H} _{\\mathrm {d} },\\,}\n  where H0 is the applied magnetic field due only to the free currents and Hd is the demagnetizing field due only to the bound currents.\nThe magnetic H-field, therefore, re-factors the bound current in terms of \"magnetic charges\". The H field lines loop only around 'free current' and, unlike the magnetic B field, begins and ends near magnetic poles as well.\n\n\n=== Magnetism ===\n\nMost materials respond to an applied B-field by producing their own magnetization M and therefore their own B-field. Typically, the response is weak and exists only when the magnetic field is applied. The term magnetism describes how materials respond on the microscopic level to an applied magnetic field and is used to categorize the magnetic phase of a material. Materials are divided into groups based upon their magnetic behavior:\n\nDiamagnetic materials produce a magnetization that opposes the magnetic field.\nParamagnetic materials produce a magnetization in the same direction as the applied magnetic field.\nFerromagnetic materials and the closely related ferrimagnetic materials and antiferromagnetic materials  can have a magnetization independent of an applied B-field with a complex relationship between the two fields.\nSuperconductors (and ferromagnetic superconductors) are materials that are characterized by perfect conductivity below a critical temperature and magnetic field. They also are highly magnetic and can be perfect diamagnets below a lower critical magnetic field. Superconductors often have a broad range of temperatures and magnetic fields (the so-named mixed state) under which they exhibit a complex hysteretic dependence of M on B.In the case of paramagnetism and diamagnetism, the magnetization M is often proportional to the applied magnetic field such that:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \u03bc\n        \n          H\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} =\\mu \\mathbf {H} ,}\n  where \u03bc is a material dependent parameter called the permeability. In some cases the permeability may be a second rank tensor so that H may not point in the same direction as B. These relations between B  and H are examples of constitutive equations. However, superconductors and ferromagnets have a more complex B to H relation; see magnetic hysteresis.\n\n\n== Energy stored in magnetic fields ==\n\nEnergy is needed to generate a magnetic field both to work against the electric field that a changing magnetic field creates and to change the magnetization of any material within the magnetic field. For non-dispersive materials, this same energy is released when the magnetic field is destroyed so that this energy can be modeled as being stored in the magnetic field.\nFor linear, non-dispersive, materials (such that B = \u03bcH where \u03bc is frequency-independent), the energy density is:\n\n  \n    \n      \n        u\n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                B\n              \n            \n            \n              2\n              \u03bc\n            \n          \n        \n        =\n        \n          \n            \n              \u03bc\n              \n                H\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle u={\\frac {\\mathbf {B} \\cdot \\mathbf {H} }{2}}={\\frac {\\mathbf {B} \\cdot \\mathbf {B} }{2\\mu }}={\\frac {\\mu \\mathbf {H} \\cdot \\mathbf {H} }{2}}.}\n  If there are no magnetic materials around then \u03bc can be replaced by \u03bc0. The above equation cannot be used for nonlinear materials, though; a more general expression given below must be used.\nIn general, the incremental amount of work per unit volume \u03b4W needed to cause a small change of magnetic field \u03b4B is:\n\n  \n    \n      \n        \u03b4\n        W\n        =\n        \n          H\n        \n        \u22c5\n        \u03b4\n        \n          B\n        \n        .\n      \n    \n    {\\displaystyle \\delta W=\\mathbf {H} \\cdot \\delta \\mathbf {B} .}\n  Once the relationship between H and B is known this equation is used to determine the work needed to reach a given magnetic state. For hysteretic materials such as ferromagnets and superconductors, the work needed also depends on how the magnetic field is created. For linear non-dispersive materials, though, the general equation leads directly to the simpler energy density equation given above.\n\n\n== Electromagnetism: the relationship between magnetic and electric fields ==\n\n\n=== Faraday's Law: Electric force due to a changing B-field ===\n\nA changing magnetic field, such as a magnet moving through a conducting coil, generates an electric field (and therefore tends to drive a current in such a coil). This is known as Faraday's law and forms the basis of many electrical generators and electric motors.\nMathematically, Faraday's law is:\n\n  \n    \n      \n        \n          \n            E\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              \u03a6\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\mathcal {E}}=-{\\frac {\\mathrm {d} \\Phi }{\\mathrm {d} t}},}\n  where \n  \n    \n      \n        \n          \n            \n              E\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\mathcal {E}}}\n   is the electromotive force (or EMF, the voltage generated around a closed loop) and \u03a6 is the magnetic flux\u2014the product of the area times the magnetic field normal to that area.  (This definition of magnetic flux is why B is often referred to as magnetic flux density.)The negative sign represents the fact that any current generated by a changing magnetic field in a coil produces a magnetic field that opposes the change in the magnetic field that induced it. This phenomenon is known as Lenz's law.\nThis integral formulation of Faraday's law can be converted into a differential form, which applies under slightly different conditions. This form is covered as one of Maxwell's equations below.\n\n\n=== Maxwell's correction to Amp\u00e8re's Law: The magnetic field due to a changing electric field ===\n\nSimilar to the way that a changing magnetic field generates an electric field, a changing electric field generates a magnetic field. This fact is known as Maxwell's correction to Amp\u00e8re's law and is applied as an additive term to Ampere's law as given above. This additional term is proportional to the time rate of change of the electric flux and is similar to Faraday's law above but with a different and positive constant out front. (The electric flux through an area is proportional to the area times the perpendicular part of the electric field.)\nThe full law including the correction term is known as the Maxwell\u2013Amp\u00e8re equation. It is not commonly given in integral form because the effect is so small that it can typically be ignored in most cases where the integral form is used.\nThe Maxwell term is critically important in the creation and propagation of electromagnetic waves. Maxwell's correction to Amp\u00e8re's Law together with Faraday's law of induction describes how mutually changing electric and magnetic fields interact to sustain each other and thus to form electromagnetic waves, such as light: a changing electric field generates a changing magnetic field, which generates a changing electric field again. These, though, are usually described using the differential form of this equation given below.\n\n\n=== Maxwell's equations ===\n\nLike all vector fields, a magnetic field has two important mathematical properties that relates it to its sources.  (For B the sources are currents and changing electric fields.) These two properties, along with the two corresponding properties of the electric field, make up Maxwell's Equations. Maxwell's Equations together with the Lorentz force law form a complete description of classical electrodynamics including both electricity and magnetism.\nThe first property is the divergence of a vector field A, \u2207 \u00b7 A, which represents how A 'flows' outward from a given point. As discussed above, a B-field line never starts or ends at a point but instead forms a complete loop. This is mathematically equivalent to saying that the divergence of B is zero. (Such vector fields are called solenoidal vector fields.) This property is called Gauss's law for magnetism and is equivalent to the statement that there are no isolated magnetic poles or magnetic monopoles. The electric field on the other hand begins and ends at electric charges so that its divergence is non-zero and proportional to the charge density (See Gauss's law).\nThe second mathematical property is called the curl, such that \u2207 \u00d7 A represents how A curls or 'circulates' around a given point. The result of the curl is called a 'circulation source'. The equations for the curl of B and of E are called the Amp\u00e8re\u2013Maxwell equation and Faraday's law respectively. They represent the differential forms of the integral equations given above.\nThe complete set of Maxwell's equations then are:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  E\n                \n              \n              \n                \n                =\n                \n                  \n                    \u03c1\n                    \n                      \u03b5\n                      \n                        0\n                      \n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  B\n                \n              \n              \n                \n                =\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  J\n                \n                +\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  \u03b5\n                  \n                    0\n                  \n                \n                \n                  \n                    \n                      \u2202\n                      \n                        E\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {E} &={\\frac {\\rho }{\\varepsilon _{0}}},\\\\\\nabla \\times \\mathbf {B} &=\\mu _{0}\\mathbf {J} +\\mu _{0}\\varepsilon _{0}{\\frac {\\partial \\mathbf {E} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}},\\end{aligned}}}\n  where J = complete microscopic current density and \u03c1 is the charge density.\nAs discussed above, materials respond to an applied electric E field and an applied magnetic B field by producing their own internal 'bound' charge and current distributions that contribute to E and B but are difficult to calculate. To circumvent this problem, H and D fields are used to re-factor Maxwell's equations in terms of the free current density Jf and free charge density \u03c1f:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  D\n                \n              \n              \n                \n                =\n                \n                  \u03c1\n                  \n                    \n                      f\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  H\n                \n              \n              \n                \n                =\n                \n                  \n                    J\n                  \n                  \n                    \n                      f\n                    \n                  \n                \n                +\n                \n                  \n                    \n                      \u2202\n                      \n                        D\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {D} &=\\rho _{\\mathrm {f} },\\\\\\nabla \\times \\mathbf {H} &=\\mathbf {J} _{\\mathrm {f} }+{\\frac {\\partial \\mathbf {D} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}}.\\end{aligned}}}\n  These equations are not any more general than the original equations (if the 'bound' charges and currents in the material are known). They also must be supplemented by the relationship between B and H as well as that between E and D. On the other hand, for simple relationships between these quantities this form of Maxwell's equations can circumvent the need to calculate the bound charges and currents.\n\n\n=== Electric and magnetic fields: different aspects of the same phenomenon ===\n\nAccording to the special theory of relativity, the partition of the electromagnetic force into separate electric and magnetic components is not fundamental, but varies with the observational frame of reference: An electric force perceived by one observer may be perceived by another (in a different frame of reference) as a magnetic force, or a mixture of electric and magnetic forces.\nFormally, special relativity combines the electric and magnetic fields into a rank-2 tensor, called the electromagnetic tensor. Changing reference frames mixes these components. This is analogous to the way that special relativity mixes space and time into spacetime, and mass, momentum and energy into four-momentum.\n\n\n=== Magnetic vector potential ===\n\nIn advanced topics such as quantum mechanics and relativity it is often easier to work with a potential formulation of electrodynamics rather than in terms of the electric and magnetic fields. In this representation, the vector potential A, and the scalar potential \u03c6, are defined such that:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  B\n                \n              \n              \n                \n                =\n                \u2207\n                \u00d7\n                \n                  A\n                \n                ,\n              \n            \n            \n              \n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \u2207\n                \u03c6\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        A\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {B} &=\\nabla \\times \\mathbf {A} ,\\\\\\mathbf {E} &=-\\nabla \\varphi -{\\frac {\\partial \\mathbf {A} }{\\partial t}}.\\end{aligned}}}\n  The vector potential A may be interpreted as a generalized potential momentum per unit charge just as \u03c6 is interpreted as a generalized potential energy per unit charge.\nMaxwell's equations when expressed in terms of the potentials can be cast into a form that agrees with special relativity with little effort. In relativity A together with \u03c6 forms the four-potential, analogous to the four-momentum that combines the momentum and energy of a particle. Using the four potential instead of the electromagnetic tensor has the advantage of being much simpler\u2014and it can be easily modified to work with quantum mechanics.\n\n\n=== Quantum electrodynamics ===\n\nIn modern physics, the electromagnetic field is understood to be not a classical field, but rather a quantum field; it is represented not as a vector of three numbers at each point, but as a vector of three quantum operators at each point. The most accurate modern description of the electromagnetic interaction (and much else) is quantum electrodynamics (QED), which is incorporated into a more complete theory known as the Standard Model of particle physics.\nIn QED, the magnitude of the electromagnetic interactions between charged particles (and their antiparticles) is computed using perturbation theory. These rather complex formulas produce a remarkable pictorial representation as Feynman diagrams in which virtual photons are exchanged.\nPredictions of QED agree with experiments to an extremely high degree of accuracy: currently about 10\u221212 (and limited by experimental errors); for details see precision tests of QED. This makes QED one of the most accurate physical theories constructed thus far.\nAll equations in this article are in the classical approximation, which is less accurate than the quantum description mentioned here. However, under most everyday circumstances, the difference between the two theories is negligible.\n\n\n== Important uses and examples of magnetic field ==\n\n\n=== Earth's magnetic field ===\n\nThe Earth's magnetic field is produced by convection of a liquid iron alloy in the outer core. In a dynamo process, the movements drive a feedback process in which electric currents create electric and magnetic fields that in turn act on the currents.The field at the surface of the Earth is approximately the same as if a giant bar magnet were positioned at the center of the Earth and tilted at an angle of about 11\u00b0 off the rotational axis of the Earth (see the figure). The north pole of a magnetic compass needle points roughly north, toward the North Magnetic Pole. However, because a magnetic pole is attracted to its opposite, the North Magnetic Pole is actually the south pole of the geomagnetic field. This confusion in terminology arises because the pole of a magnet is defined by the geographical direction it points.Earth's magnetic field is not constant\u2014the strength of the field and the location of its poles vary. Moreover, the poles periodically reverse their orientation in a process called geomagnetic reversal. The most recent reversal occurred 780,000 years ago.\n\n\n=== Rotating magnetic fields ===\n\nThe rotating magnetic field is a key principle in the operation of alternating-current motors. A permanent magnet in such a field rotates so as to maintain its alignment with the external field. This effect was conceptualized by Nikola Tesla, and later utilized in his, and others', early AC (alternating current) electric motors.\nA rotating magnetic field can be constructed using two orthogonal coils with 90 degrees phase difference in their AC currents. However, in practice such a system would be supplied through a three-wire arrangement with unequal currents.\nThis inequality would cause serious problems in standardization of the conductor size and so, to overcome it, three-phase systems are used where the three currents are equal in magnitude and have 120 degrees phase difference. Three similar coils having mutual geometrical angles of 120 degrees create the rotating magnetic field in this case. The ability of the three-phase system to create a rotating field, utilized in electric motors, is one of the main reasons why three-phase systems dominate the world's electrical power supply systems.\nSynchronous motors use DC-voltage-fed rotor windings, which lets the excitation of the machine be controlled\u2014and induction motors use short-circuited rotors (instead of a magnet) following the rotating magnetic field of a multicoiled stator. The short-circuited turns of the rotor develop eddy currents in the rotating field of the stator, and these currents in turn move the rotor by the Lorentz force.\nIn 1882, Nikola Tesla identified the concept of the rotating magnetic field. In 1885, Galileo Ferraris independently researched the concept. In 1888, Tesla gained U.S. Patent 381,968 for his work. Also in 1888, Ferraris published his research in a paper to the Royal Academy of Sciences in Turin.\n\n\n=== Hall effect ===\n\nThe charge carriers of a current-carrying conductor placed in a transverse magnetic field experience a sideways Lorentz force; this results in a charge separation in a direction perpendicular to the current and to the magnetic field. The resultant voltage in that direction is proportional to the applied magnetic field. This is known as the Hall effect.\nThe Hall effect is often used to measure the magnitude of a magnetic field. It is used as well to find the sign of the dominant charge carriers in materials such as semiconductors (negative electrons or positive holes).\n\n\n=== Magnetic circuits ===\n\nAn important use of H is in magnetic circuits where B = \u03bcH inside a linear material. Here, \u03bc is the magnetic permeability of the material. This result is similar in form to Ohm's law J = \u03c3E, where J is the current density, \u03c3 is the conductance and E is the electric field. Extending this analogy, the counterpart to the macroscopic Ohm's law (I = V\u2044R) is:\n\n  \n    \n      \n        \u03a6\n        =\n        \n          \n            \n              F\n              R\n            \n          \n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\Phi ={\\frac {F}{R}}_{\\mathrm {m} },}\n  where \n  \n    \n      \n        \u03a6\n        =\n        \u222b\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\displaystyle \\Phi =\\int \\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} }\n   is the magnetic flux in the circuit, \n  \n    \n      \n        F\n        =\n        \u222b\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle F=\\int \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is the magnetomotive force  applied to the circuit, and Rm is the reluctance of the circuit. Here the reluctance Rm is a quantity similar in nature to resistance for the flux.\nUsing this analogy it is straightforward to calculate the magnetic flux of complicated magnetic field geometries, by using all the available techniques of circuit theory.\n\n\n=== Magnetic field shape descriptions ===\n\nAn azimuthal magnetic field is one that runs east\u2013west.\nA meridional magnetic field is one that runs north\u2013south. In the solar dynamo model of the Sun, differential rotation of the solar plasma causes the meridional magnetic field to stretch into an azimuthal magnetic field, a process called the omega-effect. The reverse process is called the alpha-effect.\nA dipole magnetic field is one seen around a bar magnet or around a charged elementary particle with nonzero spin.\nA quadrupole magnetic field is one seen, for example, between the poles of four bar magnets. The field strength grows linearly with the radial distance from its longitudinal axis.\nA solenoidal magnetic field is similar to a dipole magnetic field, except that a solid bar magnet is replaced by a hollow electromagnetic coil magnet.\nA toroidal magnetic field occurs in a doughnut-shaped coil, the electric current spiraling around the tube-like surface, and is found, for example, in a tokamak.\nA poloidal magnetic field is generated by a current flowing in a ring, and is found, for example, in a tokamak.\nA radial magnetic field is one in which field lines are directed from the center outwards, similar to the spokes in a bicycle wheel. An example can be found in a loudspeaker transducers (driver).\nA helical magnetic field is corkscrew-shaped, and sometimes seen in space plasmas such as the Orion Molecular Cloud.\n\n\n=== Magnetic dipoles ===\n\nThe magnetic field of a magnetic dipole is depicted in the figure. From outside, the ideal magnetic dipole is identical to that of an ideal electric dipole of the same strength. Unlike the electric dipole, a magnetic dipole is properly modeled as a current loop having a current I and an area a. Such a current loop has a magnetic moment of:\n\n  \n    \n      \n        m\n        =\n        I\n        a\n        ,\n        \n      \n    \n    {\\displaystyle m=Ia,\\,}\n  where the direction of m is perpendicular to the area of the loop and depends on the direction of the current using the right-hand rule. An ideal magnetic dipole is modeled as a real magnetic dipole whose area a has been reduced to zero and its current I increased to infinity such that the product m = Ia is finite. This model clarifies the connection between angular momentum and magnetic moment, which is the basis of the Einstein\u2013de Haas effect rotation by magnetization and its inverse, the Barnett effect or magnetization by rotation. Rotating the loop faster (in the same direction) increases the current and therefore the magnetic moment, for example.\nIt is sometimes useful to model the magnetic dipole similar to the electric dipole with two equal but opposite magnetic charges (one south the other north) separated by distance d. This model produces an H-field not a B-field. Such a model is deficient, though, both in that there are no magnetic charges and in that it obscures the link between electricity and magnetism. Further, as discussed above it fails to explain the inherent connection between angular momentum and magnetism.\n\n\n=== Magnetic monopole (hypothetical) ===\n\nA magnetic monopole is a hypothetical particle (or class of particles) that has, as its name suggests, only one magnetic pole (either a north pole or a south pole). In other words, it would possess a \"magnetic charge\" analogous to an electric charge. Magnetic field lines would start or end on magnetic monopoles, so if they exist, they would give exceptions to the rule that magnetic field lines neither start nor end.\nModern interest in this concept stems from particle theories, notably Grand Unified Theories and superstring theories, that predict either the existence, or the possibility, of magnetic monopoles. These theories and others have inspired extensive efforts to search for monopoles. Despite these efforts, no magnetic monopole has been observed to date.In recent research, materials known as spin ices can simulate monopoles, but do not contain actual monopoles.\n\n\n== See also ==\n\n\n=== General ===\nMagnetohydrodynamics \u2013 the study of the dynamics of electrically conducting fluids\nMagnetic hysteresis \u2013 application to ferromagnetism\nMagnetic nanoparticles \u2013 extremely small magnetic particles that are tens of atoms wide\nMagnetic reconnection \u2013 an effect that causes solar flares and auroras\nMagnetic potential \u2013 the vector and scalar potential representation of magnetism\nSI electromagnetism units \u2013 common units used in electromagnetism\nOrders of magnitude (magnetic field) \u2013 list of magnetic field sources and measurement devices from smallest magnetic fields to largest detected\nUpward continuation\n\n\n=== Mathematics ===\nMagnetic helicity \u2013 extent to which a magnetic field wraps around itself\n\n\n=== Applications ===\nDynamo theory \u2013 a proposed mechanism for the creation of the Earth's magnetic field\nHelmholtz coil \u2013 a device for producing a region of nearly uniform magnetic field\nMagnetic field viewing film \u2013 Film used to view the magnetic field of an area\nMaxwell coil \u2013 a device for producing a large volume of an almost constant magnetic field\nStellar magnetic field \u2013 a discussion of the magnetic field of stars\nTeltron tube \u2013 device used to display an electron beam and demonstrates effect of electric and magnetic fields on moving charges\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==",
        "unit": "magnetic field",
        "url": "https://en.wikipedia.org/wiki/Magnetic_field"
    },
    {
        "_id": "Ampere",
        "clean": "Ampere",
        "text": "The ampere (; symbol: A), often shortened to \"amp\", is the base unit of electric current in the  International System of Units (SI). It is named after Andr\u00e9-Marie Amp\u00e8re (1775\u20131836), French mathematician and physicist, considered the father of electrodynamics.\nThe International System of Units defines the ampere in terms of other base units by measuring the electromagnetic force between electrical conductors carrying electric current. The earlier CGS measurement system had two different definitions of current, one essentially the same as the SI's and the other using electric charge as the base unit, with the unit of charge defined by measuring the force between two charged metal plates. The ampere was then defined as one coulomb of charge per second. In SI, the unit of charge, the coulomb, is defined as the charge carried by one ampere during one second.  \n\n\n== Definition ==\n\nSI defines ampere as follows:\n\nThe ampere is that constant current which, if maintained in two straight parallel conductors of infinite length, of negligible circular cross-section, and placed one metre apart in vacuum, would produce between these conductors a force equal to 2\u00d710\u22127 newtons per metre of length.\n\nAmp\u00e8re's force law states that there is an attractive or repulsive force between two parallel wires carrying an electric current. This force is used in the formal definition of the ampere.\nThe SI unit of charge, the coulomb, \"is the quantity of electricity carried in 1 second by a current of 1 ampere\". Conversely, a current of one ampere is one coulomb of charge going past a given point per second:\n\n  \n    \n      \n        \n          \n            1\n             \n            A\n            =\n            1\n            \n              \n                \n                  C\n                  s\n                \n              \n            \n            .\n          \n        \n      \n    \n    {\\displaystyle {\\rm {1\\ A=1{\\tfrac {C}{s}}.}}}\n  In general, charge Q is determined by steady current I flowing for a time t as Q = It.\nConstant, instantaneous and average current are expressed in amperes (as in \"the charging current is 1.2 A\") and the charge accumulated, or passed through a circuit over a period of time is expressed in coulombs (as in \"the battery charge is 30000 C\"). The relation of the ampere (C/s) to the coulomb is the same as that of the watt (J/s) to the joule.\n\n\n== History ==\n\nThe ampere was originally defined as one tenth of the unit of electric current in the centimetre\u2013gram\u2013second system of units. That unit, now known as the abampere, was defined as the amount of current that generates a force of two dynes per centimetre of length between two wires one centimetre apart. The size of the unit was chosen so that the units derived from it in the MKSA system would be conveniently sized.\nThe \"international ampere\" was an early realization of the ampere, defined as the current that would deposit 0.001118 grams of silver per second from a silver nitrate solution. Later, more accurate measurements revealed that this current is 0.99985 A.\nSince  power is defined as the product of current and voltage, the ampere can alternatively be expressed in terms of the other units using the relationship I=P/V, and thus 1 ampere equals 1 W/V. Current can be measured by a multimeter, a device that can measure electrical voltage, current, and resistance.\n\n\n== Realization ==\nThe standard ampere is most accurately realized using a Kibble balance, but is in practice maintained via Ohm's law from the units of electromotive force and resistance, the volt and the ohm, since the latter two can be tied to physical phenomena that are relatively easy to reproduce, the Josephson junction and the quantum Hall effect, respectively.At present, techniques to establish the realization of an ampere have a relative uncertainty of approximately a few parts in 107, and involve realizations of the watt, the ohm and the volt.\n\n\n== Proposed future definition ==\n\nRather than a definition in terms of the force between two current-carrying wires, it has been proposed that the ampere should be defined in terms of the rate of flow of elementary charges. Since a coulomb is approximately equal to 6.2415093\u00d71018 elementary charges (such as those carried by protons, or the negative of those carried by electrons), one ampere is approximately equivalent to 6.2415093\u00d71018 elementary charges moving past a boundary in one second. (6.2415093\u00d71018 is the reciprocal of the value of the elementary charge in coulombs.) The proposed change would define 1 A as being the current in the direction of flow of a particular number of elementary charges per second. In 2005, the International Committee for Weights and Measures (CIPM) agreed to study the proposed change. The new definition was discussed at the 25th General Conference on Weights and Measures (CGPM) in 2014 but for the time being was not adopted.\n\n\n== Everyday examples ==\n\nThe current drawn by typical constant-voltage energy distribution systems is usually dictated by the power (watt) consumed by the system and the operating voltage. For this reason the examples given below are grouped by voltage level.\n\n\n=== CPUs \u2013 1 V DC ===\nCurrent Notebook CPUs (up to 15...45 W at 1 V): up to 15...45 A\nCurrent High End CPUs (up to 65...140 W at 1.15 V): up to 55...120 A\n\n\n=== Portable devices ===\nHearing aid (typically 1 mW at 1.4 V): 700 \u00b5A\nUSB charging adapter (as power supply - typically 10 W at 5 V): 2 A\n\n\n=== Internal combustion engine vehicles \u2013 12 V DC ===\nA typical motor vehicle has a 12 V battery. The various accessories that are powered by the battery might include:\n\nInstrument panel light (typically 2 W): 166 mA\nHeadlight (each, typically 60 W): 5 A\nStarter motor on a smaller car: 50 A to 200 A\n\n\n=== North American domestic supply \u2013 120 V AC ===\nMost Canada, Mexico and United States domestic power suppliers run at 120 V.\nHousehold circuit breakers typically provide a maximum of 15 A or 20 A of current to a given set of outlets.\n\nUSB charging adapter (as load - typically 10 W): 83 mA\n22-inch/56-centimeter portable television (35 W): 290 mA\nTungsten light bulb (60\u2013100 W): 500\u2013830 mA\nToaster, kettle (1.5 kW): 12.5 A\nHair dryer (1.8 kW): 15 A\n\n\n=== European & Commonwealth domestic supply \u2013 230\u2013240 V AC ===\nMost European domestic power supplies run at 230 V, and most Commonwealth domestic power supplies run at 240 V. For the same amount of power (in watts), the current drawn by a particular European or Commonwealth appliance (in Europe or a Commonwealth country) will be less than for an equivalent North American appliance. Typical circuit breakers will provide 16 A.\nThe current drawn by a number of typical appliances are:\n\nCompact fluorescent lamp (11\u201330 W): 56\u2013112 mA\n22-inch/56-centimeter portable television (35 W): 145\u2013150 mA\nTungsten light bulb (60\u2013100 W): 240\u2013450 mA\nToaster, kettle (2 kW): 9 A\nImmersion heater (4.6 kW): 19\u201320 A\n\n\n== See also ==\nAmmeter\nAmpacity (current-carrying capacity)\nElectric current\nElectric shock\nHydraulic analogy\nMagnetic constant\nOrders of magnitude (current)\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nThe NIST Reference on Constants, Units, and Uncertainty\nNIST Definition of ampere and \u03bc0\nTutorial video explaining amperes and current",
        "unit": "milliampere",
        "url": "https://en.wikipedia.org/wiki/Ampere"
    },
    {
        "_id": "Concentration",
        "clean": "Concentration",
        "text": "In chemistry, concentration is the abundance of a constituent divided by the total volume of a mixture. Several types of mathematical description can be distinguished: mass concentration, molar concentration, number concentration, and volume concentration. The term concentration can be applied to any kind of chemical mixture, but most frequently it refers to solutes and solvents in solutions. The molar (amount) concentration has variants such as normal concentration and osmotic concentration.\n\n\n== Qualitative description ==\n\nOften in informal, non-technical language, concentration is described in a qualitative way, through the use of adjectives such as \"dilute\" for solutions of relatively low concentration and \"concentrated\" for solutions of relatively high concentration. To concentrate a solution, one must add more solute (for example, alcohol), or reduce the amount of solvent (for example, water). By contrast, to dilute a solution, one must add more solvent, or reduce the amount of solute. Unless two substances are fully miscible there exists a concentration at which no further solute will dissolve in a solution. At this point, the solution is said to be saturated. If additional solute is added to a saturated solution, it will not dissolve, except in certain circumstances, when supersaturation may occur. Instead, phase separation will occur, leading to coexisting phases, either completely separated or mixed as a suspension. The point of saturation depends on many variables such as ambient temperature and the precise chemical nature of the solvent and solute.\nConcentrations are often called levels, reflecting the mental schema of levels on the vertical axis of a graph, which can be high or low (for example, \"high serum levels of bilirubin\" are concentrations of bilirubin in the blood serum that are greater than normal).\n\n\n== Quantitative notation ==\nThere are four quantities that describe concentration:\n\n\n=== Mass concentration ===\n\nThe mass concentration \n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\rho _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\rho _{i}={\\frac {m_{i}}{V}}.}\n  The SI unit is kg/m3 (equal to g/L).\n\n\n=== Molar concentration ===\n\nThe molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle c_{i}={\\frac {n_{i}}{V}}.}\n  The SI unit is mol/m3. However, more commonly the unit mol/L (= mol/dm3) is used.\n\n\n=== Number concentration ===\n\nThe number concentration \n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle C_{i}}\n   is defined as the number of entities of a constituent \n  \n    \n      \n        \n          N\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle N_{i}}\n   in a mixture divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n        =\n        \n          \n            \n              N\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle C_{i}={\\frac {N_{i}}{V}}.}\n  The SI unit is 1/m3.\n\n\n=== Volume concentration ===\nThe volume concentration \n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\phi _{i}}\n   (not to be confused with volume fraction) is defined as the volume of a constituent \n  \n    \n      \n        \n          V\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle V_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n        =\n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\phi _{i}={\\frac {V_{i}}{V}}.}\n  Being dimensionless, it is expressed as a number, e.g., 0.18 or 18%; its unit is 1.\n\n\n== Related quantities ==\nSeveral other quantities can be used to describe the composition of a mixture. Note that these should not be called concentrations.\n\n\n=== Normality ===\n\nNormality is defined as the molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   divided by an equivalence factor \n  \n    \n      \n        \n          f\n          \n            \n              e\n              q\n            \n          \n        \n      \n    \n    {\\displaystyle f_{\\mathrm {eq} }}\n  . Since the definition of the equivalence factor depends on context (which reaction is being studied), IUPAC and NIST discourage the use of normality.\n\n\n=== Molality ===\n\n(Not to be confused with Molarity)\nThe molality of a solution \n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle b_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the mass of the solvent \n  \n    \n      \n        \n          m\n          \n            \n              s\n              o\n              l\n              v\n              e\n              n\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {solvent} }}\n   (not the mass of the solution):\n\n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  s\n                  o\n                  l\n                  v\n                  e\n                  n\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle b_{i}={\\frac {n_{i}}{m_{\\mathrm {solvent} }}}.}\n  The SI unit for molality is mol/kg.\n\n\n=== Mole fraction ===\n\nThe mole fraction \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the total amount of all constituents in a mixture \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  :\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              n\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }}}.}\n  The SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole fractions.\n\n\n=== Mole ratio ===\n\nThe mole ratio \n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle r_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   divided by the total amount of all other constituents in a mixture:\n\n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              \n                n\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                n\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle r_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }-n_{i}}}.}\n  If \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   is much smaller than \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  , the mole ratio is almost identical to the mole fraction.\nThe SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole ratios.\n\n\n=== Mass fraction ===\n\nThe mass fraction \n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle w_{i}}\n   is the fraction of one substance with mass \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   to the mass of the total mixture \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , defined as:\n\n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle w_{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }}}.}\n  The SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass fractions.\n\n\n=== Mass ratio ===\n\nThe mass ratio \n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\zeta _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the total mass of all other constituents in a mixture:\n\n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              \n                m\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                m\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\zeta _{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }-m_{i}}}.}\n  If \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   is much smaller than \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , the mass ratio is almost identical to the mass fraction.\nThe SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass ratios.\n\n\n== Dependence on volume ==\nConcentration depends on the variation of the volume of the solution with temperature due mainly to thermal expansion.\n\n\n== Table of concentrations and related quantities ==\n\n\n== See also ==\nDilution ratio\nDose concentration\nSerial dilution\nWine/water mixing problem\n\n\n== References ==",
        "unit": "concentration",
        "url": "https://en.wikipedia.org/wiki/Concentration"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Dynamic (shear) viscosity ===\n\nThe dynamic viscosity of a fluid expresses its resistance to shearing flows, where adjacent layers move parallel to each other with different speeds. It can be defined through the idealized situation known as a Couette flow, where a layer of fluid is trapped between two horizontal plates, one fixed and one moving horizontally at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  . This fluid has to be homogeneous in the layer and at different shear stresses. (The plates are assumed to be very large so that one need not consider what happens near their edges.)\nIf the speed of the top plate is low enough, the fluid particles will move parallel to it, and their speed will vary linearly from zero at the bottom to u at the top. Each layer of fluid will move faster than the one just below it, and friction between them will give rise to a force resisting their relative motion. In particular, the fluid will apply on the top plate a force in the direction opposite to its motion, and an equal but opposite one to the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nThe magnitude F of this force is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc in this formula is the viscosity (specifically, the dynamic viscosity) of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second).\nThe ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). Isaac Newton expressed the viscous forces by the differential equation\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This formula assumes that the flow is moving along parallel lines to x-axis. Furthermore, it assumes that the y-axis, perpendicular to the flow, points in the direction of maximum shear velocity. This equation can be used where the velocity does not vary linearly with y, such as in fluid flowing through a pipe. This equation is called the defining equation for shear viscosity. The viscosity is not a material constant, but a material property that depends on physical properties like temperature. The functional relationship between viscosity and other physical properties is described by a mathematical viscosity model called a constitutive equation which is usually more complex than the defining equation for viscosity. There exist  many viscosity models, and based on type of development-reasoning, some viscosity models are selected and presented in the article Viscosity models for mixtures.\nUse of the Greek letter mu (\u03bc) for the dynamic stress viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC.\n\n\n=== Kinematic viscosity ===\nThe kinematic viscosity (also called \"momentum diffusivity\") is the ratio of the dynamic viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {m^{2}/s} }\n  . \n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  A convenient concept when analyzing the Reynolds number, which expresses the ratio of the inertial forces to the viscous forces, is:\n\n  \n    \n      \n        \n          R\n          e\n        \n        =\n        \n          \n            \n              \u03c1\n              V\n              D\n            \n            \u03bc\n          \n        \n        =\n        \n          \n            \n              V\n              D\n            \n            \u03bd\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathrm {Re} ={\\frac {\\rho VD}{\\mu }}={\\frac {VD}{\\nu }},}\n  where D is a diameter in the system, and V is the velocity of the fluid with respect to the object (m/s).\n\n\n=== Bulk viscosity ===\n\nWhen a compressible fluid is compressed or expanded evenly, without shear, it may still exhibit a form of internal friction that resists its flow. These forces are related to the rate of compression or expansion by a factor called the volume viscosity, bulk viscosity or second viscosity.\nThe bulk viscosity is important only when the fluid is being rapidly compressed or expanded, such as in sound and shock waves. Bulk viscosity explains the loss of energy in those waves, as described by Stokes' law of sound attenuation.\n\n\n=== Viscosity tensor ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure.\nIn very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model, the relationship is by definition a linear map, described by a viscosity tensor that, multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor.\nThe viscosity tensor has nine independent degrees of freedom in general. For isotropic Newtonian fluids, these can be reduced to two independent parameters. The most usual decomposition yields the dynamic viscosity \u03bc and the bulk viscosity \u03c3.\n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes.  It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nThe viscosity of a system is determined by how molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the Transient Time Correlation Function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, in order to calculate the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations.\n\n\n=== Gases ===\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. The kinetic theory of gases allows accurate prediction of the behavior of gaseous viscosity.\nWithin the regime where the theory is applicable:\n\nViscosity is independent of pressure and\nViscosity increases as temperature increases.James Clerk Maxwell published a famous paper in 1866 using the kinetic theory of gases to study gaseous viscosity. To understand why the viscosity is independent of pressure, consider two adjacent boundary layers (A and B) moving with respect to each other. The internal friction (the viscosity) of the gas is determined by the probability a particle of layer A enters layer B with a corresponding transfer of momentum. Maxwell's calculations show that the viscosity coefficient is proportional to the density, the mean free path, and the mean velocity of the atoms. On the other hand, the mean free path is inversely proportional to the density. So an increase in density due to an increase in pressure doesn't result in any change in viscosity.\n\n\n==== Relation to mean free path of diffusing particles ====\nIn relation to diffusion, the kinematic viscosity provides a better understanding of the behavior of mass transport of a dilute species. Viscosity is related to shear stress and the rate of shear in a fluid, which illustrates its dependence on the mean free path, \u03bb, of the diffusing particles.\nFrom fluid mechanics, for a Newtonian fluid, the shear stress, \u03c4, on a unit area moving parallel to itself, is found to be proportional to the rate of change of velocity with distance perpendicular to the unit area:\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \n                d\n              \n              \n                u\n                \n                  x\n                \n              \n            \n            \n              \n                d\n              \n              y\n            \n          \n        \n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}}\n  for a unit area parallel to the xz-plane, moving along the x axis. We will derive this formula and show how \u03bc is related to \u03bb.\nInterpreting shear stress as the time rate of change of momentum, p, per unit area A (rate of momentum flux) of an arbitrary control surface gives\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            \n              \n                p\n                \u02d9\n              \n            \n            A\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    m\n                    \u02d9\n                  \n                \n              \n              \n                \u27e8\n                \n                  u\n                  \n                    x\n                  \n                \n                \u27e9\n              \n            \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau ={\\frac {\\dot {p}}{A}}={\\frac {{\\dot {m}}\\left\\langle u_{x}\\right\\rangle }{A}}.}\n  where \u27e8ux\u27e9 is the average velocity, along the x-axis, of fluid molecules hitting the unit area, with respect to the unit area and \u1e41 is the rate of fluid mass hitting the surface.\nBy making simplified assumption that the velocity of the molecules depends linearly on the distance they are coming from, the mean velocity depends linearly on the mean distance:\n\n  \n    \n      \n        \n          \u27e8\n          \n            u\n            \n              x\n            \n          \n          \u27e9\n        \n        =\n        \u03bb\n        \n          \n            \n              \n                d\n              \n              \n                u\n                \n                  x\n                \n              \n            \n            \n              \n                d\n              \n              y\n            \n          \n        \n      \n    \n    {\\displaystyle \\left\\langle u_{x}\\right\\rangle =\\lambda {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}}\n  .\nFurther manipulation will show,\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      m\n                      \u02d9\n                    \n                  \n                \n              \n              \n                \n                =\n                \u03c1\n                \n                  \n                    \n                      u\n                      \u00af\n                    \n                  \n                \n                A\n              \n            \n            \n              \n                \u03c4\n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        \u03c1\n                        \n                          \n                            \n                              u\n                              \u00af\n                            \n                          \n                        \n                        \u03bb\n                      \n                      \u23df\n                    \n                  \n                  \n                    \u03bc\n                  \n                \n                \u22c5\n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        u\n                        \n                          x\n                        \n                      \n                    \n                    \n                      \n                        d\n                      \n                      y\n                    \n                  \n                \n                \n                \u21d2\n                \n                \u03bd\n                =\n                \n                  \n                    \u03bc\n                    \u03c1\n                  \n                \n                =\n                \n                  \n                    \n                      u\n                      \u00af\n                    \n                  \n                \n                \u03bb\n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\dot {m}}&=\\rho {\\bar {u}}A\\\\\\tau &=\\underbrace {\\rho {\\bar {u}}\\lambda } _{\\mu }\\cdot {\\frac {\\mathrm {d} u_{x}}{\\mathrm {d} y}}\\quad \\Rightarrow \\quad \\nu ={\\frac {\\mu }{\\rho }}={\\bar {u}}\\lambda ,\\end{aligned}}}\n  where\n\n\u03c1 is the density of the fluid,\n\u016b is the root mean square molecular speed: \u016b = \u221a\u27e8u2\u27e9,\n\u03bb is the mean free path,\n\u03bc is the dynamic viscosity.Note, that the mean free path itself typically depends (inversely) on the density.\n\n\n==== Effect of temperature on the viscosity of a gas ====\nSutherland's formula can be used to derive the dynamic viscosity of an ideal gas as a function of the temperature:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              C\n            \n            \n              T\n              +\n              C\n            \n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            \n              3\n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}{\\frac {T_{0}+C}{T+C}}\\left({\\frac {T}{T_{0}}}\\right)^{\\frac {3}{2}}.}\n  This, in turn, is equal to\n\n  \n    \n      \n        \u03bc\n        =\n        \u03bb\n        \n          \n            \n              T\n              \n                \n                  3\n                  2\n                \n              \n            \n            \n              T\n              +\n              C\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\lambda {\\frac {T^{\\frac {3}{2}}}{T+C}},}\n  where\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              \n                (\n                \n                  \n                    T\n                    \n                      0\n                    \n                  \n                  +\n                  C\n                \n                )\n              \n            \n            \n              T\n              \n                0\n              \n              \n                \n                  3\n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda ={\\frac {\\mu _{0}\\left(T_{0}+C\\right)}{T_{0}^{\\frac {3}{2}}}}}\n  is a constant for the gas.\nin Sutherland's formula:\n\n\u03bc = dynamic viscosity (Pa\u00b7s or \u03bcPa\u00b7s) at input temperature T,\n\u03bc0 = reference viscosity (in the same units as \u03bc) at reference temperature T0,\nT = input temperature (K),\nT0 = reference temperature (K),\nC = Sutherland's constant for the gaseous material in question.Valid for temperatures between 0 < T < 555 K with an error due to pressure less than 10% below 3.45 MPa.\nAccording to Sutherland's formula, if the absolute temperature is less than C, the relative change in viscosity for a small change in temperature is greater than the relative change in the absolute temperature, but it is smaller when T is above C. The kinematic viscosity though always increases faster than the temperature (that is, d log(\u03bd)/d log(T) is greater than 1).\nSutherland's constant, reference values and \u03bb values for some gases:\n\n\n==== Viscosity of a dilute gas ====\nThe Chapman\u2013Enskog equation may be used to estimate viscosity for a dilute gas. This equation is based on a semi-theoretical assumption by Chapman and Enskog. The equation requires three empirically determined parameters: the collision diameter (\u03c3), the maximum energy of attraction divided by the Boltzmann constant (\u03b5/\u043a) and the collision integral (\u03c9(T*)).\n\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n        \u00d7\n        \n          10\n          \n            6\n          \n        \n        =\n        \n          2.6693\n        \n        \n          \n            \n              M\n              T\n            \n            \n              \n                \u03c3\n                \n                  2\n                \n              \n              \u03c9\n              (\n              \n                T\n                \n                  \u2217\n                \n              \n              )\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{0}\\times 10^{6}={2.6693}{\\frac {\\sqrt {MT}}{\\sigma ^{2}\\omega (T^{*})}},}\n  with\n\nT* = \u03baT/\u03b5 is reduced temperature (dimensionless),\n\u03bc0 is viscosity for dilute gas (\u03bcPa\u00b7s),\nM is molecular mass (g/mol),\nT is temperature (K),\n\u03c3 is the collision diameter (\u00c5),\n\u03b5/\u043a is the maximum energy of attraction divided by the Boltzmann constant (K),\n\u03c9\u03bc is the collision integral.\n\n\n=== Liquids ===\n\nIn liquids, the additional forces between molecules become important. This leads to an additional contribution to the shear stress though the exact mechanics of this are still controversial. Thus, in liquids:\n\nViscosity is independent of pressure (except at very high pressure); and\nViscosity tends to fall as temperature increases (for example, water viscosity goes from 1.79 cP to 0.28 cP in the temperature range from 0 \u00b0C to 100 \u00b0C); see temperature dependence of liquid viscosity for more details.The dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n==== Viscosity of blends of liquids ====\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b1\n            \n          \n        \n        +\n        \n          \n            \n              \u03b1\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b1\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\alpha }}+{\\frac {\\alpha x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\alpha }}}\n  \n\n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\nx[i]=mole_fraction[i]\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464. \nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654. \n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity and other physical properties of frequent used pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "kinematic viscosity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "TNT_equivalent",
        "clean": "TNT equivalent",
        "text": "TNT equivalent is a convention for expressing energy, typically used to describe the energy released in an explosion. The \"ton of TNT\" is a unit of energy defined by that convention to be 4.184 gigajoules, which is the approximate energy released in the detonation of a metric ton (1,000 kilograms or one megagram) of TNT.   In other words, for each gram of TNT exploded, 4,184 joules of energy are released. \nThis convention intends to compare the destructiveness of an event with that of traditional explosive materials, of which TNT is a typical example, although other conventional explosives such as dynamite contain more energy.\n\n\n== Kiloton and megaton ==\nThe \"kiloton (of TNT)\" is a unit of energy equal to 4.184 terajoules.\nThe \"megaton (of TNT)\" is a unit of energy equal to 4.184 petajoules.\nThe kiloton and megaton of TNT have traditionally been used to describe the energy output, and hence the destructive power, of a nuclear weapon. The TNT equivalent appears in various nuclear weapon control treaties, and has been used to characterize the energy released in such other highly destructive events as an asteroid impact.\n\n\n== Historical derivation of the value ==\nA gram of TNT releases 2673\u20136702 J (joules) upon explosion. The energy liberated by one gram of TNT was arbitrarily defined as a matter of convention to be 4184 J, which is exactly one kilocalorie.\nAn explosive's energy is normally expressed as the thermodynamic work produced by its detonation, which for TNT has been accurately measured as 4686 J/g from a large sample of air blast experiments, and theoretically calculated to be 4853 J/g.The measured, pure heat output of a gram of TNT is only 2724 J, but this is not the important value for explosive blast effect calculations.\nAlternative TNT equivalency can be calculated as a function of when in the detonation the value is measured and which property is being compared.A kiloton of TNT can be visualized as a cube of TNT 8.46 metres (27.8 ft) on a side.\n\n\n== Conversion to other units ==\n1 ton TNT equivalent is approximately:\n\n1.0\u00d7109 calories\n4.184\u00d7109 joules\n3.96831\u00d7106 British thermal units\n3.08802\u00d7109 foot pounds\n1.162\u00d7103 kilowatt hours\n\n\n== Examples ==\n\n\n== Relative effectiveness factor ==\nThe relative effectiveness factor (RE factor) relates an explosive's demolition power to that of TNT, in units of the TNT equivalent/kg (TNTe/kg). The RE factor is the relative mass of TNT to which an explosive is equivalent: The greater the RE, the more powerful the explosive.\nThis enables engineers to determine the proper masses of different explosives when applying blasting formulas developed specifically for TNT. For example, if a timber-cutting formula calls for a charge of 1 kg of TNT, then based on octanitrocubane's RE factor of 2.38, it would take only 1.0/2.38 (or 0.42) kg of it to do the same job. Using PETN, engineers would need 1.0/1.66 (or 0.60) kg to obtain the same effects as 1 kg of TNT. With ANFO or ammonium nitrate, they would require 1.0/0.74 (or 1.35) kg or 1.0/0.42 (or 2.38) kg, respectively.\n\n\n=== RE factor examples ===\n*: TBX (thermobaric explosives) or EBX (enhanced blast explosives), in a small, confined space, may have over twice the power of destruction. The total power of aluminized mixtures strictly depends on the condition of explosions.\n\n\n=== Nuclear examples ===\n\n\n== See also ==\nBrisance\nNet explosive quantity\nNuclear weapon yield\nOrders of magnitude (energy)\nRelative effectiveness factor\nTable of explosive detonation velocities\nTon\nTonne\nTonne of oil equivalent, a unit of energy almost exactly 10 tonnes of TNT\n\n\n== References ==\n\nThompson, A.; Taylor, B.N. (July 2008). Guide for the Use of the International System of Units (SI). NIST Special Publication. 811. National Institute of Standards and Technology. Version 3.2. \nNuclear Weapons FAQ Part 1.3\nRhodes, Richard (2012). The Making of the Atomic Bomb (25th Anniversary ed.). Simon & Schuster. ISBN 978-1-4516-7761-4. \nCooper, Paul W. (1996), Explosives Engineering, New York: Wiley-VCH, ISBN 0-471-18636-8 \nHQ Department of the Army (2004) [1967], Field Manual 5-25: Explosives and Demolitions, Washington, D.C.: Pentagon Publishing, pp. 83\u201384, ISBN 0-9759009-5-1 \nExplosives - Compositions, Alexandria, VA: GlobalSecurity.org, retrieved September 1, 2010 \nUrba\u0144ski, Tadeusz (1985) [1984], Chemistry and Technology of Explosives, Volumes I\u2013IV (second ed.), Oxford: Pergamon \nMathieu, J\u00f6rg; Stucki, Hans (2004), \"Military High Explosives\", CHIMIA International Journal for Chemistry, Schweizerische Chemische Gesellschaft, 58 (6): 383\u2013389, doi:10.2533/000942904777677669, ISSN 0009-4293 \n3. Thermobaric Explosives, Advanced Energetic Materials, 2004., The National Academies Press, nap.edu, 2004",
        "unit": "kiloton",
        "url": "https://en.wikipedia.org/wiki/TNT_equivalent"
    },
    {
        "_id": "Kilogram",
        "clean": "Kilogram",
        "text": "The kilogram or kilogramme (symbol: kg) is the base unit of mass in the International System of Units (SI), and is defined as being equal to the mass of the International Prototype of the Kilogram (IPK, also known as \"Le Grand K\" or \"Big K\"), a cylinder of platinum-iridium alloy stored by the International Bureau of Weights and Measures at Saint-Cloud, France.\nThe kilogram was originally defined as the mass of a litre (cubic decimetre) of water at its freezing point. That was an inconvenient quantity to precisely replicate, so in the late 18th century a platinum artefact was fashioned as a standard for the kilogram.  That artefact, or an exact replica thereof, has been the standard of the unit of mass for the metric system ever since.\nThough the IPK, the current primary artefact, and its replicas are stored in carefully controlled laboratory conditions, their masses have been subject to fluctuation as a result of poorly understood factors, possibly including handling, cleaning and contamination. The IPK has diverged from its replicas by 50 \u03bcg since their manufacture late in the 19th century.  This has led to calls to replace the artefact with a standard defined in terms of invariant constants of nature.\nThe avoirdupois (or international) pound, used in both the imperial and US customary systems, is defined as exactly 0.45359237 kg,\nmaking one kilogram approximately equal to 2.2046 avoirdupois pounds. Other traditional units of weight and mass around the world are now also defined in terms of the kilogram, making the IPK the primary standard for virtually all units of mass on Earth.\n\n\n== Definition ==\nThe gram, 1/1000 of a kilogram, was provisionally defined in 1795 as the mass of one cubic centimetre of water at the melting point of ice.\nThe final kilogram, manufactured as a prototype in 1799 and from which the International Prototype Kilogram (IPK) was derived in 1875, had a mass equal to the mass of 1 dm3 of water under atmospheric pressure and at the temperature of its maximum density, which is approximately 4 \u00b0C.\nThe kilogram is the only named SI unit with an SI prefix (kilo) as part of its name. It is also the only SI unit that is still directly defined by an artefact rather than a fundamental physical property that can be independently reproduced in different laboratories. Three other base units (cd, A, mol) and 17 derived units (N, Pa, J, W, C, V, F, \u03a9, S, Wb, T, H, kat, Gy, Sv, lm, lx) in the SI system are defined in relation to the kilogram, and thus its stability is important. The definitions of only eight other named SI units do not depend on the kilogram: those of temperature (K, \u00b0C), time and frequency (s, Hz, Bq), length (m), and angle (rad, sr).The IPK is rarely used or handled. Copies of the IPK kept by national metrology laboratories around the world were compared with the IPK in 1889, 1948, and 1989 to provide traceability of measurements of mass anywhere in the world back to the IPK.\nThe International Prototype Kilogram was commissioned by the General Conference on Weights and Measures (CGPM) under the authority of the Metre Convention (1875), and in the custody of the International Bureau of Weights and Measures (BIPM) who hold it on behalf of the CGPM. After the International Prototype Kilogram had been found to vary in mass over time relative to its reproductions, the International Committee for Weights and Measures (CIPM) recommended in 2005 that the kilogram be redefined in terms of a fundamental constant of nature. At its 2011 meeting, the CGPM agreed in principle that the kilogram should be redefined in terms of the Planck constant, h. The decision was originally deferred until 2014; in 2014 it was deferred again until the next meeting.  CIPM has proposed revised definitions of the SI base units, for consideration at the 26th CGPM.  The formal vote, scheduled for 16 November 2018, is expected to be approved and the new definitions will come into force on 20 May 2019.\n\n\n== Name and terminology ==\nThe word kilogramme or kilogram is derived from the French kilogramme, which itself was a learned coinage, prefixing the Greek stem of \u03c7\u03af\u03bb\u03b9\u03bf\u03b9 khilioi \"a thousand\" to gramma, a Late Latin term for \"a small weight\", itself from Greek \u03b3\u03c1\u03ac\u03bc\u03bc\u03b1. \nThe word kilogramme was written into French law in 1795, in the Decree of 18 Germinal,\nwhich revised the older system of units introduced by the French National Convention in 1793, where the gravet had been defined as weight (poids) of a cubic centimetre of water, equal to 1/1000 of a grave. In the decree of 1795, the term gramme thus replaced gravet, and kilogramme replaced grave.\nThe French spelling was adopted in Great Britain when the word was used for the first time in English in 1795,  with the spelling kilogram being adopted in the United States. In the United Kingdom both spellings are used, with \"kilogram\" having become by far the more common. UK law regulating the units to be used when trading by weight or measure does not prevent the use of either spelling.In the 19th century the French word kilo, a shortening of kilogramme, was imported into the English language where it has been used to mean both kilogram and kilometre. While kilo is acceptable in many generalist texts, for example The Economist, its use is typically considered inappropriate in certain applications including scientific, technical and legal writing, where authors should adhere strictly to SI nomenclature. When the United States Congress gave the metric system legal status in 1866, it permitted the use of the word kilo as an alternative to the word kilogram, but in 1990 revoked the status of the word kilo.During the 19th century, the standard system of metric units was the centimetre\u2013gram\u2013second system of units, treating the gram as the fundamental unit of mass and the kilogram simply as a derived unit. \nIn 1901, however, following the discoveries by James Clerk Maxwell to the effect that electric measurements could not be explained in terms of the three fundamental units of length, mass and time, Giovanni Giorgi proposed a new standard system that would include a fourth fundamental unit to measure quantities in electromagnetism.\nIn 1935 this was adopted by the IEC as the Giorgi system, now also known as MKS system,\nand in 1946 the CIPM approved a proposal to adopt the ampere as the electromagnetic unit of the \"MKSA system\".\nIn 1948 the CGPM commissioned the CIPM \"to make recommendations for a single practical system of units of measurement, suitable for adoption by all countries adhering to the Metre Convention\". This led to the launch of SI in 1960 and the subsequent publication of the \"SI Brochure\", which stated that \"It is not permissible to use abbreviations for unit symbols or unit names ...\".\nThe CGS and MKS systems co-existed during much of the early-to-mid 20th century, but as a result of the decision to adopt the \"Giorgi system\" as the international system of units in 1960, the kilogram is now the SI base unit for mass, while the definition of the gram is derived from that of the kilogram.\n\n\n== Mass and weight ==\n\nThe kilogram is a unit of mass, a property corresponding to the common perception of how \"heavy\" an object is. Mass is an inertial property; that is, it is related to the tendency of an object at rest to remain at rest, or if in motion to remain in motion at a constant velocity, unless acted upon by a force.\nWhile the weight of an object is dependent on the strength of the local gravitational field, the mass of an object is independent of gravity, as mass is a measure of the quantity of matter. Accordingly, for astronauts in microgravity, no effort is required to hold objects off the cabin floor; they are \"weightless\". However, since objects in microgravity still retain their mass and inertia, an astronaut must exert ten times as much force to accelerate a 10\u2011kilogram object at the same rate as a 1\u2011kilogram object.\nBecause at any given point on Earth the weight of an object is proportional to its mass, the mass of an object in kilograms is usually measured by comparing its weight to the weight of a standard mass, whose mass is known in kilograms, using a device called a weighing scale. The ratio of the force of gravity on the two objects, measured by the scale, is equal to the ratio of their masses.\n\n\n== Kilogramme des Archives ==\n\nOn April 7, 1795, the gram was decreed in France to be \"the absolute weight of a volume of pure water equal to the cube of the hundredth part of the metre, and at the temperature of melting ice\".\nSince trade and commerce typically involve items significantly more massive than one gram, and since a mass standard made of water would be inconvenient and unstable, the regulation of commerce necessitated the manufacture of a practical realization of the water-based definition of mass. Accordingly, a provisional mass standard was made as a single-piece, metallic artifact one thousand times as massive as the gram\u2014the kilogram.\nAt the same time, work was commissioned to precisely determine the mass of a cubic decimetre (one litre) of water. Although the decreed definition of the kilogram specified water at 0 \u00b0C\u2014its highly stable temperature point\u2014the French chemist Louis Lef\u00e8vre-Gineau and the Italian naturalist Giovanni Fabbroni after several years of research chose to redefine the standard in 1799 to water's most stable density point: the temperature at which water reaches maximum density, which was measured at the time as 4 \u00b0C.\nThey concluded that one cubic decimetre of water at its maximum density was equal to 99.9265% of the target mass of the provisional kilogram standard made four years earlier. That same year, 1799, an all-platinum kilogram prototype was fabricated with the objective that it would equal, as close as was scientifically feasible for the day, the mass of one cubic decimetre of water at 4 \u00b0C. The prototype was presented to the Archives of the Republic in June and on December 10, 1799, the prototype was formally ratified as the kilogramme des Archives (Kilogram of the Archives) and the kilogram was defined as being equal to its mass. This standard stood for the next 90 years.\n\n\n== International prototype kilogram ==\n\nSince 1889 the magnitude of the kilogram has been defined as the mass of an object called the international prototype kilogram, often referred to in the professional metrology world as the \"IPK\". The IPK is made of a platinum alloy known as \"Pt\u201110Ir\", which is 90% platinum and 10% iridium (by mass) and is machined into a right-circular cylinder (height = diameter) of about 39 millimetres to minimize its surface area. The addition of 10% iridium improved upon the all-platinum Kilogram of the Archives by greatly increasing hardness while still retaining platinum's many virtues: extreme resistance to oxidation, extremely high density (almost twice as dense as lead and more than 21 times as dense as water), satisfactory electrical and thermal conductivities, and low magnetic susceptibility. The IPK and its six sister copies are stored at the International Bureau of Weights and Measures (known by its French-language initials BIPM) in an environmentally monitored safe in the lower vault located in the basement of the BIPM's Pavillon de Breteuil in Saint-Cloud on the outskirts of Paris (see External images, below, for photographs). Three independently controlled keys are required to open the vault. Official copies of the IPK were made available to other nations to serve as their national standards. These are compared to the IPK roughly every 40 years, thereby providing traceability of local measurements back to the IPK.\n\nThe Metre Convention was signed on May 20, 1875 and further formalized the metric system (a predecessor to the SI), quickly leading to the production of the IPK. The IPK is one of three cylinders made in 1879 by Johnson Matthey, which continues to manufacture nearly all of the national prototypes today. In 1883, the mass of the IPK was found to be indistinguishable from that of the Kilogramme des Archives made eighty-four years prior, and was formally ratified as the kilogram by the 1st CGPM in 1889.Modern measurements of Vienna Standard Mean Ocean Water, which is pure distilled water with an isotopic composition representative of the average of the world's oceans, show that it has a density of 0.999975 \u00b10.000001 kg/L at its point of maximum density (3.984 \u00b0C) under one standard atmosphere (101 325 Pa or 760 torr) of pressure. Thus, a cubic decimetre of water at its point of maximum density is only 25 parts per million less massive than the IPK; that is to say, the 25 milligram difference shows that the scientists over 219 years ago managed to make the mass of the Kilogram of the Archives equal that of a cubic decimetre of water at 4 \u00b0C, with a margin of error at most within the mass of a single excess grain of rice.\n\n\n=== Copies of the international prototype kilogram ===\n\nThe various copies of the international prototype kilogram are given the following designations in the literature:\n\nThe IPK itself, located in Saint-Cloud, France.\nSix sister copies, numbered: K1, 7, 8(41), 32, 43 and 47. Located in Saint-Cloud, France.\nTen working copies, eight (9, 31, 42\u2032, 63, 77, 88, 91, and 650) for routine use and two (25 and 73) for special use. Located in Saint-Cloud, France.\nNational prototypes, stored in Australia (44 and 87), Austria (49), Belgium (28 and 37), Brazil (66), Canada (50 and 74), China (60 and 64; 75 in Hong Kong), Czech Republic (67), Denmark (48), Egypt (58), Finland (23), France (35), Germany (52, 55 and 70), Hungary (16), India (57), Indonesia (46), Israel (71), Italy (5 and 76), Japan (6 and 94), Kazakhstan, Kenya (95), Mexico (21, 90 and 96), Netherlands (53), North Korea (68), Norway (36), Pakistan (93), Poland (51), Portugal (69), Romania (2), Russia (12 and 26), Serbia (11 and 29), Singapore (83), Slovakia (41 and 65), South Africa (56), South Korea (39, 72 and 84), Spain (24 and 3), Sweden (40 and 86), Switzerland (38 and 89), Taiwan (78), Thailand (80), Turkey (54), United Kingdom (18, 81 and 82) and the United States (20, 4, 79, 85 and 92).\nSome additional copies held by non-national organizations, such as the French Academy of Sciences in Paris (34) and the Istituto di Metrologia G. Colonnetti in Turin (62).\n\n\n=== Stability of the international prototype kilogram ===\nBy definition, the error in the measured value of the IPK's mass is exactly zero; the mass of the IPK is the kilogram. However, any changes in the IPK's mass over time can be deduced by comparing its mass to that of its official copies stored throughout the world, a rarely undertaken process called \"periodic verification\". The only three verifications occurred in 1889, 1948, and 1989. For instance, the US owns four 90% platinum / 10% iridium (Pt\u201110Ir) kilogram standards, two of which, K4 and K20, are from the original batch of 40 replicas delivered in 1884. The K20 prototype was designated as the primary national standard of mass for the US. Both of these, as well as those from other nations, are periodically returned to the BIPM for verification. Extraordinary care is exercised when transporting prototypes. In 1984, the K4 and K20 prototypes were hand-carried in the passenger section of separate commercial airliners.\nNote that none of the replicas has a mass precisely equal to that of the IPK; their masses are calibrated and documented as offset values. For instance, K20, the US's primary standard, originally had an official mass of 1 kg \u2212 39 \u03bcg (micrograms) in 1889; that is to say, K20 was 39 \u03bcg less than the IPK. A verification performed in 1948 showed a mass of 1 kg \u2212 19 \u03bcg. The latest verification performed in 1989 shows a mass precisely identical to its original 1889 value. Quite unlike transient variations such as this, the US's check standard, K4, has persistently declined in mass relative to the IPK\u2014and for an identifiable reason: check standards are used much more often than primary standards and are prone to scratches and other wear. K4 was originally delivered with an official mass of 1 kg \u2212 75 \u03bcg in 1889, but as of 1989 was officially calibrated at 1 kg \u2212 106 \u03bcg and ten years later was 1 kg \u2212 116 \u03bcg. Over a period of 110 years, K4 lost 41 \u03bcg relative to the IPK.\n\nBeyond the simple wear that check standards can experience, the mass of even the carefully stored national prototypes can drift relative to the IPK for a variety of reasons, some known and some unknown. Since the IPK and its replicas are stored in air (albeit under two or more nested bell jars), they gain mass through adsorption of atmospheric contamination onto their surfaces. Accordingly, they are cleaned in a process the BIPM developed between 1939 and 1946 known as \"the BIPM cleaning method\" that comprises firmly rubbing with a chamois soaked in equal parts ether and ethanol, followed by steam cleaning with bi-distilled water, and allowing the prototypes to settle for 7\u201310 days before verification. Before the BIPM's published report in 1994 detailing the relative change in mass of the prototypes, different standard bodies used different techniques to clean their prototypes. The NIST's practice before then was to soak and rinse its two prototypes first in benzene, then in ethanol, and to then clean them with a jet of bi-distilled water steam. Cleaning the prototypes removes between 5 and 60 \u03bcg of contamination depending largely on the time elapsed since the last cleaning. Further, a second cleaning can remove up to 10 \u03bcg more. After cleaning\u2014even when they are stored under their bell jars\u2014the IPK and its replicas immediately begin gaining mass again. The BIPM even developed a model of this gain and concluded that it averaged 1.11 \u03bcg per month for the first 3 months after cleaning and then decreased to an average of about 1 \u03bcg per year thereafter. Since check standards like K4 are not cleaned for routine calibrations of other mass standards\u2014a precaution to minimize the potential for wear and handling damage\u2014the BIPM's model of time-dependent mass gain has been used as an \"after cleaning\" correction factor.\nBecause the first forty official copies are made of the same alloy as the IPK and are stored under similar conditions, periodic verifications using a large number of replicas\u2014especially the national primary standards, which are rarely used\u2014can convincingly demonstrate the stability of the IPK. What has become clear after the third periodic verification performed between 1988 and 1992 is that masses of the entire worldwide ensemble of prototypes have been slowly but inexorably diverging from each other. It is also clear that the mass of the IPK lost perhaps 50 \u03bcg over the last century, and possibly significantly more, in comparison to its official copies. The reason for this drift has eluded physicists who have dedicated their careers to the SI unit of mass. No plausible mechanism has been proposed to explain either a steady decrease in the mass of the IPK, or an increase in that of its replicas dispersed throughout the world. Moreover, there are no technical means available to determine whether or not the entire worldwide ensemble of prototypes suffers from even greater long-term trends upwards or downwards because their mass \"relative to an invariant of nature is unknown at a level below 1000 \u03bcg over a period of 100 or even 50 years\". Given the lack of data identifying which of the world's kilogram prototypes has been most stable in absolute terms, it is equally valid to state that the first batch of replicas has, as a group, gained an average of about 25 \u03bcg over one hundred years in comparison to the IPK.What is known specifically about the IPK is that it exhibits a short-term instability of about 30 \u03bcg over a period of about a month in its after-cleaned mass. The precise reason for this short-term instability is not understood but is thought to entail surface effects: microscopic differences between the prototypes' polished surfaces, possibly aggravated by hydrogen absorption due to catalysis of the volatile organic compounds that slowly deposit onto the prototypes as well as the hydrocarbon-based solvents used to clean them.It has been possible to rule out many explanations of the observed divergences in the masses of the world's prototypes proposed by scientists and the general public. The BIPM's FAQ explains, for example, that the divergence is dependent on the amount of time elapsed between measurements and not dependent on the number of times the prototype or its copies have been cleaned or possible changes in gravity or environment. Reports published in 2013 by Peter Cumpson of Newcastle University based on the X-ray photoelectron spectroscopy of samples that were stored alongside various prototype kilograms suggested that one source of the divergence between the various prototypes could be traced to mercury that had been absorbed by the prototypes being in the proximity of mercury-based instruments. The IPK has been stored within centimetres of a mercury thermometer since at least as far back as the late 1980s. In this Newcastle University work six platinum weights made in the nineteenth century were all found to have mercury at the surface, the most contaminated of which had the equivalent of 250 \u03bcg of mercury when scaled to the surface area of a kilogram prototype.\nScientists are seeing far greater variability in the prototypes than previously believed. The increasing divergence in the masses of the world's prototypes and the short-term instability in the IPK has prompted research into improved methods to obtain a smooth surface finish using diamond turning on newly manufactured replicas and has intensified the search for a new definition of the kilogram. See \u00a7 Proposed future definitions, below.\n\n\n=== Dependency of the SI on the IPK ===\n\nThe stability of the IPK is crucial because the kilogram underpins much of the SI system of measurement as it is currently defined and structured. For instance, the newton is defined as the force necessary to accelerate one kilogram at one metre per second squared. If the mass of the IPK were to change slightly then the newton would also change proportionally. In turn, the pascal, the SI unit of pressure, is defined in terms of the newton. This chain of dependency follows to many other SI units of measure. For instance, the joule, the SI unit of energy, is defined as that expended when a force of one newton acts through one metre. Next to be affected is the SI unit of power, the watt, which is one joule per second. The ampere too is defined relative to the newton.\nWith the magnitude of the primary units of electricity thus determined by the kilogram, so too follow many others, namely the coulomb, volt, tesla, and weber.  Even units used in the measure of light would be affected; the candela\u2014following the change in the watt\u2014would in turn affect the lumen and lux.\nBecause the magnitude of many of the units comprising the SI system of measurement is ultimately defined by the mass of a 139-year-old, golf-ball-sized piece of metal, the quality of the IPK must be diligently protected to preserve the integrity of the SI system. Yet, despite the best stewardship, the average mass of the worldwide ensemble of prototypes and the mass of the IPK have likely diverged another 6.8 \u03bcg since the third periodic verification 29 years ago. Further, the world's national metrology laboratories must wait for the fourth periodic verification to confirm whether the historical trends persisted.\nFortunately, definitions of the SI units are quite different from their practical realizations. For instance, the metre is defined as the distance light travels in a vacuum during a time interval of \u200b1\u2044299,792,458 of a second. However, the metre's practical realization typically takes the form of a helium\u2013neon laser, and the metre's length is delineated\u2014not defined\u2014as 1579800.298728 wavelengths of light from this laser. Now suppose that the official measurement of the second was found to have drifted by a few parts per billion (it is actually extremely stable with a reproducibility of a few parts in 1015). \nThere would be no automatic effect on the metre because the second\u2014and thus the metre's length\u2014is abstracted via the laser comprising the metre's practical realization. Scientists performing metre calibrations would simply continue to measure out the same number of laser wavelengths until an agreement was reached to do otherwise. \nThe same is true with regard to the real-world dependency on the kilogram: if the mass of the IPK was found to have changed slightly, there would be no automatic effect upon the other units of measure because their practical realizations provide an insulating layer of abstraction. Any discrepancy would eventually have to be reconciled though, because the virtue of the SI system is its precise mathematical and logical harmony amongst its units. If the IPK's value were definitively proven to have changed, one solution would be to simply redefine the kilogram as being equal to the mass of the IPK plus an offset value, similarly to what is currently done with its replicas; e.g., \"the kilogram is equal to the mass of the IPK\u2009+\u200942 parts per billion\" (equivalent to 42 \u03bcg).\nThe long-term solution to this problem, however, is to liberate the SI system's dependency on the IPK by developing a practical realization of the kilogram that can be reproduced in different laboratories by following a written specification. The units of measure in such a practical realization would have their magnitudes precisely defined and expressed in terms of fundamental physical constants. While major portions of the SI system would still be based on the kilogram, the kilogram would in turn be based on invariant, universal constants of nature. Much work towards that end is ongoing, though no alternative has yet achieved the uncertainty of 20 parts per billion (~20 \u03bcg) required to improve upon the IPK.\n\n\n== Proposed future definitions ==\n\nIn the following subsections, wherever numeric equalities are shown in 'concise form'\u2014such as 1.85487(14)\u00d71013\u2014the two digits between the parentheses denote the uncertainty at one standard deviation (1\u03c3, the 68% confidence level) in the two least significant digits of the significand. A final X in a proposed definition denotes digits yet to be agreed on.As of 2018 the International Prototype Kilogram was the only artefact referenced by the definition of the units of the SI, directly defining the kilogram and indirectly defining several other SI units. In 1960, the metre, previously similarly having been defined with reference to a single platinum-iridium bar with two marks on it, was redefined in terms of an invariant physical constant (the wavelength of a particular emission of light emitted by krypton, and later the speed of light) so that the standard can be independently reproduced in different laboratories by following a written specification.  At the 94th Meeting of the International Committee for Weights and Measures (CIPM) in 2005, it was recommended that the same be done with the kilogram.In October 2010, the CIPM voted to submit a resolution for consideration at the General Conference on Weights and Measures (CGPM), to \"take note of an intention\" that the kilogram be defined in terms of the Planck constant, h (which has dimensions of energy times time) together with other physical constants. This resolution was accepted by the 24th conference of the CGPM in October 2011 and further discussed at the 25th conference in 2014. Although the Committee recognised that significant progress had been made, they concluded that the data did not appear sufficiently robust to adopt the revised definition, and that work should continue to enable the adoption at the 26th meeting, scheduled for 2018. Such a definition would theoretically permit any apparatus that was capable of delineating the kilogram in terms of the Planck constant to be used as long as it possessed sufficient precision, accuracy and stability. The Kibble balance (discussed below) may be able to do this.\nIn the project to replace the last artefact that underpins much of the International System of Units (SI), a variety of other very different technologies and approaches were considered and explored over many years. They too are covered below. Some of these now-abandoned approaches were based on equipment and procedures that would have enabled the reproducible production of new, kilogram-mass prototypes on demand (albeit with extraordinary effort) using measurement techniques and material properties that are ultimately based on, or traceable to, physical constants. Others were based on devices that measured either the acceleration or weight of hand-tuned kilogram test masses and which expressed their magnitudes in electrical terms via special components that permit traceability to physical constants. All approaches depend on converting a weight measurement to a mass, and therefore require the precise measurement of the strength of gravity in laboratories. All approaches would have precisely fixed one or more constants of nature at a defined value.\n\n\n=== Kibble balance ===\n\nThe Kibble balance (known as a \"watt balance\" before 2016) is essentially a single-pan weighing scale that measures the electric power necessary to oppose the weight of a kilogram test mass as it is pulled by Earth's gravity. It is a variation of an ampere balance in that it employs an extra calibration step that nulls the effect of geometry. The electric potential in the Kibble balance is delineated by a Josephson voltage standard, which allows voltage to be linked to an invariant constant of nature with extremely high precision and stability. Its circuit resistance is calibrated against a quantum Hall effect resistance standard.\nThe Kibble balance requires extremely precise measurement of the local gravitational acceleration g in the laboratory, using a gravimeter. For instance, the NIST compensates for Earth's gravity gradient of 309 \u03bcGal per metre when the elevation of the centre of the gravimeter differs from that of the nearby test mass in the Kibble balance; a change in the weight of a one-kilogram test mass that equates to about 316 \u03bcg/m.\nIn April 2007, the NIST's implementation of the Kibble balance demonstrated a combined relative standard uncertainty (CRSU) of 36 \u03bcg and a short-term resolution of 10\u221215 \u03bcg. The UK's National Physical Laboratory's Kibble balance demonstrated a CRSU of 70.3 \u03bcg in 2007. That Kibble balance was disassembled and shipped in 2009 to Canada's Institute for National Measurement Standards (part of the National Research Council), where research and development with the device could continue.\nIf the CGPM adopts the new proposal and the new definition of the kilogram becomes part of the SI, the value in SI units of the Planck constant (h), which is a measure that relates the energy of particles such as photons to their frequency, would be precisely fixed (the currently accepted value of 6.626070040(81)\u00d710\u221234 J\u22c5s has an uncertainty of about 1 in 23 million). Once agreed upon internationally, the kilogram would no longer be defined as the mass of the IPK. All the remaining unit definitions in the International System of Units (the SI) that today depend upon the kilogram and the joule would thus also have their magnitudes ultimately defined entirely in terms of constants of nature.\n\nGravity and the nature of the Kibble balance, which oscillates test masses up and down against the local gravitational acceleration g, are exploited so that mechanical power is compared against electrical power, which is the square of voltage divided by electrical resistance. However, g varies significantly\u2014by nearly 1%\u2014depending on where on the Earth's surface the measurement is made (see Earth's gravity). There are also slight seasonal variations in g at a location due to changes in underground water tables, and larger semimonthly and diurnal changes due to tidal distortions in the Earth's shape caused by the Moon and the Sun. Although g would not be a term in the definition of the kilogram, it would be crucial in the process of measurement of the kilogram when relating energy to power. Accordingly, g must be measured with at least as much precision and accuracy as are the other terms, so measurements of g must also be traceable to fundamental constants of nature. For the most precise work in mass metrology, g is measured using dropping-mass absolute gravimeters that contain an iodine-stabilized helium\u2013neon laser interferometer. The fringe-signal, frequency-sweep output from the interferometer is measured with a rubidium atomic clock. Since this type of dropping-mass gravimeter derives its accuracy and stability from the constancy of the speed of light as well as the innate properties of helium, neon, and rubidium atoms, the 'gravity' term in the delineation of an all-electronic kilogram is also measured in terms of invariants of nature\u2014and with very high precision. For instance, in the basement of the NIST's Gaithersburg facility in 2009, when measuring the gravity acting upon Pt\u201110Ir test masses (which are denser, smaller, and have a slightly lower center of gravity inside the Kibble balance than stainless steel masses), the measured value was typically within 8 ppb of 9.80101644 m/s2.The virtue of electronic realizations like the Kibble balance is that the definition and dissemination of the kilogram would no longer be dependent upon the stability of kilogram prototypes, which must be very carefully handled and stored. It would free physicists from the need to rely on assumptions about the stability of those prototypes. Instead, hand-tuned, close-approximation mass standards would simply be weighed and documented as being equal to one kilogram plus an offset value. With the Kibble balance, while the kilogram would be delineated in electrical and gravity terms, all of which are traceable to invariants of nature; it would be defined in a manner that is directly traceable to three fundamental constants of nature. The Planck constant defines the kilogram in terms of the second and the metre. By fixing the Planck constant, the definition of the kilogram would in addition depend only on the definitions of the second and the metre. The definition of the second depends on a single defined physical constant: the ground state hyperfine splitting frequency of the caesium 133 atom \u0394\u03bd(133Cs)hfs. The metre depends on the second and on an additional defined physical constant: the speed of light c. If the kilogram is redefined in this manner, physical objects such as the IPK would no longer be part of the definition, but would instead become transfer standards.\nScales like the Kibble balance also permit more flexibility in choosing materials with especially desirable properties for mass standards. For instance, Pt\u201110Ir could continue to be used so that the specific gravity of newly produced mass standards would be the same as existing national primary and check standards (\u224821.55 g/ml). This would reduce the relative uncertainty when making mass comparisons in air. Alternatively, entirely different materials and constructions could be explored with the objective of producing mass standards with greater stability. For instance, osmium-iridium alloys could be investigated if platinum's propensity to absorb hydrogen (due to catalysis of VOCs and hydrocarbon-based cleaning solvents) and atmospheric mercury proved to be sources of instability. Also, vapor-deposited, protective ceramic coatings like nitrides could be investigated for their suitability for chemically isolating these new alloys.\nThe challenge with Kibble balances is not only in reducing their uncertainty, but also in making them truly practical realizations of the kilogram. Nearly every aspect of Kibble balances and their support equipment requires such extraordinarily precise and accurate, state-of-the-art technology that\u2014unlike a device like an atomic clock\u2014few countries would currently choose to fund their operation. For instance, the NIST's Kibble balance used four resistance standards in 2007, each of which was rotated through the Kibble balance every two to six weeks after being calibrated in a different part of NIST headquarters facility in Gaithersburg, Maryland. It was found that simply moving the resistance standards down the hall to the Kibble balance after calibration altered their values 10 ppb (equivalent to 10 \u03bcg) or more. Present-day technology is insufficient to permit stable operation of Kibble balances between even biannual calibrations. If the kilogram is defined in terms of the Planck constant, it is likely there will only be a few\u2014at most\u2014Kibble balances initially operating in the world.\nAlternative approaches to redefining the kilogram that were fundamentally different from the Kibble balance were explored to varying degrees with some abandoned, as follows:\n\n\n=== Atom-counting approaches ===\n\n\n==== Carbon-12 ====\nThough not offering a practical realization, this definition would precisely define the magnitude of the kilogram in terms of a certain number of carbon\u201112 atoms. Carbon\u201112 (12C) is an isotope of carbon. The mole is currently defined as \"the quantity of entities (elementary particles like atoms or molecules) equal to the number of atoms in 12 grams of carbon\u201112\". Thus, the current definition of the mole requires that \u200b1000\u204412 moles (\u200b83 1\u20443 mol) of 12C has a mass of precisely one kilogram. The number of atoms in a mole, a quantity known as the Avogadro constant, is experimentally determined, and the current best estimate of its value is 6.022140857(74)\u00d71023 entities per mole. This new definition of the kilogram proposed to fix the Avogadro constant at precisely 6.02214X\u00d710^23 with the kilogram being defined as \"the mass equal to that of \u200b1000\u204412 \u22c5 6.02214X\u00d710^23 atoms of 12C\".\nThe accuracy of the measured value of the Avogadro constant is currently limited by the uncertainty in the value of the Planck constant. That relative standard uncertainty has been 50 parts per billion (ppb) since 2006. By fixing the Avogadro constant, the practical effect of this proposal would be that the uncertainty in the mass of a 12C atom\u2014and the magnitude of the kilogram\u2014could be no better than the current 50 ppb uncertainty in the Planck constant. Under this proposal, the magnitude of the kilogram would be subject to future refinement as improved measurements of the value of the Planck constant become available; electronic realizations of the kilogram would be recalibrated as required. Conversely, an electronic definition of the kilogram (see \u00a7 Electronic approaches, below), which would precisely fix the Planck constant, would continue to allow \u200b83 1\u20443 moles of 12C to have a mass of precisely one kilogram but the number of atoms comprising a mole (the Avogadro constant) would continue to be subject to future refinement.\nA variation on a 12C-based definition proposes to define the Avogadro constant as being precisely 844468893 (\u2248 6.02214162\u00d71023) atoms. An imaginary realization of a 12-gram mass prototype would be a cube of 12C atoms measuring precisely 84446889 atoms across on a side. With this proposal, the kilogram would be defined as \"the mass equal to 844468893 \u00d7 \u200b83 1\u20443 atoms of 12C.\"\n\n\n==== Avogadro project ====\n \n\nAnother Avogadro constant-based approach, known as the International Avogadro Coordination's Avogadro project, would define and delineate the kilogram as a 93.6 mm diameter sphere of silicon atoms. Silicon was chosen because a commercial infrastructure with mature processes for creating defect-free, ultra-pure monocrystalline silicon already exists to service the semiconductor industry. To make a practical realization of the kilogram, a silicon boule (a rod-like, single-crystal ingot) would be produced. Its isotopic composition would be measured with a mass spectrometer to determine its average relative atomic mass. The boule would be cut, ground, and polished into spheres. The size of a select sphere would be measured using optical interferometry to an uncertainty of about 0.3 nm on the radius\u2014roughly a single atomic layer. The precise lattice spacing between the atoms in its crystal structure (\u2248 192 pm) would be measured using a scanning X-ray interferometer. This permits its atomic spacing to be determined with an uncertainty of only three parts per billion. With the size of the sphere, its average atomic mass, and its atomic spacing known, the required sphere diameter can be calculated with sufficient precision and low uncertainty to enable it to be finish-polished to a target mass of one kilogram.\nExperiments are being performed on the Avogadro Project's silicon spheres to determine whether their masses are most stable when stored in a vacuum, a partial vacuum, or ambient pressure. However, no technical means currently exist to prove a long-term stability any better than that of the IPK's, because the most sensitive and accurate measurements of mass are made with dual-pan balances like the BIPM's FB\u20112 flexure-strip balance (see \u00a7 External links, below). Balances can only compare the mass of a silicon sphere to that of a reference mass. Given the latest understanding of the lack of long-term mass stability with the IPK and its replicas, there is no known, perfectly stable mass artefact to compare against. Single-pan scales, which measure weight relative to an invariant of nature, are not precise to the necessary long-term uncertainty of 10\u201320 parts per billion. Another issue to be overcome is that silicon oxidizes and forms a thin layer (equivalent to 5\u201320 silicon atoms deep) of silicon dioxide (quartz) and silicon monoxide. This layer slightly increases the mass of the sphere, an effect that must be accounted for when polishing the sphere to its finished size.  Oxidation is not an issue with platinum and iridium, both of which are noble metals that are roughly as cathodic as oxygen and therefore don't oxidize unless coaxed to do so in the laboratory. The presence of the thin oxide layer on a silicon-sphere mass prototype places additional restrictions on the procedures that might be suitable to clean it to avoid changing the layer's thickness or oxide stoichiometry.\nAll silicon-based approaches would fix the Avogadro constant but vary in the details of the definition of the kilogram. One approach would use silicon with all three of its natural isotopes present. About 7.78% of silicon comprises the two heavier isotopes: 29Si and 30Si. As described in \u00a7 Carbon-12 above, this method would define the magnitude of the kilogram in terms of a certain number of 12C atoms by fixing the Avogadro constant; the silicon sphere would be the practical realization. This approach could accurately delineate the magnitude of the kilogram because the masses of the three silicon nuclides relative to 12C are known with great precision (relative uncertainties of 1 ppb or better). An alternative method for creating a silicon sphere-based kilogram proposes to use isotopic separation techniques to enrich the silicon until it is nearly pure 28Si, which has a relative atomic mass of 27.9769265325(19). With this approach, the Avogadro constant would not only be fixed, but so too would the atomic mass of 28Si. As such, the definition of the kilogram would be decoupled from 12C and the kilogram would instead be defined as \u200b1000\u204427.9769265325 \u22c5 6.02214179\u00d71023 atoms of 28Si (\u2248 35.74374043 fixed moles of 28Si atoms). Physicists could elect to define the kilogram in terms of 28Si even when kilogram prototypes are made of natural silicon (all three isotopes present). Even with a kilogram definition based on theoretically pure 28Si, a silicon-sphere prototype made of only nearly pure 28Si would necessarily deviate slightly from the defined number of moles of silicon to compensate for various chemical and isotopic impurities as well as the effect of surface oxides.\n\n\n==== Ion accumulation ====\nAnother Avogadro-based approach, ion accumulation, since abandoned, would have defined and delineated the kilogram by precisely creating new metal prototypes on demand. It would have done so by accumulating gold or bismuth ions (atoms stripped of an electron) and counting them by measuring the electric current required to neutralize the ions. Gold (197Au) and bismuth (209Bi) were chosen because they can be safely handled and have the two highest atomic masses among the mononuclidic elements that is effectively non-radioactive (bismuth) or is perfectly stable (gold). See also Table of nuclides.With a gold-based definition of the kilogram for instance, the relative atomic mass of gold could have been fixed as precisely 196.9665687, from the current value of 196.9665687(6). As with a definition based upon carbon\u201112, the Avogadro constant would also have been fixed. The kilogram would then have been defined as \"the mass equal to that of precisely \u200b1000\u2044196.9665687 \u22c5 6.02214179\u00d71023 atoms of gold\" (precisely 3,057,443,620,887,933,963,384,315 atoms of gold or about 5.07700371 fixed moles).\nIn 2003, German experiments with gold at a current of only 10 \u03bcA demonstrated a relative uncertainty of 1.5%. Follow-on experiments using bismuth ions and a current of 30 mA were expected to accumulate a mass of 30 g in six days and to have a relative uncertainty of better than 1 ppm. Ultimately, ion\u2011accumulation approaches proved to be unsuitable. Measurements required months and the data proved too erratic for the technique to be considered a viable future replacement to the IPK.Among the many technical challenges of the ion-deposition apparatus was obtaining a sufficiently high ion current (mass deposition rate) while simultaneously decelerating the ions so they could all deposit onto a target electrode embedded in a balance pan. Experiments with gold showed the ions had to be decelerated to very low energies to avoid sputtering effects\u2014a phenomenon whereby ions that had already been counted ricochet off the target electrode or even dislodged atoms that had already been deposited. The deposited mass fraction in the 2003 German experiments only approached very close to 100% at ion energies of less than around 1 eV (< 1 km/s for gold).If the kilogram had been defined as a precise quantity of gold or bismuth atoms deposited with an electric current, not only would the Avogadro constant and the atomic mass of gold or bismuth have to have been precisely fixed, but also the value of the elementary charge (e), likely to 1.60217X\u00d710^\u221219 C (from the currently recommended value of 1.6021766208(98)\u00d710\u221219 C). Doing so would have effectively defined the ampere as a flow of \u200b1\u20441.60217X\u00d710^\u221219 electrons per second past a fixed point in an electric circuit. The SI unit of mass would have been fully defined by having precisely fixed the values of the Avogadro constant and elementary charge, and by exploiting the fact that the atomic masses of bismuth and gold atoms are invariant, universal constants of nature.\nBeyond the slowness of making a new mass standard and the poor reproducibility, there were other intrinsic shortcomings to the ion\u2011accumulation approach that proved to be formidable obstacles to ion-accumulation-based techniques becoming a practical realization. The apparatus necessarily required that the deposition chamber have an integral balance system to enable the convenient calibration of a reasonable quantity of transfer standards relative to any single internal ion-deposited prototype. Furthermore, the mass prototypes produced by ion deposition techniques would have been nothing like the freestanding platinum-iridium prototypes currently in use; they would have been deposited onto\u2014and become part of\u2014an electrode imbedded into one pan of a special balance integrated into the device. Moreover, the ion-deposited mass wouldn't have had a hard, highly polished surface that can be vigorously cleaned like those of current prototypes. Gold, while dense and a noble metal (resistant to oxidation and the formation of other compounds), is extremely soft so an internal gold prototype would have to be kept well isolated and scrupulously clean to avoid contamination and the potential of wear from having to remove the contamination. Bismuth, which is an inexpensive metal used in low-temperature solders, slowly oxidizes when exposed to room-temperature air and forms other chemical compounds and so would not have produced stable reference masses unless it was continually maintained in a vacuum or inert atmosphere.\n\n\n=== Ampere-based force ===\n\nThis approach would define the kilogram as \"the mass which would be accelerated at precisely 2\u00d710\u22127 m/s2 when subjected to the per-metre force between two straight parallel conductors of infinite length, of negligible circular cross section, placed one metre apart in vacuum, through which flow a constant current of \u200b1\u20441.60217X\u00d710^\u221219 elementary charges per second\".\nEffectively, this would define the kilogram as a derivative of the ampere rather than the present relationship, which defines the ampere as a derivative of the kilogram. This redefinition of the kilogram would specify elementary charge (e) as precisely 1.60217X\u00d710^\u221219 coulomb rather than the current recommended value of 1.6021766208(98)\u00d710\u221219 C. It would necessarily follow that the ampere (one coulomb per second) would also become an electric current of this precise quantity of elementary charges per second passing a given point in an electric circuit.\nThe virtue of a practical realization based upon this definition is that unlike the Kibble balance and other scale-based methods, all of which require the careful characterization of gravity in the laboratory, this method delineates the magnitude of the kilogram directly in the very terms that define the nature of mass: acceleration due to an applied force. Unfortunately, it is extremely difficult to develop a practical realization based upon accelerating masses. Experiments over a period of years in Japan with a superconducting, 30 g mass supported by diamagnetic levitation never achieved an uncertainty better than ten parts per million. Magnetic hysteresis was one of the limiting issues. Other groups performed similar research that used different techniques to levitate the mass.\n\n\n== SI multiples ==\n\nBecause SI prefixes may not be concatenated (serially linked) within the name or symbol for a unit of measure, SI prefixes are used with the gram, not the kilogram, which already has a prefix as part of its name. For instance, one-millionth of a kilogram is 1 mg (one milligram), not 1 \u03bckg (one microkilogram).\n\nThe microgram is typically abbreviated \"mcg\" in pharmaceutical and nutritional supplement labelling, to avoid confusion, since the \"\u03bc\" prefix is not always well recognized outside of technical disciplines. (The expression \"mcg\" is also the symbol for an obsolete CGS unit of measure known as the \"millicentigram\", which is equal to 10 \u03bcg.)\nIn the United Kingdom, because serious medication errors have been made from the confusion between milligrams and micrograms when micrograms has been abbreviated, the recommendation given in the Scottish Palliative Care Guidelines is that doses of less than one milligram must be expressed in micrograms and that the word microgram must be written in full, and that it is never acceptable to use \"mcg\" or \"\u03bcg\".[2]\nThe hectogram is a very commonly used unit in the retail food trade in Italy, usually called an etto, short for ettogrammo, the Italian for hectogram.\nThe former standard spelling and abbreviation \"deka-\" and \"dk\" produced abbreviations such as \"dkm\" (dekametre) and \"dkg\" (dekagram).  The abbreviation \"dkg\" is still used in parts of central Europe in retail for some foods such as cheese and meat.\nThe unit name megagram is rarely used, and even then typically only in technical fields in contexts where especially rigorous consistency with the SI standard is desired. For most purposes, the name tonne is instead used. The tonne and its symbol, \"t\", were adopted by the CIPM in 1879. It is a non-SI unit accepted by the BIPM for use with the SI. According to the BIPM, \"In English speaking countries this unit is usually called 'metric ton'.\" The unit name megatonne or megaton (Mt) is often used in general-interest literature on greenhouse gas emissions, whereas the equivalent unit in scientific papers on the subject is often the teragram (Tg).\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNIST Improves Accuracy of 'Watt Balance' Method for Defining the Kilogram\nThe UK's National Physical Laboratory (NPL): Are any problems caused by having the kilogram defined in terms of a physical artefact? (FAQ - Mass & Density)\nNPL: NPL Kibble balance\nMetrology in France: Watt balance\nAustralian National Measurement Institute: Redefining the kilogram through the Avogadro constant\nInternational Bureau of Weights and Measures (BIPM): Home page\nNZZ Folio: What a kilogram really weighs\nNPL: What are the differences between mass, weight, force and load?\nBBC: Getting the measure of a kilogram\nNPR: This Kilogram Has A Weight-Loss Problem, an interview with National Institute of Standards and Technology physicist Richard Steiner\nAvogadro and molar Planck constants for the redefinition of the kilogram\nRealization of the awaited definition of the kilogram",
        "unit": "kilogram",
        "url": "https://en.wikipedia.org/wiki/Kilogram"
    },
    {
        "_id": "Swiss_franc",
        "clean": "Swiss franc",
        "text": "The franc (sign: Fr. or SFr.; German: Franken, French and Romansh: franc, Italian: franco; code: CHF) is the currency and legal tender of Switzerland and Liechtenstein; it is also legal tender in the Italian exclave Campione d'Italia. The Swiss National Bank (SNB) issues banknotes and the federal mint Swissmint issues coins.\nThe smaller denomination, a hundredth of a franc, is a Rappen (Rp.) in German, centime (c.) in French, centesimo (ct.) in Italian, and rap (rp.) in Romansh. The ISO code of the currency used by banks and financial institutions is CHF, although Fr. is also widely used by businesses and advertisers; some use SFr. for Swiss Franc and to a lesser extent Fr.sv. The Latinate \"CH\" stands for Confoederatio Helvetica.\nGiven the different languages used in Switzerland, Latin is used for language-neutral inscriptions on its coins.\n\n\n== History ==\n\n\n=== Before the Helvetic Republic ===\nBefore 1798, about 75 entities were making coins in Switzerland, including the 25 cantons and half-cantons, 16 cities, and abbeys, resulting in about 860 different coins in circulation, with different values, denominations and monetary systems.The local Swiss currencies included the Basel thaler, Berne thaler, Fribourg gulden, Geneva thaler, Geneva genevoise, Luzern gulden, Neuch\u00e2tel gulden, St. Gallen thaler, Schwyz gulden, Solothurn thaler, Valais thaler, and Z\u00fcrich thaler.\n\n\t\t\n\n\n=== Helvetic Republic to Regeneration 1798\u20131847 ===\nIn 1798, the Helvetic Republic introduced the franc, a currency based on the Berne thaler, subdivided into 10 batzen or 100 centimes. The Swiss franc was equal to \u200b6 3\u20444 grams of pure silver or \u200b1 1\u20442 French francs.\n\nThis franc was issued until the end of the Helvetic Republic in 1803, but served as the model for the currencies of several cantons in the Mediation period (1803\u20131814). These 19 cantonal currencies were the  Appenzell frank, Argovia frank, Basel frank, Berne frank, Fribourg frank, Geneva franc, Glarus frank, Graub\u00fcnden frank, Luzern frank, St. Gallen frank, Schaffhausen frank, Schwyz frank, Solothurn frank, Thurgau frank, Ticino franco, Unterwalden frank, Uri frank, Vaud franc, and Z\u00fcrich frank.\n\nAfter 1815, the restored Swiss Confederacy attempted to simplify the system of currencies once again. \nAs of 1820, a total number of 8,000 distinct coins was current in Switzerland, issued by cantons, cities, abbeys, and principalities or lordships, mixed with surviving coins of the Helvetic Republic and the pre-1798 Helvetic Republic. In 1825, the cantons of Berne, Basel, Fribourg, Solothurn, Aargau, and Vaud formed a monetary concordate, issuing standardised coins, the so-called Konkordanzbatzen, still carrying the coat of arms of the issuing canton, but interchangeable and identical in value. The reverse side of the coin displayed a Swiss cross with the letter C in the center.\n\n\n=== Franc of the Swiss Confederation, 1850\u2013present ===\nAlthough 22 cantons and half-cantons issued coins between 1803 and 1850, less than 15% of the money in circulation in Switzerland in 1850 was locally produced, with the rest being foreign, mainly brought back by mercenaries. In addition, some private banks also started issuing the first banknotes, so that in total, at least 8000 different coins and notes were in circulation at that time, making the monetary system extremely complicated.To solve this problem, the new Swiss Federal Constitution of 1848 specified that the federal government would be the only entity allowed to make money in Switzerland. This was followed two years later by the first Federal Coinage Act, passed by the Federal Assembly on 7 May 1850, which introduced the franc as the monetary unit of Switzerland. The franc was introduced at par with the French franc. It replaced the different currencies of the Swiss cantons, some of which had been using a franc (divided into 10 batzen and 100 centimes) which was worth \u200b1 1\u20442 French francs.\n\nIn 1865, France, Belgium, Italy, and Switzerland formed the Latin Monetary Union, wherein they agreed to value their national currencies to a standard of 4.5 grams of silver or 0.290322 grams of gold. Even after the monetary union faded away in the 1920s and officially ended in 1927, the Swiss franc remained on that standard until 1936, when it suffered its sole devaluation, on 27 September during the Great Depression. The currency was devalued by 30% following the devaluations of the British pound, U.S. dollar and French franc. In 1945, Switzerland joined the Bretton Woods system and pegged the franc to the U.S. dollar at a rate of $1 = 4.30521 francs (equivalent to 1 franc = 0.206418 grams of gold). This was changed to $1 = 4.375 francs (1 franc = 0.203125 grams of gold) in 1949.\nThe Swiss franc has historically been considered a safe-haven currency with virtually zero inflation and a legal requirement that a minimum of 40% be backed by gold reserves. However, this link to gold, which dates from the 1920s, was terminated on 1 May 2000 following a referendum. By March 2005, following a gold-selling program, the Swiss National Bank held 1,290 tonnes of gold in reserves which equated to 20% of its assets.In November 2014, the referendum on the \"Swiss Gold Initiative\" which proposed a restoration of 20% gold backing for the Swiss franc was voted down.\n\n\n==== 2011\u20132014: Big movements and capping ====\nIn March 2011, the franc climbed past the US$1.10 mark (CHF 0.91 per U.S. dollar). In June 2011, the franc climbed past US$1.20 (CHF 0.833 per U.S. dollar) as investors sought safety amidst the continuation of the Greek sovereign-debt crisis. Continuation of the same crisis in Europe and the debt crisis in the U.S. propelled the Swiss franc past US$1.30 (CHF 0.769 per U.S. dollar) as of August 2011, prompting the Swiss National Bank to boost the franc's liquidity in an attempt to counter its \"massive overvaluation\". The Economist argued that its Big Mac Index in July 2011 indicated an overvaluation of 98% over the dollar and cited Swiss companies releasing profit warnings and threatening to move operations out of the country due to the strength of the franc. Demand for francs and franc-denominated assets was so strong that nominal short-term Swiss interest rates became negative.On 6 September 2011, when the exchange rate was 1.095 CHF/\u20ac and appeared to be heading for parity with the euro, the SNB set a minimum exchange rate of 1.20 francs to the euro (capping franc's appreciation) saying \"the value of the franc is a threat to the economy\", and that it was \"prepared to buy foreign currency in unlimited quantities\". In response to the announcement the franc fell against the euro, to 1.22 francs from 1.12 francs and lost 9% against the U.S. dollar within fifteen minutes. The intervention stunned currency traders since the franc had long been regarded as a safe haven.The franc fell 8.8% against the euro, 9.5% against the dollar, and at least 8.2% against all 16 of the most active currencies on the day of the announcement. It was the largest plunge of the franc ever against the euro. The SNB had previously set an exchange rate target in 1978 against the Deutsche mark and maintained it, although at the cost of high inflation. Until mid-January 2015, the franc continued to trade below the target level set by the SNB, though the ceiling was broken at least once on 5 April 2012, albeit briefly.\n\n\n==== End of capping ====\nOn 18 December 2014, the Swiss central bank introduced a negative interest rate on bank deposits to support its CHF ceiling. However, with the euro declining in value over the following weeks, in a move dubbed Francogeddon for its effect on markets, the Swiss National Bank abandoned the ceiling on 15 January 2015, and the franc promptly increased in value compared with the euro by 30%, although this only lasted a few minutes before part of the increase was reversed. The move was not announced in advance and resulted in \"turmoil\" in stock and currency markets. By the close of trading that day, the franc was up 23% against the euro and 21% against the US dollar. The full daily range of franc was equal to $31,000 per single futures contract (to the positive if long, to the negative if short), and is more than the market moved collectively in the previous thousand days.  The key interest rate was also lowered from \u22120.25% to \u22120.75%, meaning investors would be paying an increased fee to keep their funds in a Swiss bank account. This devaluation of the euro against the franc is expected to hurt Switzerland's large export industry. The Swatch Group, for example, saw its shares drop 15% (in Swiss franc terms) with the announcements so that the share price may have increased on that day in terms of other major currencies.\nThe large and unexpected jump caused major losses for some currency traders. Alpari, a Russian-owned spread betting firm established in the UK, temporarily declared insolvency before announcing its desire to be acquired (and later denied rumours of an acquisition) by FXCM. FXCM was bailed out by its parent company. Saxo Bank of Denmark reported losses on 19 January 2015. New Zealand foreign exchange broker Global Brokers NZ announced it \"could no longer meet New Zealand regulators' minimum capital requirements\" and terminated its business.Media questioned the ongoing credibility of the Swiss central bank, and indeed central banks in general. Using phrases like \"extend-and-pretend\" to describe central bank exchange rate control measures, Saxobank chief economist Steen Jakobsen stated, \"as a group, central banks have lost credibility and when the ECB starts QE this week, the beginning of the end for central banks will be well under way\". BT Investment Management's head of income and fixed interest, Vimal Gor stated, \"central banks are becoming more and more impotent. It also ultimately proves that central banks cannot drive economic growth like they think they can\". UBS interest rate strategist Andrew Lilley commented, \"central banks can have inconsistent goals from one-day to another\".\n\n\n== Coins ==\n\n\n=== Coins of the Helvetic Republic ===\n\nBetween 1798 and 1803, billon coins were issued in denominations of 1 centime, \u200b1\u20442 batzen, and 1 batzen. Silver coins were issued for 10, 20 and 40 batzen, with the 40-batzen coin also issued with the denomination given as 4 francs. Gold 16- and 32-franc coins were issued in 1800.\n\n\n=== Coins of the Swiss Confederation ===\nIn 1850, coins were introduced in denominations of 1, 2, 5, 10, and 20 centimes and \u200b1\u20442, 1, 2, and 5 francs, with the 1 and 2 centimes struck in bronze, the 5, 10, and 20 centimes in billon (with 5% to 15% silver content), and the franc denominations in .900 fine silver. Between 1860 and 1863, .800 fine silver was used, before the standard used in France of .835 fineness was adopted for all silver coins except the 5 francs (which remained .900 fineness) in 1875. In 1879, billon was replaced by cupronickel in the 5 and 10 centimes and by nickel in the 20 centimes. Gold coins in denominations of 10, 20, and 100 francs, known as Vreneli, circulated until 1936.Both world wars only had a small effect on the Swiss coinage, with brass and zinc coins temporarily being issued. In 1931, the size of the 5-franc coin was reduced from 25 grams to 15, with the silver content reduced to .835 fineness. The next year, nickel replaced cupronickel in the 5 and 10 centimes.In the late 1960s, the prices of internationally traded commodities rose significantly. A silver coin's metal value exceeded its monetary value, and many were being sent abroad for melting, which prompted the federal government to make this practice illegal. The statute was of little effect, and the melting of francs only subsided when the collectible value of the remaining francs again exceeded their material value.The 1-centime coin was still produced until 2006, albeit in ever decreasing quantities, but its importance declined. Those who could justify the use of 1-centime coins for monetary purposes could obtain them at face value; any other user (such as collectors) had to pay an additional four centimes per coin to cover the production costs, which had exceeded the actual face value of the coin for many years. The coin fell into disuse in the late 1970s and early 1980s, but was only officially fully withdrawn from circulation and declared to be no longer legal tender on 1 January 2007. The long-forgotten 2-centime coin, not minted since 1974, was demonetized on 1 January 1978.\n\nThe designs of the coins have changed very little since 1879. Among the notable changes were new designs for the 5-franc coins in 1888, 1922, 1924 (minor), and 1931 (mostly just a size reduction). A new design for the bronze coins was used from 1948. Coins depicting a ring of stars (such as the 1-franc coin seen beside this paragraph) were altered from 22 stars to 23 stars in 1983; since the stars represent the Swiss cantons, the design was updated when in 1979 Jura seceded from the Canton of Bern and became the 23rd canton of the Swiss Confederation.\n\nThe 10-centime coins from 1879 onwards (except the years 1918\u201319 and 1932\u201339) have had the same composition, size, and design until 2014 and are still legal tender and found in circulation.\n\nAll Swiss coins are language-neutral with respect to Switzerland's four national languages, featuring only numerals, the abbreviation \"Fr.\" for franc, and the Latin phrases Helvetia or Conf\u0153deratio Helvetica (depending on the denomination) or the inscription Libertas (Roman goddess of liberty) on the small coins. The name of the artist is present on the coins with the standing Helvetia and the herder.In addition to these general-circulation coins, numerous series of commemorative coins have been issued, as well as silver and gold coins. These coins are no longer legal tender, but can in theory be exchanged at face value at post offices, and at national and cantonal banks, although their metal or collectors' value equals or exceeds their face value.\n\n\n== Banknotes ==\n\nIn 1907, the Swiss National Bank took over the issuance of banknotes from the cantons and various banks. It introduced denominations of 50, 100, 500 and 1000 francs. 20-franc notes were introduced in 1911, followed by 5-franc notes in 1913. In 1914, the Federal Treasury issued paper money in denominations of 5, 10 and 20 francs. These notes were issued in three different versions: French, German and Italian. The State Loan Bank also issued 25-franc notes that year. In 1952, the national bank ceased issuing 5-franc notes but introduced 10-franc notes in 1955. In 1996, 200-franc notes were introduced whilst the 500-franc note was discontinued.\nEight series of banknotes have been printed by the Swiss National Bank, six of which have been released for use by the general public. The sixth series from 1976, designed by Ernst and Ursula Hiestand, depicted persons from the world of science.\nThis series was recalled on 1 May 2000 and is no longer legal tender, but notes can still be exchanged for valid ones of the same face value at any National Bank branch or authorized agent, or mailed in by post to the National Bank in exchange for a bank account deposit. The exchange program will end on 30 April 2020, after which sixth-series notes will lose all value. As of 2016, 1.1 billion francs' worth of sixth-series notes had not yet been exchanged, even though they had not been legal tender for 16 years and only 4 more years remained to exchange them. To avoid having to expire such large amounts of money in 2020, the Federal Council (cabinet) and National Bank proposed in April 2017 to remove the time limit on exchanges for the sixth and future recalled series; this proposal is still in the draft bill stage as of early 2018.\nThe seventh series was printed in 1984, but kept as a \"reserve series\", ready to be used if, for example, wide counterfeiting of the current series suddenly happened. When the Swiss National Bank decided to develop new security features and to abandon the concept of a reserve series, the details of the seventh series were released and the printed notes were destroyed.\nThe current, eighth series of banknotes was designed by J\u00f6rg Zintzmeyer around the theme of the arts and released starting in 1995. In addition to its new vertical design, this series was different from the previous one on several counts. Probably the most important difference from a practical point of view was that the seldom-used 500-franc note was replaced by a new 200-franc note; this new note has indeed proved more successful than the old 500-franc note. The base colours of the new notes were kept similar to the old ones, except that the 20-franc note was changed from blue to red to prevent a frequent confusion with the 100-franc note, and that the 10-franc note was changed from red to yellow. The size of the notes was changed as well, with all notes from the eighth series having the same height (74 mm), while the widths were changed as well, still increasing with the value of the notes. The new series contains many more security features than the previous one; many of them are now visibly displayed and have been widely advertised, in contrast with the previous series for which most of the features were kept secret.\n\nAll banknotes are quadrilingual, displaying all information in the four national languages. The banknotes depicting a Germanophone person have German and Romansch on the same side as the picture, whereas banknotes depicting a Francophone or an Italophone person have French and Italian on the same side as the picture. The reverse has the other two languages.\nWhen the fifth series lost its validity at the end of April 2000, the banknotes that had not been exchanged represented a total value of 244.3 million Swiss francs; in accordance with Swiss law, this amount was transferred to the Swiss Fund for Emergency Losses in the Case of Non-insurable Natural Disasters.\nNinth series of the Swiss franc\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\nIn February 2005, a competition was announced for the design of the ninth series, planned to be released around 2010 on the theme \"Switzerland open to the world\". The results were announced in November 2005, but the selected design drew widespread criticisms from the population. As a result, the release date has been repeatedly postponed. In February 2010, it was announced that the release would take place in 2012, and in December 2012 the date was given as \"2015 at the earliest\". In August 2015 it was announced that the new series would start being issued in April 2016. The first denomination to be released was the 50-franc note, which was first issued on 12 April 2016; the new 20-franc banknote followed on 17 May 2017, and the new 10-franc banknote on 18 October 2017. The 200 franc note's release is due on 15 August 2018. The final two notes will follow in 2019.\n\n\n== Circulation ==\nThe Swiss franc is the currency and legal tender of Switzerland and Liechtenstein and also legal tender in the Italian exclave of Campione d'Italia. Although not formally legal tender in the German exclave of B\u00fcsingen am Hochrhein (the sole legal currency is the euro), it is in wide daily use there; prices are quoted in Swiss francs. The Swiss franc is the only version of the franc still issued in Europe.\nAs of March 2010, the total value of released Swiss coins and banknotes was 49.6640 billion Swiss francs.\nCombinations of up to 100 circulating Swiss coins (not including special or commemorative coins) are legal tender; banknotes are legal tender for any amount.\n\n\n== Current exchange rates ==\n\n\n== See also ==\nBanking in Switzerland\nEconomy of Switzerland\nHard currency\nIraqi Swiss dinar, a common name for the old Iraqi currency but not related to Swiss currency.\nLiechtenstein franc\nGold standard\n\n\n== Notes and references ==\n\n\n== Bibliography ==\n\n\n== External links ==\n(in German) CashFollow.ch, Swiss Franc Tracker\n(in German) Schweizer-Franken.ch, Information about the Swiss Franc\n(in English) Switzerland Banknotes, Swiss Franc: Banknote Catalog from 1907\nhttp://www.forexuklv.net/Major_Currency_Pairs/Chart_07.html  -  historical exchange rates of USD/CHF (from the year 1800 to present time).\nhttp://www.forexuklv.net/Major_Currency_Pairs/Chart_01.html  -  historical chart of USD/CHF (from the year 1800 to present time).\n(in English) (in German) The Banknotes of Switzerland",
        "unit": "swiss franc",
        "url": "https://en.wikipedia.org/wiki/Swiss_franc"
    },
    {
        "_id": "Roentgen_(unit)",
        "clean": "Roentgen (unit)",
        "text": "The roentgen or r\u00f6ntgen () (symbol R) is a legacy unit of measurement for the exposure of X-rays and gamma rays. It is defined as the electric charge freed by such radiation in a specified volume of air divided by the mass of that air. \nIn 1928 it was the first international measurement quantity for ionising radiation to be defined for radiation protection, and was an easily replicated method of measuring air ionization directly by using an ion chamber. It is named after the German physicist Wilhelm R\u00f6ntgen, who discovered X-rays.\nAlthough relatively easy to measure, it had the disadvantage that it was only a measure of air ionisation and not a direct measure of radiation absorption in other materials. As the science of radiation dosimetry developed, it was realised that the ionising effect, and hence damage, was linked to energy absorbed by irradiated materials, and new radiometric units for radiation protection were defined from 1953 onwards which took this into account. A new quantity Kerma was defined which can measure air ionisation, and is the modern metrological successor to the roengten, and from this the absorbed dose can be calculated using known coefficients for specific target materials. In radiation protection the absorbed dose is the energy absorption which is an indication of likely acute tissue effects occurring at high dose rates, and from low levels of absorbed dose the equivalent dose, representing the stochastic health risk, can be calculated; for which the current SI units used are the gray (Gy) and the sievert (Sv) respectively.\nThe roengten has been redefined over the years. It was last defined by the US National Institute of Standards and Technology (NIST) in 1998 as 2.58\u00d710\u22124 C/kg, with a recommendation that the definition be given in every document where the roentgen is used. One roentgen deposits  0.00877 grays (0.877 rads) of absorbed dose in dry air, or 0.0096 Gy (0.96 rad) in soft tissue. One roentgen of X-rays may deposit anywhere from 0.01 to 0.04 Gy (1.0 to 4.0 rad) in bone depending on the beam energy.  This tissue-dependent conversion from kerma to absorbed dose is called the F-factor in radiotherapy contexts. The conversion depends on the ionizing energy of a reference medium, which is ambiguous in the latest NIST definition.\n\n\n== History ==\nThe roentgen has its roots in the Villard unit defined in 1908 by the American Roentgen Ray Society as \"the quantity of radiation which liberates by ionisation one esu of electricity per cm3 of air under normal conditions of temperature and pressure.\" Using 1 esu \u2248 3.33564\u00d710\u221210 C and the air density of ~1.293 kg/m\u00b3 at 0 \u00b0C and 101 kPa, this converts to 2.58 \u00d7 10\u22124 C/kg, which is the modern value given by NIST.\n1 esu/cm3 \u00d7 3.33564 \u00d7 10\u221210 C/esu \u00d7 1,000,000 cm3/m3 \u00f7 1.293 kg/m3 = 2.58 \u00d7 10\u22124 C/kg\nThis definition was used under different names (e, R, and German unit of radiation) for the next 20 years. In the meantime, the French Roentgen was given a different definition which amounted to 0.444 German R.\n\n\n=== ICR definitions ===\nIn 1928, the International Congress of Radiology (ICR) defined the roentgen as \"the quantity of X-radiation which, when the secondary electrons are fully utilised and the wall effect of the chamber is avoided, produce in 1 cc of atmospheric air at 0 \u00b0C and 76 cm of mercury pressure such a degree of conductivity that 1 esu of charge is measured at saturation current.\"  The stated 1 cc of air would have a mass of 1.293 mg at the conditions given, so in 1937 the ICR rewrote this definition in terms of this mass of air instead of volume, temperature and pressure. The 1937 definition was also extended to gamma rays, but later capped at 3 MeV in 1950.\n\n\n=== GOST definition ===\nThe USSR all-union committee of standards (GOST) had meanwhile adopted a significantly different definition of the roentgen in 1934. GOST standard 7623 defined it as \"the physical dose of X-rays which produces charges each of one electrostatic unit in magnitude per cm3 of irradiated volume in air at 0 \u00b0C and normal atmospheric pressure when ionization is complete.\"  The distinction of physical dose from dose caused confusion, some of which may have led Cantrill and Parker report that the roentgen had become shorthand for 83 ergs per gram (0.0083 Gy) of tissue. They named this derivative quantity the roentgen equivalent physical (rep) to distinguish it from the ICR roentgen.\n\n\n=== ICRP definition ===\nThe introduction of the roentgen measurement unit, which relied upon measuring the ionisation of air, replaced earlier less accurate practices that relied on timed exposure, film exposure, or fluorescence. This led the way to setting exposure limits,and the National Council on Radiation Protection and Measurements of the United States established the first formal dose limit in 1931 as 0.1 roentgen per day. The International X-ray and Radium Protection Committee, now known as the International Commission on Radiological Protection (ICRP) soon followed with a limit of 0.2 roentgen per day in 1934. In 1950, the ICRP reduced their recommended limit to 0.3 roentgen per week for whole-body exposure.\nThe International Commission on Radiation Units and Measurements (ICRU) took over the definition of the roentgen in 1950, defining it as \"the quantity of X or \u03b3-radiation such that the associated corpuscular emission per 0.001293 gram of air produces, in air, ions carrying 1 electrostatic unit of quantity of electricity of either sign.\" The 3 MeV cap was no longer part of the definition, but the degraded usefulness of this unit at high beam energies was mentioned in the accompanying text. In the meantime, the new concept of roentgen equivalent man (rem) had been developed.\nStarting in 1957, the ICRP began to publish their recommendations in terms of rem, and the roentgen fell into disuse. The medical imaging community still has a need for ionization measurements, but they gradually converted to using C/kg as legacy equipment was replaced. The ICRU recommended redefining the roentgen to be exactly 2.58 \u00d7 10\u22124 C/kg in 1971.\n\n\n=== European Union ===\nIn 1971 the European Economic Community, in Directive 71/354/EEC, catalogued the units of measure that could be used \"for ... public health ... purposes\".  The directive included the curie, rad, rem and roentgen  as permissible units, but required that the use of the rad, rem and roentgen be reviewed before 31 December 1977. This document defined the roentgen as exactly 2.58 \u00d7 10\u22124 C/kg, as per the ICRU recommendation. Directive 80/181/EEC, published in December 1979, which replaced directive 71/354/EEC, explicitly catalogued the gray, becquerel and sievert for this purpose and required that the curie, rad, rem and roentgen be phased out by 31 December 1985.\n\n\n=== NIST definition ===\nToday the roentgen is rarely used, and the International Committee for Weights and Measures (CIPM) never accepted the use of the roentgen. From 1977 to 1998, the US NIST's translations of the SI brochure stated that the CIPM temporarily accepted the use of the roentgen (and other radiology units) with SI units since 1969. However, the only related CIPM decision shown in the appendix are with regards to the curie in 1964. The NIST brochures defined the roentgen as 2.58 \u00d7 10\u22124 C/kg, to be employed with exposures of x or \u03b3 radiation, but did not state the medium to be ionized. The CIPM's current SI brochure excludes the roentgen from the tables of non-SI units accepted for use with the SI. The US NIST clarified in 1998 that it was providing its own interpretations of the SI system, whereby it accepted the roentgen for use in the US with the SI, while recognizing that the CIPM did not. By then, the limitation to x and \u03b3 radiation had been dropped. NIST recommends defining the roentgen in every document where this unit is used. The continued use of the roentgen is strongly discouraged by the NIST.\n\n\n== Development of replacement radiometric quantities ==\n\nWhilst a convenient quantity to measure with an air ion chamber, the rontgen had the disadvantage that it was not a direct measure of either the intensity of X-rays or their absorption, but rather was a measurement of the ionising effect of X-rays in a specific circumstance; which was dry air at 0 \u00b0C and 1 standard atmosphere of pressure.Because of this the rontgen had a variable relationship to the amount of energy absorbed dose per unit mass in the target material, as different materials have different absorption characteristics. As the science of radiation dosimetry developed, this was seen as a serious shortcoming.\nIn 1940, Louis Harold Gray, who had been studying the effect of neutron damage on human tissue, together with William Valentine Mayneord and the radiobiologist John Read, published a paper in which a unit of measure, dubbed the \"gram roentgen\" (symbol: gr) defined as \"that amount of neutron radiation which produces an increment in energy in unit volume of tissue equal to the increment of energy produced in unit volume of water by one roentgen of radiation\" was proposed. This unit was found to be equivalent to 88 ergs in air. In 1953 the ICRU recommended the rad, equal to 100 erg/g, as the new unit of measure of absorbed radiation. The rad was expressed in coherent cgs units.In the late 1950s the General Conference on Weights and Measures (CGPM) invited the ICRU to join other scientific bodies to work with the International Committee for Weights and Measures (CIPM) in the development of a system of units that could be used consistently over many disciplines. This body, initially known as the \"Commission for the System of Units\", renamed in 1964 as the \"Consultative Committee for Units\" (CCU), was responsible for overseeing the development of the International System of Units (SI). At the same time it was becoming increasingly obvious that the definition of the roentgen was unsound, and in 1962 it was redefined.\nThe CCU decided to define the SI unit of absorbed radiation in terms of energy per unit mass, which in MKS units was J/kg. This was confirmed in 1975 by the 15th CGPM, and the unit was named the \"gray\" in honour of Louis Harold Gray, who had died in 1965. The gray was equal to 100 rad. The definition of the roentgen had had the attraction of being relatively simple to define for photons in air, but the gray is independent of the primary ionizing radiation type, and can be used for both kerma and absorbed dose in a wide range of matter.When measuring absorbed dose in a human due to external exposure, the SI unit the gray, or the related non-SI rad are used. From these can be developed the dose equivalents to consider biological effects from differing radiation types and target materials. These are equivalent dose, and effective dose for which the SI unit sievert or the non-SI  rem are used.\n\n\n== Radiation-related quantities ==\nThe following table shows radiation quantities in SI and non-SI units:\n\n\n== See also ==\nWilhelm Conrad R\u00f6ntgen\nRad (unit)\u2014c.g.s. unit of absorbed dose\nGray (unit)\u2014SI unit of absorbed dose\nRoentgen equivalent man, or rem, a unit of radiation dose equivalent\nSievert\u2014The sievert (symbol: Sv) is the SI derived unit of dose equivalent.\nOrders of magnitude (radiation)\n\n\n== References ==\n\n\n== External links ==\nNIST: Units outside the SI\nHealth Physics Society information page on radiation dose units",
        "unit": "roentgen",
        "url": "https://en.wikipedia.org/wiki/Roentgen_(unit)"
    },
    {
        "_id": "Short_ton",
        "clean": "Short ton",
        "text": "The short ton is a unit of weight equal to 2,000 pounds (907.18474 kg). The term is most commonly used in the United States where it is known simply as the ton.\n\n\n== United States ==\n\nIn the United States, a short ton is usually known simply as a \"ton\", without distinguishing it from the tonne (1,000 kilograms or 2,204.62262 pounds), known there as the \"metric ton\", or the long ton also known as the \"Imperial ton\" (2,240 pounds or 1,016.0469088 kilograms). There are, however, some U.S. applications where unspecified tons normally means long tons (for example, naval ships) or metric tons (world grain production figures).\nBoth the long and short ton are defined as 20 hundredweights, but a hundredweight is 100 pounds (45.359237 kg) in the U.S. system (short or net hundredweight) and 112 pounds (50.80234544 kg) in the imperial system (long or gross hundredweight).A short ton\u2013force is 2,000 pounds-force (8,896.443230521 N).\n\n\n== United Kingdom ==\nIn the United Kingdom, short tons are rarely used.  The word \"ton\" is taken to refer to a long ton, and metric tons are distinguished by the \"tonne\" spelling.  Most Commonwealth countries followed British practice with the exception of Canada, which used short tons as well as long tons.  Canada now predominantly uses metric tons (tonnes).\n\n\n== See also ==\nLong ton, 2,240 lb (1,016.0469088 kg)\nTon\nTonne, also known as a metric ton (t), equal to 1,000 kg (2,204.6226218 lb) or 1 megagram.\nTonnage, volume measurement used in maritime shipping, originally based on 100 cubic feet (2.8316846592 m3).\n\n\n== References ==",
        "unit": "short ton",
        "url": "https://en.wikipedia.org/wiki/Short_ton"
    },
    {
        "_id": "Linear_density",
        "clean": "Linear density",
        "text": "Linear density is the measure of a quantity of any characteristic value per unit of length.  Linear mass density (titer in textile engineering, the amount of mass per unit length) and linear charge density (the amount of electric charge per unit length) are two common examples used in science and engineering.\nThe term linear density is most often used when describing the characteristics of one-dimensional objects, although linear density can also be used to describe the density of a three-dimensional quantity along one particular dimension.  Just as density is most often used to mean mass density, the term linear density likewise often refers to linear mass density.  However, this is only one example of a linear density, as any quantity can be measured in terms of its value along one dimension.\nConsider a long, thin rod of mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear mass density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{m}}\n  , of this one dimensional object, we can simply divide the total mass, \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        m\n        =\n        \n          \n            M\n            L\n          \n        \n      \n    \n    {\\displaystyle m={\\frac {M}{L}}}\n  If we describe the rod as having a varying mass (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        m\n        =\n        m\n        (\n        l\n        )\n      \n    \n    {\\displaystyle m=m(l)}\n  Each infinitesimal unit of mass, \n  \n    \n      \n        d\n        m\n      \n    \n    {\\displaystyle dm}\n  , is equal to the product of its linear mass density, \n  \n    \n      \n        \n          \u03bb\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{m}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        m\n        =\n        \n          \u03bb\n          \n            m\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dm=\\lambda _{m}dl}\n  The linear mass density can then be understood as the derivative of the mass function with respect to the one dimension of the rod (the position along its length \n  \n    \n      \n        m\n        =\n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle m={\\frac {dm}{dl}}}\n  )\nThe SI unit of linear mass density is the kilogram per meter (kg/m).\nLinear density of fibers and yarns can be measured by many methods. The simplest one is to measure a length of material and weigh it. However, this requires a large sample and masks the variability of linear density along the thread, and is difficult to apply if the fibers are crimped or otherwise cannot lay flat relaxed. If the density of the material is known, the fibers are measured individually and have a simple shape, a more accurate method is direct imaging of the fiber with SEM to measure the diameter and calculation of the linear density. Finally, linear density is directly measured with a vibroscope. The sample is tensioned between two hard points, mechanical vibration is induced and the fundamental frequency is measured.\n\n\n== Linear charge density ==\nConsider a long, thin wire of charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear charge density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}}\n  , of this one dimensional object, we can simply divide the total charge, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n        =\n        \n          \n            Q\n            L\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}={\\frac {Q}{L}}}\n  If we describe the wire as having a varying charge (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        q\n        =\n        q\n        (\n        l\n        )\n      \n    \n    {\\displaystyle q=q(l)}\n  Each infinitesimal unit of charge, \n  \n    \n      \n        d\n        q\n      \n    \n    {\\displaystyle dq}\n  , is equal to the product of its linear charge density, \n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        q\n        =\n        \n          \u03bb\n          \n            q\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dq=\\lambda _{q}dl}\n  The linear charge density can then be understood as the derivative of the charge function with respect to the one dimension of the wire (the position along its length, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  )\n\n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n        =\n        \n          \n            \n              d\n              q\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}={\\frac {dq}{dl}}}\n  Notice that these steps were the exact same ones we took before to find :\n  \n    \n      \n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {dm}{dl}}}\n  \nThe SI unit of linear charge density is the coulomb per meter (C/m).\n\n\n== Other applications ==\nIn drawing or printing, the term linear density also refers to how densely or heavily a line is drawn.\n\n\n== Units ==\n\nCommon units include:\n\nkilogram per meter\nounce (mass) per foot\nounce (mass) per inch\npound (mass) per yard: used in the North American railway industry for the linear density of rails\npound (mass) per foot\npound (mass) per inch\ntex, a unit of measure for the linear density of fibers, defined as the mass in grams per 1,000 meters\ndenier, a unit of measure for the linear density of fibers, defined as the mass in grams per 9,000 meters\ndecitex (dtex), the SI unit for the linear density of fibers, defined as the mass in grams per 10,000 meters\n\n\n== See also ==\nDensity\nColumnar density\nPaper density\n\n\n== References ==",
        "unit": "linear current density",
        "url": "https://en.wikipedia.org/wiki/Linear_density"
    },
    {
        "_id": "Energy",
        "clean": "Energy",
        "text": "In physics, energy is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object.  Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton.\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.\nMass and energy are closely related. Due to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy (in that frame of reference), and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale.\nLiving organisms require available energy to stay alive, such as the energy humans get from food.  Human civilization requires energy to function, which it gets from  energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth.\n\n\n== Forms ==\n\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object -- or the composite motion of the components of an object - and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may stored in the field itself.\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient refer to particular combinations of potential and kinetic energy as its own form. For example, macroscopic mechanical energy is the sum of translational and rotational kinetic and potential energy in a system neglects the kinetic energy due to temperature, and nuclear energy which combines utilize potentials from the nuclear force and the weak force), among others.\n\n\n== History ==\n\nThe word energy derives from the Ancient Greek: \u1f10\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1, translit. energeia, lit. 'activity, operation', which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\nIn the late 17th century, Gottfried Leibniz proposed the idea of the Latin: vis viva, or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total vis viva was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the random motion of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from vis viva only by a factor of two.\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of vis viva, in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\n\n\n== Units of measure ==\n\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\nIn the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second.  Thus, one joule is one watt-second, and 3600 joules equal one watt-hour.  The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\n\n\n== Scientific use ==\n\n\n=== Classical mechanics ===\n\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\nWork, a function of energy, is force times distance.\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle W=\\int _{C}\\mathbf {F} \\cdot \\mathrm {d} \\mathbf {s} }\n  This says that the work (\n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  ) is equal to the line integral of the force F along a path C; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy minus the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\n\n\n=== Chemistry ===\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor e\u2212E/kT \u2013 that is the probability of molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation.The activation energy necessary for a chemical reaction can be in the form of thermal energy.\n\n\n=== Biology ===\n\nIn biology, energy is an attribute of all biological systems from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or an organelle of a biological organism. Energy is thus often said to be stored by cells in the structures of molecules of substances such as carbohydrates (including sugars), lipids, and proteins, which release energy when reacted with oxygen in respiration. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, assuming an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.Sunlight's radiant energy is also captured by plants as chemical potential energy in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into the high-energy compounds carbohydrates, lipids, and proteins. Plants also release oxygen during photosynthesis, which is utilized by living organisms as an electron acceptor, to release the energy of carbohydrates, lipids, and proteins. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark, in a forest fire, or it may be made available more slowly for animal or human metabolism, when these molecules are ingested, and catabolism is triggered by enzyme action.\nAny living organism relies on an external source of energy\u2014radiant energy from the Sun in the case of green plants, chemical energy in some form in the case of animals\u2014to be able to grow and reproduce. The daily 1500\u20132000 Calories (6\u20138 MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidised to carbon dioxide and water in the mitochondria\n\n  \n    \n      \n        \n          \n            C\n            \n              6\n            \n            \n              \n            \n          \n          \n            H\n            \n              12\n            \n            \n              \n            \n          \n          \n            O\n            \n              6\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            O\n            \n              2\n            \n            \n              \n            \n          \n          \u27f6\n          6\n          \n          \n            CO\n            \n              2\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            H\n            \n              2\n            \n            \n              \n            \n          \n          O\n        \n      \n    \n    {\\displaystyle {\\ce {C6H12O6 + 6O2 -> 6CO2 + 6H2O}}}\n  \nC57H110O6 + 81.5O2 \u2192 57CO2 + 55H2Oand some of the energy is used to convert ADP into ATP.\n\nADP + HPO42\u2212 \u2192 ATP + H2OThe rest of the chemical energy in O2 and the carbohydrate or fat is converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100 m race: 4 kJ\ngain in gravitational potential energy of a 150 kg weight lifted through 2 metres: 3 kJ\nDaily food intake of a normal adult: 6\u20138 MJIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy), and it is true that most real machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology: to take just the first step in the food chain, of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\n\n\n=== Earth sciences ===\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations brought about by solar energy on the atmosphere of the planet Earth.\nSunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives many weather phenomena, save those generated by volcanic events. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement.\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may be later released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars created these atoms.\n\n\n=== Cosmology ===\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\n\n\n=== Quantum mechanics ===\n\nIn quantum mechanics, energy is defined in terms of the energy operator\nas a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: \n  \n    \n      \n        E\n        =\n        h\n        \u03bd\n      \n    \n    {\\displaystyle E=h\\nu }\n   (where \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is Planck's constant and \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\n\n\n=== Relativity ===\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{0}=mc^{2}}\n  ,where\n\nm is the mass of the body,\nc is the speed of light in vacuum,\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is the rest energy.For example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles.  This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.Energy and mass are manifestations of one and the same underlying physical property of a system.  This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of space-time (= boosts).\n\n\n== Transformation ==\n\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery, from chemical energy to electric energy; a dam: gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator; or a heat engine, from heat to work.\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\nEnergy transformations in the universe over time are characterized by various kinds of potential energy that has been available since the Big Bang later being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nuclear decay, in which energy is released that was originally \"stored\" in heavy isotopes (such as uranium and thorium), by nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae, to store energy in the creation of these heavy elements before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic energy and thermal energy in a very short time. Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at maximum. At its lowest point the kinetic energy is at maximum and is equal to the decrease of potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\nEnergy is also transferred from potential energy (\n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle E_{p}}\n  ) to kinetic energy (\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n  ) and then back to potential energy constantly. This is referred to as conservation of energy. In this closed system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\n\nThe equation can then be simplified further since \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        =\n        m\n        g\n        h\n      \n    \n    {\\displaystyle E_{p}=mgh}\n   (mass times acceleration due to gravity times the height) and \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{k}={\\frac {1}{2}}mv^{2}}\n   (half mass times velocity squared). Then the total amount of energy can be found by adding \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        +\n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            t\n            o\n            t\n            a\n            l\n          \n        \n      \n    \n    {\\displaystyle E_{p}+E_{k}=E_{total}}\n  .\n\n\n=== Conservation of energy and mass in transformation ===\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula E = mc\u00b2, derived by Albert Einstein (1905) quantifies the relationship between rest-mass and rest-energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J. J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass-energy equivalence#History for further information).\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since \n  \n    \n      \n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle c^{2}}\n   is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~\n  \n    \n      \n        9\n        \u00d7\n        \n          10\n          \n            16\n          \n        \n      \n    \n    {\\displaystyle 9\\times 10^{16}}\n   joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics.\n\n\n=== Reversible and non-reversible transformations ===\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).\nAs the universe evolves in time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or other kinds of increases in disorder). This has been referred to as the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), grows less and less.\n\n\n== Conservation of energy ==\n\nThe fact that energy can be neither created nor be destroyed is called the law of conservation of energy.  In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out by work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\nRichard Feynman said during a 1961 lecture:\nThere is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law\u2014it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same.\n\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle - it is impossible to define the exact amount of energy during any definite time interval. The uncertainty principle should not be confused with energy conservation - rather it provides mathematical limits to which energy can in principle be defined and measured.\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appears as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n\n  \n    \n      \n        \u0394\n        E\n        \u0394\n        t\n        \u2265\n        \n          \n            \u210f\n            2\n          \n        \n      \n    \n    {\\displaystyle \\Delta E\\Delta t\\geq {\\frac {\\hbar }{2}}}\n  which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since H and t are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\nIn particle physics, this inequality permits a qualitative understanding of virtual particles which carry momentum, exchange by which and with real particles, is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons (which are simply lowest quantum mechanical energy state of photons) are also responsible for electrostatic interaction between electric charges (which results in Coulomb law), for spontaneous radiative decay of exited atomic and nuclear states, for the Casimir force, for van der Waals bond forces and some other observable phenomena.\n\n\n== Energy transfer ==\n\n\n=== Closed systems ===\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\n\nwhere \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the amount of energy transferred, \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n    represents the work done on the system, and \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   represents the heat flow into the system. As a simplification, the heat term, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , is sometimes ignored, especially when the thermal efficiency of the transfer is high.\n\nThis simplified equation is the one used to define the joule, for example.\n\n\n=== Open systems ===\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (both of these process are illustrated by fueling an auto, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , one may write\n\n\n== Thermodynamics ==\n\n\n=== Internal energy ===\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\n\n\n=== First law of thermodynamics ===\nThe first law of thermodynamics asserts that energy (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a gain in energy signified by a positive quantity) is given as\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        T\n        \n          d\n        \n        S\n        \u2212\n        P\n        \n          d\n        \n        V\n        \n      \n    \n    {\\displaystyle \\mathrm {d} E=T\\mathrm {d} S-P\\mathrm {d} V\\,}\n  ,where the first term on the right is the heat transferred into the system, expressed in terms of temperature T and entropy S (in which entropy increases and the change dS is positive when the system is heated), and the last term on the right hand side is identified as work done on the system, where pressure is P and volume V (the negative sign results since compression of the system requires work to be done on it and so the volume change, dV, is negative when work is done on the system).\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and pV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a closed system is expressed in a general form by\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        \u03b4\n        Q\n        +\n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\mathrm {d} E=\\delta Q+\\delta W}\n  where \n  \n    \n      \n        \u03b4\n        Q\n      \n    \n    {\\displaystyle \\delta Q}\n   is the heat supplied to the system and \n  \n    \n      \n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\delta W}\n   is the work applied to the system.\n\n\n=== Equipartition of energy ===\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternatively kinetic and potential. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over the whole cycle, or over many cycles, net energy is thus equally split between kinetic and potential. This is called equipartition principle; total energy of a system with many degrees of freedom is equally split among all available degrees of freedom.\nThis principle is vitally important to understanding the behaviour of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is called the second law of thermodynamics. The second law of thermodynamics is valid only for systems which are near or in equilibrium state. For non-equilibrium systems, the laws governing system\u2019s behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way to maximize its entropy production.\n\n\n== See also ==\n\nCombustion\nIndex of energy articles\nIndex of wave articles\nOrders of magnitude (energy)\nPower station\nTransfer energy\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n\nEnergy at Curlie (based on DMOZ)\nDifferences between Heat and Thermal energy - BioCab",
        "unit": "energy",
        "url": "https://en.wikipedia.org/wiki/Energy"
    },
    {
        "_id": "Kelvin",
        "clean": "Kelvin",
        "text": "The Kelvin scale is an absolute thermodynamic temperature scale using as its null point absolute zero, the temperature at which all thermal motion ceases in the classical description of thermodynamics.  The kelvin (symbol: K) is the base unit of temperature in the International System of Units (SI).  The kelvin is defined as the fraction \u200b1\u2044273.16 of the thermodynamic temperature of the triple point of water (exactly 0.01 \u00b0C or 32.018 \u00b0F). In other words, it is defined such that the triple point of water is exactly 273.16 K.\nThe Kelvin scale is named after the Belfast-born, Glasgow University engineer and physicist William Thomson, 1st Baron Kelvin (1824\u20131907), who wrote of the need for an \"absolute thermometric scale\". Unlike the degree Fahrenheit and degree Celsius, the kelvin is not referred to or written as a degree. The kelvin is the primary unit of temperature measurement in the physical sciences, but is often used in conjunction with the degree Celsius, which has the same magnitude. The definition implies that absolute zero (0 K) is equivalent to \u2212273.15 \u00b0C (\u2212459.67 \u00b0F).\nFor expressing temperature difference or interval, using kelvins instead of degrees Celsius helps to avoid situations when people mistake such quantities for Celsius temperature. The kelvin is the proper temperature unit to be used in derived units, like W/(m\u00b7K) or to have a prefix, like milli in mK.\n\n\n== History ==\n\nIn 1848, William Thomson, who later was made Lord Kelvin, wrote in his paper, On an Absolute Thermometric Scale, of the need for a scale whereby \"infinite cold\" (absolute zero) was the scale's null point, and which used the degree Celsius for its unit increment. Kelvin calculated that absolute zero was equivalent to \u2212273 \u00b0C on the air thermometers of the time. This absolute scale is known today as the Kelvin thermodynamic temperature scale. Kelvin's value of \"\u2212273\" was the negative reciprocal of 0.00366\u2014the accepted expansion coefficient of gas per degree Celsius relative to the ice point, giving a remarkable consistency to the currently accepted value.\nIn 1954, Resolution 3 of the 10th General Conference on Weights and Measures (CGPM) gave the Kelvin scale its modern definition by designating the triple point of water as its second defining point and assigned its temperature to exactly 273.16 kelvins.In 1967/1968  Resolution 3 of the 13th CGPM renamed the unit increment of thermodynamic temperature \"kelvin\", symbol K, replacing \"degree Kelvin\", symbol \u00b0K. Furthermore, feeling it useful to more explicitly define the magnitude of the unit increment, the 13th CGPM also held in Resolution 4 that \"The kelvin, unit of thermodynamic temperature, is equal to the fraction \u200b1\u2044273.16 of the thermodynamic temperature of the triple point of water.\"In 2005  The Comit\u00e9 International des Poids et Mesures (CIPM), a committee of the CGPM, affirmed that for the purposes of delineating the temperature of the triple point of water, the definition of the Kelvin thermodynamic temperature scale would refer to water having an isotopic composition specified as VSMOW.\n\n\n== Usage conventions ==\nWhen spelled out or spoken, the unit is pluralised using the same grammatical rules as for other SI units such as the volt or ohm (e.g. \"the triple point of water is exactly 273.16 kelvins\"). When reference is made to the \"Kelvin scale\", the word \"kelvin\"\u2014which is normally a noun\u2014functions adjectivally to modify the noun \"scale\" and is capitalized. As with most other SI unit symbols (angle symbols, e.g. 45\u00b0 3\u2032 4\u2033, are the exception) there is a space between the numeric value and the kelvin symbol (e.g. \"99.987 K\").Before the 13th CGPM in 1967\u20131968, the unit kelvin was called a \"degree\", the same as with the other temperature scales at the time. It was distinguished from the other scales with either the adjective suffix \"Kelvin\" (\"degree Kelvin\") or with \"absolute\" (\"degree absolute\") and its symbol was \u00b0K. The latter term (degree absolute), which was the unit's official name from 1948 until 1954, was ambiguous since it could also be interpreted as referring to the Rankine scale. Before the 13th CGPM, the plural form was \"degrees absolute\". The 13th CGPM changed the unit name to simply \"kelvin\" (symbol: K). The omission of \"degree\" indicates that it is not relative to an arbitrary reference point like the Celsius and Fahrenheit scales (although the Rankine scale continued to use \"degree Rankine\"), but rather an absolute unit of measure which can be manipulated algebraically (e.g. multiplied by two to indicate twice the amount of \"mean energy\" available among elementary degrees of freedom of the system).\n\n\n=== Use in conjunction with degrees Celsius ===\n\nIn science and engineering, degrees Celsius and kelvins are often used simultaneously in the same article, where absolute temperatures are given in degrees Celsius, but temperature intervals are given in kelvins.  E.g. \"its measured value was 0.01028 \u00b0C with an uncertainty of 60 \u00b5K.\"\nThis practice is permissible because the degree Celsius is a special name for the kelvin for use in expressing relative temperatures, and the magnitude of the degree Celsius is exactly equal to that of the kelvin. Notwithstanding that the official endorsement provided by Resolution 3 of the 13th CGPM states \"a temperature interval may also be expressed in degrees Celsius\", the practice of simultaneously using both \"\u00b0C\" and \"K\" is widespread throughout the scientific world. The use of SI prefixed forms of the degree Celsius (such as \"\u00b5\u00b0C\" or \"microdegree Celsius\") to express a temperature interval has not been widely adopted.\n\n\n== Proposed redefinition ==\n\nIn 2005 the CIPM embarked on a program to redefine the kelvin (along with the other SI units) using a more experimentally rigorous methodology. The current definition as of  2016 is unsatisfactory for temperatures below 20 K and above 1300 K. In particular, the committee proposed redefining the kelvin such that Boltzmann's constant takes the exact value 1.3806505\u00d710\u221223 J/K. The committee had hoped that the program would be completed in time for its adoption by the CGPM at its 2011 meeting, but at the 2011 meeting the decision was postponed to the 2014 meeting when it would be considered as part of a larger program.The redefinition was further postponed in 2014, pending more accurate measurements of Boltzmann's constant in terms of the current definition, but it is expected to be adopted at the 26th CGPM in late 2018.From a scientific point of view, this will link temperature to the rest of SI and result in a stable definition that is independent of any particular substance. From a practical point of view, the redefinition will pass unnoticed; water will still freeze at 273.15 K (0 \u00b0C).\n\n\n== Practical uses ==\n\n\n=== Colour temperature ===\n\nThe kelvin is often used in the measure of the colour temperature of light sources. Colour temperature is based upon the principle that a black body radiator emits light whose colour depends on the temperature of the radiator. Black bodies with temperatures below about 4000 K appear reddish, whereas those above about 7500 K appear bluish. Colour temperature is important in the fields of image projection and photography, where a colour temperature of approximately 5600 K is required to match \"daylight\" film emulsions. In astronomy, the stellar classification of stars and their place on the Hertzsprung\u2013Russell diagram are based, in part, upon their surface temperature, known as effective temperature. The photosphere of the Sun, for instance, has an effective temperature of 5778 K.\nDigital cameras and photographic software often use colour temperature in K in edit and setup menus. The simple guide is that the higher the colour temperature, the more white or blue the image will be. The reduction in colour temperature will give an image more dominated by reddish, \"warmer\" colours.\n\n\n=== Kelvin as a measure of noise ===\n\nIn electronics, the kelvin is used as an indicator of how noisy a circuit is in relation to an ultimate noise floor, i.e. the noise temperature. The so-called Johnson\u2013Nyquist noise of discrete resistors and capacitors is a type of thermal noise derived from the Boltzmann constant and can be used to determine the noise temperature of a circuit using the Friis formulas for noise.\n\n\n== Unicode character ==\nThe symbol is encoded in Unicode at code point U+212A K kelvin sign. However, this is a compatibility character provided for compatibility with legacy encodings. The Unicode standard recommends using U+004B K latin capital letter k instead; that is, a normal capital K. \"Three letterlike symbols have been given canonical equivalence to regular letters: U+2126 \u03a9 ohm sign, U+212A K kelvin sign, and U+212B \u00c5 angstrom sign. In all three instances, the regular letter should be used.\"\n\n\n== See also ==\nComparison of temperature scales\nInternational Temperature Scale of 1990\nNegative temperature\n\n\n== Notes and references ==\n\n\n== External links ==\nBureau International des Poids et Mesures (2006). \"The International System of Units (SI) Brochure\" (PDF). 8th Edition. International Committee for Weights and Measures. Retrieved 2008-02-06. \nOnlineConversion.com \u2013 Convert different temperature units (Celsius, Fahrenheit, Rankine, R\u00e9aumur, kelvin)",
        "unit": "kelvin",
        "url": "https://en.wikipedia.org/wiki/Kelvin"
    },
    {
        "_id": "Nibble",
        "clean": "Nibble",
        "text": "In computing, a nibble (occasionally nybble or nyble to match the spelling of byte) is a four-bit aggregation, or half an octet. It is also known as half-byte or tetrade.\nIn a networking or telecommunication context, the nibble is often called a semi-octet, quadbit, or quartet.\nA nibble has sixteen (24) possible values. A nibble can be represented by a single hexadecimal digit and called a hex digit.A full byte (octet) is represented by two hexadecimal digits; therefore, it is common to display a byte of information as two nibbles. Sometimes the set of all 256 byte values is represented as a 16\u00d716 table, which gives easily readable hexadecimal codes for each value.\nFour-bit computer architectures use groups of four bits as their fundamental unit. Such architectures were used in early microprocessors, pocket calculators and pocket computers. They continue to be used in some microcontrollers.\n\n\n== History ==\nThe term 'nibble' originates from its representing 'half a byte', with 'byte' a homophone of the English word 'bite'.\nIn 2014, David B. Benson, a professor emeritus at Washington State University, remembered that he playfully used (and may have possibly coined) the term nibble as \"half a byte\" and unit of storage required to hold a binary-coded decimal (BCD) decimal digit around 1958, when talking to a programmer of Los Alamos Scientific Laboratory.\nThe alternative spelling 'nybble' reflects the spelling of 'byte', as noted in editorials of Kilobaud and Byte in the early 1980s.\nAnother early recorded use of the term 'nybble' was in 1977 within the consumer-banking technology group at Citibank. It created a pre-ISO 8583 standard for transactional messages between cash machines and Citibank's data centers that used the basic informational unit 'NABBLE'.\nThe nibble is used to describe the amount of memory used to store a digit of a number stored in packed decimal format (BCD) within an IBM mainframe. This technique is used to make computations faster and debugging easier. An 8-bit byte is split in half and each nibble is used to store one decimal digit. The last (rightmost) nibble of the variable is reserved for the sign. Thus a variable which can store up to nine digits would be \"packed\" into 5 bytes. Ease of debugging resulted from the numbers being readable in a hex dump where two hex numbers are used to represent the value of a byte, as 16\u00d716 = 28. For example, a five-byte BCD value of 31 41 59 26 5C represents a decimal value of +314159265.\nHistorically, there are cases where nybble was used for a group of bits greater than 4. In the Apple II microcomputer line, much of the disk drive control and group-coded recording was implemented in software. Writing data to a disk was done by converting 256-byte pages into sets of 5-bit (later, 6-bit) nibbles and loading disk data required the reverse. Moreover, 1982 documentation for the Integrated Woz Machine refers consistently to an \"8 bit nibble\".\nThe term byte once had the same ambiguity and meant a set of bits but not necessarily 8, hence the distinction of bytes and octets or of nibbles and quartets (or quadbits). Today, the terms 'byte' and 'nibble' almost always refer to 8-bit and 4-bit collections respectively and are very rarely used to express any other sizes.\n\n\n== Table of nibbles ==\nThe sixteen nibbles and their equivalents in other numeral systems:\n\n\n== Low and high nibbles ==\nThe terms \"low nibble\" and \"high nibble\" are used to denote the nibbles containing, respectively, the less significant bits and the more significant bits within a byte. In graphical representations of bits within a byte, the leftmost bit could represent the most significant bit (MSB), corresponding to ordinary decimal notation in which the digit at the left of a number is the most significant. In such illustrations the four bits on the left end of the byte form the high nibble, and the remaining four bits form the low nibble.  For example,\nninety-seven = 9710 = (0110 0001)2the high nibble is 01102 (6), and the low nibble is 00012 (1).  The total value is high-nibble \u00d7 16 + low-nibble (6\u00d716+1=97).\n\n\n== Extracting a nibble from a byte ==\nIn the C programming language:\n\nwhere b must be a variable or constant of an integral data type, and only the least-significant byte of b is used.\nFor example, HI_NIBBLE(0xAB)==0xA and LO_NIBBLE(0xAB)==0xB.\nIn Common Lisp:\n\n\n== See also ==\nBinary numeral system\nSyllable (computing)\nWord\n\n\n== References ==\n\n\n== External links ==\nApple Assembly Line, May 1981, Volume 1, Number 8",
        "unit": "nibble",
        "url": "https://en.wikipedia.org/wiki/Nibble"
    },
    {
        "_id": "Barn_(unit)",
        "clean": "Barn (unit)",
        "text": "A barn (symbol: b) is a unit of area equal to 10\u221228 m2 (100 fm2). Originally used in nuclear physics for expressing the cross sectional area of nuclei and nuclear reactions, today it is also used in all fields of high-energy physics to express the cross sections of any scattering process, and is best understood as a measure of the probability of interaction between small particles. A barn is  approximately the cross-sectional area of a uranium nucleus. The barn is also the unit of area used in nuclear quadrupole resonance and nuclear magnetic resonance to quantify the interaction of a nucleus with an electric field gradient. While the barn is not an SI unit, the SI standards body acknowledges its existence due to its continued use in particle physics.\n\n\n== Etymology ==\nThe etymology of the unit barn is whimsical: during Manhattan Project research on the atomic bomb during World War II, American physicists at Purdue University needed a secretive unit to describe the approximate cross sectional area presented by the typical nucleus (10\u221228 m2) and decided on \"barn.\" This was particularly applicable because they considered this a large target for particle accelerators that needed to have direct strikes on nuclei and the American idiom \"couldn't hit the broad side of a barn\" refers to someone whose aim is terrible. Initially they hoped the name would obscure any reference to the study of nuclear structure; eventually, the word became a standard unit in nuclear and particle physics.\n\n\n== Commonly used prefixed versions ==\nOther related units are the outhouse (1 \u03bcb, or 10\u221234 m2) and the shed (10\u221224 b (1 yb), or 10\u221252 m2), although these are rarely used in practice.\n\n\n== Conversions ==\nCalculated cross sections are often given in terms of gigaelectronvolts (GeV), via the conversion \u01272c2/GeV2 = 0.3894 mb = 38 940 am2.\nIn natural units (where \u0127 = c = 1), this simplifies to GeV\u22122 = 0.3894 mb = 38 940 am2.\n\n\n=== SI units with prefix ===\nIn SI, one can use units such as square femtometers (fm2).\n\n\n== Inverse femtobarn ==\nThe inverse femtobarn (fb\u22121) is the unit typically used to measure the number of particle collision events per femtobarn of target cross-section, and is the conventional unit for time-integrated luminosity. Thus if a detector has accumulated 100 fb\u22121 of integrated luminosity, one expects to find 100 events per femtobarn of cross-section within these data.\nConsider a particle accelerator where two streams of particles, with cross-sectional areas measured in femtobarns, are directed to collide over a period of time. The total number of collisions will be directly proportional to the luminosity of the collisions measured over this time. Therefore, the collision count can be calculated by multiplying the integrated luminosity by the sum of the cross-section for those collision processes. This count is then expressed as inverse femtobarns for the time period (e.g., 100 fb\u22121 in nine months). Inverse femtobarns are often quoted as an indication of particle collider productivity.Fermilab produced 10 fb\u22121 in the first decade of the 21st century.  Fermilab's Tevatron took about 4 years to reach 1 fb\u22121 in 2005, while two of CERN's LHC experiments, ATLAS and CMS, reached over 5 fb\u22121 of proton-proton data in 2011 alone. In April 2012 the LHC achieved the collision energy of 8 TeV with a luminosity peak of 6760 inverse microbarns per second; by May 2012 the LHC delivered 1 inverse femtobarn of data per week to each detector collaboration. A record of over 23 fb\u22121 was achieved during 2012. As of November 2016, the LHC had achieved 40  fb\u22121 over that year, significantly exceeding the stated goal of 25  fb\u22121.\n\n\n=== Usage example ===\nAs a simplified example, if a beamline runs for 8 hours (28 800 seconds) at an instantaneous luminosity of 300 \u00d7 1030 cm\u22122s\u22121 = 300 \u03bcb\u22121s\u22121, then it will gather data totaling an integrated luminosity of 8 640 000 \u03bcb\u22121 = 8.64 pb\u22121 = 0.008 64 fb\u22121 during this period. If this is multiplied by the cross-section, then a dimensionless number is obtained which would be simply the number of expected scattering events.\n\n\n== See also ==\nOrders of magnitude (area)\nList of unusual units of measurement\n\n\n== References ==\n\n\n== External links ==\nIUPAC citation for this usage of \"barn\"",
        "unit": "barn",
        "url": "https://en.wikipedia.org/wiki/Barn_(unit)"
    },
    {
        "_id": "Coulomb",
        "clean": "Coulomb",
        "text": "The coulomb (symbol: C) is the International System of Units (SI) unit of electric charge. It is the charge (symbol: Q or q) transported by a constant current of one ampere in one second:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          A\n        \n        \u22c5\n        1\n         \n        \n          s\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{A}}\\cdot 1~{\\text{s}}}\n  Thus, it is also the amount of excess charge on a capacitor of one farad charged to a potential difference of one volt:\n\n  \n    \n      \n        1\n         \n        \n          C\n        \n        =\n        1\n         \n        \n          F\n        \n        \u22c5\n        1\n         \n        \n          V\n        \n      \n    \n    {\\displaystyle 1~{\\text{C}}=1~{\\text{F}}\\cdot 1~{\\text{V}}}\n  It is equivalent to the charge of approximately 6.242\u00d71018 (1.036\u00d710\u22125 mol) protons, and \u22121 C is equivalent to the charge of approximately 6.242\u00d71018 electrons.\n\n\n== Name and notation ==\nThis SI unit is named after Charles-Augustin de Coulomb. As with every International System of Units (SI) unit named for a person, the first letter of its symbol is upper case (C). However, when an SI unit is spelled out in English, it is treated as a common noun and should always begin with a lower case letter (coulomb)\u2014except in a situation where any word in that position would be capitalized, such as at the beginning of a sentence or in material using title case.\n\n\n== Definition ==\nThe SI system defines the coulomb in terms of the ampere and second: 1 C = 1 A \u00d7 1 s. The second is defined in terms of a frequency naturally emitted by caesium atoms. The ampere is defined using Amp\u00e8re's force law; the definition relies in part on the mass of the international prototype kilogram, a metal cylinder housed in France. In practice, the Kibble balance is used to measure amperes with the highest possible accuracy.Since the charge of one electron is known to be about 1.6021766208(98)\u00d710\u221219 C, 1 C can also be considered the charge of roughly 6.241509\u00d710^18 electrons or +1 C the charge of that many positrons or protons, where the number is the reciprocal of 1.602177\u00d710^\u221219.\nThe proposed redefinition of the ampere and other SI base units would have the effect of fixing the numerical value of the elementary charge to an explicit constant expressed in coulombs, and therefore it would implicitly fix the value of the coulomb when expressed as a multiple of the fundamental charge (the numerical values of those quantities are the multiplicative inverses of each other).\n\n\n== SI prefixes ==\nSee also Metric prefix.\n\n\n== Conversions ==\nOne coulomb is the magnitude (absolute value) of electrical charge in 6.24150934(14)\u00d710^18 protons or electrons.\nThe inverse of this number gives the elementary charge of 1.6021766208(98)\u00d710\u221219 C.\nThe magnitude of the electrical charge of one mole of elementary charges (approximately 6.022\u00d71023, or Avogadro's number) is known as a faraday unit of charge (closely related to the Faraday constant). One faraday equals 96485.3399 coulombs. In terms of Avogadro's number (NA), one coulomb is equal to approximately 1.036 \u00d7 NA\u00d710\u22125 elementary charges.\nOne ampere hour = 3600 C \u2234 1 mA\u22c5h = 3.6 C.\nOne statcoulomb (statC), the obsolete CGS electrostatic unit of charge (esu), is approximately 3.3356\u00d710\u221210 C or about one-third of a nanocoulomb.\n\n\n== Relation to elementary charge ==\nThe elementary charge, the charge of a proton (equivalently, the negative of the charge of an electron), is approximately 1.6021766208(98)\u00d710\u221219 C. In SI, the elementary charge in coulombs is an approximate value: no experiment can be infinitely accurate. However, in other unit systems, the elementary charge has an exact value by definition, and other charges are ultimately measured relative to the elementary charge. For example, in conventional electrical units, the values of the Josephson constant KJ and von Klitzing constant RK are exact defined values (written KJ-90 and RK-90), and it follows that the elementary charge e = 2/(KJRK) is also an exact defined value in this unit system. Specifically, e90 = (2\u00d710\u22129)/(25812.807 \u00d7 483597.9) C exactly. SI itself may someday change its definitions in a similar way. For example, one possible proposed redefinition is \"the ampere...is [defined] such that the value of the elementary charge e (charge on a proton) is exactly 1.602176487\u00d710\u221219 coulombs\", (in which the numeric value is the 2006 CODATA recommended value, since superseded). This proposal is not yet accepted as part of the SI.\n\n\n== In everyday terms ==\nThe charges in static electricity from rubbing materials together are typically a few microcoulombs.\nThe amount of charge that travels through a lightning bolt is typically around 15 C, although large bolts can be up to 350 C.\nThe amount of charge that travels through a typical alkaline AA battery from being fully charged to discharged is about 5 kC = 5000 C \u2248 1400 mA\u22c5h.\nThe hydraulic analogy uses everyday terms to illustrate movement of charge and the transfer of energy. The analogy equates charge to a volume of water, and voltage to pressure. One coulomb equals (the negative of) the charge of 6.24\u00d71018 electrons. The amount of energy transferred by the flow of 1 coulomb can vary; for example, 300 times fewer electrons flow through a lightning bolt than in the discharge of an AA battery, but the total energy transferred by the flow of the lightning's electrons is 300 million times greater.\n\n\n== See also ==\nAbcoulomb, a cgs unit of charge\nAmp\u00e8re's circuital law\nCoulomb's law\nElectrostatics\nElementary charge\nFaraday constant, the number of coulombs per mole\n\n\n== Notes and references ==",
        "unit": "coulomb",
        "url": "https://en.wikipedia.org/wiki/Coulomb"
    },
    {
        "_id": "Volume",
        "clean": "Volume",
        "text": "Volume is the quantity of three-dimensional space enclosed by a closed surface, for example, the space that a substance (solid, liquid, gas, or plasma) or shape occupies or contains. Volume is often quantified numerically using the SI derived unit, the cubic metre. The volume of a container is generally understood to be the capacity of the container; i. e., the amount of fluid (gas or liquid) that the container could hold, rather than the amount of space the container itself displaces.\nThree dimensional mathematical shapes are also assigned volumes. Volumes of some simple shapes, such as regular, straight-edged, and circular shapes can be easily calculated using arithmetic formulas. Volumes of complicated shapes can be calculated with integral calculus if a formula exists for the shape's boundary. One-dimensional figures (such as lines) and two-dimensional shapes (such as squares) are assigned zero volume in the three-dimensional space.\nThe volume of a solid (whether regularly or irregularly shaped) can be determined by fluid displacement. Displacement of liquid can also be used to determine the volume of a gas. The combined volume of two substances is usually greater than the volume of just one of the substances. However, sometimes one substance dissolves in the other and in such cases the combined volume is not additive.In differential geometry, volume is expressed by means of the volume form, and is an important global Riemannian invariant.\nIn thermodynamics, volume is a fundamental parameter, and is a conjugate variable to pressure.\n\n\n== Units ==\n\nAny unit of length gives a corresponding unit of volume: the volume of a cube whose sides have the given length.  For example, a cubic centimetre (cm3) is the volume of a cube whose sides are one centimetre (1 cm) in length.\nIn the International System of Units (SI), the standard unit of volume is the cubic metre (m3).  The metric system also includes the litre (L) as a unit of volume, where one litre is the volume of a 10-centimetre cube.  Thus\n\n1 litre = (10 cm)3 = 1000 cubic centimetres = 0.001 cubic metres,so\n\n1 cubic metre = 1000 litres.Small amounts of liquid are often measured in millilitres, where\n\n1 millilitre = 0.001 litres = 1 cubic centimetre.In the same way, large amounts can be measured in megalitres, where\n\n1 million litres = 1000 cubic metres = 1 megalitre.Various other traditional units of volume are also in use, including the cubic inch, the cubic foot, the cubic yard, the cubic mile, the teaspoon, the tablespoon, the fluid ounce, the fluid dram, the gill, the pint, the quart, the gallon, the minim, the barrel, the cord, the peck, the bushel, the hogshead, the acre-foot and the board foot.\n\n\n== Related terms ==\nCapacity is defined by the Oxford English Dictionary as \"the measure applied to the content of a vessel, and to liquids, grain, or the like, which take the shape of that which holds them\". (The word capacity has other unrelated meanings, as in e.g. capacity management.) Capacity is not identical in meaning to volume, though closely related; the capacity of a container is always the volume in its interior. Units of capacity are the SI litre and its derived units, and Imperial units such as gill, pint, gallon, and others. Units of volume are the cubes of units of length. In SI the units of volume and capacity are closely related: one litre is exactly 1 cubic decimetre, the capacity of a cube with a 10 cm side. In other systems the conversion is not trivial; the capacity of a vehicle's fuel tank is rarely stated in cubic feet, for example, but in gallons (an imperial gallon fills a volume of 0.1605 cu ft).\nThe density of an object is defined as the ratio of the mass to the volume. The inverse of density is specific volume which is defined as volume divided by mass. Specific volume is a concept important in thermodynamics where the volume of a working fluid is often an important parameter of a system being studied.\nThe volumetric flow rate in fluid dynamics is the volume of fluid which passes through a given surface per unit time (for example cubic meters per second [m3 s\u22121]).\n\n\n== Volume in calculus ==\n\nIn calculus, a branch of mathematics, the volume of a region D in R3 is given by a triple integral of the constant function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        =\n        1\n      \n    \n    {\\displaystyle f(x,y,z)=1}\n   and is usually written as:\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        1\n        \n        d\n        x\n        \n        d\n        y\n        \n        d\n        z\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}1\\,dx\\,dy\\,dz.}\n  The volume integral in cylindrical coordinates is\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        r\n        \n        d\n        r\n        \n        d\n        \u03b8\n        \n        d\n        z\n        ,\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}r\\,dr\\,d\\theta \\,dz,}\n  and the volume integral in spherical coordinates (using the convention for angles with \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   as the azimuth and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   measured from the polar axis; see more on conventions) has the form\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        \n          \u03c1\n          \n            2\n          \n        \n        sin\n        \u2061\n        \u03d5\n        \n        d\n        \u03c1\n        \n        d\n        \u03b8\n        \n        d\n        \u03d5\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}\\rho ^{2}\\sin \\phi \\,d\\rho \\,d\\theta \\,d\\phi .}\n  \n\n\n== Volume formulas ==\n\n\n=== Volume ratios for a cone, sphere and cylinder of the same radius and height ===\n\nThe above formulas can be used to show that the volumes of a cone, sphere and cylinder of the same radius and height are in the ratio 1 : 2 : 3, as follows.\nLet the radius be r and the height be h (which is 2r for the sphere), then the volume of cone is\n\n  \n    \n      \n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          (\n          \n            2\n            r\n          \n          )\n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        1\n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{3}}\\pi r^{2}h={\\frac {1}{3}}\\pi r^{2}\\left(2r\\right)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 1,}\n  the volume of the sphere is\n\n  \n    \n      \n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        2\n        ,\n      \n    \n    {\\displaystyle {\\frac {4}{3}}\\pi r^{3}=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 2,}\n  while the volume of the cylinder is\n\n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        (\n        2\n        r\n        )\n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        3.\n      \n    \n    {\\displaystyle \\pi r^{2}h=\\pi r^{2}(2r)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 3.}\n  The discovery of the 2 : 3 ratio of the volumes of the sphere and cylinder is credited to Archimedes.\n\n\n=== Volume formula derivations ===\n\n\n==== Sphere ====\nThe volume of a sphere is the integral of an infinite number of infinitesimally small circular disks of thickness dx. The calculation for the volume of a sphere with center 0 and radius r is as follows.\nThe surface area of the circular disk is \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n  .\nThe radius of the circular disks, defined such that the x-axis cuts perpendicularly through them, is\n\n  \n    \n      \n        y\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle y={\\sqrt {r^{2}-x^{2}}}}\n  or\n\n  \n    \n      \n        z\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle z={\\sqrt {r^{2}-x^{2}}}}\n  where y or z can be taken to represent the radius of a disk at a particular x value.\nUsing y as the disk radius, the volume of the sphere can be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          y\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n          )\n        \n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi y^{2}\\,dx=\\int _{-r}^{r}\\pi \\left(r^{2}-x^{2}\\right)\\,dx.}\n  Now\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        x\n        \u2212\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          x\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u2212\n        \n          \n            \u03c0\n            3\n          \n        \n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        =\n        2\n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        \u2212\n        \n          \n            \n              2\n              \u03c0\n              \n                r\n                \n                  3\n                \n              \n            \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi r^{2}\\,dx-\\int _{-r}^{r}\\pi x^{2}\\,dx=\\pi \\left(r^{3}+r^{3}\\right)-{\\frac {\\pi }{3}}\\left(r^{3}+r^{3}\\right)=2\\pi r^{3}-{\\frac {2\\pi r^{3}}{3}}.}\n  Combining yields \n  \n    \n      \n        V\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle V={\\frac {4}{3}}\\pi r^{3}.}\n  \nThis formula can be derived more quickly using the formula for the sphere's surface area, which is \n  \n    \n      \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 4\\pi r^{2}}\n  . The volume of the sphere consists of layers of infinitesimally thin spherical shells, and the sphere volume is equal to\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            r\n          \n        \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        r\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{0}^{r}4\\pi r^{2}\\,dr={\\frac {4}{3}}\\pi r^{3}.}\n  \n\n\n==== Cone ====\nThe cone is a type of pyramidal shape. The fundamental equation for pyramids, one-third times base times altitude, applies to cones as well.\nHowever, using calculus, the volume of a cone is the integral of an infinite number of infinitesimally thin circular disks of thickness dx. The calculation for the volume of a cone of height h, whose base is centered at (0, 0, 0) with radius r, is as follows.\nThe radius of each circular disk is r if x = 0 and 0 if x = h, and varying linearly in between\u2014that is,\n\n  \n    \n      \n        r\n        \n          \n            \n              h\n              \u2212\n              x\n            \n            h\n          \n        \n        .\n      \n    \n    {\\displaystyle r{\\frac {h-x}{h}}.}\n  The surface area of the circular disk is then\n\n  \n    \n      \n        \u03c0\n        \n          \n            (\n            \n              r\n              \n                \n                  \n                    h\n                    \u2212\n                    x\n                  \n                  h\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\pi \\left(r{\\frac {h-x}{h}}\\right)^{2}=\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}.}\n  The volume of the cone can then be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle \\int _{0}^{h}\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}dx,}\n  and after extraction of the constants\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        (\n        h\n        \u2212\n        x\n        \n          )\n          \n            2\n          \n        \n        d\n        x\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\int _{0}^{h}(h-x)^{2}dx}\n  Integrating gives us\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          (\n          \n            \n              \n                h\n                \n                  3\n                \n              \n              3\n            \n          \n          )\n        \n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        .\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\left({\\frac {h^{3}}{3}}\\right)={\\frac {1}{3}}\\pi r^{2}h.}\n  \n\n\n==== Polyhedron ====\n\n\n== Volume in differential geometry ==\n\nIn differential geometry, a branch of mathematics, a volume form on a differentiable manifold is a differential form of top degree (i.e., whose degree is equal to the dimension of the manifold) that is nowhere equal to zero.  A manifold has a volume form if and only if it is orientable. An orientable manifold has infinitely many volume forms, since multiplying a volume form by a non-vanishing function yields another volume form. On non-orientable manifolds, one may instead define the weaker notion of a density. Integrating the volume form gives the volume of the manifold according to that form.\nAn oriented pseudo-Riemannian manifold has a natural volume form.  In local coordinates, it can be expressed as\n\n  \n    \n      \n        \u03c9\n        =\n        \n          \n            \n              |\n            \n            g\n            \n              |\n            \n          \n        \n        \n        d\n        \n          x\n          \n            1\n          \n        \n        \u2227\n        \u22ef\n        \u2227\n        d\n        \n          x\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\omega ={\\sqrt {|g|}}\\,dx^{1}\\wedge \\dots \\wedge dx^{n},}\n  where the \n  \n    \n      \n        d\n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle dx^{i}}\n   are 1-forms that form a positively oriented basis for the cotangent bundle of the manifold, and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   is the determinant of the matrix representation of the metric tensor on the manifold in terms of the same basis.\n\n\n== Volume in thermodynamics ==\n\nIn thermodynamics, the volume of a system is an important extensive parameter for describing its thermodynamic state. The specific volume, an intensive property, is the system's volume per unit of mass. Volume is a function of state and is interdependent with other thermodynamic properties such as pressure and temperature. For example, volume is related to the pressure and temperature of an ideal gas by the ideal gas law.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n Perimeters, Areas, Volumes at Wikibooks\n Volume at Wikibooks",
        "unit": "volume",
        "url": "https://en.wikipedia.org/wiki/Volume"
    },
    {
        "_id": "Lumber",
        "clean": "Lumber",
        "text": "Lumber (American English; used only in North America) or timber (used in the rest of the English speaking world) is a type of wood that has been processed into beams and planks, a stage in the process of wood production. Lumber is mainly used for structural purposes but has many other uses as well.\nThere are two main types of lumber. It may be supplied either rough-sawn, or surfaced on one or more of its faces. Besides pulpwood, rough lumber is the raw material for furniture-making and other items requiring additional cutting and shaping. It is available in many species, usually hardwoods; but it is also readily available in softwoods, such as white pine and red pine, because of their low cost.Finished lumber is supplied in standard sizes, mostly for the construction industry \u2013 primarily softwood, from coniferous species, including pine, fir and spruce (collectively spruce-pine-fir), cedar, and hemlock, but also some hardwood, for high-grade flooring. It is classified more commonly made from softwood than hardwoods, and 80% of lumber comes from softwood.\n\n\n== Terminology ==\nIn the United States milled boards of wood are referred to as lumber. However, in Britain and other Commonwealth nations, the term timber is instead used to describe sawn wood products, like floor boards.\nIn the United States and Canada, generally timber describes standing or felled trees. Specifically in Canada, lumber describes cut and surfaced wood.In the United Kingdom, the word lumber is rarely used in relation to wood and has several other meanings, including unused or unwanted items. Referring to wood, Timber is almost universally used instead.\n\n\n=== Remanufactured lumber ===\n\nRemanufactured lumber is the result of secondary or tertiary processing/cutting of previously milled lumber. Specifically, it is lumber cut for industrial or wood-packaging use. Lumber is cut by ripsaw or resaw to create dimensions that are not usually processed by a primary sawmill.\nResawing is the splitting of 1-inch through 12-inch hardwood or softwood lumber into two or more thinner pieces of full-length boards. For example, splitting a ten-foot 2\u00d74 into two ten-foot 1\u00d74s is considered resawing.\n\n\n=== Plastic lumber ===\n\nStructural lumber may also be produced from recycled plastic and new plastic stock. Its introduction has been strongly opposed by the forestry industry. Blending fiberglass in plastic lumber enhances its strength, durability, and fire resistance. Plastic fiberglass structural lumber can have a \"class 1 flame spread rating of 25 or less, when tested in accordance with ASTM standard E 84,\" which means it burns slower than almost all treated wood lumber.\n\n\n== Conversion of wood logs ==\nLogs are converted into timber by being sawn, hewn, or split. Sawing with a rip saw is the most common method, because sawing allows logs of lower quality, with irregular grain and large knots, to be used and is more economical. There are various types of sawing:\n\nPlain sawn (flat sawn, through and through, bastard sawn) \u2013 A log sawn through without adjusting the position of the log and the grain runs across the width of the boards.\nQuarter sawn and rift sawn \u2013 These terms have been confused in history but generally mean lumber sawn so the annual rings are reasonably perpendicular to the sides (not edges) of the lumber.\nBoxed heart \u2013 The pith remains within the piece with some allowance for exposure.\nHeart center \u2013 the center core of a log.\nFree of heart center (FOHC) \u2013 A side-cut timber without any pith.\nFree of knots (FOK) \u2013 No knots are present.\n\n\n== Dimensional lumber ==\n\nDimensional lumber is lumber that is cut to standardized width and depth, specified in inches. Carpenters extensively use dimensional lumber in framing wooden buildings. Common sizes include 2\u00d74 (pictured) (also two-by-four and other variants, such as four-by-two in Australia, New Zealand, and the UK), 2\u00d76, and 4\u00d74. The length of a board is usually specified separately from the width and depth. It is thus possible to find 2\u00d74s that are four, eight, and twelve feet in length. In Canada and the United States, the standard lengths of lumber are 6, 8, 10, 12, 14, 16, 18, 20, 22 and 24 feet (1.83, 2.44, 3.05, 3.66, 4.27, 4.88, 5.49, 6.10, 6.71 and 7.32 meters).  For wall framing, \"stud\" or \"precut\" sizes are available, and are commonly used. For an eight-, nine-, or ten-foot ceiling height, studs are available in 92 5\u20448 inches (235 cm), 104 5\u20448 inches (266 cm), and 116 5\u20448 inches (296 cm). The term \"stud\" is used inconsistently to specify length; where the exact length matters, one must specify the length explicitly.\n\n\n=== Historical Chinese construction ===\nUnder the prescription of the Method of Construction (\u71df\u9020\u6cd5\u5f0f) issued by the Southern Song government in the early 12th century, timbers were standardized to eight cross-sectional dimensions.  Regardless of the actual dimensions of the timber, the ratio between width and height was maintained at 1:1.5.  Units are in Song Dynasty inches (3.12 cm).\n\nTimber smaller than the 8th class were called \"unclassed\" (\u7b49\u5916).  The width of a timber is referred to as one \"timber\" (\u6750), and the dimensions of other structural components were quoted in multiples of \"timber\"; thus, as the width of the actual timber varied, the dimensions of other components were easily calculated, without resorting to specific figures for each scale.  The dimensions of timbers in similar application show a gradual diminution from the Sui Dyansty (580~618) to the modern era; a 1st class timber during the Sui was reconstructed as 15\u00d710 (Sui Dynasty inches, or 2.94 cm).\n\n\n=== North American softwoods ===\nThe length of a unit of dimensional lumber is limited by the height and girth of the tree it is milled from.  In general the maximum length is 24 ft (7.32 m). Engineered wood products, manufactured by binding the strands, particles, fibers, or veneers of wood, together with adhesives, to form composite materials, offer more flexibility and greater structural strength than typical wood building materials.Pre-cut studs save a framer much time, because they are pre-cut by the manufacturer for use in 8-, 9-, and 10-ft (2.44, 2.74 and 3.05 m) ceiling applications, which means the manufacturer has removed a few inches or centimetres of the piece to allow for the sill plate and the double top plate with no additional sizing necessary.\nIn the Americas, two-bys (2\u00d74s, 2\u00d76s, 2\u00d78s, 2\u00d710s, and 2\u00d712s), named for traditional board thickness in inches, along with the 4\u00d74 (89 mm \u00d7 89 mm), are common lumber sizes used in modern construction. They are the basic building blocks for such common structures as balloon-frame or platform-frame housing. Dimensional lumber made from softwood is typically used for construction, while hardwood boards are more commonly used for making cabinets or furniture.\nLumber's nominal dimensions are larger than the actual standard dimensions of finished lumber.  Historically, the nominal dimensions were the size of the green (not dried), rough (unfinished) boards that eventually became smaller finished lumber through drying and planing (to smooth the wood).  Today, the standards specify the final finished dimensions and the mill cuts the logs to whatever size it needs to achieve those final dimensions.  Typically, that rough cut is smaller than the nominal dimensions because modern technology makes it possible and it uses the logs more efficiently.  For example, a \"2\u00d74\" board historically started out as a green, rough board actually 2 by 4 inches (51 mm \u00d7 102 mm).  After drying and planing, it would be smaller, by a nonstandard amount.  Today, a \"2\u00d74\" board starts out as something smaller than 2 inches by 4 inches and not specified by standards, and after drying and planing is reliably 1 1\u20442 by 3 1\u20442 inches (38 mm \u00d7 89 mm).\n\nEarly standards called for green rough lumber to be of full nominal dimension when dry. However, the dimensions have diminished over time.  In 1910, a typical finished 1-inch (25 mm) board was 13\u204416 in (21 mm).  In 1928, that was reduced by 4%, and yet again by 4% in 1956.  In 1961, at a meeting in Scottsdale, Arizona, the Committee on Grade Simplification and Standardization agreed to what is now the current U.S. standard: in part, the dressed size of a 1-inch (nominal) board was fixed at \u200b3\u20444 inch; while the dressed size of 2 inch (nominal) lumber was reduced from \u200b1 5\u20448 inch to the current \u200b1 1\u20442 inch.Dimensional lumber is available in green, unfinished state, and for that kind of lumber, the nominal dimensions are the actual dimensions.\n\n\n=== Grades and standards ===\n\nIndividual pieces of lumber exhibit a wide range in quality and appearance with respect to knots, slope of grain, shakes and other natural characteristics. Therefore, they vary considerably in strength, utility, and value.\nThe move to set national standards for lumber in the United States began with publication of the American Lumber Standard in 1924, which set specifications for lumber dimensions, grade, and moisture content; it also developed  inspection and accreditation programs.  These standards have changed over the years to meet the changing needs of manufacturers and distributors, with the goal of keeping lumber competitive with other construction products. Current standards are set by the American Lumber Standard Committee, appointed by the U.S. Secretary of Commerce.Design values for most species and grades of visually graded structural products are determined in accordance with ASTM standards, which consider the effect of strength reducing characteristics, load duration, safety and other influencing factors. The applicable standards are based on results of tests conducted in cooperation with the USDA Forest Products Laboratory. Design Values for Wood Construction, which is a supplement to the ANSI/AF&PA National Design Specification\u00ae for Wood Construction, provides these lumber design values, which are recognized by the model building codes.Canada has grading rules that maintain a standard among mills manufacturing similar woods to assure customers of uniform quality. Grades standardize the quality of lumber at different levels and are based on moisture content, size, and manufacture at the time of grading, shipping, and unloading by the buyer. The National Lumber Grades Authority (NLGA) is responsible for writing, interpreting and maintaining Canadian lumber grading rules and standards. The Canadian Lumber Standards Accreditation Board (CLSAB) monitors the quality of Canada's lumber grading and identification system.\nAttempts to maintain lumber quality over time have been challenged by historical changes in the timber resources of the United States \u2013 from the slow-growing virgin forests common over a century ago to the fast-growing plantations now common in today's commercial forests.  Resulting declines in lumber quality have been of concern to both the lumber industry and consumers and have caused increased use of alternative construction products.Machine stress-rated and machine-evaluated lumber is readily available for end-uses where high strength is critical, such as trusses, rafters, laminating stock, I-beams and web joints. Machine grading measures a characteristic such as stiffness or density that correlates with the structural properties of interest, such as bending strength. The result is a more precise understanding of the strength of each piece of lumber than is possible with visually graded lumber, which allows designers to use full-design strength and avoid overbuilding.In Europe, strength grading of rectangular sawn timber (both softwood and hardwood) is done according to EN-14081  and commonly sorted into classes defined by EN-338. For softwoods the common classes are (in increasing strength) C16, C18, C24 and C30.  There are also classes specifically for hardwoods and those in most common use (in increasing strength) are D24, D30, D40, D50, D60 and D70. For these classes, the number refers to the required 5th percentile bending strength in Newtons per square millimetre. There are other strength classes, including T-classes based on tension intended for use in glulam.\n\nC14, used for scaffolding and formwork\nC16 and C24, general construction\nC30, prefab roof trusses and where design requires somewhat stronger joists than C24 can offer. TR26 is also a common trussed rafter strength class in long standing use in the UK.\nC40, usually seen in glulamGrading rules for African and South American sawn timber have been developed by ATIBT according to the rules of the Sciages Aviv\u00e9s Tropicaux Africains (SATA) and is based on clear cuttings \u2013 established by the percentage of the clear surface.\n\n\n=== North American hardwoods ===\nIn North America, market practices for dimensional lumber made from hardwoods varies significantly from the regularized standardized 'dimension lumber' sizes used for sales and specification of softwoods \u2013 hardwood boards are often sold totally rough cut, or machine planed only on the two (broader) face sides. When Hardwood Boards are also supplied with planed faces, it is usually both by random widths of a specified thickness (normally matching milling of softwood dimensional lumbers) and somewhat random lengths. But besides those older (traditional and normal) situations, in recent years some product lines have been widened to also market boards in standard stock sizes; these usually retail in big-box stores and using only a relatively small set of specified lengths; in all cases hardwoods are sold to the consumer by the board-foot (144 cubic inches or 2,360 cubic centimetres), whereas that measure is not used for softwoods at the retailer (to the cognizance of the buyer).\nAlso in North America, hardwood lumber is commonly sold in a \"quarter\" system, when referring to thickness; 4/4 (four quarter) refers to a 1-inch-thick (25 mm) board, 8/4 (eight quarter) is a 2-inch-thick (51 mm) board, etc. This \"quarter\" system is rarely used for softwood lumber; although softwood decking is sometimes sold as 5/4, even though it is actually one-inch thick (from milling 1/8th inch off each side in a motorized planing step of production).\nThe \"quarter\" system of reference is a traditional (cultural) North American lumber industry nomenclature used specifically to indicate the thickness of rough sawn hardwood lumber.\nThe following paragraph is exactly backwards from North American cultural practices where finished retail and rough lumber share the same terminology, as is discussed in the paragraph after about 'architects, designers, and builders':\nIn rough sawn lumber it immediately clarifies that the lumber is not yet milled, avoiding confusion with milled dimension lumber which is measured as actual thickness after machining. Examples \u2013 3/4\", 19mm, or 1x.\nIn recent years architects, designers, and builders have begun to use the \"quarter\" system in specifications as a vogue of insider knowledge, though the materials being specified are finished lumber, thus conflating  the separate systems and causing confusion.\nHardwoods cut for furniture are cut in the fall and winter, after the sap has stopped running in the trees. If hardwoods are cut in the spring or summer the sap ruins the natural color of the timber and decreases the value of the timber for furniture.\n\n\n=== Engineered lumber ===\n\nEngineered lumber is lumber created by a manufacturer and designed for a certain structural purpose. The main categories of engineered lumber are:\nLaminated veneer lumber (LVL) \u2013 LVL comes in \u200b1 3\u20444 inch thicknesses with depths such as \u200b9 1\u20442, \u200b11 7\u20448, 14, 16, 18, and 24 inches, and are often doubled or tripled up. They function as beams to provide support over large spans, such as removed support walls and garage door openings, places where dimensional lumber is insufficient, and also in areas where a heavy load is bearing from a floor, wall or roof above on a somewhat short span where dimensional lumber is  impractical. This type of lumber is compromised if it is altered by holes or notches anywhere within the span or at the ends, but nails can be driven into it wherever necessary to anchor the beam or to add hangers for I-joists or dimensional lumber joists that terminate at an LVL beam.\nWooden I-joists \u2013 sometimes called \"TJI\", \"Trus Joists\" or \"BCI\", all of which are brands of wooden I-joists, they are used for floor joists on upper floors and also in first floor conventional foundation construction on piers as opposed to slab floor construction. They are engineered for long spans and are doubled up in places where a wall will be aligned over them, and sometimes tripled where heavy roof-loaded support walls are placed above them. They consist of a top and bottom chord or flange made from dimensional lumber with a webbing in-between made from oriented strand board (OSB) (or, latterly, steel mesh forms which allow passage of services without cutting). The webbing can be removed up to certain sizes or shapes according to the manufacturer's or engineer's specifications, but for small holes, wooden I-joists come with \"knockouts\", which are perforated, pre-cut areas where holes can be made easily, typically without engineering approval. When large holes are needed, they can typically be made in the webbing only and only in the center third of the span; the top and bottom chords lose their integrity if cut. Sizes and shapes of the hole, and typically the placing of a hole itself, must be approved by an engineer prior to the cutting of the hole and in many areas, a sheet showing the calculations made by the engineer must be provided to the building inspection authorities before the hole will be approved. Some I-joists are made with W-style webbing like a truss to eliminate cutting and to allow ductwork to pass through.\nFinger-jointed lumber \u2013 solid dimensional lumber lengths typically are limited to lengths of 22 to 24 feet, but can be made longer by the technique of \"finger-jointing\" by using small solid pieces, usually 18 to 24 inches long, and joining them together using finger joints and glue to produce lengths that can be up to 36 feet long in 2\u00d76 size. Finger-jointing also is predominant in precut wall studs. It is also an affordable alternative for non-structural hardwood that will be painted (staining would leave the finger-joints visible). Care is taken during construction to avoid nailing directly into a glued joint as stud breakage can occur.\nGlulam beams \u2013 created from 2\u00d74 or 2\u00d76 stock by gluing the faces together to create beams such as 4\u00d712 or 6\u00d716. As such, a beam acts as one larger piece of lumber \u2013 thus eliminating the need to harvest larger, older trees for the same size beam.\nManufactured trusses \u2013 trusses are used in home construction as a pre-fabricated replacement for roof rafters and ceiling joists (stick-framing). It is seen as an easier installation and a better solution for supporting roofs than the use of dimensional lumber's struts and purlins as bracing. In the southern U.S. and elsewhere, stick-framing with dimensional lumber roof support is still predominant. The main drawbacks of trusses are reduced attic space, time required for engineering and ordering, and a cost higher than the dimensional lumber needed if the same project were conventionally framed. The advantages are significantly reduced labor costs (installation is faster than conventional framing), consistency, and overall schedule savings.\n\n\n=== Various pieces and cuts ===\n\nSquare and rectangular forms: Plank, slat, batten, board, lath, strapping (typically \u200b3\u20444 in \u00d7 \u200b1 1\u20442 in), cant (A partially sawn log such as sawn on two sides or squared to a large size and later resawn into lumber. A flitch is a type of cant with wane on one or both sides). Various pieces are also known by their uses such as post, beam, (girt), stud, rafter, joist, sill plate, wall plate.\nRod forms: pole, (dowel), stick (staff, baton)\n\n\n=== Timber piles ===\nIn the United States, pilings are mainly cut from southern yellow pines and Douglas firs. Treated pilings are available in Chromated copper arsenate retentions of 0.60, 0.80 and 2.50 pounds per cubic foot (9.6, 12.8 and 40.0 kg/m3) if treatment is required.\n\n\n== Defects in lumber ==\nDefects occurring in lumber are grouped into the following four divisions:\n\n\n=== Conversion ===\nDuring the process of converting timber to commercial form the following defects may occur:\n\nChip mark: this defect is indicated by the marks or signs placed by chips on the finished surface of timber\nDiagonal grain: improper sawing of timber\nTorn grain: when a small depression is made on the finished surface due to falling of some tool\nWane: presence of original rounded surface in the finished product\n\n\n=== Defects due to fungi and animals ===\nFungi attack timber when these conditions are all present:\n\nThe timber moisture content is above 25% on a dry-weight basis\nThe environment is sufficiently warm\nOxygen (O2) is presentWood with less than 25% moisture (dry weight basis) can remain free of decay for centuries. Similarly, wood submerged in water may not be attacked by fungi if the amount of oxygen is inadequate.\nFungi timber defects:\n\nBlue stain\nBrown rot\nDry rot\nHeart rot\nSap stain\nWet rot\nWhite rotFollowing are the insects and molluscs which are usually responsible for the decay of timber:\n\nWoodboring beetles\nMarine borers (Barnea similis)\nTeredos (Teredo navalis)\nTermites\nCarpenter ants\nCarpenter bees\n\n\n=== Natural forces ===\n\nThere are two main natural forces responsible for causing defects in timber: abnormal growth and rupture of tissues. Rupture of tissue includes cracks or splits in the wood called \"shakes\". \"Ring shake\", \"wind shake\", or \"ring failure\" is when the wood grain separates around the growth rings either while standing or during felling. Shakes may reduce the strength of a timber and the appearance thus reduce lumber grade and may capture moisture, promoting decay. Eastern hemlock is known for having ring shake. A \"check\" is a crack on the surface of the wood caused by the outside of a timber shrinking as it seasons. Checks may extend to the pith and follow the grain. Like shakes, checks can hold water promoting rot. A \"split\" goes all the way through a timber. Checks and splits occur more frequently at the ends of lumber because of the more rapid drying in these locations.\n\n\n=== Seasoning ===\nThe seasoning of lumber is typically either kiln- or air-dried. Defects due to seasoning are the main cause of splits, bowing and honeycombing.\n\n\n== Durability and service life ==\nUnder proper conditions, wood provides excellent, lasting performance. However, it also faces several potential threats to service life, including fungal activity and insect damage \u2013 which can be avoided in numerous ways. Section 2304.11 of the International Building Code  addresses protection against decay and termites. This section provides requirements for non-residential construction applications, such as wood used above ground (e.g., for framing, decks, stairs, etc.), as well as other applications.\nThere are four recommended methods to protect wood-frame structures against durability hazards and thus provide maximum service life for the building. All require proper design and construction:\n\nControlling moisture using design techniques to avoid decay\nProviding effective control of termites and other insects\nUsing durable materials such as pressure treated or naturally durable species of wood where appropriate\nProviding quality assurance during design and construction and throughout the building\u2019s service life using appropriate maintenance practices\n\n\n=== Moisture control ===\nWood is a hygroscopic material, which means it naturally absorbs and releases water to balance its internal moisture content with the surrounding environment. The moisture content of wood is measured by the weight of water as a percentage of the oven-dry weight of the wood fiber. The key to controlling decay is controlling moisture. Once decay fungi are established, the minimum moisture content for decay to propagate is 22 to 24 percent, so building experts recommend 19 percent as the maximum safe moisture content for untreated wood in service. Water by itself does not harm the wood, but rather, wood with consistently high moisture content enables fungal organisms to grow.\nThe primary objective when addressing moisture loads is to keep water from entering the building envelope in the first place, and to balance the moisture content within the building itself. Moisture control by means of accepted design and construction details is a simple and practical method of protecting a wood-frame building against decay. For applications with a high risk of staying wet, designers specify durable materials such as naturally decay-resistant species or wood that has been treated with preservatives. Cladding, shingles, sill plates and exposed timbers or glulam beams are examples of potential applications for treated wood.\n\n\n=== Controlling termites and other insects ===\nFor buildings in termite zones, basic protection practices addressed in current building codes include (but are not limited to) the following:\n\u2022 Grading the building site away from the foundation to provide proper drainage\n\u2022 Covering exposed ground in any crawl spaces with 6-mil polyethylene film and maintaining at least 12 to 18 inches (300 to 460 mm) of clearance between the ground and the bottom of framing members above (12 inches to beams or girders, 18 inches to joists or plank flooring members)\n\u2022 Supporting post columns by concrete piers so that there is at least 6 inches (150 mm) of clear space between the wood and exposed earth\n\u2022 Installing wood framing and sheathing in exterior walls at least eight inches above exposed earth; locating siding at least six inches from the finished grade\n\u2022 Where appropriate, ventilating crawl spaces according to local building codes\n\u2022 Removing building material scraps from the job site before backfilling.\n\u2022 If allowed by local regulation, treating the soil around the foundation with an approved termiticide to provide protection against subterranean termites\n\n\n=== Preservatives ===\n\nTo avoid decay and termite infestation, untreated wood is separated from the ground and other sources of moisture. These separations are required by many building codes and are considered necessary to maintain wood elements in permanent structures at a safe moisture content for decay protection. When it is not possible to separate wood from the sources of moisture, designers often rely on preservative-treated wood.Wood can be treated with a preservative that improves service life under severe conditions without altering its basic characteristics. It can also be pressure-impregnated with fire-retardant chemicals that improve its performance in a fire. One of the early treatments to \"fireproof lumber\", which retard fires, was developed in 1936 by the Protexol Corporation, in which lumber is heavily treated with salt.\nWood does not deteriorate simply because it gets wet. When wood breaks down, it is because an organism is eating it. Preservatives work by making the food source inedible to these organisms. Properly preservative-treated wood can have 5 to 10 times the service life of untreated wood. Preserved wood is used most often for railroad ties, utility poles, marine piles, decks, fences and other outdoor applications. Various treatment methods and types of chemicals are available, depending on the attributes required in the particular application and the level of protection needed.There are two basic methods of treating: with and without pressure. Non-pressure methods are the application of preservative by brushing, spraying or dipping the piece to be treated. Deeper, more thorough penetration is achieved by driving the preservative into the wood cells with pressure. Various combinations of pressure and vacuum are used to force adequate levels of chemical into the wood. Pressure-treating preservatives consist of chemicals carried in a solvent.\nChromated copper arsenate, once the most commonly used wood preservative in North America began being phased out of most residential applications in 2004. Replacing it are amine copper quat and copper azole.\nAll wood preservatives used in the United States and Canada are registered and regularly re-examined for safety by the U.S. Environmental Protection Agency and Health Canada's Pest Management and Regulatory Agency, respectively.\n\n\n== Ancient construction works ==\nTimber was used as a dominant building material in most of the ancient temples of Kerala and coastal Karnataka of India.\n\n\n== Timber framing ==\n\nTimber framing is a style of construction which uses heavier framing elements than modern stick framing, which uses dimensional lumber. The timbers originally were tree boles squared with a broadaxe or adze and joined together with joinery without nails. Modern timber framing has been growing in popularity in the United States since the 1970s.\n\n\n== Environmental effects of lumber ==\nGreen building minimizes the impact or \"environmental footprint\" of a building. Wood is a major building material that is renewable and replenishable in a continuous cycle. Studies show manufacturing wood uses less energy and results in less air and water pollution than steel and concrete. However, demand for lumber is blamed for deforestation.\n\n\n=== Residual wood ===\nThe conversion from coal to biomass power is a growing trend in the United States.The United Kingdom, Uzbekistan, Kazakhstan, Australia, Fiji, Madagascar, Mongolia, Russia, Denmark, Switzerland and Swaziland governments all support an increased role for energy derived from biomass, which are organic materials available on a renewable basis and include residues and/or byproducts of the logging, sawmilling and papermaking processes. In particular, they view it as a way to lower greenhouse gas emissions by reducing consumption of oil and gas while supporting the growth of forestry, agriculture and rural economies. Studies by the U.S. government have found the country\u2019s combined forest and agriculture land resources have the power to sustainably supply more than one-third of its current petroleum consumption.Biomass is already an important source of energy for the North American forest products industry. It is common for companies to have cogeneration facilities, also known as combined heat and power, which convert some of the biomass that results from wood and paper manufacturing to electrical and thermal energy in the form of steam. The electricity is used to, among other things, dry lumber and supply heat to the dryers used in paper-making.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nSathre, R; O'Conner, J (2010). A Synthesis of Research on Wood Products and Greenhouse Gas Impacts (PDF) (2 ed.). FPInnovations. ISBN 978-0-86488-546-3. Archived from the original (PDF) on 2012-03-21. \n\n\n== External links ==\nNational Hardwood Lumber Association (Rules for Grading Hardwood Lumber \u2013 Inspector Training School)\nTimber Development Association of NSW \u2013 Australia\nTDA: Timber Decking Association \u2013 UK\nTRADA: Timber Research And Development Association\nThe Forest Products Laboratory. U.S. main wood products research lab. Madison, WI (E)\nWCTE, World Conference on Timber Engineering\u3000June 20\u201324, 2010, Riva del Garda, Trentino, Italy\nForest Products data in Canada since 1990",
        "unit": "volume (lumber)",
        "url": "https://en.wikipedia.org/wiki/Lumber"
    },
    {
        "_id": "Statcoulomb",
        "clean": "Statcoulomb",
        "text": "The statcoulomb (statC) or franklin (Fr) or electrostatic unit of charge (esu) is the physical unit for electrical charge used in the esu-cgs (centimetre\u2013gram\u2013second system of units) and Gaussian units. It is a derived unit given by\n\n1 statC = dyn1/2 cm = cm3/2 g1/2 s\u22121.It can be converted using\n\n1 newton = 105 dyne\n1 cm = 10\u22122 mThe SI system of units uses the coulomb (C) instead. The conversion between C and statC is different in different contexts. The most common contexts are:\n\nFor electric charge:\n1 C \u2194 2997924580 statC \u2248 3.00\u00d7109 statC\n\u21d2 1 statC \u2194 ~3.33564\u00d710\u221210 C.\nFor electric flux (\u03a6D):\n1 C \u2194 4\u03c0 \u00d7 2997924580 statC \u2248 3.77\u00d71010 statC\n\u21d2 1 statC \u2194 ~2.65\u00d710\u221211 C.The symbol \"\u2194\" is used instead of \"=\" because the two sides are not necessarily interchangeable, as discussed below. The number 2997924580 is 10 times the value of the speed of light expressed in meters/second, and the conversions are exact except where indicated.  The second context implies that the SI and cgs units for an electric displacement field (D) are related by:\n\n1 C/m2 \u2194 4\u03c0 \u00d7 2997924580\u00d710\u22124 statC/cm2 \u2248 3.77\u00d7106 statC/cm2\n\u21d2 1 statC/cm2 \u2194 ~2.65\u00d710\u22127 C/m2due to the relation between the metre and the centimetre.  The coulomb is an extremely large charge rarely encountered in electrostatics, while the statcoulomb is closer to everyday charges.\n\n\n== Definition and relation to cgs base units ==\nThe statcoulomb is defined as follows: if two stationary objects each carry a charge of 1 statC and are 1 cm apart, they will electrically repel each other with a force of 1 dyne. This repulsion is governed by Coulomb's law, which in the Gaussian-cgs system states:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{r^{2}}}}\n  where F is the force, q1 and q2 are the two charges, and r is the distance between the charges. Performing dimensional analysis on Coulomb's law, the dimension of electrical charge in cgs must be [mass]1/2 [length]3/2 [time]\u22121. (This statement is not true in SI units; see below.) We can be more specific in light of the definition above: Substituting F = 1 dyn, q1 = q2 = 1 statC, and r = 1 cm, we get:\n\n1 statC = g1/2 cm3/2 s\u22121as expected.\n\n\n== Dimensional relation between Statcoulomb and Coulomb ==\n\n\n=== General incompatibility ===\nCoulomb's law in cgs-Gaussian unit system and SI are respectively:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{r^{2}}}}\n   (cgs-Gaussian)\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                \u03f5\n                \n                  0\n                \n              \n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{4\\pi \\epsilon _{0}r^{2}}}}\n   (SI)Since \u03b50, the vacuum permittivity, is not dimensionless, the coulomb (the SI unit of charge) is not dimensionally equivalent to [mass]1/2 [length]3/2 [time]\u22121, unlike the statcoulomb. In fact, it is impossible to express the coulomb in terms of mass, length, and time alone.\nConsequently, a conversion equation like \"1 C = N statC\" can be misleading: the units on the two sides are not consistent. One cannot freely switch between coulombs and statcoulombs within a formula or equation, as one would freely switch between centimeters and meters. One can, however, find a correspondence between coulombs and statcoulombs in different contexts. As described below, \"1 C corresponds to 3.00\u00d7109 statC\" when describing the charge of objects. In other words, if a physical object has a charge of 1 C, it also has a charge of 3.00\u00d7109 statC. Likewise, \"1 C corresponds to 3.77\u00d71010 statC\" when describing an electric displacement field flux.\n\n\n=== As a unit of charge ===\nThe statcoulomb is defined as follows: If two stationary objects each carry a charge of 1 statC and are 1 cm apart in vacuum, they will electrically repel each other with a force of 1 dyne. From this definition, it is straightforward to find an equivalent charge in SI coulombs. Using the SI equation\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                \u03f5\n                \n                  0\n                \n              \n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {q_{1}q_{2}}{4\\pi \\epsilon _{0}r^{2}}}}\n   (SI),and plugging in F = 1 dyn = 10\u22125 N, and r = 1 cm = 10\u22122 m, and then solving for q = q1 = q2, the result is q = (1/2997924580)C \u2248 3.34\u00d710\u221210 C. Therefore, an object with a charge of 1 statC has a charge of 3.34\u00d710\u221210 C.\nThis can also be expressed by the following conversion, which is fully dimensionally consistent, and often useful for switching between SI and cgs formulae:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n          \n            \n              \n                \n                  10\n                  \n                    9\n                  \n                \n                \n                  4\n                  \u03c0\n                  \n                    \u03f5\n                    \n                      0\n                    \n                  \n                \n              \n            \n          \n        \n        =\n        2997924580\n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\sqrt {\\tfrac {10^{9}}{4\\pi \\epsilon _{0}}}}=2997924580\\;\\mathrm {statC} }\n  \n\n\n=== As a unit of electric displacement field or flux ===\nAn electric flux (specifically, a flux of the electric displacement field D) has units of charge: statC in cgs and coulombs in SI. The conversion factor can be derived from Gauss's law:\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        =\n        4\n        \u03c0\n        Q\n      \n    \n    {\\displaystyle \\Phi _{D}=4\\pi Q}\n   (cgs)\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        =\n        Q\n      \n    \n    {\\displaystyle \\Phi _{D}=Q}\n   (SI)where\n\n  \n    \n      \n        \n          \u03a6\n          \n            D\n          \n        \n        \u2261\n        \n          \u222b\n          \n            S\n          \n        \n        \n          D\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\displaystyle \\Phi _{D}\\equiv \\int _{S}\\mathbf {D} \\cdot \\mathrm {d} \\mathbf {A} }\n  Therefore, the conversion factor for flux is 4\u03c0 different from the conversion factor for charge:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n           corresponds to \n        \n        3.7673\n        \u00d7\n        \n          10\n          \n            10\n          \n        \n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\text{ corresponds to }}3.7673\\times 10^{10}\\;\\mathrm {statC} }\n   (as unit of \u03a6D).The dimensionally consistent version is:\n\n  \n    \n      \n        1\n        \n        \n          C\n        \n        \n          \n            \n              \n                \n                  4\n                  \u03c0\n                  \n                    10\n                    \n                      9\n                    \n                  \n                \n                \n                  \u03f5\n                  \n                    0\n                  \n                \n              \n            \n          \n        \n        =\n        3.7673\n        \u00d7\n        \n          10\n          \n            10\n          \n        \n        \n        \n          s\n          t\n          a\n          t\n          C\n        \n      \n    \n    {\\displaystyle 1\\;\\mathrm {C} {\\sqrt {\\tfrac {4\\pi 10^{9}}{\\epsilon _{0}}}}=3.7673\\times 10^{10}\\;\\mathrm {statC} }\n   (as unit of \u03a6D)",
        "unit": "statcoulomb",
        "url": "https://en.wikipedia.org/wiki/Statcoulomb"
    },
    {
        "_id": "Barye",
        "clean": "Barye",
        "text": "The barye (symbol: Ba), or sometimes barad, barrie, bary, baryd, baryed, or barie,  is the centimetre\u2013gram\u2013second (CGS) unit of pressure. It is equal to 1 dyne per square centimetre.\n1 Ba = 0.1 Pa = 1\u00d710\u22126 bar = 1\u00d710\u22124 pieze = 0.1 N/m2 = 1 g\u22c5cm\u22121\u22c5s\u22122\n\n\n== See also ==\nMetre\u2013tonne\u2013second system of units\nInternational System of Units\n\n\n== References ==",
        "unit": "barye",
        "url": "https://en.wikipedia.org/wiki/Barye"
    },
    {
        "_id": "Fuel_efficiency",
        "clean": "Fuel efficiency",
        "text": "Fuel efficiency is a form of thermal efficiency, meaning the ratio from effort to result of a process that converts chemical potential energy contained in a carrier (fuel) into kinetic energy or work. Overall fuel efficiency may vary per device, which in turn may vary per application fuel efficiency, especially fossil fuel power plants or industries dealing with combustion, such as ammonia production during the Haber process.\nIn the context of transport, fuel economy is the energy efficiency of a particular vehicle,  given as a ratio of distance traveled per unit of fuel consumed. It is dependent on engine efficiency, transmission design, and tire design. Fuel economy is expressed in miles per gallon (mpg) in the USA and usually also in the UK (imperial gallon); there is sometimes confusion as the imperial gallon is 20% larger than the US gallon so that mpg values are not directly comparable. In countries using the metric system fuel economy is stated as \"fuel consumption\" in liters per 100 kilometers (L/100 km). Litres per mil are used in Norway and Sweden.\nFuel consumption is a more accurate measure of a vehicle\u2019s performance because it is a linear relationship while fuel economy leads to distortions in efficiency improvements.Weight-specific efficiency (efficiency per unit weight) may be stated for freight, and passenger-specific efficiency (vehicle efficiency per passenger).\n\n\n== Vehicle design ==\nFuel efficiency is dependent on many parameters of a vehicle, including its engine parameters, aerodynamic drag, weight, AC usage, fuel and rolling resistance. There have been advances in all areas of vehicle design in recent decades. Fuel efficiency of vehicles can also be improved by careful maintenance and driving habits.Hybrid vehicles use two or more power sources for propulsion. In many designs, a small combustion engine is combined with electric motors.  Kinetic energy which would otherwise be lost to heat during braking is recaptured as electrical power to improve fuel efficiency. Engines automatically shut off when vehicles come to a stop and start again when the accelerator is pressed preventing wasted energy from idling.\n\n\n== Fleet efficiency ==\nFleet efficiency describes the average efficiency of a population of vehicles.  Technological advances in efficiency may be offset by a change in buying habits with a propensity to heavier vehicles, which are less efficient, all else being equal.\n\n\n== Energy efficiency terminology ==\nEnergy efficiency is similar to fuel efficiency but the input is usually in units of energy such as British thermal units (BTU), megajoules (MJ), gigajoules (GJ), kilocalories (kcal), or kilowatt-hours (kW\u00b7h).  The inverse of \"energy efficiency\" is \"energy intensity\", or the amount of input energy required for a unit of output such as MJ/passenger-km (of passenger transport), BTU/ton-mile or kJ/t-km (of freight transport), GJ/t (for production of steel and other materials), BTU/(kW\u00b7h) (for electricity generation), or litres/100 km (of vehicle travel). Litres per 100 km is also a measure of \"energy intensity\" where the input is measured by the amount of fuel and the output is measured by the distance travelled.  For example: Fuel economy in automobiles.\nGiven a heat value of a fuel, it would be trivial to convert from fuel units (such as litres of gasoline) to energy units (such as MJ) and conversely. But there are two problems with comparisons made using energy units:\n\nThere are two different heat values for any hydrogen-containing fuel which can differ by several percent (see below).\nWhen comparing transportation energy costs, it must be remembered that a kilowatt hour of electric energy may require an amount of fuel with heating value of 2 or 3 kilowatt hours to produce it.\n\n\n== Energy content of fuel ==\nThe specific energy content of a fuel is the heat energy obtained when a certain quantity is burned (such as a gallon, litre, kilogram).  It is sometimes called the heat of combustion.  There exists two different values of specific heat energy for the same batch of fuel.  One is the high (or gross) heat of combustion and the other is the low (or net) heat of combustion.  The high value is obtained when, after the combustion, the water in the exhaust is in liquid form.  For the low value, the exhaust has all the water in vapor form (steam).  Since water vapor gives up heat energy when it changes from vapor to liquid, the liquid water value is larger since it includes the latent heat of vaporization of water.  The difference between the high and low values is significant, about 8 or 9%.  This accounts for most of the apparent discrepancy in the heat value of gasoline. In the U.S. (and the table) the high heat values have traditionally been used, but in many other countries, the low heat values are commonly used.\n\nNeither the gross heat of combustion nor the net heat of combustion gives the theoretical amount of mechanical energy (work) that can be obtained from the reaction. (This is given by the change in Gibbs free energy, and is around 45.7 MJ/kg for gasoline.) The actual amount of mechanical work obtained from fuel (the inverse of the specific fuel consumption) depends on the engine. A figure of 17.6 MJ/kg is possible with a gasoline engine, and 19.1 MJ/kg for a diesel engine. See Brake specific fuel consumption for more information.\n\n\n== Fuel efficiency of motor vehicles ==\n\nThe fuel efficiency of motor vehicles can be expressed in more ways:\n\nFuel consumption is the amount of fuel used per unit distance; for example, litres per 100 kilometres (L/100 km). In this case, the lower the value, the more economic a vehicle is (the less fuel it needs to travel a certain distance); this is the measure generally used across Europe (except the UK, Denmark and The Netherlands - see below), New Zealand, Australia and Canada. Also in Uruguay, Paraguay, Guatemala, Colombia, China, and Madagascar., as also in post-Soviet space.\nFuel economy is the distance travelled per unit volume of fuel used; for example, kilometres per litre (km/L) or miles per gallon (MPG), where 1 MPG (imperial) \u2248 0.354006 km/L.  In this case, the higher the value, the more economic a vehicle is (the more distance it can travel with a certain volume of fuel). This measure is popular in the USA and the UK (mpg), but in Europe, India, Japan, South Korea and Latin America the metric unit km/L is used instead.Converting from mpg or to L/100 km (or vice versa) involves the use of the reciprocal function, which is not distributive. Therefore, the average of two fuel economy numbers gives different values if those units are used, because one of the functions is reciprocal, thus not linear. If two people calculate the fuel economy average of two groups of cars with different units, the group with better fuel economy may be one or the other. However, from the point of energy used as a shared method of measure, the result shall be the same in both the cases.\nThe formula for converting to miles per US gallon (exactly 3.785411784 L) from L/100 km is \n  \n    \n      \n        \n          \n            \n              235.215\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {235.215}{x}}}\n  , where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is value of L/100 km. For miles per Imperial gallon (exactly 4.54609 L) the formula is \n  \n    \n      \n        \n          \n            \n              282.481\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {282.481}{x}}}\n  .\nIn parts of Europe, the two standard measuring cycles for \"litre/100 km\" value are \"urban\" traffic with speeds up to 50 km/h from a cold start, and then \"extra urban\" travel at various speeds up to 120 km/h which follows the urban test. A combined figure is also quoted showing the total fuel consumed in divided by the total distance traveled in both tests. A reasonably modern European supermini and many mid-size cars, including station wagons, may manage motorway travel at 5 L/100 km (47 mpg US/56 mpg imp) or 6.5 L/100 km in city traffic (36 mpg US/43 mpg imp), with carbon dioxide emissions of around 140 g/km.\nAn average North American mid-size car travels 21 mpg (US) (11 L/100 km) city, 27 mpg (US) (9 L/100 km) highway; a full-size SUV usually travels 13 mpg (US) (18 L/100 km) city and 16 mpg (US) (15 L/100 km) highway.  Pickup trucks vary considerably; whereas a 4 cylinder-engined light pickup can achieve 28 mpg (8 L/100 km), a V8 full-size pickup with extended cabin only travels 13 mpg (US) (18 L/100 km) city and 15 mpg (US) (15 L/100 km) highway.\nThe average fuel economy is higher in Europe due to the higher cost of fuel. In the UK, a gallon of gas without tax would cost US$1.97, but with taxes cost US$6.06 in 2005. The average cost in the United States was US$2.61. Consumers prefer \"muscle cars\" but choose more fuel efficient ones when gas prices increase.European-built cars are generally more fuel-efficient than US vehicles. While Europe has many higher efficiency diesel cars, European gasoline vehicles are on average also more efficient than gasoline-powered vehicles in the USA. Most European vehicles cited in the CSI study run on diesel engines, which tend to achieve greater fuel efficiency than gas engines. Selling those cars in the United States is difficult because of emission standards, notes Walter McManus, a fuel economy expert at the University of Michigan Transportation Research Institute. \"For the most part, European diesels don\u2019t meet U.S. emission standards\", McManus said in 2007. Another reason why many European models are not marketed in the United States is that labor unions object to having the big 3 import any new foreign built models regardless of fuel economy while laying off workers at home.An example of European cars' capabilities of fuel economy is the microcar Smart Fortwo cdi, which can achieve up to 3.4 l/100 km (69.2 mpg US) using a turbocharged three-cylinder 41 bhp (30 kW) Diesel engine. The Fortwo is produced by Daimler AG and is currently only sold by one company in the United States. Furthermore, the current (and to date already 10-year-old) world record in fuel economy of production cars is held by the Volkswagen Group, with special production models (labeled \"3L\") of the Volkswagen Lupo and the Audi A2, consuming as little as 3 L/100 km (94 mpg\u2011imp; 78 mpg\u2011US).Diesel engines generally achieve greater fuel efficiency than petrol (gasoline) engines. Passenger car diesel engines have energy efficiency of up to 41% but more typically 30%, and petrol engines of up to 37.3%, but more typically 20%. That is one of the reasons why diesels have better fuel efficiency than equivalent petrol cars. A common margin is 25% more miles per gallon for an efficient turbodiesel.\nFor example, the current model Skoda Octavia, using Volkswagen engines, has a combined European fuel efficiency of 41.3 mpg for the 105 bhp (78 kW) petrol engine and 52.3 mpg for the 105 bhp (78 kW) \u2014 and heavier \u2014 diesel engine. The higher compression ratio is helpful in raising the energy efficiency, but diesel fuel also contains approximately 10% more energy per unit volume than gasoline which contributes to the reduced fuel consumption for a given power output.\nIn 2002, the United States had 85,174,776 trucks, and averaged 13.5 miles per US gallon (17.4 L/100 km; 16.2 mpg\u2011imp). Large trucks, over 33,000 pounds (15,000 kg), averaged 5.7 miles per US gallon (41 L/100 km; 6.8 mpg\u2011imp).\nThe average economy of automobiles in the United States in 2002 was 22.0 miles per US gallon (10.7 L/100 km; 26.4 mpg\u2011imp). By 2010 this had increased to 23.0 miles per US gallon (10.2 L/100 km; 27.6 mpg\u2011imp). Average fuel economy in the United States gradually declined until 1973, when it reached a low of 13.4 miles per US gallon (17.6 L/100 km; 16.1 mpg\u2011imp) and gradually has increased since, as a result of higher fuel cost. A study indicates that a 10% increase in gas prices will eventually produce a 2.04% increase in fuel economy. One method by car makers to increase fuel efficiency is lightweighting in which lighter-weight materials are substituted in for improved engine performance and handling.\n\n\n== Fuel efficiency in microgravity ==\nHow fuel combusts affects how much energy is produced. The National Aeronautics and Space Administration (NASA) has investigated fuel consumption in microgravity.\nThe common distribution of a flame under normal gravity conditions depends on convection, because soot tends to rise to the top of a flame, such as in a candle, making the flame yellow. In microgravity or zero gravity, such as an environment in outer space, convection no longer occurs, and the flame becomes spherical, with a tendency to become more blue and more efficient. There are several possible explanations for this difference, of which the most likely one given is the hypothesis that the temperature is evenly distributed enough that soot is not formed and complete combustion occurs., National Aeronautics and Space Administration, April 2005. Experiments by NASA in microgravity reveal that diffusion flames in microgravity allow more soot to be completely oxidised after they are produced than diffusion flames on Earth, because of a series of mechanisms that behaved differently in microgravity when compared to normal gravity conditions.LSP-1 experiment results, National Aeronautics and Space Administration, April 2005. Premixed flames in microgravity burn at a much slower rate and more efficiently than even a candle on Earth, and last much longer.\n\n\n== Transportation ==\n\n\n=== Fuel efficiency in transportation ===\n\n\n=== Vehicle efficiency and transportation pollution ===\n\nFuel efficiency directly affects emissions causing pollution by affecting the amount of fuel used. However, it also depends on the fuel source used to drive the vehicle concerned. Cars for example, can run on a number of fuel types other than gasoline, such as natural gas, LPG or biofuel or electricity which creates various quantities of atmospheric pollution.\nA kilogram of carbon, whether contained in petrol, diesel, kerosene, or any other hydrocarbon fuel in a vehicle, leads to approximately 3.6 kg of CO2 emissions.  Due to the carbon content of gasoline, its combustion emits 2.3 kg/l (19.4 lb/US gal) of CO2; since diesel fuel is more energy dense per unit volume, diesel emits 2.6 kg/l (22.2 lb/US gal).  This figure is only the CO2 emissions of the final fuel product and does not include additional CO2 emissions created during the drilling, pumping, transportation and refining steps required to produce the fuel. Additional measures to reduce overall emission includes improvements to the efficiency of air conditioners, lights and tires.\n\n\n=== Driving technique ===\n\nMany drivers have the potential to improve their fuel efficiency significantly. These five basic fuel-efficient driving techniques can be effective. Simple things such as keeping tires properly inflated, having a vehicle well-maintained and avoiding idling can dramatically improve fuel efficiency.There is a growing community of enthusiasts known as hypermilers who develop and practice driving techniques to increase fuel efficiency and reduce consumption. Hypermilers have broken records of fuel efficiency, for example, achieving 109 miles per gallon in a Prius. In non-hybrid vehicles these techniques are also beneficial, with fuel efficiencies of up to 59 MPG in a Honda Accord or 30 MPG in an Acura MDX.\n\n\n== Advanced technology improvements to improve fuel efficiency ==\nThe most efficient machines for converting energy to rotary motion are electric motors, as used in electric vehicles. However, electricity is not a primary energy source so the efficiency of the electricity production has also to be taken into account. Currently railway trains can be powered using electricity, delivered through an additional running rail, overhead catenary system or by on-board generators used in diesel-electric locomotives as common on the US and UK rail networks. Pollution produced from centralised generation of electricity is emitted at a distant power station, rather than \"on site\". Pollution can be reduced by using more railway electrification and low carbon power for electricity. Some railways, such as the French SNCF and Swiss federal railways derive most, if not 100% of their power, from hydroelectric or nuclear power stations, therefore atmospheric pollution from their rail networks is very low. This was reflected in a study by AEA Technology between a Eurostar train and airline journeys between London and Paris, which showed the trains on average emitting 10 times less CO2, per passenger, than planes, helped in part by French nuclear generation.\n\n\n=== Hydrogen Fuel Cells ===\nIn the future, hydrogen cars may be commercially available. Toyota is test marketing hydrogen fuel cell powered vehicles in southern California where a series of hydrogen fueling stations has been established. Powered either through chemical reactions in a fuel cell that create electricity to drive very efficient electrical motors or by directly burning hydrogen in a combustion engine (near identically to a natural gas vehicle, and similarly compatible with both natural gas and gasoline); these vehicles promise to have near-zero pollution from the tailpipe (exhaust pipe). Potentially the atmospheric pollution could be minimal, provided the hydrogen is made by electrolysis using electricity from non-polluting sources such as solar, wind or hydroelectricity or nuclear. Commercial hydrogen production uses fossil fuels and produces more carbon dioxide than hydrogen.\nBecause there are pollutants involved in the manufacture and destruction of a car and the production, transmission and storage of electricity and hydrogen, the use of the label \"zero pollution\" should be understood as applying only to the car's conversion of stored energy into transportation.\nIn 2004, a consortium of major auto-makers \u2014 BMW, General Motors, Honda, Toyota and Volkswagen/Audi \u2014 came up with \"Top Tier Detergent Gasoline Standard\" to gasoline brands in the US and Canada that meet their minimum standards for detergent content and do not contain metallic additives. Top Tier gasoline contains higher levels of detergent additives in order to prevent the build-up of deposits (typically, on fuel injector and intake valve) known to reduce fuel economy and engine performance.\n\n\n=== Electric Turbo Compounding (ETC) ===\nElectric Turbo Compounding (ETC) is a technology solution to the challenge of improving energy efficiency for the stationary power generation industry.\nFossil fuel based power generation is predicted to continue for decades, especially in developing economies. This is against the global need to reduce carbon emissions, of which, a high percentage is produced by the power sector worldwide.\nETC works by making gas and diesel-powered gensets (Electric Generators) work more effectively and cleaner, by recovering waste energy from the exhaust to improve power density and fuel efficiency.\n\n\n==== Advantages of using ETC ====\nHelps developing economies with unreliable or insufficient power infrastructure. \nGives independent power providers (IPPs), power rental companies and generator OEMs (original equipment manufacturers) a competitive advantage and potential increased market share.\nImproves overall efficiency of the genset, including fuel input costs and helping end-users reduce amount of fuel burned. \nTypically 4-7% less fuel consumption for both diesel and gas gensets. \nFewer carbon emissions.\nIncreased power density. \nCapability to increase power output and capacity, with improved fuel efficiency.\nETC system integration offers a step change in efficiency without increasing service or maintenance requirements.\nThe cost of generating power through waste heat recovery is substantially less than burning more fuel, even with low diesel prices.\n\n\n==== Disadvantages of using ETC ====\nUpfront costs incur an additional expense for businesses.\nThe need to update existing turbomachinery and recertification of the unit adds additional costs and can be time consuming.\nThere will be additional weight to add an ETC to a current unit.\nProcess still uses fossil fuels, thus still has a carbon footprint in a renewable age.\nThey are bespoke to each generator so the design, build and implementation can be a lengthy process.\nThere are challenges with high speed turbo generators such as high stress in the rotors, heat generation of the electrical machine and rotordynamics of the turbo generator system.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nUS Government website on fuel economy\nUK DfT comparisons on road and rail\nNASA Offers a $1.5 Million Prize for a Fast and Fuel-Efficient Aircraft\nCar Fuel Consumption Official Figures\nSpritmonitor.de \"the most fuel efficient cars\" - Database of thousands of (mostly German) car owners' actual fuel consumption figures (cf. Spritmonitor)\nSearchable fuel economy data from the EPA - United States Environmental Protection Agency\npenghemat bbm - Alat penghemat bbm\nNy Times: A Road Test of Alternative Fuel Visions",
        "unit": "fuel consumption",
        "url": "https://en.wikipedia.org/wiki/Fuel_efficiency"
    },
    {
        "_id": "Radian",
        "clean": "Radian",
        "text": "The radian (SI symbol rad) is the SI unit for measuring angles, and is the standard unit of angular measure used in many areas of mathematics.  The length of an arc of a unit circle is numerically equal to the measurement in radians of the angle that it subtends; one radian is just under 57.3 degrees (expansion at \u200aA072097). The unit was formerly an SI supplementary unit, but this category was abolished in 1995 and the radian is now considered an SI derived unit.Separately, the SI unit of solid angle measurement is the steradian.\nThe radian is most commonly represented by the symbol rad. An alternative symbol is c, the superscript letter c (for \"circular measure\"), the letter r, or a superscript R, but these symbols are infrequently used as it can be easily mistaken for a degree symbol (\u00b0) or a radius (r). So, for example, a value of 1.2 radians could be written as 1.2 rad, 1.2 r, 1.2rad, 1.2c, or 1.2R.\n\n\n== Definition ==\nRadian describes the plane angle subtended by a circular arc as the length of the arc divided by the radius of the arc. One radian is the angle subtended at the center of a circle by an arc that is equal in length to the radius of the circle. More generally, the magnitude in radians of such a subtended angle is equal to the ratio of the arc length to the radius of the circle; that is, \u03b8 = s / r, where \u03b8 is the subtended angle in radians, s is arc length, and r is radius. Conversely, the length of the enclosed arc is equal to the radius multiplied by the magnitude of the angle in radians; that is, s = r\u03b8.\nAs the ratio of two lengths, the radian is a \"pure number\" that needs no unit symbol, and in mathematical writing the symbol \"rad\" is almost always omitted. When quantifying an angle in the absence of any symbol, radians are assumed, and when degrees are meant the symbol \u00b0 is used.\n\nIt follows that the magnitude in radians of one complete revolution (360 degrees) is the length of the entire circumference divided by the radius, or 2\u03c0r / r, or 2\u03c0. Thus 2\u03c0 radians is equal to 360 degrees, meaning that one radian is equal to 180/\u03c0 degrees.\nThe relation \n  \n    \n      \n        2\n        \u03c0\n        \n           rad\n        \n        =\n        \n          360\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 2\\pi {\\text{ rad}}=360^{\\circ }}\n   can be derived using the formula for arc length. Taking the formula for arc length, or \n  \n    \n      \n        \n          \u2113\n          \n            a\n            r\n            c\n          \n        \n        =\n        2\n        \u03c0\n        r\n        \n          (\n          \n            \n              \u03b8\n              \n                360\n                \n                  \u2218\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\ell _{arc}=2\\pi r\\left({\\frac {\\theta }{360^{\\circ }}}\\right)}\n  . Assuming a unit circle; the radius is therefore one. Knowing that the definition of radian is the measure of an angle that subtends an arc of a length equal to the radius of the circle, we know that \n  \n    \n      \n        1\n        =\n        2\n        \u03c0\n        \n          (\n          \n            \n              \n                1\n                \n                   rad\n                \n              \n              \n                360\n                \n                  \u2218\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle 1=2\\pi \\left({\\frac {1{\\text{ rad}}}{360^{\\circ }}}\\right)}\n  . This can be further simplified to \n  \n    \n      \n        1\n        =\n        \n          \n            \n              2\n              \u03c0\n              \n                 rad\n              \n            \n            \n              360\n              \n                \u2218\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 1={\\frac {2\\pi {\\text{ rad}}}{360^{\\circ }}}}\n  . Multiplying both sides by \n  \n    \n      \n        \n          360\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 360^{\\circ }}\n   gives \n  \n    \n      \n        \n          360\n          \n            \u2218\n          \n        \n        =\n        2\n        \u03c0\n        \n           rad\n        \n      \n    \n    {\\displaystyle 360^{\\circ }=2\\pi {\\text{ rad}}}\n  .\n\n\n== History ==\nThe concept of radian measure, as opposed to the degree of an angle, is normally credited to Roger Cotes in 1714. He described the radian in everything but name, and he recognized its naturalness as a unit of angular measure. The idea of measuring angles by the length of the arc was already in use by other mathematicians. For example, al-Kashi (c. 1400) used so-called diameter parts as units where one diameter part was 1/60 radian and they also used sexagesimal subunits of the diameter part.The term radian first appeared in print on 5 June 1873, in examination questions set by James Thomson (brother of Lord Kelvin) at Queen's College, Belfast. He had used the term as early as 1871, while in 1869, Thomas Muir, then of the University of St Andrews, vacillated between the terms rad, radial, and radian. In 1874, after a consultation with James Thomson, Muir adopted radian.\n\n\n== Conversions ==\n\n\n=== Conversion between radians and degrees ===\nAs stated, one radian is equal to 180/\u03c0 degrees. Thus, to convert from radians to degrees, multiply by 180/\u03c0.\n\n  \n    \n      \n        \n          angle in degrees\n        \n        =\n        \n          angle in radians\n        \n        \u22c5\n        \n          \n            \n              180\n              \n                \u2218\n              \n            \n            \u03c0\n          \n        \n      \n    \n    {\\displaystyle {\\text{angle in degrees}}={\\text{angle in radians}}\\cdot {\\frac {180^{\\circ }}{\\pi }}}\n  For example:\n\n  \n    \n      \n        1\n        \n           rad\n        \n        =\n        1\n        \u22c5\n        \n          \n            \n              180\n              \n                \u2218\n              \n            \n            \u03c0\n          \n        \n        \u2248\n        \n          57.2958\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 1{\\text{ rad}}=1\\cdot {\\frac {180^{\\circ }}{\\pi }}\\approx 57.2958^{\\circ }}\n  \n\n  \n    \n      \n        2.5\n        \n           rad\n        \n        =\n        2.5\n        \u22c5\n        \n          \n            \n              180\n              \n                \u2218\n              \n            \n            \u03c0\n          \n        \n        \u2248\n        \n          143.2394\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 2.5{\\text{ rad}}=2.5\\cdot {\\frac {180^{\\circ }}{\\pi }}\\approx 143.2394^{\\circ }}\n  \n\n  \n    \n      \n        \n          \n            \u03c0\n            3\n          \n        \n        \n           rad\n        \n        =\n        \n          \n            \u03c0\n            3\n          \n        \n        \u22c5\n        \n          \n            \n              180\n              \n                \u2218\n              \n            \n            \u03c0\n          \n        \n        =\n        \n          60\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\pi }{3}}{\\text{ rad}}={\\frac {\\pi }{3}}\\cdot {\\frac {180^{\\circ }}{\\pi }}=60^{\\circ }}\n  Conversely, to convert from degrees to radians, multiply by \u03c0/180.\n\n  \n    \n      \n        \n          angle in radians\n        \n        =\n        \n          angle in degrees\n        \n        \u22c5\n        \n          \n            \u03c0\n            \n              180\n              \n                \u2218\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{angle in radians}}={\\text{angle in degrees}}\\cdot {\\frac {\\pi }{180^{\\circ }}}}\n  For example:\n\n  \n    \n      \n        \n          1\n          \n            \u2218\n          \n        \n        =\n        1\n        \u22c5\n        \n          \n            \u03c0\n            \n              180\n              \n                \u2218\n              \n            \n          \n        \n        \u2248\n        0.0175\n        \n           rad\n        \n      \n    \n    {\\displaystyle 1^{\\circ }=1\\cdot {\\frac {\\pi }{180^{\\circ }}}\\approx 0.0175{\\text{ rad}}}\n  \n  \n    \n      \n        \n          23\n          \n            \u2218\n          \n        \n        =\n        23\n        \u22c5\n        \n          \n            \u03c0\n            \n              180\n              \n                \u2218\n              \n            \n          \n        \n        \u2248\n        0.4014\n        \n           rad\n        \n      \n    \n    {\\displaystyle 23^{\\circ }=23\\cdot {\\frac {\\pi }{180^{\\circ }}}\\approx 0.4014{\\text{ rad}}}\n  \nRadians can be converted to turns (complete revolutions) by dividing the number of radians by 2\u03c0.\n\n\n==== Radian to degree conversion derivation ====\nThe length of circumference of a circle is given by \n  \n    \n      \n        2\n        \u03c0\n        r\n      \n    \n    {\\displaystyle 2\\pi r}\n  , where \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the radius of the circle.\nSo the following equivalent relation is true:\n\n  \n    \n      \n        \n          360\n          \n            \u2218\n          \n        \n        \n        \u27fa\n        \n        2\n        \u03c0\n        r\n      \n    \n    {\\displaystyle 360^{\\circ }\\iff 2\\pi r}\n   [Since a \n  \n    \n      \n        \n          360\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 360^{\\circ }}\n   sweep is needed to draw a full circle]\nBy the definition of radian, a full circle represents:\n\n  \n    \n      \n        \n          \n            \n              2\n              \u03c0\n              r\n            \n            r\n          \n        \n        \n           rad\n        \n      \n    \n    {\\displaystyle {\\frac {2\\pi r}{r}}{\\text{ rad}}}\n  \n  \n    \n      \n        =\n        2\n        \u03c0\n        \n           rad\n        \n      \n    \n    {\\displaystyle =2\\pi {\\text{ rad}}}\n  Combining both the above relations:\n\n  \n    \n      \n        2\n        \u03c0\n        \n           rad\n        \n        =\n        \n          360\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 2\\pi {\\text{ rad}}=360^{\\circ }}\n  \n  \n    \n      \n        \u21db\n        1\n        \n           rad\n        \n        =\n        \n          \n            \n              360\n              \n                \u2218\n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n      \n    \n    {\\displaystyle \\Rrightarrow 1{\\text{ rad}}={\\frac {360^{\\circ }}{2\\pi }}}\n  \n  \n    \n      \n        \u21db\n        1\n        \n           rad\n        \n        =\n        \n          \n            \n              180\n              \n                \u2218\n              \n            \n            \u03c0\n          \n        \n      \n    \n    {\\displaystyle \\Rrightarrow 1{\\text{ rad}}={\\frac {180^{\\circ }}{\\pi }}}\n  \n\n\n=== Conversion between radians and gradians ===\n\n  \n    \n      \n        2\n        \u03c0\n      \n    \n    {\\displaystyle 2\\pi }\n   radians equals one turn, which is by definition 400 gradians (400 gons or 400g). So, to convert from radians to gradians multiply by \n  \n    \n      \n        200\n        \n          /\n        \n        \u03c0\n      \n    \n    {\\displaystyle 200/\\pi }\n  , and to convert from gradians to radians multiply by \n  \n    \n      \n        \u03c0\n        \n          /\n        \n        200\n      \n    \n    {\\displaystyle \\pi /200}\n  . For example,\n\n  \n    \n      \n        1.2\n        \n           rad\n        \n        =\n        1.2\n        \u22c5\n        \n          \n            \n              200\n              \n                g\n              \n            \n            \u03c0\n          \n        \n        \u2248\n        \n          76.3944\n          \n            g\n          \n        \n      \n    \n    {\\displaystyle 1.2{\\text{ rad}}=1.2\\cdot {\\frac {200^{\\text{g}}}{\\pi }}\\approx 76.3944^{\\text{g}}}\n  \n\n  \n    \n      \n        \n          50\n          \n            g\n          \n        \n        =\n        50\n        \u22c5\n        \n          \n            \u03c0\n            \n              200\n              \n                g\n              \n            \n          \n        \n        \u2248\n        0.7854\n        \n           rad\n        \n      \n    \n    {\\displaystyle 50^{\\text{g}}=50\\cdot {\\frac {\\pi }{200^{\\text{g}}}}\\approx 0.7854{\\text{ rad}}}\n  \n\n\n== Advantages of measuring in radians ==\n\nIn calculus and most other branches of mathematics beyond practical geometry, angles are universally measured in radians. This is because radians have a mathematical \"naturalness\" that leads to a more elegant formulation of a number of important results.\nMost notably, results in analysis involving trigonometric functions are simple and elegant when the functions' arguments are expressed in radians. For example, the use of radians leads to the simple limit formula\n\n  \n    \n      \n        \n          lim\n          \n            h\n            \u2192\n            0\n          \n        \n        \n          \n            \n              sin\n              \u2061\n              h\n            \n            h\n          \n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle \\lim _{h\\rightarrow 0}{\\frac {\\sin h}{h}}=1,}\n  which is the basis of many other identities in mathematics, including\n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              x\n            \n          \n        \n        sin\n        \u2061\n        x\n        =\n        cos\n        \u2061\n        x\n      \n    \n    {\\displaystyle {\\frac {d}{dx}}\\sin x=\\cos x}\n  \n\n  \n    \n      \n        \n          \n            \n              d\n              \n                2\n              \n            \n            \n              d\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        sin\n        \u2061\n        x\n        =\n        \u2212\n        sin\n        \u2061\n        x\n        .\n      \n    \n    {\\displaystyle {\\frac {d^{2}}{dx^{2}}}\\sin x=-\\sin x.}\n  Because of these and other properties, the trigonometric functions appear in solutions to mathematical problems that are not obviously related to the functions' geometrical meanings (for example, the solutions to the differential equation \n  \n    \n      \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              y\n            \n            \n              d\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \u2212\n        y\n      \n    \n    {\\displaystyle {\\frac {d^{2}y}{dx^{2}}}=-y}\n  , the evaluation of the integral \n  \n    \n      \n        \u222b\n        \n          \n            \n              d\n              x\n            \n            \n              1\n              +\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\int {\\frac {dx}{1+x^{2}}}}\n  , and so on). In all such cases it is found that the arguments to the functions are most naturally written in the form that corresponds, in geometrical contexts, to the radian measurement of angles.\nThe trigonometric functions also have simple and elegant series expansions when radians are used; for example, the following Taylor series for sin x :\n\n  \n    \n      \n        sin\n        \u2061\n        x\n        =\n        x\n        \u2212\n        \n          \n            \n              x\n              \n                3\n              \n            \n            \n              3\n              !\n            \n          \n        \n        +\n        \n          \n            \n              x\n              \n                5\n              \n            \n            \n              5\n              !\n            \n          \n        \n        \u2212\n        \n          \n            \n              x\n              \n                7\n              \n            \n            \n              7\n              !\n            \n          \n        \n        +\n        \u22ef\n        .\n      \n    \n    {\\displaystyle \\sin x=x-{\\frac {x^{3}}{3!}}+{\\frac {x^{5}}{5!}}-{\\frac {x^{7}}{7!}}+\\cdots .}\n  If x were expressed in degrees then the series would contain messy factors involving powers of \u03c0/180: if x is the number of degrees, the number of radians is y = \u03c0x / 180, so\n\n  \n    \n      \n        sin\n        \u2061\n        \n          x\n          \n            \n              d\n              e\n              g\n            \n          \n        \n        =\n        sin\n        \u2061\n        \n          y\n          \n            \n              r\n              a\n              d\n            \n          \n        \n        =\n        \n          \n            \u03c0\n            180\n          \n        \n        x\n        \u2212\n        \n          \n            (\n            \n              \n                \u03c0\n                180\n              \n            \n            )\n          \n          \n            3\n          \n        \n         \n        \n          \n            \n              x\n              \n                3\n              \n            \n            \n              3\n              !\n            \n          \n        \n        +\n        \n          \n            (\n            \n              \n                \u03c0\n                180\n              \n            \n            )\n          \n          \n            5\n          \n        \n         \n        \n          \n            \n              x\n              \n                5\n              \n            \n            \n              5\n              !\n            \n          \n        \n        \u2212\n        \n          \n            (\n            \n              \n                \u03c0\n                180\n              \n            \n            )\n          \n          \n            7\n          \n        \n         \n        \n          \n            \n              x\n              \n                7\n              \n            \n            \n              7\n              !\n            \n          \n        \n        +\n        \u22ef\n        .\n      \n    \n    {\\displaystyle \\sin x_{\\mathrm {deg} }=\\sin y_{\\mathrm {rad} }={\\frac {\\pi }{180}}x-\\left({\\frac {\\pi }{180}}\\right)^{3}\\ {\\frac {x^{3}}{3!}}+\\left({\\frac {\\pi }{180}}\\right)^{5}\\ {\\frac {x^{5}}{5!}}-\\left({\\frac {\\pi }{180}}\\right)^{7}\\ {\\frac {x^{7}}{7!}}+\\cdots .}\n  Mathematically important relationships between the sine and cosine functions and the exponential function (see, for example, Euler's formula) are, again, elegant when the functions' arguments are in radians and messy otherwise.\n\n\n== Dimensional analysis ==\nAlthough the radian is a unit of measure, it is a dimensionless quantity. This can be seen from the definition given earlier: the angle subtended at the centre of a circle, measured in radians, is equal to the ratio of the length of the enclosed arc to the length of the circle's radius. Since the units of measurement cancel, this ratio is dimensionless.\nAlthough polar and spherical coordinates use radians to describe coordinates in two and three dimensions, the unit is derived from the radius coordinate, so the angle measure is still dimensionless.\n\n\n== Use in physics ==\nThe radian is widely used in physics when angular measurements are required. For example, angular velocity is typically measured in radians per second (rad/s). One revolution per second is equal to 2\u03c0 radians per second.\nSimilarly, angular acceleration is often measured in radians per second per second (rad/s2).\nFor the purpose of dimensional analysis, the units of angular velocity and angular acceleration are s\u22121 and s\u22122 respectively.\nLikewise, the phase difference of two waves can also be measured in radians. For example, if the phase difference of two waves is (k\u22c52\u03c0) radians, where k is an integer, they are considered in phase, whilst if the phase difference of two waves is (k\u22c52\u03c0 + \u03c0), where k is an integer, they are considered in antiphase.\n\n\n== SI multiples ==\nMetric prefixes have limited use with radians, and none in mathematics. A milliradian (mrad) is a thousandth of a radian and a microradian (\u03bcrad) is a millionth of a radian, i.e. 1 rad = 103 mrad = 106 \u03bcrad.\nThere are 2\u03c0 \u00d7 1000 milliradians (\u2248 6283.185 mrad) in a circle. So a trigonometric milliradian is just under 1/6283 of a circle. This \u201creal\u201d trigonometric unit of angular measurement of a circle is in use by telescopic sight manufacturers using (stadiametric) rangefinding in reticles. The divergence of laser beams is also usually measured in milliradians.\nAn approximation of the trigonometric milliradian (0.001 rad) is used by NATO and other military organizations in gunnery and targeting. Each angular mil represents 1/6400 of a circle and is 15/8% or 1.875% smaller than the trigonometric milliradian. For the small angles typically found in targeting work, the convenience of using the number 6400 in calculation outweighs the small mathematical errors it introduces. In the past, other gunnery systems have used different approximations to 1/2000\u03c0; for example Sweden used the 1/6300 streck and the USSR used 1/6000. Being based on the milliradian, the NATO mil subtends roughly 1 m at a range of 1000 m (at such small angles, the curvature is negligible).\nSmaller units like microradians (\u03bcrad) and nanoradians (nrad) are used in astronomy, and can also be used to measure the beam quality of lasers with ultra-low divergence. More common is arc second, which is \u03c0/648,000 rad (around 4.8481 microradians). Similarly, the prefixes smaller than milli- are potentially useful in measuring extremely small angles.\n\n\n== See also ==\nAngular frequency\nMilliradian\nGradian (also known as gon)\nHarmonic analysis\nSteradian \u2013 the \"square radian\"\nTrigonometry\n\n\n== Notes and references ==\n\n\n== External links ==\nRadian at MathWorld",
        "unit": "radian",
        "url": "https://en.wikipedia.org/wiki/Radian"
    },
    {
        "_id": "Japanese_yen",
        "clean": "Japanese yen",
        "text": "The yen (Japanese: \u5186, Hepburn: en, symbol: \u00a5; code: JPY; also abbreviated as JP\u00a5) is the official currency of Japan. It is the third most traded currency in the foreign exchange market after the United States dollar and the euro. It is also widely used as a reserve currency after the U.S. dollar, the euro, and the pound sterling.\nThe concept of the yen was a component of the Meiji government's modernization program of Japan's economy; which postulated the pursuit of a uniform currency throughout the country modeled after the European decimal currency system.\nBefore the Meiji Restoration, Japan's feudal fiefs all issued their own money, hansatsu, in an array of incompatible denominations. The New Currency Act of 1871 did away with these and established the yen, which was defined as 1.5 g (0.048 troy ounces) of gold, or 24.26 g (0.780 troy ounces) of silver, as the new decimal currency. The former han (fiefs) became prefectures and their mints private chartered banks, which initially retained the right to print money. To bring an end to this situation the Bank of Japan was founded in 1882 and given a monopoly on controlling the money supply.Following World War II the yen lost much of its prewar value. To stabilize the Japanese economy the exchange rate of the yen was fixed at \u00a5360 per $1 as part of the Bretton Woods system. When that system was abandoned in 1971, the yen became undervalued and was allowed to float. The yen had appreciated to a peak of \u00a5271 per $1 in 1973, then underwent periods of depreciation and appreciation due to the 1973 oil crisis, arriving at a value of \u00a5227 per $1 by 1980.\nSince 1973, the Japanese government has maintained a policy of currency intervention, and the yen is therefore under a \"dirty float\" regime. This intervention continues to this day. The Japanese government focuses on a competitive export market, and tries to ensure a low yen value through a trade surplus. The Plaza Accord of 1985 temporarily changed this situation from its average of \u00a5239 per US$1 in 1985 to \u00a5128 in 1988 and led to a peak value of \u00a580 against the U.S. dollar in 1995, effectively increasing the value of Japan\u2019s GDP to almost that of the United States. Since that time, however, the yen has greatly decreased in value. The Bank of Japan maintains a policy of zero to near-zero interest rates and the Japanese government has an extreme anti-inflation policy.\n\n\n== Pronunciation and etymology ==\nYen derives from the Japanese word \u5713 (\u3048\u3093, en, [e\u0274]; lit. \"round\"), which is cognate with the Chinese yuan, North Korean won and South Korean won. Originally, the Chinese had traded silver in mass called sycees and when Spanish and Mexican silver coins arrived, the Chinese called them \"silver rounds\" (Chinese: \u9280\u5713) for their circular shapes. The coins and the name also appeared in Japan. While the Chinese eventually replaced \u5713 with \u5143, the Japanese continued to use the same word, which was given the shinjitai form \u5186 in reforms at the end of World War II.\nThe spelling and pronunciation \"yen\" is standard in English. This is because mainly English speakers who visited Japan at the end of the Edo period to the early Meiji period spelled words this way. \u3091\u3093 /wen/ in historical kana orthography. In the 16th century, Japanese /e/ (\u3048) and /we/ (\u3091) both had been pronounced [je] and Portuguese missionaries had spelled them \"ye\". Some time thereafter, by the middle of the 18th century, /e/ and /we/ came to be pronounced [e] as in modern Japanese, although some regions retain the [je] pronunciation. Walter Henry Medhurst, who had neither been to Japan nor met any Japanese, having consulted mainly a Japanese-Dutch dictionary, spelled some \"e\"s as \"ye\" in his An English and Japanese, and Japanese and English Vocabulary (1830). In the early Meiji era, James Curtis Hepburn, following Medhurst, spelled all \"e\"s as \"ye\" in his A Japanese and English dictionary (1867); in Japanese, e and i are slightly palatalized, somewhat as in Russian. That was the first full-scale Japanese-English/English-Japanese dictionary, which had a strong influence on Westerners in Japan and probably prompted the spelling \"yen\". Hepburn revised most of \"ye\"s to \"e\" in the 3rd edition (1886) in order to mirror the contemporary pronunciation, except \"yen\". This was probably already fixed and has remained so ever since.\n\n\n== History ==\n\n\n=== Introduction ===\n\nIn the 19th century, silver Spanish dollar coins were common throughout Southeast Asia, the China coast, and Japan. These coins had been introduced through Manila over a period of two hundred and fifty years, arriving on ships from Acapulco in Mexico. These ships were known as the Manila galleons. Until the 19th century, these silver dollar coins were actual Spanish dollars minted in the new world, mostly at Mexico City. But from the 1840s, they were increasingly replaced by silver dollars of the new Latin American republics. In the later half of the 19th century, some local coins in the region were made in the resemblance of the Mexican peso. The first of these local silver coins was the Hong Kong silver dollar coin that was minted in Hong Kong between the years 1866 and 1869. The Chinese were slow to accept unfamiliar coinage and preferred the familiar Mexican dollars, and so the Hong Kong government ceased minting these coins and sold the mint machinery to Japan.\n\nThe Japanese then decided to adopt a silver dollar coinage under the name of 'yen', meaning 'a round object'. The yen was officially adopted by the Meiji government in an Act signed on June 27, 1871. The new currency was gradually introduced beginning from July of that year. The yen was therefore basically a dollar unit, like all dollars, descended from the Spanish Pieces of eight, and up until the year 1873, all the dollars in the world had more or less the same value. The yen replaced Tokugawa coinage, a complex monetary system of the Edo period based on the mon. The New Currency Act of 1871, stipulated the adoption of the decimal accounting system of yen (1, \u5713), sen (\u200b1\u2044100, \u9322), and rin (\u200b1\u20441000, \u5398), with the coins being round and manufactured using Western machinery. The yen was legally defined as 0.78 troy ounces (24.26 g) of pure silver, or 1.5 grams of pure gold (as recommended by the European Congress of Economists in Paris in 1867; the 5-yen coin was equivalent to the Argentine 5 peso fuerte coin),\nhence putting it on a bimetallic standard. (The same amount of silver is worth about 1300 modern yen, while the same amount of gold is worth about 6500 yen.)\n\nFollowing the silver devaluation of 1873, the yen devalued against the U.S. dollar and the Canadian dollar (since those two countries adhered to a gold standard), and by the year 1897, the yen was worth only about US$0.50. In that year, Japan adopted a gold exchange standard and hence froze the value of the yen at $0.50. This exchange rate remained in place until Japan left the gold standard in December 1931, after which the yen fell to $0.30 by July 1932 and to $0.20 by 1933. It remained steady at around $0.30 until the start of the Second World War on December 7, 1941, at which time it fell to $0.23.The sen and the rin were eventually taken out of circulation at the end of 1953.\n\n\n=== Fixed value of the yen to the U.S. dollar ===\nNo true exchange rate existed for the yen between December 7, 1941, and April 25, 1949; wartime inflation reduced the yen to a fraction of its pre-war value. After a period of instability, on April 25, 1949, the U.S. occupation government fixed the value of the yen at \u00a5360 per US$1 through a United States plan, which was part of the Bretton Woods System, to stabilize prices in the Japanese economy. That exchange rate was maintained until 1971, when the United States abandoned the gold standard, which had been a key element of the Bretton Woods System, and imposed a 10 percent surcharge on imports, setting in motion changes that eventually led to floating exchange rates in 1973.\n\n\n=== Undervalued yen ===\nBy 1971, the yen had become undervalued. Japanese exports were costing too little in international markets, and imports from abroad were costing the Japanese too much. This undervaluation was reflected in the current account balance, which had risen from the deficits of the early 1960s, to a then-large surplus of US$5.8 billion in 1971. The belief that the yen, and several other major currencies, were undervalued motivated the United States' actions in 1971.\n\n\n=== Yen and major currencies float ===\nFollowing the United States' measures to devalue the dollar in the summer of 1971, the Japanese government agreed to a new, fixed exchange rate as part of the Smithsonian Agreement, signed at the end of the year. This agreement set the exchange rate at \u00a5308 per US$1. However, the new fixed rates of the Smithsonian Agreement were difficult to maintain in the face of supply and demand pressures in the foreign-exchange market. In early 1973, the rates were abandoned, and the major nations of the world allowed their currencies to float.\n\n\n=== Japanese government intervention in the currency market ===\nIn the 1970s, Japanese government and business people were very concerned that a rise in the value of the yen would hurt export growth by making Japanese products less competitive and would damage the industrial base. The government therefore continued to intervene heavily in foreign-exchange marketing (buying or selling dollars), even after the 1973 decision to allow the yen to float.\nDespite intervention, market pressures caused the yen to continue climbing in value, peaking temporarily at an average of \u00a5271 per US$1 in 1973, before the impact of the 1973 oil crisis was felt. The increased costs of imported oil caused the yen to depreciate to a range of \u00a5290 to \u00a5300 between 1974 and 1976. The re-emergence of trade surpluses drove the yen back up to \u00a5211 in 1978. This currency strengthening was again reversed by the second oil shock in 1979, with the yen dropping to \u00a5227 by 1980.\n\n\n=== Yen in the early 1980s ===\nDuring the first half of the 1980s, the yen failed to rise in value even though current account surpluses returned and grew quickly. From \u00a5221 in 1981, the average value of the yen actually dropped to \u00a5239 in 1985. The rise in the current account surplus generated stronger demand for yen in foreign-exchange markets, but this trade-related demand for yen was offset by other factors. A wide differential in interest rates, with United States interest rates much higher than those in Japan, and the continuing moves to deregulate the international flow of capital, led to a large net outflow of capital from Japan. This capital flow increased the supply of yen in foreign-exchange markets, as Japanese investors changed their yen for other currencies (mainly dollars) to invest overseas. This kept the yen weak relative to the dollar and fostered the rapid rise in the Japanese trade surplus that took place in the 1980s.\n\n\n=== Effect of the Plaza Accord ===\n\nIn 1985, a dramatic change began. Finance officials from major nations signed an agreement (the Plaza Accord) affirming that the dollar was overvalued (and, therefore, the yen undervalued). This agreement, and shifting supply and demand pressures in the markets, led to a rapid rise in the value of the yen. From its average of \u00a5239 per US$1 in 1985, the yen rose to a peak of \u00a5128 in 1988, virtually doubling its value relative to the dollar. After declining somewhat in 1989 and 1990, it reached a new high of \u00a5123 to US$1 in December 1992. In April 1995, the yen hit a peak of under 80 yen per dollar, temporarily making Japan's economy nearly the size of the US.\n\n\n=== Post-bubble years ===\nThe yen declined during the Japanese asset price bubble and continued to do so afterwards, reaching a low of \u00a5134 to US$1 in February 2002. The Bank of Japan's policy of zero interest rates has discouraged yen investments, with the carry trade of investors borrowing yen and investing in better-paying currencies (thus further pushing down the yen) estimated to be as large as $1 trillion. In February 2007, The Economist estimated that the yen was 15% undervalued against the dollar, and as much as 40% undervalued against the euro.\n\n\n=== After the global economic crisis of 2008 ===\n\nHowever, this trend of depreciation reversed after the global economic crisis of 2008. Other major currencies, except the Swiss franc, have been declining relative to the yen.\nOn April 4, 2013, the Bank of Japan announced that they would expand their Asset Purchase Program by $1.4 trillion in two years. The Bank of Japan hopes to bring Japan from deflation to inflation, aiming for 2% inflation. The amount of purchases is so large that it is expected to double the money supply. But this move has sparked concerns that the authorities in Japan are deliberately devaluing the yen in order to boost exports. However, the commercial sector in Japan worried that the devaluation would trigger an increase in import prices, especially for energy and raw materials.\nOn May 9, 2013, the currency weakened to 100 yen = 1 US$ for the first time since April 2009.\n\n\n== Coins ==\n\nCoins were introduced in 1870. There were silver 5-, 10-, 20- and 50-sen and 1-yen, and gold 2-, 5-, 10- and 20-yen. Gold 1-yen were introduced in 1871, followed by copper 1-rin, \u200b1\u20442-, 1- and 2-sen in 1873.\n\nCupronickel 5-sen coins were introduced in 1889. In 1897, the silver 1-yen coin was demonetized and the sizes of the gold coins were reduced by 50%, with 5-, 10- and 20-yen coins issued. In 1920, cupro-nickel 10-sen coins were introduced.\nProduction of silver coins ceased in 1938, after which a variety of base metals were used to produce 1-, 5- and 10-sen coins during the Second World War. Clay 5- and 10-sen coins were produced in 1945, but not issued for circulation.\nAfter the war, brass 50-sen, 1- and 5-yen were introduced between 1946 and 1948. In 1949, the current type of holed 5-yen was introduced, followed by bronze 10-yen (of the type still in circulation) in 1951.\nCoins in denominations of less than 1-yen became invalid on December 31, 1953, following enforcement of the Small Currency Disposition and Fractional Rounding in Payments Act (\u5c0f\u984d\u901a\u8ca8\u306e\u6574\u7406\u53ca\u3073\u652f\u6255\u91d1\u306e\u7aef\u6570\u8a08\u7b97\u306b\u95a2\u3059\u308b\u6cd5\u5f8b, Sh\u014dgaku ts\u016bka no seiri oyobi shiharaikin no has\u016bkeisan ni kan suru h\u014dritsu).\nIn 1955, the current type of aluminium 1-yen was introduced, along with unholed, nickel 50-yen. In 1957, silver 100-yen pieces were introduced. These were replaced in 1967, by the current cupro-nickel type, along with the holed 50-yen coin. In 1982, the first 500-yen coins were introduced.The date (expressed as the year in the reign of the emperor at the time the coin was stamped) is on the reverse of all coins, and, in most cases, country name (through 1945, Dai Nippon (\u5927\u65e5\u672c, \"Great Japan\"); after 1945, Nippon-koku (\u65e5\u672c\u56fd, \"State of Japan\") and the value in kanji is on the obverse, except for the present 5-yen coin where the country name is on the reverse.\nAlongside with the 5-Swiss franc coin and the rarely used 5-Cuban convertible peso coin, the 500-yen coin is one of the highest-valued coin to be used regularly in the world, with value of US$4.5 as of  October 2017. Because of this high face value, the 500-yen coin has been a favorite target for counterfeiters; it was counterfeited to such an extent, that in 2000, a new series of coins was issued with various security features, but counterfeiting continued.The 1-yen coin is made out of 100% aluminum and can float on water if placed correctly.\nOn various occasions, commemorative coins are minted, often in gold and silver with face values up to 100,000 yen. The first of these were silver \u00a5100 and \u00a51000 Summer Olympic coins issued on the occasion of the 1964 games. Recently this practice is undertaken with the 500-yen coin, the first two types were issued in 1985, in commemoration of the science and technology exposition in Tsukuba and the 100th anniversary of the Governmental Cabinet system. The current commemorative 500- and 1000-yen coin series honouring the 47 prefectures of Japan commenced in 2008, with 47 unique designs planned for each denomination. Only one coin per customer is available from banks in each prefecture. 100,000 of each 1000-yen silver coin have been minted. Even though all commemorative coins can be spent like ordinary (non-commemorative) coins, they are not seen often in typical daily use and normally do not circulate.\nInstead of displaying the Gregorian calendar year of mintage like most nations' coins, yen coins instead display the year of the current emperor's reign. For example, a coin minted in 2009, would bear the date Heisei 21 (the 21st year of Emperor Akihito's reign).\nDue to the great differences in style, size, weight and the pattern present on the edge of the coin they are very easy for people with visual impairments to tell apart from one another.\n\n\n== Banknotes ==\n\nThe issuance of the yen banknotes began in 1872, two years after the currency was introduced. Throughout its history, the denominations have ranged from 10 yen to 10,000 yen.\n\nBefore and during World War II, various bodies issued banknotes in yen, such as the Ministry of Finance and the Imperial Japanese National Bank. The Allied forces also issued some notes shortly after the war. Since then, the Bank of Japan has been the exclusive note issuing authority. The bank has issued five series after World War II. Series E, the current series introduced in 2004, consists of \u00a51000, \u00a55000, and \u00a510,000 notes. The EURion constellation pattern is present in the designs.\nJapan is generally considered a cash-based society, with 38% of payments in Japan made by cash in 2014. Possible explanations are that cash payments protect one's privacy, merchants do not have to wait for payment, and it does not carry any negative connotation like credit.\n\n\n== Determinants of value ==\nBeginning in December 1931, Japan gradually shifted from the gold standard system to the managed currency system.The relative value of the yen is determined in foreign exchange markets by the economic forces of supply and demand. The supply of the yen in the market is governed by the desire of yen holders to exchange their yen for other currencies to purchase goods, services, or assets. The demand for the yen is governed by the desire of foreigners to buy goods and services in Japan and by their interest in investing in Japan (buying yen-denominated real and financial assets).\nSince the 1990s, the Bank of Japan, the country's central bank, has kept interest rates low in order to spur economic growth. Short-term lending rates have responded to this monetary relaxation and fell from 3.7% to 1.3% between 1993 and 2008. Low interest rates combined with a ready liquidity for the yen prompted investors to borrow money in Japan and invest it in other countries (a practice known as carry trade). This has helped to keep the value of the yen low compared to other currencies.\n\n\n== International reserve currency ==\n\nThe percental composition of currencies of official foreign exchange reserves from 1995 to 2017.\n\n\n=== SDR basket ===\nThe special drawing rights (SDR) valuation is an IMF basket of currencies, including the Japanese yen. The SDR is linked to a basket of currencies with 41.9% for the U.S. dollar, 37.4% for the euro, 11.3% for the pound sterling, and 9.4% for the yen (as of 2011). The percentage for the yen has, however, declined from 18% in 2000. The exchange rate for the Japanese yen is expressed in terms of currency units per U.S. dollar; other rates are expressed as U.S. dollars per currency unit. The SDR currency value is calculated daily and the valuation basket is reviewed and adjusted every five years. The SDR was created in 1969, to support the fixed exchange system.\n\n\n== Historical exchange rate ==\nThe table below shows the monthly average of the U.S. dollar\u2013yen spot rate (JPY per USD) at 17:00 JST:\n\n\n== See also ==\n\nJapan Mint\nJapanese military yen\nEconomy of Japan\nCapital flows in Japan\nMonetary and fiscal policy of Japan\nBalance of payments accounts of Japan (1960\u201390)\n\n\n=== Older currency ===\nJapanese mon (currency)\nKoban (coin)\nRy\u014d (Japanese coin)\nWad\u014dkaichin\n\n\n== Footnotes ==\n\n\n== Notes ==\n This article incorporates public domain material from the Library of Congress Country Studies website http://lcweb2.loc.gov/frd/cs/.\n\n\n== Further reading ==\n\n\n== External links ==\nJapanese Yen on Wikinvest\nJapanese currency FAQ in Currency Museum, Bank of Japan\nMoney in Japan. A guide while traveling.\nImages of historic and modern Japanese bank notes\nChart: US dollar in yen) (in German)\nChart: 100 yen in euros (in German)\nHistorical Currency Converter Estimates the historical value of the yen into other currencies",
        "unit": "japanese yen",
        "url": "https://en.wikipedia.org/wiki/Japanese_yen"
    },
    {
        "_id": "Area",
        "clean": "Area",
        "text": "Area is the quantity that expresses the extent of a two-dimensional figure or shape, or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a  three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).\nThe area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m2), which is the area of a square whose sides are one metre long.  A shape with an area of three square metres would have the same area as three such squares.  In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.\nThere are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles.  Using these formulas, the area of any polygon can be found by dividing the polygon into triangles.  For shapes with curved boundary, calculus is usually required to compute the area.  Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.\nArea plays an important role in modern mathematics.  In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable.  In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.\n\n\n== Formal definition ==\n\nAn approach to defining what is meant by \"area\" is through axioms. \"Area\" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers which satisfies the following properties:\n\nFor all S in M, a(S) \u2265 0.\nIf S and T are in M then so are S \u222a T and S \u2229 T, and also a(S\u222aT) = a(S) + a(T) \u2212 a(S\u2229T).\nIf S and T are in M with S \u2286 T then T \u2212 S is in M and a(T\u2212S) = a(T) \u2212 a(S).\nIf a set S is in M and S is congruent to T then T is also in M and a(S) = a(T).\nEvery rectangle R is in M. If the rectangle has length h and breadth k then a(R) = hk.\nLet Q be a set enclosed between two step regions S and T. A step region is formed from a finite union of adjacent rectangles resting on a common base, i.e. S \u2286 Q \u2286 T. If there is a unique number c such that a(S) \u2264 c \u2264 a(T) for all such step regions S and T, then a(Q) = c.It can be proved that such an area function actually exists.\n\n\n== Units ==\n\nEvery unit of length has a corresponding unit of area, namely the area of a square with the given side length.  Thus areas can be measured in square metres (m2), square centimetres (cm2), square millimetres (mm2), square kilometres (km2), square feet (ft2), square yards (yd2), square miles (mi2), and so forth.  Algebraically, these units can be thought of as the squares of the corresponding length units.\nThe SI unit of area is the square metre, which is considered an SI derived unit.\n\n\n=== Conversions ===\n\nCalculation of the area of a square whose length and width are 1 metre would be:\n1 metre x 1 metre = 1 m2and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:\n3 metres x 2 metres = 6 m2. This is equivalent to 6 million square millimetres. Other useful conversions are:\n\n1 square kilometre = 1,000,000 square metres\n1 square metre = 10,000 square centimetres = 1,000,000 square millimetres\n1 square centimetre = 100 square millimetres.\n\n\n==== Non-metric units ====\nIn non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.\n\n1 foot = 12 inches,the relationship between square feet and square inches is\n\n1 square foot = 144 square inches,where 144 = 122 = 12 \u00d7 12.  Similarly:\n\n1 square yard = 9 square feet\n1 square mile = 3,097,600 square yards = 27,878,400 square feetIn addition, conversion factors include:\n\n1 square inch = 6.4516 square centimetres\n1 square foot = 0.09290304 square metres\n1 square yard = 0.83612736 square metres\n1 square mile = 2.589988110336 square kilometres\n\n\n=== Other units including historical ===\n\nThere are several other common units for area.  The are was the original unit of area in the metric system, with:\n\n1 are = 100 square metresThough the are has fallen out of use, the hectare is still commonly used to measure land:\n1 hectare = 100 ares = 10,000 square metres = 0.01 square kilometresOther uncommon metric units of area include the tetrad, the hectad, and the myriad.\nThe acre is also commonly used to measure land areas, where\n\n1 acre = 4,840 square yards = 43,560 square feet.An acre is approximately 40% of a hectare.\nOn the atomic scale, area is measured in units of barns, such that:\n1 barn = 10\u221228 square meters.The barn is commonly used in describing the cross-sectional area of interaction in nuclear physics.In India,\n\n20 dhurki = 1 dhur\n20 dhur = 1 khatha\n20 khata = 1 bigha\n32 khata = 1 acre\n\n\n== History ==\n\n\n=== Circle area ===\nIn the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.Subsequently, Book I of Euclid's Elements dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book Measurement of a Circle. (The circumference is 2\u03c0r, and the area of a triangle is half the base times the height, yielding the area \u03c0r2 for the disk.) Archimedes approximated the value of \u03c0 (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).\nSwiss scientist Johann Heinrich Lambert in 1761 proved that \u03c0, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that \u03c02 is irrational; this also proves that \u03c0 is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that \u03c0 is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.\n\n\n=== Triangle area ===\nHeron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, Metrica, written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since Metrica is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the Aryabhatiya (section 2.6).\nA formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in Shushu Jiuzhang (\"Mathematical Treatise in Nine Sections\"), written by Qin Jiushao.\n\n\n=== Quadrilateral area ===\nIn the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.\n\n\n=== General polygon area ===\nThe development of Cartesian coordinates by Ren\u00e9 Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.\n\n\n=== Areas determined using calculus ===\nThe development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.\n\n\n== Area formulas ==\n\n\n=== Polygon formulas ===\n\nFor a non-self-intersecting (simple) polygon, the Cartesian coordinates \n  \n    \n      \n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{i},y_{i})}\n   (i=0, 1, ..., n-1) of whose n vertices are known, the area is given by the surveyor's formula:\n\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          |\n        \n        \n          \u2211\n          \n            i\n            =\n            0\n          \n          \n            n\n            \u2212\n            1\n          \n        \n        (\n        \n          x\n          \n            i\n          \n        \n        \n          y\n          \n            i\n            +\n            1\n          \n        \n        \u2212\n        \n          x\n          \n            i\n            +\n            1\n          \n        \n        \n          y\n          \n            i\n          \n        \n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle A={\\frac {1}{2}}|\\sum _{i=0}^{n-1}(x_{i}y_{i+1}-x_{i+1}y_{i})|}\n  where when i=n-1, then i+1 is expressed as modulus n and so refers to 0.\n\n\n==== Rectangles ====\n\nThe most basic area formula is the formula for the area of a rectangle.  Given a rectangle with length l and width w, the formula for the area is:\nA = lw (rectangle).That is, the area of the rectangle is the length multiplied by the width.  As a special case, as l = w in the case of a square, the area of a square with side length s is given by the formula:\nA = s2 (square).The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom.  On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.\n\n\n==== Dissection, parallelograms, and triangles ====\n\nMost other simple formulas for area follow from the method of dissection.\nThis involves cutting a shape into pieces, whose areas must sum to the area of the original shape.\nFor an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left.  If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle.  It follows that the area of the parallelogram is the same as the area of the rectangle:\nA = bh  (parallelogram).However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right.  It follows that the area of each triangle is half the area of the parallelogram:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        b\n        h\n      \n    \n    {\\displaystyle A={\\frac {1}{2}}bh}\n    (triangle).Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.\n\n\n=== Area of curved shapes ===\n\n\n==== Circles ====\n\nThe formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method.  Given a circle of radius r, it is possible to partition the circle into sectors, as shown in the figure to the right.  Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram.  The height of this parallelogram is r, and the width is half the circumference of the circle, or \u03c0r.  Thus, the total area of the circle is \u03c0r2:\nA = \u03c0r2  (circle).Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors.  The limit of the areas of the approximate parallelograms is exactly \u03c0r2, which is the area of the circle.This argument is actually a simple application of the ideas of calculus.  In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus.  Using modern methods, the area of a circle can be computed using a definite integral:\n\n  \n    \n      \n        A\n        \n        =\n        \n        2\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n        \n        d\n        x\n        \n        =\n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle A\\;=\\;2\\int _{-r}^{r}{\\sqrt {r^{2}-x^{2}}}\\,dx\\;=\\;\\pi r^{2}.}\n  \n\n\n==== Ellipses ====\n\nThe formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes x and y the formula is:\n\n  \n    \n      \n        A\n        =\n        \u03c0\n        x\n        y\n        .\n      \n    \n    {\\displaystyle A=\\pi xy.}\n  \n\n\n==== Surface area ====\n\nMost basic formulas for surface area can be obtained by cutting surfaces and flattening them out.  For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle.  Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.\nThe formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out.  The formula for the surface area of a sphere was first obtained by Archimedes in his work On the Sphere and Cylinder.  The formula is:\nA = 4\u03c0r2  (sphere),where r is the radius of the sphere.  As with the formula for the area of a circle, any derivation of this formula inherently uses methods similar to calculus.\n\n\n=== General formulas ===\n\n\n==== Areas of 2-dimensional figures ====\nA triangle: \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        B\n        h\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}Bh}\n   (where B is any side, and h is the distance from the line on which B lies to the other vertex of the triangle). This formula can be used if the height h is known. If the lengths of the three sides are known then Heron's formula can be used: \n  \n    \n      \n        \n          \n            s\n            (\n            s\n            \u2212\n            a\n            )\n            (\n            s\n            \u2212\n            b\n            )\n            (\n            s\n            \u2212\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {s(s-a)(s-b)(s-c)}}}\n   where a, b, c are the sides of the triangle, and \n  \n    \n      \n        s\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        a\n        +\n        b\n        +\n        c\n        )\n      \n    \n    {\\displaystyle s={\\tfrac {1}{2}}(a+b+c)}\n   is half of its perimeter. If an angle and its two included sides are given, the area is \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        a\n        b\n        sin\n        \u2061\n        (\n        C\n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}ab\\sin(C)}\n   where C is the given angle and a and b are its included sides. If the triangle is graphed on a coordinate plane, a matrix can be used and is simplified to the absolute value of \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            3\n          \n        \n        +\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            2\n          \n        \n        \u2212\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}(x_{1}y_{2}+x_{2}y_{3}+x_{3}y_{1}-x_{2}y_{1}-x_{3}y_{2}-x_{1}y_{3})}\n  . This formula is also known as the shoelace formula and is an easy way to solve for the area of a coordinate triangle by substituting the 3 points (x1,y1), (x2,y2), and (x3,y3). The shoelace formula can also be used to find the areas of other polygons when their vertices are known. Another approach for a coordinate triangle is to use calculus to find the area.\nA simple polygon constructed on a grid of equal-distanced points (i.e., points with integer coordinates) such that all the polygon's vertices are grid points: \n  \n    \n      \n        i\n        +\n        \n          \n            b\n            2\n          \n        \n        \u2212\n        1\n      \n    \n    {\\displaystyle i+{\\frac {b}{2}}-1}\n  , where i is the number of grid points inside the polygon and b is the number of boundary points. This result is known as Pick's theorem.\n\n\n==== Area in calculus ====\n\nThe area between a positive-valued curve and the horizontal axis, measured between two values a and b (b is defined as the larger of the two values) on the horizontal axis, is given by the integral from a to b of the function that represents the curve:\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        f\n        (\n        x\n        )\n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}f(x)\\,dx.}\n  The area between the graphs of two functions is equal to the integral of one function, f(x), minus the integral of the other function, g(x):\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        (\n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        )\n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}(f(x)-g(x))\\,dx,}\n   where \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n   is the curve with the greater y-value.An area bounded by a function r = r(\u03b8) expressed in polar coordinates is:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \u222b\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        \u03b8\n        .\n      \n    \n    {\\displaystyle A={1 \\over 2}\\int r^{2}\\,d\\theta .}\n  The area enclosed by a parametric curve \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        t\n        )\n        =\n        (\n        x\n        (\n        t\n        )\n        ,\n        y\n        (\n        t\n        )\n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t)=(x(t),y(t))}\n   with endpoints \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t_{0})={\\vec {u}}(t_{1})}\n   is given by the line integrals:\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \u2212\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        (\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \u2212\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        )\n        \n        d\n        t\n      \n    \n    {\\displaystyle \\oint _{t_{0}}^{t_{1}}x{\\dot {y}}\\,dt=-\\oint _{t_{0}}^{t_{1}}y{\\dot {x}}\\,dt={1 \\over 2}\\oint _{t_{0}}^{t_{1}}(x{\\dot {y}}-y{\\dot {x}})\\,dt}\n  (see Green's theorem) or the z-component of\n\n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                \n                  u\n                  \u2192\n                \n              \n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle {1 \\over 2}\\oint _{t_{0}}^{t_{1}}{\\vec {u}}\\times {\\dot {\\vec {u}}}\\,dt.}\n  \n\n\n==== Bounded area between two quadratic functions ====\nTo find the bounded area between two quadratic functions, we subtract one from the other to write the difference as\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        =\n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        a\n        (\n        x\n        \u2212\n        \u03b1\n        )\n        (\n        x\n        \u2212\n        \u03b2\n        )\n      \n    \n    {\\displaystyle f(x)-g(x)=ax^{2}+bx+c=a(x-\\alpha )(x-\\beta )}\n  where f(x) is the quadratic upper bound and g(x) is the quadratic lower bound. Define the discriminant of f(x)-g(x) as\n\n  \n    \n      \n        \u0394\n        =\n        \n          b\n          \n            2\n          \n        \n        \u2212\n        4\n        a\n        c\n        .\n      \n    \n    {\\displaystyle \\Delta =b^{2}-4ac.}\n  By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain\n\n  \n    \n      \n        A\n        =\n        \n          \n            \n              \u0394\n              \n                \n                  \u0394\n                \n              \n            \n            \n              6\n              \n                a\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            a\n            6\n          \n        \n        (\n        \u03b2\n        \u2212\n        \u03b1\n        \n          )\n          \n            3\n          \n        \n        ,\n        \n        a\n        \u2260\n        0.\n      \n    \n    {\\displaystyle A={\\frac {\\Delta {\\sqrt {\\Delta }}}{6a^{2}}}={\\frac {a}{6}}(\\beta -\\alpha )^{3},\\qquad a\\neq 0.}\n  The above remains valid if one of the bounding functions is linear instead of quadratic.\n\n\n==== Surface area of 3-dimensional figures ====\nCone: \n  \n    \n      \n        \u03c0\n        r\n        \n          (\n          \n            r\n            +\n            \n              \n                \n                  r\n                  \n                    2\n                  \n                \n                +\n                \n                  h\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\pi r\\left(r+{\\sqrt {r^{2}+h^{2}}}\\right)}\n  , where r is the radius of the circular base, and h is the height. That can also be rewritten as \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        +\n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi r^{2}+\\pi rl}\n   or \n  \n    \n      \n        \u03c0\n        r\n        (\n        r\n        +\n        l\n        )\n        \n        \n      \n    \n    {\\displaystyle \\pi r(r+l)\\,\\!}\n   where r is the radius and l is the slant height of the cone. \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n   is the base area while \n  \n    \n      \n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi rl}\n   is the lateral surface area of the cone.\ncube: \n  \n    \n      \n        6\n        \n          s\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 6s^{2}}\n  , where s is the length of an edge.\ncylinder: \n  \n    \n      \n        2\n        \u03c0\n        r\n        (\n        r\n        +\n        h\n        )\n      \n    \n    {\\displaystyle 2\\pi r(r+h)}\n  , where r is the radius of a base and h is the height. The 2\n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  r can also be rewritten as \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   d, where d is the diameter.\nprism: 2B + Ph, where B is the area of a base, P is the perimeter of a base, and h is the height of the prism.\npyramid: \n  \n    \n      \n        B\n        +\n        \n          \n            \n              P\n              L\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle B+{\\frac {PL}{2}}}\n  , where B is the area of the base, P is the perimeter of the base, and L is the length of the slant.\nrectangular prism: \n  \n    \n      \n        2\n        (\n        \u2113\n        w\n        +\n        \u2113\n        h\n        +\n        w\n        h\n        )\n      \n    \n    {\\displaystyle 2(\\ell w+\\ell h+wh)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length, w is the width, and h is the height.\n\n\n==== General formula for surface area ====\nThe general formula for the surface area of the graph of a continuously differentiable function \n  \n    \n      \n        z\n        =\n        f\n        (\n        x\n        ,\n        y\n        )\n        ,\n      \n    \n    {\\displaystyle z=f(x,y),}\n   where \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (x,y)\\in D\\subset \\mathbb {R} ^{2}}\n   and \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   is a region in the xy-plane with the smooth boundary:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          \n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      x\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      y\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            1\n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}{\\sqrt {\\left({\\frac {\\partial f}{\\partial x}}\\right)^{2}+\\left({\\frac {\\partial f}{\\partial y}}\\right)^{2}+1}}\\,dx\\,dy.}\n  An even more general formula for the area of the graph of a parametric surface in the vector form \n  \n    \n      \n        \n          r\n        \n        =\n        \n          r\n        \n        (\n        u\n        ,\n        v\n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {r} =\\mathbf {r} (u,v),}\n   where \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a continuously differentiable vector function of \n  \n    \n      \n        (\n        u\n        ,\n        v\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (u,v)\\in D\\subset \\mathbb {R} ^{2}}\n   is:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          |\n          \n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  u\n                \n              \n            \n            \u00d7\n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  v\n                \n              \n            \n          \n          |\n        \n        \n        d\n        u\n        \n        d\n        v\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}\\left|{\\frac {\\partial \\mathbf {r} }{\\partial u}}\\times {\\frac {\\partial \\mathbf {r} }{\\partial v}}\\right|\\,du\\,dv.}\n  \n\n\n=== List of formulas ===\nThe above calculations show how to find the areas of many common shapes.\nThe areas of irregular polygons can be calculated using the \"Surveyor's formula\".\n\n\n=== Relation of area to perimeter ===\nThe isoperimetric inequality states that, for a closed curve of length L (so the region it encloses has perimeter L) and for area A of the region that it encloses,\n\n  \n    \n      \n        4\n        \u03c0\n        A\n        \u2264\n        \n          L\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle 4\\pi A\\leq L^{2},}\n  and  equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.\nAt the other extreme, a figure with given perimeter L could have an arbitrarily small area, as illustrated by a rhombus that is \"tipped over\" arbitrarily far so that two of its angles are arbitrarily close to 0\u00b0 and the other two are arbitrarily close to 180\u00b0.\nFor a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius r. This can be seen from the area formula \u03c0r2 and the circumference formula 2\u03c0r.\nThe area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).\n\n\n=== Fractals ===\nDoubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a  fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.\n\n\n== Area bisectors ==\n\nThere are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.\nAny line through the midpoint of a parallelogram bisects the area.\nAll area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.\n\n\n== Optimization ==\nGiven a wire contour, the surface of least area spanning (\"filling\") it is a minimal surface.  Familiar examples include soap bubbles.\nThe question of the filling area of the Riemannian circle remains open.The circle has the largest area of any two-dimensional object having the same perimeter.\nA cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.\nA version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.The ratio of the area of the incircle to the area of an equilateral triangle, \n  \n    \n      \n        \n          \n            \u03c0\n            \n              3\n              \n                \n                  3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\pi }{3{\\sqrt {3}}}}}\n  , is larger than that of any non-equilateral triangle.The ratio of the area to the square of the perimeter of an equilateral triangle, \n  \n    \n      \n        \n          \n            1\n            \n              12\n              \n                \n                  3\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{12{\\sqrt {3}}}},}\n   is larger than that for any other triangle.\n\n\n== See also ==\nBrahmagupta quadrilateral, a cyclic quadrilateral with integer sides, integer diagonals, and integer area.\nEqui-areal mapping\nHeronian triangle, a triangle with integer sides and integer area.\nList of triangle inequalities#Area\nOne-seventh area triangle, an inner triangle with one-seventh the area of the reference triangle.Routh's theorem, a generalization of the one-seventh area triangle.Orders of magnitude (area)\u2014A list of areas by size.\nPentagon#Derivation of the area formula\nPlanimeter, an instrument for measuring small areas, e.g. on maps.\nQuadrilateral#Area of a convex quadrilateral\nRobbins pentagon, a cyclic pentagon whose side lengths and area are all rational numbers.\n\n\n== References ==\n\n\n== External links ==",
        "unit": "area",
        "url": "https://en.wikipedia.org/wiki/Area"
    },
    {
        "_id": "Minute",
        "clean": "Minute",
        "text": "The minute is a unit of time or angle. As a unit of time, the minute is most of times equal to \u200b1\u204460 (the first sexagesimal fraction) of an hour, or 60 seconds. In the UTC time standard, a minute on rare occasions has 61 seconds, a consequence of leap seconds (there is a provision to insert a negative leap second, which would result in a 59-second minute, but this has never happened in more than 40 years under this system). As a unit of angle, the minute of arc is equal to \u200b1\u204460 of a degree, or 60 seconds (of arc). Although not an SI unit for either time or angle, the minute is accepted for use with SI units for both. The SI symbols for minute or minutes are min for time measurement, and the prime symbol after a number, e.g. 5\u2032, for angle measurement. The prime is also sometimes used informally to denote minutes of time.\n\n\n== History ==\nIn contrast to the hour, the minute (and the second) does not have a clear historical background. An early use of sexagesimal divisions of the hour is found in John of Sacrobosco's Computus (ca. 1235), where it was used in discussions of the length of the tropical year.  Another motivation that has been suggested for the emergence of these fine divisions of time was the construction of \"precision\" timepieces (mechanical and water clocks). However, no specific records of the origin for the division as \u200b1\u204460 part of the hour (and the second \u200b1\u204460 of the minute) have ever been found.\nHistorically, the word \"minute\" comes from the Latin pars minuta prima, meaning \"first small part\".  This division of the hour can be further refined with a \"second small part\" (Latin: pars minuta secunda), and this is where the word \"second\" comes from.  For even further refinement, the term \"third\" (\u200b1\u204460 of a second) remains in some languages, for example Polish (tercja) and Turkish (salise), although most modern usage subdivides seconds by using decimals.  The symbol notation of the prime for minutes and double prime for seconds can be seen as indicating the first and second cut of the hour (similar to how the foot is the first cut of the yard or perhaps chain, with inches as the second cut).  In 1267, the medieval scientist Roger Bacon, writing in Latin, defined the division of time between full moons as a number of hours, minutes, seconds, thirds, and fourths (horae, minuta, secunda, tertia, and quarta) after noon on specified calendar dates.\n\n\n== See also ==\nInternational System of Units\nLatitude and longitude\nOrders of magnitude (time)\n\n\n== Notes and references ==\n\n\n== Bibliography ==\nHenry Campbell Black, Black's Law Dictionary, 6th Edition, entry on Minute. West Publishing Company, St. Paul, Minnesota, 1991.\nEric W. Weisstein. \"Arc Minute.\" From MathWorld\u2014A Wolfram",
        "unit": "minute",
        "url": "https://en.wikipedia.org/wiki/Minute"
    },
    {
        "_id": "Farad",
        "clean": "Farad",
        "text": "The farad (symbol: F) is the SI derived unit of electrical capacitance, the ability of a body to store an electrical charge. It is named after the English physicist Michael Faraday.\n\n\n== Definition ==\nOne farad is defined as the capacitance across which, when charged with one coulomb, there is a potential difference of one volt. Equally, one farad can be described as the capacitance which stores a one-coulomb charge across a potential difference of one volt.The relationship between capacitance, charge and potential difference is linear. For example, if the potential difference across a capacitor is halved, the quantity of charge stored by that capacitor will also be halved.\nFor most applications, the farad is an impractically large unit of capacitance. Most electrical and electronic applications are covered by the following SI prefixes:\n\n1 mF (millifarad, one thousandth (10\u22123) of a farad) = 1000 \u03bcF = 1000000 nF\n1 \u03bcF (microfarad, one millionth (10\u22126) of a farad) = 0.000 001 F = 1000 nF = 1000000 pF\n1 nF (nanofarad, one billionth (10\u22129) of a farad) = 0.001 \u03bcF = 1000 pF\n1 pF (picofarad, one trillionth (10\u221212) of a farad)\n\n\n=== Equalities ===\nA farad is represented in terms of SI base units as\ns4\u22c5A2\u22c5m\u22122\u22c5kg\u22121It can further be expressed as:\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              C\n              V\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  A\n                \n                \n                  \u22c5\n                \n                \n                  s\n                \n              \n              V\n            \n          \n        \n        =\n        \n          \n            \n              J\n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  W\n                \n                \n                  \u22c5\n                \n                \n                  s\n                \n              \n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  N\n                \n                \n                  \u22c5\n                \n                \n                  m\n                \n              \n              \n                \n                  V\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  C\n                \n                \n                  2\n                \n              \n              J\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  C\n                \n                \n                  2\n                \n              \n              \n                \n                  N\n                \n                \n                  \u22c5\n                \n                \n                  m\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    s\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  \n                    C\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  kg\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    s\n                  \n                  \n                    4\n                  \n                \n                \n                  \u22c5\n                \n                \n                  \n                    A\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n                \n                  \u22c5\n                \n                \n                  kg\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              s\n              \u03a9\n            \n          \n        \n        =\n        \n          \n            \n              1\n              \n                \u03a9\n                \n                  \u22c5\n                \n                \n                  Hz\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  s\n                \n                \n                  2\n                \n              \n              H\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\text{F}}={\\dfrac {\\text{C}}{\\text{V}}}={\\dfrac {{\\text{A}}{\\cdot }{\\text{s}}}{\\text{V}}}={\\dfrac {\\text{J}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{W}}{\\cdot }{\\text{s}}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{N}}{\\cdot }{\\text{m}}}{{\\text{V}}^{2}}}={\\dfrac {{\\text{C}}^{2}}{\\text{J}}}={\\dfrac {{\\text{C}}^{2}}{{\\text{N}}{\\cdot }{\\text{m}}}}={\\dfrac {{\\text{s}}^{2}{\\cdot }{\\text{C}}^{2}}{{\\text{m}}^{2}{\\cdot }{\\text{kg}}}}={\\dfrac {{\\text{s}}^{4}{\\cdot }{\\text{A}}^{2}}{{\\text{m}}^{2}{\\cdot }{\\text{kg}}}}={\\dfrac {\\text{s}}{\\Omega }}={\\dfrac {1}{\\Omega {\\cdot }{\\text{Hz}}}}={\\dfrac {{\\text{s}}^{2}}{\\text{H}}},}\n  where F = farad, A = ampere, V = volt, C = coulomb, J = joule, m = metre, N = newton, s = second, W = watt, kg = kilogram, \u03a9 = ohm, Hz = hertz, H = henry.\n\n\n== History ==\nThe term \"farad\" was originally coined by Latimer Clark and Charles Bright in 1861, in honor of Michael Faraday, for a unit of quantity of charge but by 1873, the farad had become a unit of capacitance.  In 1881 at the International Congress of Electricians in Paris, the name farad was officially used for the unit of electrical capacitance.\n\n\n== Explanation ==\n\nA capacitor generally consists of two conducting surfaces, frequently referred to as plates, separated by an insulating layer usually referred to as a dielectric. The original capacitor was the Leyden jar developed in the 18th century. It is the accumulation of electric charge on the plates that results in capacitance. Modern capacitors are constructed using a range of manufacturing techniques and materials to provide the extraordinarily wide range of capacitance values used in electronics applications from femtofarads to farads, with maximum-voltage ratings ranging from a few volts to several kilovolts.\nValues of capacitors are usually specified in farads (F),  microfarads (\u03bcF), nanofarads (nF) and picofarads (pF). The millifarad is rarely used in practice (a capacitance of 4.7 mF (0.0047 F), for example, is instead written as 4700 \u00b5F), while the nanofarad is uncommon in North America. The size of commercially available capacitors ranges from around 0.1 pF to 5000F (5 kF) supercapacitors. Parasitic capacitance in high-performance integrated circuits can be measured in femtofarads (1 fF = 0.001 pF = 10\u221215 F), while high-performance test equipment can detect changes in capacitance on the order of tens of attofarads (1 aF = 10\u221218 F).A value of 0.1 pF is about the smallest available in capacitors for general use in electronic design, since smaller ones would be dominated by the parasitic capacitances of other components, wiring or printed circuit boards. Capacitance values of 1 pF or lower can be achieved by twisting two short lengths of insulated wire together.The capacitance of the Earth's ionosphere with respect to the ground is calculated to be about 1 F.\n\n\n=== Informal and deprecated terminology ===\nThe picofarad is sometimes colloquially pronounced as \"puff\" or \"pic\", as in \"a ten-puff capacitor\". Similarly, \"mic\" (pronounced \"mike\") is sometimes used informally to signify microfarads. If the Greek letter \u03bc is not available, the notation \"uF\" is often used as a substitute for \"\u03bcF\" in electronics literature. A \"micro-microfarad\" (\u03bc\u03bcF, and confusingly often mmf or MMF), an obsolete unit sometimes found in older texts, is the equivalent of a picofarad.  In texts prior to 1960, and on capacitor packages even much more recently, \"mf\" or \"MFD\" rather than the modern \"\u00b5F\" frequently represented microfarads. Similarly, \"mmf\" or \"MMFD\" represented picofarads.\n\n\n=== Related concepts ===\nThe reciprocal of capacitance is called electrical elastance, the (non-standard, non-SI) unit of which is the daraf.\n\n\n== CGS units ==\nThe abfarad (abbreviated abF) is an obsolete CGS unit of capacitance equal to 109 farads (1 gigafarad, GF).The statfarad (abbreviated statF) is a rarely used CGS unit equivalent to the capacitance of a capacitor with a charge of 1 statcoulomb across a potential difference of 1 statvolt. It is 1/(10\u22125c2) farad, approximately 1.1126 picofarads.\n\n\n== See also ==\nCapacitor\nSupercapacitor\nOrders of magnitude (capacitance)\n\n\n== Notes ==\n\n\n== External links ==\nFarad unit conversion tool",
        "unit": "farad",
        "url": "https://en.wikipedia.org/wiki/Farad"
    }
]