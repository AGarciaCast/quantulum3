[
    {
        "_id": "Short_ton",
        "clean": "Short ton",
        "text": "The short ton is a unit of weight equal to 2,000 pounds (907.18474 kg). The unit is most commonly used in the United States where it is known simply as the ton.\n\n\n== United States ==\n\nIn the United States, a short ton is usually known simply as a \"ton\", without distinguishing it from the tonne (1,000 kilograms or 2,204.62262 pounds), known there as the \"metric ton\", or the long ton also known as the \"Imperial ton\" (2,240 pounds or 1,016.0469088 kilograms). There are, however, some U.S. applications where unspecified tons normally means long tons (for example, naval ships) or metric tons (world grain production figures).\nBoth the long and short ton are defined as 20 hundredweights, but a hundredweight is 100 pounds (45.359237 kg) in the U.S. system (short or net hundredweight) and 112 pounds (50.80234544 kg) in the imperial system (long or gross hundredweight).A short ton\u2013force is 2,000 pounds-force (8,896.443230521 N).\n\n\n== United Kingdom ==\nIn the United Kingdom, short tons are rarely used.  The word \"ton\" is taken to refer to a long ton, and metric tons are distinguished by the \"tonne\" spelling.  Most Commonwealth countries followed British practice with the exception of Canada, which used short tons as well as long tons.  Canada now predominantly uses metric tons (tonnes).\n\n\n== See also ==\nLong ton, 2,240 lb (1,016.0469088 kg)\nTon\nTonne, also known as a metric ton (t), equal to 1,000 kg (2,204.6226218 lb) or 1 megagram.\nTonnage, volume measurement used in maritime shipping, originally based on 100 cubic feet (2.8316846592 m3).\n\n\n== References ==",
        "unit": "short ton",
        "url": "https://en.wikipedia.org/wiki/Short_ton"
    },
    {
        "_id": "Kilogram",
        "clean": "Kilogram",
        "text": "The kilogram or kilogramme (symbol: kg) is the base unit of mass in the International System of Units (SI), and is defined as being equal to the mass of the International Prototype of the Kilogram (IPK, also known as \"Le Grand K\" or \"Big K\"), a cylinder of platinum-iridium alloy stored by the International Bureau of Weights and Measures at Saint-Cloud, France.\nThe kilogram was originally defined as the mass of a litre (cubic decimetre) of water at its freezing point. That was an inconvenient quantity to precisely replicate, so in the late 18th century a platinum artefact was fashioned as a standard for the kilogram.  That artefact, or an exact replica thereof, has been the standard of the unit of mass for the metric system ever since.\nThough the IPK, the current primary artefact, and its replicas are stored in carefully controlled laboratory conditions, their masses have been subject to fluctuation as a result of poorly understood factors, possibly including handling, cleaning and contamination. The IPK has diverged from its replicas by 50 \u03bcg since their manufacture late in the 19th century.  This has led to calls to replace the artefact with a standard defined in terms of invariant constants of nature.\nThe avoirdupois (or international) pound, used in both the imperial and US customary systems, is defined as exactly 0.45359237 kg,\nmaking one kilogram approximately equal to 2.2046 avoirdupois pounds. Other traditional units of weight and mass around the world are now also defined in terms of the kilogram, making the IPK the primary standard for virtually all units of mass on Earth.\n\n\n== Definition ==\nThe gram, 1/1000 of a kilogram, was provisionally defined in 1795 as the mass of one cubic centimetre of water at the melting point of ice.\nThe final kilogram, manufactured as a prototype in 1799 and from which the International Prototype Kilogram (IPK) was derived in 1875, had a mass equal to the mass of 1 dm3 of water under atmospheric pressure and at the temperature of its maximum density, which is approximately 4 \u00b0C.\nThe kilogram is the only named SI unit with an SI prefix (kilo) as part of its name. It is also the only SI unit that is still directly defined by an artefact rather than a fundamental physical property that can be independently reproduced in different laboratories. Three other base units (cd, A, mol) and 17 derived units (N, Pa, J, W, C, V, F, \u03a9, S, Wb, T, H, kat, Gy, Sv, lm, lx) in the SI system are defined in relation to the kilogram, and thus its stability is important. The definitions of only eight other named SI units do not depend on the kilogram: those of temperature (K, \u00b0C), time and frequency (s, Hz, Bq), length (m), and angle (rad, sr).The IPK is rarely used or handled. Copies of the IPK kept by national metrology laboratories around the world were compared with the IPK in 1889, 1948, and 1989 to provide traceability of measurements of mass anywhere in the world back to the IPK.\nThe International Prototype Kilogram was commissioned by the General Conference on Weights and Measures (CGPM) under the authority of the Metre Convention (1875), and in the custody of the International Bureau of Weights and Measures (BIPM) who hold it on behalf of the CGPM. After the International Prototype Kilogram had been found to vary in mass over time relative to its reproductions, the International Committee for Weights and Measures (CIPM) recommended in 2005 that the kilogram be redefined in terms of a fundamental constant of nature. At its 2011 meeting, the CGPM agreed in principle that the kilogram should be redefined in terms of the Planck constant, h. The decision was originally deferred until 2014; in 2014 it was deferred again until the next meeting.  CIPM has proposed revised definitions of the SI base units, for consideration at the 26th CGPM.  The formal vote, scheduled for 16 November 2018, is expected to be approved and the new definitions will come into force on 20 May 2019.\n\n\n== Name and terminology ==\nThe word kilogramme or kilogram is derived from the French kilogramme, which itself was a learned coinage, prefixing the Greek stem of \u03c7\u03af\u03bb\u03b9\u03bf\u03b9 khilioi \"a thousand\" to gramma, a Late Latin term for \"a small weight\", itself from Greek \u03b3\u03c1\u03ac\u03bc\u03bc\u03b1. \nThe word kilogramme was written into French law in 1795, in the Decree of 18 Germinal,\nwhich revised the older system of units introduced by the French National Convention in 1793, where the gravet had been defined as weight (poids) of a cubic centimetre of water, equal to 1/1000 of a grave. In the decree of 1795, the term gramme thus replaced gravet, and kilogramme replaced grave.\nThe French spelling was adopted in Great Britain when the word was used for the first time in English in 1795,  with the spelling kilogram being adopted in the United States. In the United Kingdom both spellings are used, with \"kilogram\" having become by far the more common. UK law regulating the units to be used when trading by weight or measure does not prevent the use of either spelling.In the 19th century the French word kilo, a shortening of kilogramme, was imported into the English language where it has been used to mean both kilogram and kilometre. While kilo is acceptable in many generalist texts, for example The Economist, its use is typically considered inappropriate in certain applications including scientific, technical and legal writing, where authors should adhere strictly to SI nomenclature. When the United States Congress gave the metric system legal status in 1866, it permitted the use of the word kilo as an alternative to the word kilogram, but in 1990 revoked the status of the word kilo.During the 19th century, the standard system of metric units was the centimetre\u2013gram\u2013second system of units, treating the gram as the fundamental unit of mass and the kilogram simply as a derived unit. \nIn 1901, however, following the discoveries by James Clerk Maxwell to the effect that electric measurements could not be explained in terms of the three fundamental units of length, mass and time, Giovanni Giorgi proposed a new standard system that would include a fourth fundamental unit to measure quantities in electromagnetism.\nIn 1935 this was adopted by the IEC as the Giorgi system, now also known as MKS system,\nand in 1946 the CIPM approved a proposal to adopt the ampere as the electromagnetic unit of the \"MKSA system\".\nIn 1948 the CGPM commissioned the CIPM \"to make recommendations for a single practical system of units of measurement, suitable for adoption by all countries adhering to the Metre Convention\". This led to the launch of SI in 1960 and the subsequent publication of the \"SI Brochure\", which stated that \"It is not permissible to use abbreviations for unit symbols or unit names ...\".\nThe CGS and MKS systems co-existed during much of the early-to-mid 20th century, but as a result of the decision to adopt the \"Giorgi system\" as the international system of units in 1960, the kilogram is now the SI base unit for mass, while the definition of the gram is derived from that of the kilogram.\n\n\n== Mass and weight ==\n\nThe kilogram is a unit of mass, a property corresponding to the common perception of how \"heavy\" an object is. Mass is an inertial property; that is, it is related to the tendency of an object at rest to remain at rest, or if in motion to remain in motion at a constant velocity, unless acted upon by a force.\nWhile the weight of an object is dependent on the strength of the local gravitational field, the mass of an object is independent of gravity, as mass is a measure of the quantity of matter. Accordingly, for astronauts in microgravity, no effort is required to hold objects off the cabin floor; they are \"weightless\". However, since objects in microgravity still retain their mass and inertia, an astronaut must exert ten times as much force to accelerate a 10\u2011kilogram object at the same rate as a 1\u2011kilogram object.\nBecause at any given point on Earth the weight of an object is proportional to its mass, the mass of an object in kilograms is usually measured by comparing its weight to the weight of a standard mass, whose mass is known in kilograms, using a device called a weighing scale. The ratio of the force of gravity on the two objects, measured by the scale, is equal to the ratio of their masses.\n\n\n== Kilogramme des Archives ==\n\nOn April 7, 1795, the gram was decreed in France to be \"the absolute weight of a volume of pure water equal to the cube of the hundredth part of the metre, and at the temperature of melting ice\".\nSince trade and commerce typically involve items significantly more massive than one gram, and since a mass standard made of water would be inconvenient and unstable, the regulation of commerce necessitated the manufacture of a practical realization of the water-based definition of mass. Accordingly, a provisional mass standard was made as a single-piece, metallic artifact one thousand times as massive as the gram\u2014the kilogram.\nAt the same time, work was commissioned to precisely determine the mass of a cubic decimetre (one litre) of water. Although the decreed definition of the kilogram specified water at 0 \u00b0C\u2014its highly stable temperature point\u2014the French chemist Louis Lef\u00e8vre-Gineau and the Italian naturalist Giovanni Fabbroni after several years of research chose to redefine the standard in 1799 to water's most stable density point: the temperature at which water reaches maximum density, which was measured at the time as 4 \u00b0C.\nThey concluded that one cubic decimetre of water at its maximum density was equal to 99.9265% of the target mass of the provisional kilogram standard made four years earlier. That same year, 1799, an all-platinum kilogram prototype was fabricated with the objective that it would equal, as close as was scientifically feasible for the day, the mass of one cubic decimetre of water at 4 \u00b0C. The prototype was presented to the Archives of the Republic in June and on December 10, 1799, the prototype was formally ratified as the kilogramme des Archives (Kilogram of the Archives) and the kilogram was defined as being equal to its mass. This standard stood for the next 90 years.\n\n\n== International prototype kilogram ==\n\nSince 1889 the magnitude of the kilogram has been defined as the mass of an object called the international prototype kilogram, often referred to in the professional metrology world as the \"IPK\". The IPK is made of a platinum alloy known as \"Pt\u201110Ir\", which is 90% platinum and 10% iridium (by mass) and is machined into a right-circular cylinder (height = diameter) of about 39 millimetres to minimize its surface area. The addition of 10% iridium improved upon the all-platinum Kilogram of the Archives by greatly increasing hardness while still retaining platinum's many virtues: extreme resistance to oxidation, extremely high density (almost twice as dense as lead and more than 21 times as dense as water), satisfactory electrical and thermal conductivities, and low magnetic susceptibility. The IPK and its six sister copies are stored at the International Bureau of Weights and Measures (known by its French-language initials BIPM) in an environmentally monitored safe in the lower vault located in the basement of the BIPM's Pavillon de Breteuil in Saint-Cloud on the outskirts of Paris (see External images, below, for photographs). Three independently controlled keys are required to open the vault. Official copies of the IPK were made available to other nations to serve as their national standards. These are compared to the IPK roughly every 40 years, thereby providing traceability of local measurements back to the IPK.\n\nThe Metre Convention was signed on May 20, 1875 and further formalized the metric system (a predecessor to the SI), quickly leading to the production of the IPK. The IPK is one of three cylinders made in 1879 by Johnson Matthey, which continues to manufacture nearly all of the national prototypes today. In 1883, the mass of the IPK was found to be indistinguishable from that of the Kilogramme des Archives made eighty-four years prior, and was formally ratified as the kilogram by the 1st CGPM in 1889.Modern measurements of Vienna Standard Mean Ocean Water, which is pure distilled water with an isotopic composition representative of the average of the world's oceans, show that it has a density of 0.999975 \u00b10.000001 kg/L at its point of maximum density (3.984 \u00b0C) under one standard atmosphere (101 325 Pa or 760 torr) of pressure. Thus, a cubic decimetre of water at its point of maximum density is only 25 parts per million less massive than the IPK; that is to say, the 25 milligram difference shows that the scientists over 219 years ago managed to make the mass of the Kilogram of the Archives equal that of a cubic decimetre of water at 4 \u00b0C, with a margin of error at most within the mass of a single excess grain of rice.\n\n\n=== Copies of the international prototype kilogram ===\n\nThe various copies of the international prototype kilogram are given the following designations in the literature:\n\nThe IPK itself, located in Saint-Cloud, France.\nSix sister copies, numbered: K1, 7, 8(41), 32, 43 and 47. Located in Saint-Cloud, France.\nTen working copies, eight (9, 31, 42\u2032, 63, 77, 88, 91, and 650) for routine use and two (25 and 73) for special use. Located in Saint-Cloud, France.\nNational prototypes, stored in Australia (44 and 87), Austria (49), Belgium (28 and 37), Brazil (66), Canada (50 and 74), China (60 and 64; 75 in Hong Kong), Czech Republic (67), Denmark (48), Egypt (58), Finland (23), France (35), Germany (52, 55 and 70), Hungary (16), India (57), Indonesia (46), Israel (71), Italy (5 and 76), Japan (6 and 94), Kazakhstan, Kenya (95), Mexico (21, 90 and 96), Netherlands (53), North Korea (68), Norway (36), Pakistan (93), Poland (51), Portugal (69), Romania (2), Russia (12 and 26), Serbia (11 and 29), Singapore (83), Slovakia (41 and 65), South Africa (56), South Korea (39, 72 and 84), Spain (24 and 3), Sweden (40 and 86), Switzerland (38 and 89), Taiwan (78), Thailand (80), Turkey (54), United Kingdom (18, 81 and 82) and the United States (20, 4, 79, 85 and 92).\nSome additional copies held by non-national organizations, such as the French Academy of Sciences in Paris (34) and the Istituto di Metrologia G. Colonnetti in Turin (62).\n\n\n=== Stability of the international prototype kilogram ===\nBy definition, the error in the measured value of the IPK's mass is exactly zero; the mass of the IPK is the kilogram. However, any changes in the IPK's mass over time can be deduced by comparing its mass to that of its official copies stored throughout the world, a rarely undertaken process called \"periodic verification\". The only three verifications occurred in 1889, 1948, and 1989. For instance, the US owns four 90% platinum / 10% iridium (Pt\u201110Ir) kilogram standards, two of which, K4 and K20, are from the original batch of 40 replicas delivered in 1884. The K20 prototype was designated as the primary national standard of mass for the US. Both of these, as well as those from other nations, are periodically returned to the BIPM for verification. Extraordinary care is exercised when transporting prototypes. In 1984, the K4 and K20 prototypes were hand-carried in the passenger section of separate commercial airliners.\nNote that none of the replicas has a mass precisely equal to that of the IPK; their masses are calibrated and documented as offset values. For instance, K20, the US's primary standard, originally had an official mass of 1 kg \u2212 39 \u03bcg (micrograms) in 1889; that is to say, K20 was 39 \u03bcg less than the IPK. A verification performed in 1948 showed a mass of 1 kg \u2212 19 \u03bcg. The latest verification performed in 1989 shows a mass precisely identical to its original 1889 value. Quite unlike transient variations such as this, the US's check standard, K4, has persistently declined in mass relative to the IPK\u2014and for an identifiable reason: check standards are used much more often than primary standards and are prone to scratches and other wear. K4 was originally delivered with an official mass of 1 kg \u2212 75 \u03bcg in 1889, but as of 1989 was officially calibrated at 1 kg \u2212 106 \u03bcg and ten years later was 1 kg \u2212 116 \u03bcg. Over a period of 110 years, K4 lost 41 \u03bcg relative to the IPK.\n\nBeyond the simple wear that check standards can experience, the mass of even the carefully stored national prototypes can drift relative to the IPK for a variety of reasons, some known and some unknown. Since the IPK and its replicas are stored in air (albeit under two or more nested bell jars), they gain mass through adsorption of atmospheric contamination onto their surfaces. Accordingly, they are cleaned in a process the BIPM developed between 1939 and 1946 known as \"the BIPM cleaning method\" that comprises firmly rubbing with a chamois soaked in equal parts ether and ethanol, followed by steam cleaning with bi-distilled water, and allowing the prototypes to settle for 7\u201310 days before verification. Before the BIPM's published report in 1994 detailing the relative change in mass of the prototypes, different standard bodies used different techniques to clean their prototypes. The NIST's practice before then was to soak and rinse its two prototypes first in benzene, then in ethanol, and to then clean them with a jet of bi-distilled water steam. Cleaning the prototypes removes between 5 and 60 \u03bcg of contamination depending largely on the time elapsed since the last cleaning. Further, a second cleaning can remove up to 10 \u03bcg more. After cleaning\u2014even when they are stored under their bell jars\u2014the IPK and its replicas immediately begin gaining mass again. The BIPM even developed a model of this gain and concluded that it averaged 1.11 \u03bcg per month for the first 3 months after cleaning and then decreased to an average of about 1 \u03bcg per year thereafter. Since check standards like K4 are not cleaned for routine calibrations of other mass standards\u2014a precaution to minimize the potential for wear and handling damage\u2014the BIPM's model of time-dependent mass gain has been used as an \"after cleaning\" correction factor.\nBecause the first forty official copies are made of the same alloy as the IPK and are stored under similar conditions, periodic verifications using a large number of replicas\u2014especially the national primary standards, which are rarely used\u2014can convincingly demonstrate the stability of the IPK. What has become clear after the third periodic verification performed between 1988 and 1992 is that masses of the entire worldwide ensemble of prototypes have been slowly but inexorably diverging from each other. It is also clear that the mass of the IPK lost perhaps 50 \u03bcg over the last century, and possibly significantly more, in comparison to its official copies. The reason for this drift has eluded physicists who have dedicated their careers to the SI unit of mass. No plausible mechanism has been proposed to explain either a steady decrease in the mass of the IPK, or an increase in that of its replicas dispersed throughout the world. Moreover, there are no technical means available to determine whether or not the entire worldwide ensemble of prototypes suffers from even greater long-term trends upwards or downwards because their mass \"relative to an invariant of nature is unknown at a level below 1000 \u03bcg over a period of 100 or even 50 years\". Given the lack of data identifying which of the world's kilogram prototypes has been most stable in absolute terms, it is equally valid to state that the first batch of replicas has, as a group, gained an average of about 25 \u03bcg over one hundred years in comparison to the IPK.What is known specifically about the IPK is that it exhibits a short-term instability of about 30 \u03bcg over a period of about a month in its after-cleaned mass. The precise reason for this short-term instability is not understood but is thought to entail surface effects: microscopic differences between the prototypes' polished surfaces, possibly aggravated by hydrogen absorption due to catalysis of the volatile organic compounds that slowly deposit onto the prototypes as well as the hydrocarbon-based solvents used to clean them.It has been possible to rule out many explanations of the observed divergences in the masses of the world's prototypes proposed by scientists and the general public. The BIPM's FAQ explains, for example, that the divergence is dependent on the amount of time elapsed between measurements and not dependent on the number of times the prototype or its copies have been cleaned or possible changes in gravity or environment. Reports published in 2013 by Peter Cumpson of Newcastle University based on the X-ray photoelectron spectroscopy of samples that were stored alongside various prototype kilograms suggested that one source of the divergence between the various prototypes could be traced to mercury that had been absorbed by the prototypes being in the proximity of mercury-based instruments. The IPK has been stored within centimetres of a mercury thermometer since at least as far back as the late 1980s. In this Newcastle University work six platinum weights made in the nineteenth century were all found to have mercury at the surface, the most contaminated of which had the equivalent of 250 \u03bcg of mercury when scaled to the surface area of a kilogram prototype.\nScientists are seeing far greater variability in the prototypes than previously believed. The increasing divergence in the masses of the world's prototypes and the short-term instability in the IPK has prompted research into improved methods to obtain a smooth surface finish using diamond turning on newly manufactured replicas and has intensified the search for a new definition of the kilogram. See \u00a7 Proposed future definitions, below.\n\n\n=== Dependency of the SI on the IPK ===\n\nThe stability of the IPK is crucial because the kilogram underpins much of the SI system of measurement as it is currently defined and structured. For instance, the newton is defined as the force necessary to accelerate one kilogram at one metre per second squared. If the mass of the IPK were to change slightly then the newton would also change proportionally. In turn, the pascal, the SI unit of pressure, is defined in terms of the newton. This chain of dependency follows to many other SI units of measure. For instance, the joule, the SI unit of energy, is defined as that expended when a force of one newton acts through one metre. Next to be affected is the SI unit of power, the watt, which is one joule per second. The ampere too is defined relative to the newton.\nWith the magnitude of the primary units of electricity thus determined by the kilogram, so too follow many others, namely the coulomb, volt, tesla, and weber.  Even units used in the measure of light would be affected; the candela\u2014following the change in the watt\u2014would in turn affect the lumen and lux.\nBecause the magnitude of many of the units comprising the SI system of measurement is ultimately defined by the mass of a 139-year-old, golf-ball-sized piece of metal, the quality of the IPK must be diligently protected to preserve the integrity of the SI system. Yet, despite the best stewardship, the average mass of the worldwide ensemble of prototypes and the mass of the IPK have likely diverged another 6.9 \u03bcg since the third periodic verification 29 years ago. Further, the world's national metrology laboratories must wait for the fourth periodic verification to confirm whether the historical trends persisted.\nFortunately, definitions of the SI units are quite different from their practical realizations. For instance, the metre is defined as the distance light travels in a vacuum during a time interval of \u200b1\u2044299,792,458 of a second. However, the metre's practical realization typically takes the form of a helium\u2013neon laser, and the metre's length is delineated\u2014not defined\u2014as 1579800.298728 wavelengths of light from this laser. Now suppose that the official measurement of the second was found to have drifted by a few parts per billion (it is actually extremely stable with a reproducibility of a few parts in 1015). \nThere would be no automatic effect on the metre because the second\u2014and thus the metre's length\u2014is abstracted via the laser comprising the metre's practical realization. Scientists performing metre calibrations would simply continue to measure out the same number of laser wavelengths until an agreement was reached to do otherwise. \nThe same is true with regard to the real-world dependency on the kilogram: if the mass of the IPK was found to have changed slightly, there would be no automatic effect upon the other units of measure because their practical realizations provide an insulating layer of abstraction. Any discrepancy would eventually have to be reconciled though, because the virtue of the SI system is its precise mathematical and logical harmony amongst its units. If the IPK's value were definitively proven to have changed, one solution would be to simply redefine the kilogram as being equal to the mass of the IPK plus an offset value, similarly to what is currently done with its replicas; e.g., \"the kilogram is equal to the mass of the IPK\u2009+\u200942 parts per billion\" (equivalent to 42 \u03bcg).\nThe long-term solution to this problem, however, is to liberate the SI system's dependency on the IPK by developing a practical realization of the kilogram that can be reproduced in different laboratories by following a written specification. The units of measure in such a practical realization would have their magnitudes precisely defined and expressed in terms of fundamental physical constants. While major portions of the SI system would still be based on the kilogram, the kilogram would in turn be based on invariant, universal constants of nature. Much work towards that end is ongoing, though no alternative has yet achieved the uncertainty of 20 parts per billion (~20 \u03bcg) required to improve upon the IPK.\n\n\n== Proposed future definitions ==\n\nIn the following subsections, wherever numeric equalities are shown in 'concise form'\u2014such as 1.85487(14)\u00d71013\u2014the two digits between the parentheses denote the uncertainty at one standard deviation (1\u03c3, the 68% confidence level) in the two least significant digits of the significand. A final X in a proposed definition denotes digits yet to be agreed on.As of 2018 the International Prototype Kilogram was the only artefact referenced by the definition of the units of the SI, directly defining the kilogram and indirectly defining several other SI units. In 1960, the metre, previously similarly having been defined with reference to a single platinum-iridium bar with two marks on it, was redefined in terms of an invariant physical constant (the wavelength of a particular emission of light emitted by krypton, and later the speed of light) so that the standard can be independently reproduced in different laboratories by following a written specification.  At the 94th Meeting of the International Committee for Weights and Measures (CIPM) in 2005, it was recommended that the same be done with the kilogram.In October 2010, the CIPM voted to submit a resolution for consideration at the General Conference on Weights and Measures (CGPM), to \"take note of an intention\" that the kilogram be defined in terms of the Planck constant, h (which has dimensions of energy times time) together with other physical constants. This resolution was accepted by the 24th conference of the CGPM in October 2011 and further discussed at the 25th conference in 2014. Although the Committee recognised that significant progress had been made, they concluded that the data did not appear sufficiently robust to adopt the revised definition, and that work should continue to enable the adoption at the 26th meeting, scheduled for 2018. Such a definition would theoretically permit any apparatus that was capable of delineating the kilogram in terms of the Planck constant to be used as long as it possessed sufficient precision, accuracy and stability. The Kibble balance (discussed below) may be able to do this.\nIn the project to replace the last artefact that underpins much of the International System of Units (SI), a variety of other very different technologies and approaches were considered and explored over many years. They too are covered below. Some of these now-abandoned approaches were based on equipment and procedures that would have enabled the reproducible production of new, kilogram-mass prototypes on demand (albeit with extraordinary effort) using measurement techniques and material properties that are ultimately based on, or traceable to, physical constants. Others were based on devices that measured either the acceleration or weight of hand-tuned kilogram test masses and which expressed their magnitudes in electrical terms via special components that permit traceability to physical constants. All approaches depend on converting a weight measurement to a mass, and therefore require the precise measurement of the strength of gravity in laboratories. All approaches would have precisely fixed one or more constants of nature at a defined value.\n\n\n=== Kibble balance ===\n\nThe Kibble balance (known as a \"watt balance\" before 2016) is essentially a single-pan weighing scale that measures the electric power necessary to oppose the weight of a kilogram test mass as it is pulled by Earth's gravity. It is a variation of an ampere balance in that it employs an extra calibration step that nulls the effect of geometry. The electric potential in the Kibble balance is delineated by a Josephson voltage standard, which allows voltage to be linked to an invariant constant of nature with extremely high precision and stability. Its circuit resistance is calibrated against a quantum Hall effect resistance standard.\nThe Kibble balance requires extremely precise measurement of the local gravitational acceleration g in the laboratory, using a gravimeter. For instance, the NIST compensates for Earth's gravity gradient of 309 \u03bcGal per metre when the elevation of the centre of the gravimeter differs from that of the nearby test mass in the Kibble balance; a change in the weight of a one-kilogram test mass that equates to about 316 \u03bcg/m.\nIn April 2007, the NIST's implementation of the Kibble balance demonstrated a combined relative standard uncertainty (CRSU) of 36 \u03bcg and a short-term resolution of 10\u221215 \u03bcg. The UK's National Physical Laboratory's Kibble balance demonstrated a CRSU of 70.3 \u03bcg in 2007. That Kibble balance was disassembled and shipped in 2009 to Canada's Institute for National Measurement Standards (part of the National Research Council), where research and development with the device could continue.\nIf the CGPM adopts the new proposal and the new definition of the kilogram becomes part of the SI, the value in SI units of the Planck constant (h), which is a measure that relates the energy of particles such as photons to their frequency, would be precisely fixed (the currently accepted value of 6.626070040(81)\u00d710\u221234 J\u22c5s has an uncertainty of about 1 in 23 million). Once agreed upon internationally, the kilogram would no longer be defined as the mass of the IPK. All the remaining unit definitions in the International System of Units (the SI) that today depend upon the kilogram and the joule would thus also have their magnitudes ultimately defined entirely in terms of constants of nature.\n\nGravity and the nature of the Kibble balance, which oscillates test masses up and down against the local gravitational acceleration g, are exploited so that mechanical power is compared against electrical power, which is the square of voltage divided by electrical resistance. However, g varies significantly\u2014by nearly 1%\u2014depending on where on the Earth's surface the measurement is made (see Earth's gravity). There are also slight seasonal variations in g at a location due to changes in underground water tables, and larger semimonthly and diurnal changes due to tidal distortions in the Earth's shape caused by the Moon and the Sun. Although g would not be a term in the definition of the kilogram, it would be crucial in the process of measurement of the kilogram when relating energy to power. Accordingly, g must be measured with at least as much precision and accuracy as are the other terms, so measurements of g must also be traceable to fundamental constants of nature. For the most precise work in mass metrology, g is measured using dropping-mass absolute gravimeters that contain an iodine-stabilized helium\u2013neon laser interferometer. The fringe-signal, frequency-sweep output from the interferometer is measured with a rubidium atomic clock. Since this type of dropping-mass gravimeter derives its accuracy and stability from the constancy of the speed of light as well as the innate properties of helium, neon, and rubidium atoms, the 'gravity' term in the delineation of an all-electronic kilogram is also measured in terms of invariants of nature\u2014and with very high precision. For instance, in the basement of the NIST's Gaithersburg facility in 2009, when measuring the gravity acting upon Pt\u201110Ir test masses (which are denser, smaller, and have a slightly lower center of gravity inside the Kibble balance than stainless steel masses), the measured value was typically within 8 ppb of 9.80101644 m/s2.The virtue of electronic realizations like the Kibble balance is that the definition and dissemination of the kilogram would no longer be dependent upon the stability of kilogram prototypes, which must be very carefully handled and stored. It would free physicists from the need to rely on assumptions about the stability of those prototypes. Instead, hand-tuned, close-approximation mass standards would simply be weighed and documented as being equal to one kilogram plus an offset value. With the Kibble balance, while the kilogram would be delineated in electrical and gravity terms, all of which are traceable to invariants of nature; it would be defined in a manner that is directly traceable to three fundamental constants of nature. The Planck constant defines the kilogram in terms of the second and the metre. By fixing the Planck constant, the definition of the kilogram would in addition depend only on the definitions of the second and the metre. The definition of the second depends on a single defined physical constant: the ground state hyperfine splitting frequency of the caesium 133 atom \u0394\u03bd(133Cs)hfs. The metre depends on the second and on an additional defined physical constant: the speed of light c. If the kilogram is redefined in this manner, physical objects such as the IPK would no longer be part of the definition, but would instead become transfer standards.\nScales like the Kibble balance also permit more flexibility in choosing materials with especially desirable properties for mass standards. For instance, Pt\u201110Ir could continue to be used so that the specific gravity of newly produced mass standards would be the same as existing national primary and check standards (\u224821.55 g/ml). This would reduce the relative uncertainty when making mass comparisons in air. Alternatively, entirely different materials and constructions could be explored with the objective of producing mass standards with greater stability. For instance, osmium-iridium alloys could be investigated if platinum's propensity to absorb hydrogen (due to catalysis of VOCs and hydrocarbon-based cleaning solvents) and atmospheric mercury proved to be sources of instability. Also, vapor-deposited, protective ceramic coatings like nitrides could be investigated for their suitability for chemically isolating these new alloys.\nThe challenge with Kibble balances is not only in reducing their uncertainty, but also in making them truly practical realizations of the kilogram. Nearly every aspect of Kibble balances and their support equipment requires such extraordinarily precise and accurate, state-of-the-art technology that\u2014unlike a device like an atomic clock\u2014few countries would currently choose to fund their operation. For instance, the NIST's Kibble balance used four resistance standards in 2007, each of which was rotated through the Kibble balance every two to six weeks after being calibrated in a different part of NIST headquarters facility in Gaithersburg, Maryland. It was found that simply moving the resistance standards down the hall to the Kibble balance after calibration altered their values 10 ppb (equivalent to 10 \u03bcg) or more. Present-day technology is insufficient to permit stable operation of Kibble balances between even biannual calibrations. If the kilogram is defined in terms of the Planck constant, it is likely there will only be a few\u2014at most\u2014Kibble balances initially operating in the world.\nAlternative approaches to redefining the kilogram that were fundamentally different from the Kibble balance were explored to varying degrees with some abandoned, as follows:\n\n\n=== Atom-counting approaches ===\n\n\n==== Carbon-12 ====\nThough not offering a practical realization, this definition would precisely define the magnitude of the kilogram in terms of a certain number of carbon\u201112 atoms. Carbon\u201112 (12C) is an isotope of carbon. The mole is currently defined as \"the quantity of entities (elementary particles like atoms or molecules) equal to the number of atoms in 12 grams of carbon\u201112\". Thus, the current definition of the mole requires that \u200b1000\u204412 moles (\u200b83 1\u20443 mol) of 12C has a mass of precisely one kilogram. The number of atoms in a mole, a quantity known as the Avogadro constant, is experimentally determined, and the current best estimate of its value is 6.022140857(74)\u00d71023 entities per mole. This new definition of the kilogram proposed to fix the Avogadro constant at precisely 6.02214X\u00d710^23 with the kilogram being defined as \"the mass equal to that of \u200b1000\u204412 \u22c5 6.02214X\u00d710^23 atoms of 12C\".\nThe accuracy of the measured value of the Avogadro constant is currently limited by the uncertainty in the value of the Planck constant. That relative standard uncertainty has been 50 parts per billion (ppb) since 2006. By fixing the Avogadro constant, the practical effect of this proposal would be that the uncertainty in the mass of a 12C atom\u2014and the magnitude of the kilogram\u2014could be no better than the current 50 ppb uncertainty in the Planck constant. Under this proposal, the magnitude of the kilogram would be subject to future refinement as improved measurements of the value of the Planck constant become available; electronic realizations of the kilogram would be recalibrated as required. Conversely, an electronic definition of the kilogram (see \u00a7 Electronic approaches, below), which would precisely fix the Planck constant, would continue to allow \u200b83 1\u20443 moles of 12C to have a mass of precisely one kilogram but the number of atoms comprising a mole (the Avogadro constant) would continue to be subject to future refinement.\nA variation on a 12C-based definition proposes to define the Avogadro constant as being precisely 844468893 (\u2248 6.02214162\u00d71023) atoms. An imaginary realization of a 12-gram mass prototype would be a cube of 12C atoms measuring precisely 84446889 atoms across on a side. With this proposal, the kilogram would be defined as \"the mass equal to 844468893 \u00d7 \u200b83 1\u20443 atoms of 12C.\"\n\n\n==== Avogadro project ====\n \n\nAnother Avogadro constant-based approach, known as the International Avogadro Coordination's Avogadro project, would define and delineate the kilogram as a 93.6 mm diameter sphere of silicon atoms. Silicon was chosen because a commercial infrastructure with mature processes for creating defect-free, ultra-pure monocrystalline silicon already exists to service the semiconductor industry. To make a practical realization of the kilogram, a silicon boule (a rod-like, single-crystal ingot) would be produced. Its isotopic composition would be measured with a mass spectrometer to determine its average relative atomic mass. The boule would be cut, ground, and polished into spheres. The size of a select sphere would be measured using optical interferometry to an uncertainty of about 0.3 nm on the radius\u2014roughly a single atomic layer. The precise lattice spacing between the atoms in its crystal structure (\u2248 192 pm) would be measured using a scanning X-ray interferometer. This permits its atomic spacing to be determined with an uncertainty of only three parts per billion. With the size of the sphere, its average atomic mass, and its atomic spacing known, the required sphere diameter can be calculated with sufficient precision and low uncertainty to enable it to be finish-polished to a target mass of one kilogram.\nExperiments are being performed on the Avogadro Project's silicon spheres to determine whether their masses are most stable when stored in a vacuum, a partial vacuum, or ambient pressure. However, no technical means currently exist to prove a long-term stability any better than that of the IPK's, because the most sensitive and accurate measurements of mass are made with dual-pan balances like the BIPM's FB\u20112 flexure-strip balance (see \u00a7 External links, below). Balances can only compare the mass of a silicon sphere to that of a reference mass. Given the latest understanding of the lack of long-term mass stability with the IPK and its replicas, there is no known, perfectly stable mass artefact to compare against. Single-pan scales, which measure weight relative to an invariant of nature, are not precise to the necessary long-term uncertainty of 10\u201320 parts per billion. Another issue to be overcome is that silicon oxidizes and forms a thin layer (equivalent to 5\u201320 silicon atoms deep) of silicon dioxide (quartz) and silicon monoxide. This layer slightly increases the mass of the sphere, an effect that must be accounted for when polishing the sphere to its finished size.  Oxidation is not an issue with platinum and iridium, both of which are noble metals that are roughly as cathodic as oxygen and therefore don't oxidize unless coaxed to do so in the laboratory. The presence of the thin oxide layer on a silicon-sphere mass prototype places additional restrictions on the procedures that might be suitable to clean it to avoid changing the layer's thickness or oxide stoichiometry.\nAll silicon-based approaches would fix the Avogadro constant but vary in the details of the definition of the kilogram. One approach would use silicon with all three of its natural isotopes present. About 7.78% of silicon comprises the two heavier isotopes: 29Si and 30Si. As described in \u00a7 Carbon-12 above, this method would define the magnitude of the kilogram in terms of a certain number of 12C atoms by fixing the Avogadro constant; the silicon sphere would be the practical realization. This approach could accurately delineate the magnitude of the kilogram because the masses of the three silicon nuclides relative to 12C are known with great precision (relative uncertainties of 1 ppb or better). An alternative method for creating a silicon sphere-based kilogram proposes to use isotopic separation techniques to enrich the silicon until it is nearly pure 28Si, which has a relative atomic mass of 27.9769265325(19). With this approach, the Avogadro constant would not only be fixed, but so too would the atomic mass of 28Si. As such, the definition of the kilogram would be decoupled from 12C and the kilogram would instead be defined as \u200b1000\u204427.9769265325 \u22c5 6.02214179\u00d71023 atoms of 28Si (\u2248 35.74374043 fixed moles of 28Si atoms). Physicists could elect to define the kilogram in terms of 28Si even when kilogram prototypes are made of natural silicon (all three isotopes present). Even with a kilogram definition based on theoretically pure 28Si, a silicon-sphere prototype made of only nearly pure 28Si would necessarily deviate slightly from the defined number of moles of silicon to compensate for various chemical and isotopic impurities as well as the effect of surface oxides.\n\n\n==== Ion accumulation ====\nAnother Avogadro-based approach, ion accumulation, since abandoned, would have defined and delineated the kilogram by precisely creating new metal prototypes on demand. It would have done so by accumulating gold or bismuth ions (atoms stripped of an electron) and counting them by measuring the electric current required to neutralize the ions. Gold (197Au) and bismuth (209Bi) were chosen because they can be safely handled and have the two highest atomic masses among the mononuclidic elements that is effectively non-radioactive (bismuth) or is perfectly stable (gold). See also Table of nuclides.With a gold-based definition of the kilogram for instance, the relative atomic mass of gold could have been fixed as precisely 196.9665687, from the current value of 196.9665687(6). As with a definition based upon carbon\u201112, the Avogadro constant would also have been fixed. The kilogram would then have been defined as \"the mass equal to that of precisely \u200b1000\u2044196.9665687 \u22c5 6.02214179\u00d71023 atoms of gold\" (precisely 3,057,443,620,887,933,963,384,315 atoms of gold or about 5.07700371 fixed moles).\nIn 2003, German experiments with gold at a current of only 10 \u03bcA demonstrated a relative uncertainty of 1.5%. Follow-on experiments using bismuth ions and a current of 30 mA were expected to accumulate a mass of 30 g in six days and to have a relative uncertainty of better than 1 ppm. Ultimately, ion\u2011accumulation approaches proved to be unsuitable. Measurements required months and the data proved too erratic for the technique to be considered a viable future replacement to the IPK.Among the many technical challenges of the ion-deposition apparatus was obtaining a sufficiently high ion current (mass deposition rate) while simultaneously decelerating the ions so they could all deposit onto a target electrode embedded in a balance pan. Experiments with gold showed the ions had to be decelerated to very low energies to avoid sputtering effects\u2014a phenomenon whereby ions that had already been counted ricochet off the target electrode or even dislodged atoms that had already been deposited. The deposited mass fraction in the 2003 German experiments only approached very close to 100% at ion energies of less than around 1 eV (< 1 km/s for gold).If the kilogram had been defined as a precise quantity of gold or bismuth atoms deposited with an electric current, not only would the Avogadro constant and the atomic mass of gold or bismuth have to have been precisely fixed, but also the value of the elementary charge (e), likely to 1.60217X\u00d710^\u221219 C (from the currently recommended value of 1.6021766208(98)\u00d710\u221219 C). Doing so would have effectively defined the ampere as a flow of \u200b1\u20441.60217X\u00d710^\u221219 electrons per second past a fixed point in an electric circuit. The SI unit of mass would have been fully defined by having precisely fixed the values of the Avogadro constant and elementary charge, and by exploiting the fact that the atomic masses of bismuth and gold atoms are invariant, universal constants of nature.\nBeyond the slowness of making a new mass standard and the poor reproducibility, there were other intrinsic shortcomings to the ion\u2011accumulation approach that proved to be formidable obstacles to ion-accumulation-based techniques becoming a practical realization. The apparatus necessarily required that the deposition chamber have an integral balance system to enable the convenient calibration of a reasonable quantity of transfer standards relative to any single internal ion-deposited prototype. Furthermore, the mass prototypes produced by ion deposition techniques would have been nothing like the freestanding platinum-iridium prototypes currently in use; they would have been deposited onto\u2014and become part of\u2014an electrode imbedded into one pan of a special balance integrated into the device. Moreover, the ion-deposited mass wouldn't have had a hard, highly polished surface that can be vigorously cleaned like those of current prototypes. Gold, while dense and a noble metal (resistant to oxidation and the formation of other compounds), is extremely soft so an internal gold prototype would have to be kept well isolated and scrupulously clean to avoid contamination and the potential of wear from having to remove the contamination. Bismuth, which is an inexpensive metal used in low-temperature solders, slowly oxidizes when exposed to room-temperature air and forms other chemical compounds and so would not have produced stable reference masses unless it was continually maintained in a vacuum or inert atmosphere.\n\n\n=== Ampere-based force ===\n\nThis approach would define the kilogram as \"the mass which would be accelerated at precisely 2\u00d710\u22127 m/s2 when subjected to the per-metre force between two straight parallel conductors of infinite length, of negligible circular cross section, placed one metre apart in vacuum, through which flow a constant current of \u200b1\u20441.60217X\u00d710^\u221219 elementary charges per second\".\nEffectively, this would define the kilogram as a derivative of the ampere rather than the present relationship, which defines the ampere as a derivative of the kilogram. This redefinition of the kilogram would specify elementary charge (e) as precisely 1.60217X\u00d710^\u221219 coulomb rather than the current recommended value of 1.6021766208(98)\u00d710\u221219 C. It would necessarily follow that the ampere (one coulomb per second) would also become an electric current of this precise quantity of elementary charges per second passing a given point in an electric circuit.\nThe virtue of a practical realization based upon this definition is that unlike the Kibble balance and other scale-based methods, all of which require the careful characterization of gravity in the laboratory, this method delineates the magnitude of the kilogram directly in the very terms that define the nature of mass: acceleration due to an applied force. Unfortunately, it is extremely difficult to develop a practical realization based upon accelerating masses. Experiments over a period of years in Japan with a superconducting, 30 g mass supported by diamagnetic levitation never achieved an uncertainty better than ten parts per million. Magnetic hysteresis was one of the limiting issues. Other groups performed similar research that used different techniques to levitate the mass.\n\n\n== SI multiples ==\n\nBecause SI prefixes may not be concatenated (serially linked) within the name or symbol for a unit of measure, SI prefixes are used with the gram, not the kilogram, which already has a prefix as part of its name. For instance, one-millionth of a kilogram is 1 mg (one milligram), not 1 \u03bckg (one microkilogram).\n\nThe microgram is typically abbreviated \"mcg\" in pharmaceutical and nutritional supplement labelling, to avoid confusion, since the \"\u03bc\" prefix is not always well recognized outside of technical disciplines. (The expression \"mcg\" is also the symbol for an obsolete CGS unit of measure known as the \"millicentigram\", which is equal to 10 \u03bcg.)\nIn the United Kingdom, because serious medication errors have been made from the confusion between milligrams and micrograms when micrograms has been abbreviated, the recommendation given in the Scottish Palliative Care Guidelines is that doses of less than one milligram must be expressed in micrograms and that the word microgram must be written in full, and that it is never acceptable to use \"mcg\" or \"\u03bcg\".[2]\nThe hectogram is a very commonly used unit in the retail food trade in Italy, usually called an etto, short for ettogrammo, the Italian for hectogram.\nThe former standard spelling and abbreviation \"deka-\" and \"dk\" produced abbreviations such as \"dkm\" (dekametre) and \"dkg\" (dekagram).  The abbreviation \"dkg\" is still used in parts of central Europe in retail for some foods such as cheese and meat.\nThe unit name megagram is rarely used, and even then typically only in technical fields in contexts where especially rigorous consistency with the SI standard is desired. For most purposes, the name tonne is instead used. The tonne and its symbol, \"t\", were adopted by the CIPM in 1879. It is a non-SI unit accepted by the BIPM for use with the SI. According to the BIPM, \"In English speaking countries this unit is usually called 'metric ton'.\" The unit name megatonne or megaton (Mt) is often used in general-interest literature on greenhouse gas emissions, whereas the equivalent unit in scientific papers on the subject is often the teragram (Tg).\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNIST Improves Accuracy of 'Watt Balance' Method for Defining the Kilogram\nThe UK's National Physical Laboratory (NPL): Are any problems caused by having the kilogram defined in terms of a physical artefact? (FAQ - Mass & Density)\nNPL: NPL Kibble balance\nMetrology in France: Watt balance\nAustralian National Measurement Institute: Redefining the kilogram through the Avogadro constant\nInternational Bureau of Weights and Measures (BIPM): Home page\nNZZ Folio: What a kilogram really weighs\nNPL: What are the differences between mass, weight, force and load?\nBBC: Getting the measure of a kilogram\nNPR: This Kilogram Has A Weight-Loss Problem, an interview with National Institute of Standards and Technology physicist Richard Steiner\nAvogadro and molar Planck constants for the redefinition of the kilogram\nRealization of the awaited definition of the kilogram",
        "unit": "kilogram",
        "url": "https://en.wikipedia.org/wiki/Kilogram"
    },
    {
        "_id": "Volume",
        "clean": "Volume",
        "text": "Volume is the quantity of three-dimensional space enclosed by a closed surface, for example, the space that a substance (solid, liquid, gas, or plasma) or shape occupies or contains. Volume is often quantified numerically using the SI derived unit, the cubic metre. The volume of a container is generally understood to be the capacity of the container; i. e., the amount of fluid (gas or liquid) that the container could hold, rather than the amount of space the container itself displaces.\nThree dimensional mathematical shapes are also assigned volumes. Volumes of some simple shapes, such as regular, straight-edged, and circular shapes can be easily calculated using arithmetic formulas. Volumes of complicated shapes can be calculated with integral calculus if a formula exists for the shape's boundary. One-dimensional figures (such as lines) and two-dimensional shapes (such as squares) are assigned zero volume in the three-dimensional space.\nThe volume of a solid (whether regularly or irregularly shaped) can be determined by fluid displacement. Displacement of liquid can also be used to determine the volume of a gas. The combined volume of two substances is usually greater than the volume of just one of the substances. However, sometimes one substance dissolves in the other and in such cases the combined volume is not additive.In differential geometry, volume is expressed by means of the volume form, and is an important global Riemannian invariant.\nIn thermodynamics, volume is a fundamental parameter, and is a conjugate variable to pressure.\n\n\n== Units ==\n\nAny unit of length gives a corresponding unit of volume: the volume of a cube whose sides have the given length.  For example, a cubic centimetre (cm3) is the volume of a cube whose sides are one centimetre (1 cm) in length.\nIn the International System of Units (SI), the standard unit of volume is the cubic metre (m3).  The metric system also includes the litre (L) as a unit of volume, where one litre is the volume of a 10-centimetre cube.  Thus\n\n1 litre = (10 cm)3 = 1000 cubic centimetres = 0.001 cubic metres,so\n\n1 cubic metre = 1000 litres.Small amounts of liquid are often measured in millilitres, where\n\n1 millilitre = 0.001 litres = 1 cubic centimetre.In the same way, large amounts can be measured in megalitres, where\n\n1 million litres = 1000 cubic metres = 1 megalitre.Various other traditional units of volume are also in use, including the cubic inch, the cubic foot, the cubic yard, the cubic mile, the teaspoon, the tablespoon, the fluid ounce, the fluid dram, the gill, the pint, the quart, the gallon, the minim, the barrel, the cord, the peck, the bushel, the hogshead, the acre-foot and the board foot.\n\n\n== Related terms ==\nCapacity is defined by the Oxford English Dictionary as \"the measure applied to the content of a vessel, and to liquids, grain, or the like, which take the shape of that which holds them\". (The word capacity has other unrelated meanings, as in e.g. capacity management.) Capacity is not identical in meaning to volume, though closely related; the capacity of a container is always the volume in its interior. Units of capacity are the SI litre and its derived units, and Imperial units such as gill, pint, gallon, and others. Units of volume are the cubes of units of length. In SI the units of volume and capacity are closely related: one litre is exactly 1 cubic decimetre, the capacity of a cube with a 10 cm side. In other systems the conversion is not trivial; the capacity of a vehicle's fuel tank is rarely stated in cubic feet, for example, but in gallons (an imperial gallon fills a volume of 0.1605 cu ft).\nThe density of an object is defined as the ratio of the mass to the volume. The inverse of density is specific volume which is defined as volume divided by mass. Specific volume is a concept important in thermodynamics where the volume of a working fluid is often an important parameter of a system being studied.\nThe volumetric flow rate in fluid dynamics is the volume of fluid which passes through a given surface per unit time (for example cubic meters per second [m3 s\u22121]).\n\n\n== Volume in calculus ==\n\nIn calculus, a branch of mathematics, the volume of a region D in R3 is given by a triple integral of the constant function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        =\n        1\n      \n    \n    {\\displaystyle f(x,y,z)=1}\n   and is usually written as:\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        1\n        \n        d\n        x\n        \n        d\n        y\n        \n        d\n        z\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}1\\,dx\\,dy\\,dz.}\n  The volume integral in cylindrical coordinates is\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        r\n        \n        d\n        r\n        \n        d\n        \u03b8\n        \n        d\n        z\n        ,\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}r\\,dr\\,d\\theta \\,dz,}\n  and the volume integral in spherical coordinates (using the convention for angles with \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   as the azimuth and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   measured from the polar axis; see more on conventions) has the form\n\n  \n    \n      \n        \n          \u222d\n          \n            D\n          \n        \n        \n          \u03c1\n          \n            2\n          \n        \n        sin\n        \u2061\n        \u03d5\n        \n        d\n        \u03c1\n        \n        d\n        \u03b8\n        \n        d\n        \u03d5\n        .\n      \n    \n    {\\displaystyle \\iiint \\limits _{D}\\rho ^{2}\\sin \\phi \\,d\\rho \\,d\\theta \\,d\\phi .}\n  \n\n\n== Volume formulas ==\n\n\n=== Volume ratios for a cone, sphere and cylinder of the same radius and height ===\n\nThe above formulas can be used to show that the volumes of a cone, sphere and cylinder of the same radius and height are in the ratio 1 : 2 : 3, as follows.\nLet the radius be r and the height be h (which is 2r for the sphere), then the volume of cone is\n\n  \n    \n      \n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          (\n          \n            2\n            r\n          \n          )\n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        1\n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{3}}\\pi r^{2}h={\\frac {1}{3}}\\pi r^{2}\\left(2r\\right)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 1,}\n  the volume of the sphere is\n\n  \n    \n      \n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        2\n        ,\n      \n    \n    {\\displaystyle {\\frac {4}{3}}\\pi r^{3}=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 2,}\n  while the volume of the cylinder is\n\n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        (\n        2\n        r\n        )\n        =\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            \u03c0\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u00d7\n        3.\n      \n    \n    {\\displaystyle \\pi r^{2}h=\\pi r^{2}(2r)=\\left({\\frac {2}{3}}\\pi r^{3}\\right)\\times 3.}\n  The discovery of the 2 : 3 ratio of the volumes of the sphere and cylinder is credited to Archimedes.\n\n\n=== Volume formula derivations ===\n\n\n==== Sphere ====\nThe volume of a sphere is the integral of an infinite number of infinitesimally small circular disks of thickness dx. The calculation for the volume of a sphere with center 0 and radius r is as follows.\nThe surface area of the circular disk is \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n  .\nThe radius of the circular disks, defined such that the x-axis cuts perpendicularly through them, is\n\n  \n    \n      \n        y\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle y={\\sqrt {r^{2}-x^{2}}}}\n  or\n\n  \n    \n      \n        z\n        =\n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle z={\\sqrt {r^{2}-x^{2}}}}\n  where y or z can be taken to represent the radius of a disk at a particular x value.\nUsing y as the disk radius, the volume of the sphere can be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          y\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n          )\n        \n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi y^{2}\\,dx=\\int _{-r}^{r}\\pi \\left(r^{2}-x^{2}\\right)\\,dx.}\n  Now\n\n  \n    \n      \n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        x\n        \u2212\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \u03c0\n        \n          x\n          \n            2\n          \n        \n        \n        d\n        x\n        =\n        \u03c0\n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        \u2212\n        \n          \n            \u03c0\n            3\n          \n        \n        \n          (\n          \n            \n              r\n              \n                3\n              \n            \n            +\n            \n              r\n              \n                3\n              \n            \n          \n          )\n        \n        =\n        2\n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        \u2212\n        \n          \n            \n              2\n              \u03c0\n              \n                r\n                \n                  3\n                \n              \n            \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{-r}^{r}\\pi r^{2}\\,dx-\\int _{-r}^{r}\\pi x^{2}\\,dx=\\pi \\left(r^{3}+r^{3}\\right)-{\\frac {\\pi }{3}}\\left(r^{3}+r^{3}\\right)=2\\pi r^{3}-{\\frac {2\\pi r^{3}}{3}}.}\n  Combining yields \n  \n    \n      \n        V\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle V={\\frac {4}{3}}\\pi r^{3}.}\n  \nThis formula can be derived more quickly using the formula for the sphere's surface area, which is \n  \n    \n      \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 4\\pi r^{2}}\n  . The volume of the sphere consists of layers of infinitesimally thin spherical shells, and the sphere volume is equal to\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            r\n          \n        \n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        r\n        =\n        \n          \n            4\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle \\int _{0}^{r}4\\pi r^{2}\\,dr={\\frac {4}{3}}\\pi r^{3}.}\n  \n\n\n==== Cone ====\nThe cone is a type of pyramidal shape. The fundamental equation for pyramids, one-third times base times altitude, applies to cones as well.\nHowever, using calculus, the volume of a cone is the integral of an infinite number of infinitesimally thin circular disks of thickness dx. The calculation for the volume of a cone of height h, whose base is centered at (0, 0, 0) with radius r, is as follows.\nThe radius of each circular disk is r if x = 0 and 0 if x = h, and varying linearly in between\u2014that is,\n\n  \n    \n      \n        r\n        \n          \n            \n              h\n              \u2212\n              x\n            \n            h\n          \n        \n        .\n      \n    \n    {\\displaystyle r{\\frac {h-x}{h}}.}\n  The surface area of the circular disk is then\n\n  \n    \n      \n        \u03c0\n        \n          \n            (\n            \n              r\n              \n                \n                  \n                    h\n                    \u2212\n                    x\n                  \n                  h\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\pi \\left(r{\\frac {h-x}{h}}\\right)^{2}=\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}.}\n  The volume of the cone can then be calculated as\n\n  \n    \n      \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        \n          \n            \n              (\n              h\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle \\int _{0}^{h}\\pi r^{2}{\\frac {(h-x)^{2}}{h^{2}}}dx,}\n  and after extraction of the constants\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          \u222b\n          \n            0\n          \n          \n            h\n          \n        \n        (\n        h\n        \u2212\n        x\n        \n          )\n          \n            2\n          \n        \n        d\n        x\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\int _{0}^{h}(h-x)^{2}dx}\n  Integrating gives us\n\n  \n    \n      \n        \n          \n            \n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n            \n              h\n              \n                2\n              \n            \n          \n        \n        \n          (\n          \n            \n              \n                h\n                \n                  3\n                \n              \n              3\n            \n          \n          )\n        \n        =\n        \n          \n            1\n            3\n          \n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        h\n        .\n      \n    \n    {\\displaystyle {\\frac {\\pi r^{2}}{h^{2}}}\\left({\\frac {h^{3}}{3}}\\right)={\\frac {1}{3}}\\pi r^{2}h.}\n  \n\n\n==== Polyhedron ====\n\n\n== Volume in differential geometry ==\n\nIn differential geometry, a branch of mathematics, a volume form on a differentiable manifold is a differential form of top degree (i.e., whose degree is equal to the dimension of the manifold) that is nowhere equal to zero.  A manifold has a volume form if and only if it is orientable. An orientable manifold has infinitely many volume forms, since multiplying a volume form by a non-vanishing function yields another volume form. On non-orientable manifolds, one may instead define the weaker notion of a density. Integrating the volume form gives the volume of the manifold according to that form.\nAn oriented pseudo-Riemannian manifold has a natural volume form.  In local coordinates, it can be expressed as\n\n  \n    \n      \n        \u03c9\n        =\n        \n          \n            \n              |\n            \n            g\n            \n              |\n            \n          \n        \n        \n        d\n        \n          x\n          \n            1\n          \n        \n        \u2227\n        \u22ef\n        \u2227\n        d\n        \n          x\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\omega ={\\sqrt {|g|}}\\,dx^{1}\\wedge \\dots \\wedge dx^{n},}\n  where the \n  \n    \n      \n        d\n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle dx^{i}}\n   are 1-forms that form a positively oriented basis for the cotangent bundle of the manifold, and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   is the determinant of the matrix representation of the metric tensor on the manifold in terms of the same basis.\n\n\n== Volume in thermodynamics ==\n\nIn thermodynamics, the volume of a system is an important extensive parameter for describing its thermodynamic state. The specific volume, an intensive property, is the system's volume per unit of mass. Volume is a function of state and is interdependent with other thermodynamic properties such as pressure and temperature. For example, volume is related to the pressure and temperature of an ideal gas by the ideal gas law.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n Perimeters, Areas, Volumes at Wikibooks\n Volume at Wikibooks",
        "unit": "volume",
        "url": "https://en.wikipedia.org/wiki/Volume"
    },
    {
        "_id": "Radioactive_decay",
        "clean": "Radioactive decay",
        "text": "Radioactive decay (also known as nuclear decay, radioactivity or nuclear radiation) is the process by which an unstable atomic nucleus loses energy (in terms of mass in its rest frame) by emitting radiation, such as an alpha particle, beta particle with neutrino or only a neutrino in the case of electron capture, or a gamma ray or electron in the case of internal conversion. A material containing such unstable nuclei is considered radioactive. Certain highly excited short-lived nuclear states can decay through neutron emission, or more rarely, proton emission.\nRadioactive decay is a stochastic (i.e. random) process at the level of single atoms. According to quantum theory, it is impossible to predict when a particular atom will decay, regardless of how long the atom has existed. However, for a collection of atoms, the collection's expected decay rate is characterized in terms of their measured decay constants or half-lives. This is the basis of radiometric dating. The half-lives of radioactive atoms have no known upper limit, spanning a time range of over 55 orders of magnitude, from nearly instantaneous to far longer than the age of the universe.\nA radioactive nucleus with zero spin can have no defined orientation, and hence emits the total momentum of its decay products isotropically (all directions and without bias). If there are multiple particles produced during a single decay, as in beta decay, their relative angular distribution, or spin directions may not be isotropic. Decay products from a nucleus with spin may be distributed non-isotropically with respect to that spin direction, either because of an external influence such as an electromagnetic field, or because the nucleus was produced in a dynamic process that constrained the direction of its spin. Such a parent process could be a previous decay, or a nuclear reaction.The decaying nucleus is called the parent radionuclide (or parent radioisotope), and the process produces at least one daughter nuclide. Except for gamma decay or internal conversion from a nuclear excited state, the decay is a nuclear transmutation resulting in a daughter containing a different number of protons or neutrons (or both). When the number of protons changes, an atom of a different chemical element is created.\nThe first decay processes to be discovered were alpha decay, beta decay, and gamma decay. Alpha decay occurs when the nucleus ejects an alpha particle (helium nucleus). This is the most common process of emitting nucleons, but highly excited nuclei can eject single nucleons, or in the case of cluster decay, specific light nuclei of other elements. Beta decay occurs in two ways:\n(i) beta-minus decay, when the nucleus emits an electron and an antineutrino in a process that changes a neutron to a proton, or\n(ii) beta-plus decay, when the nucleus emits a positron and a neutrino in a process that changes a proton to a neutron. \nHighly excited neutron-rich nuclei, formed as the product of other types of decay, occasionally lose energy by way of neutron emission, resulting in a change from one isotope to another of the same element. The nucleus may capture an orbiting electron, causing a proton to convert into a neutron in a process called electron capture. All of these processes result in a well-defined nuclear transmutation.\nBy contrast, there are radioactive decay processes that do not result in a nuclear transmutation. The energy of an excited nucleus may be emitted as a gamma ray in a process called gamma decay, or that energy may be lost when the nucleus interacts with an orbital electron causing its ejection from the atom, in a process called internal conversion.\nAnother type of radioactive decay results in products that vary, appearing as two or more \"fragments\" of the original nucleus with a range of possible masses. This decay, called spontaneous fission, happens when a large unstable nucleus spontaneously splits into two (or occasionally three) smaller daughter nuclei, and generally leads to the emission of gamma rays, neutrons, or other particles from those products.\nFor a summary table showing the number of stable and radioactive nuclides in each category, see radionuclide. There are 28 naturally occurring chemical elements on Earth that are radioactive, consisting of 33 radionuclides (5 elements have 2 different radionuclides) that date before the time of formation of the solar system. These 33 are known as primordial nuclides. Well-known examples are uranium and thorium, but also included are naturally occurring long-lived radioisotopes, such as potassium-40. Another 50 or so shorter-lived radionuclides, such as radium and radon, found on Earth, are the products of decay chains that began with the primordial nuclides, or are the product of ongoing cosmogenic processes, such as the production of carbon-14 from nitrogen-14 in the atmosphere by cosmic rays. Radionuclides may also be produced artificially in particle accelerators or nuclear reactors, resulting in 650 of these with half-lives of over an hour, and several thousand more with even shorter half-lives. [See here for a list of these sorted by half life.]\n\n\n== History of discovery ==\n\nRadioactivity was discovered in 1896 by the French scientist Henri Becquerel, while working with phosphorescent materials. These materials glow in the dark after exposure to light, and he suspected that the glow produced in cathode ray tubes by X-rays might be associated with phosphorescence. He wrapped a photographic plate in black paper and placed various phosphorescent salts on it. All results were negative until he used uranium salts. The uranium salts caused a blackening of the plate in spite of the plate being wrapped in black paper. These radiations were given the name \"Becquerel Rays\".\nIt soon became clear that the blackening of the plate had nothing to do with phosphorescence, as the blackening was also produced by non-phosphorescent salts of uranium and metallic uranium. It became clear from these experiments that there was a form of invisible radiation that could pass through paper and was causing the plate to react as if exposed to light.\nAt first, it seemed as though the new radiation was similar to the then recently discovered X-rays. Further research by Becquerel, Ernest Rutherford, Paul Villard, Pierre Curie, Marie Curie, and others showed that this form of radioactivity was significantly more complicated. Rutherford was the first to realize that all such elements decay in accordance with the same mathematical exponential formula. Rutherford and his student Frederick Soddy were the first to realize that many decay processes resulted in the transmutation of one element to another. Subsequently, the radioactive displacement law of Fajans and Soddy was formulated to describe the products of alpha and beta decay.The early researchers also discovered that many other chemical elements, besides uranium, have radioactive isotopes. A systematic search for the total radioactivity in uranium ores also guided Pierre and Marie Curie to isolate two new elements: polonium and radium. Except for the radioactivity of radium, the chemical similarity of radium to barium made these two elements difficult to distinguish.\nMarie and Pierre Curie\u2019s study of radioactivity is an important factor in science and medicine. After their research on Becquerel's rays led them to the discovery of both radium and polonium, they coined the term \"radioactivity\". Their research on the penetrating rays in uranium and the discovery of radium launched an era of using radium for the treatment of cancer. Their exploration of radium could be seen as the first peaceful use of nuclear energy and the start of modern nuclear medicine.\n\n\n== Early health dangers ==\n\nThe dangers of ionizing radiation due to radioactivity and X-rays were not immediately recognized.\n\n\n=== X-rays ===\nThe discovery of x\u2011rays by Wilhelm R\u00f6ntgen in 1895 led to widespread experimentation by scientists, physicians, and inventors. Many people began recounting stories of burns, hair loss and worse in technical journals as early as 1896. In February of that year, Professor Daniel and Dr. Dudley of Vanderbilt University performed an experiment involving X-raying Dudley's head that resulted in his hair loss. A report by Dr. H.D. Hawks, of his suffering severe hand and chest burns in an X-ray demonstration, was the first of many other reports in Electrical Review.Other experimenters, including Elihu Thomson and Nikola Tesla, also reported burns. Thomson deliberately exposed a finger to an X-ray tube over a period of time and suffered pain, swelling, and blistering. Other effects, including ultraviolet rays and ozone, were sometimes blamed for the damage, and many physicians still claimed that there were no effects from X-ray exposure at all.Despite this, there were some early systematic hazard investigations, and as early as 1902 William Herbert Rollins wrote almost despairingly that his warnings about the dangers involved in the careless use of X-rays were not being heeded, either by industry or by his colleagues. By this time, Rollins had proved that X-rays could kill experimental animals, could cause a pregnant guinea pig to abort, and that they could kill a fetus. He also stressed that \"animals vary in susceptibility to the external action of X-light\" and warned that these differences be considered when patients were treated by means of X-rays.\n\n\n=== Radioactive substances ===\n\nHowever, the biological effects of radiation due to radioactive substances were less easy to gauge. This gave the opportunity for many physicians and corporations to market radioactive substances as patent medicines. Examples were radium enema treatments, and radium-containing waters to be drunk as tonics. Marie Curie protested against this sort of treatment, warning that the effects of radiation on the human body were not well understood. Curie later died from aplastic anaemia, likely caused by exposure to ionizing radiation. By the 1930s, after a number of cases of bone necrosis and death of radium treatment enthusiasts, radium-containing medicinal products had been largely removed from the market (radioactive quackery).\n\n\n=== Radiation protection ===\n\nOnly a year after R\u00f6ntgen's discovery of X rays, the American engineer Wolfram Fuchs (1896) gave what is probably the first protection advice, but it was not until 1925 that the first International Congress of Radiology (ICR) was held and considered establishing international protection standards. The effects of radiation on genes, including the effect of cancer risk, were recognized much later. In 1927, Hermann Joseph Muller published research showing genetic effects and, in 1946, was awarded the Nobel Prize in Physiology or Medicine for his findings.\nThe second ICR was held in Stockholm in 1928 and proposed the adoption of the rontgen unit, and the 'International X-ray and Radium Protection Committee' (IXRPC) was formed. Rolf Sievert was named Chairman, but a driving force was George Kaye of the British National Physical Laboratory. The committee met in 1931, 1934 and 1937.\nAfter World War II, the increased range and quantity of radioactive substances being handled as a result of military and civil nuclear programmes led to large groups of occupational workers and the public being potentially exposed to harmful levels of ionising radiation. This was considered at the first post-war ICR convened in London in 1950, when the present International Commission on Radiological Protection (ICRP) was born.\nSince then the ICRP has developed the present international system of radiation protection, covering all aspects of radiation hazard.\n\n\n== Units of radioactivity ==\n\nThe International System of Units (SI) unit of radioactive activity is the becquerel (Bq), named in honor of the scientist Henri Becquerel. One Bq is defined as one transformation (or decay or disintegration) per second.\nAn older unit of radioactivity is the curie, Ci, which was originally defined as \"the quantity or mass of radium emanation in equilibrium with one gram of radium (element)\". Today, the curie is defined as 3.7\u00d71010 disintegrations per second, so that 1 curie (Ci) = 3.7\u00d71010 Bq.\nFor radiological protection purposes, although the United States Nuclear Regulatory Commission permits the use of the unit curie alongside SI units, the European Union European units of measurement directives required that its use for \"public health ... purposes\" be phased out by 31 December 1985.The effects of ionizing radiation are often measured in units of gray for mechanical or sievert for damage to tissue.\n\n\n== Types of decay ==\n\nEarly researchers found that an electric or magnetic field could split radioactive emissions into three types of beams. The rays were given the names alpha, beta, and gamma, in increasing order of their ability to penetrate matter. Alpha decay is observed only in heavier elements of atomic number 52 (tellurium) and greater, with the exception of beryllium-8 which decays to two alpha particles. The other two types of decay are produced by all of the elements. Lead, atomic number 82, is the heaviest element to have any isotopes stable (to the limit of measurement) to radioactive decay. Radioactive decay is seen in all isotopes of all elements of atomic number 83 (bismuth) or greater. Bismuth-209, however, is only very slightly radioactive, with a half-life greater than the age of the universe; radioisotopes with extremely long half-lives are considered effectively stable for practical purposes.\n\nIn analysing the nature of the decay products, it was obvious from the direction of the electromagnetic forces applied to the radiations by external magnetic and electric fields that alpha particles carried a positive charge, beta particles carried a negative charge, and gamma rays were neutral. From the magnitude of deflection, it was clear that alpha particles were much more massive than beta particles. Passing alpha particles through a very thin glass window and trapping them in a discharge tube allowed researchers to study the emission spectrum of the captured particles, and ultimately proved that alpha particles are helium nuclei. Other experiments showed beta radiation, resulting from decay and cathode rays, were high-speed electrons. Likewise, gamma radiation and X-rays were found to be high-energy electromagnetic radiation.\nThe relationship between the types of decays also began to be examined: For example, gamma decay was almost always found to be associated with other types of decay, and occurred at about the same time, or afterwards. Gamma decay as a separate phenomenon, with its own half-life (now termed isomeric transition), was found in natural radioactivity to be a result of the gamma decay of excited metastable nuclear isomers, which were in turn created from other types of decay.\nAlthough alpha, beta, and gamma radiations were most commonly found, other types of emission were eventually discovered. Shortly after the discovery of the positron in cosmic ray products, it was realized that the same process that operates in classical beta decay can also produce positrons (positron emission), along with neutrinos (classical beta decay produces antineutrinos). In a more common analogous process, called electron capture, some proton-rich nuclides were found to capture their own atomic electrons instead of emitting positrons, and subsequently these nuclides emit only a neutrino and a gamma ray from the excited nucleus (and often also Auger electrons and characteristic X-rays, as a result of the re-ordering of electrons to fill the place of the missing captured electron). These types of decay involve the nuclear capture of electrons or emission of electrons or positrons, and thus acts to move a nucleus toward the ratio of neutrons to protons that has the least energy for a given total number of nucleons. This consequently produces a more stable (lower energy) nucleus.\n(A theoretical process of positron capture, analogous to electron capture, is possible in antimatter atoms, but has not been observed, as complex antimatter atoms beyond antihelium are not experimentally available. Such a decay would require antimatter atoms at least as complex as beryllium-7, which is the lightest known isotope of normal matter to undergo decay by electron capture.)\nShortly after the discovery of the neutron in 1932, Enrico Fermi realized that certain rare beta-decay reactions immediately yield neutrons as a decay particle (neutron emission). Isolated proton emission was eventually observed in some elements. It was also found that some heavy elements may undergo spontaneous fission into products that vary in composition. In a phenomenon called cluster decay, specific combinations of neutrons and protons other than alpha particles (helium nuclei) were found to be spontaneously emitted from atoms.\nOther types of radioactive decay were found to emit previously-seen particles, but via different mechanisms. An example is internal conversion, which results in an initial electron emission, and then often further characteristic X-rays and Auger electrons emissions, although the internal conversion process involves neither beta nor gamma decay. A neutrino is not emitted, and none of the electron(s) and photon(s) emitted originate in the nucleus, even though the energy to emit all of them does originate there. Internal conversion decay, like isomeric transition gamma decay and neutron emission, involves the release of energy by an excited nuclide, without the transmutation of one element into another.\nRare events that involve a combination of two beta-decay type events happening simultaneously are known (see below). Any decay process that does not violate the conservation of energy or momentum laws (and perhaps other particle conservation laws) is permitted to happen, although not all have been detected. An interesting example discussed in a final section, is bound state beta decay of rhenium-187. In this process, beta electron-decay of the parent nuclide is not accompanied by beta electron emission, because the beta particle has been captured into the K-shell of the emitting atom. An antineutrino is emitted, as in all negative beta decays.\nRadionuclides can undergo a number of different reactions. These are summarized in the following table. A nucleus with mass number A and atomic number Z is represented as (A, Z). The column \"Daughter nucleus\" indicates the difference between the new nucleus and the original nucleus. Thus, (A \u2212 1, Z) means that the mass number is one less than before, but the atomic number is the same as before.\nIf energy circumstances are favorable, a given radionuclide may undergo many competing types of decay, with some atoms decaying by one route, and others decaying by another. An example is copper-64, which has 29 protons, and 35 neutrons, which decays with a half-life of about 12.7 hours. This isotope has one unpaired proton and one unpaired neutron, so either the proton or the neutron can decay to the opposite particle. This particular nuclide (though not all nuclides in this situation) is almost equally likely to decay through positron emission (18%), or through electron capture (43%), as it does through electron emission (39%). The excited energy states resulting from these decays which fail to end in a ground energy state, also produce later internal conversion and gamma decay in almost 0.5% of the time.\nMore common in heavy nuclides is competition between alpha and beta decay. The daughter nuclides will then normally decay through beta or alpha, respectively, to end up in the same place.\n\nRadioactive decay results in a reduction of summed rest mass, once the released energy (the disintegration energy) has escaped in some way. Although decay energy is sometimes defined as associated with the difference between the mass of the parent nuclide products and the mass of the decay products, this is true only of rest mass measurements, where some energy has been removed from the product system. This is true because the decay energy must always carry mass with it, wherever it appears (see mass in special relativity) according to the formula E = mc2. The decay energy is initially released as the energy of emitted photons plus the kinetic energy of massive emitted particles (that is, particles that have rest mass). If these particles come to thermal equilibrium with their surroundings and photons are absorbed, then the decay energy is transformed to thermal energy, which retains its mass.\nDecay energy therefore remains associated with a certain measure of mass of the decay system, called invariant mass, which does not change during the decay, even though the energy of decay is distributed among decay particles. The energy of photons, the kinetic energy of emitted particles, and, later, the thermal energy of the surrounding matter, all contribute to the invariant mass of the system. Thus, while the sum of the rest masses of the particles is not conserved in radioactive decay, the system mass and system invariant mass (and also the system total energy) is conserved throughout any decay process. This is a restatement of the equivalent laws of conservation of energy and conservation of mass.\n\n\n== Radioactive decay rates ==\nThe decay rate, or activity, of a radioactive substance is characterized by:\nConstant quantities:\n\nThe half-life\u2014t1/2, is the time taken for the activity of a given amount of a radioactive substance to decay to half of its initial value; see List of nuclides.\nThe decay constant\u2014 \u03bb, \"lambda\" the reciprocal of the mean lifetime, sometimes referred to as simply decay rate.\nThe mean lifetime\u2014 \u03c4, \"tau\" the average lifetime (1/e life) of a radioactive particle before decay.Although these are constants, they are associated with the statistical behavior of populations of atoms. In consequence, predictions using these constants are less accurate for minuscule samples of atoms.\nIn principle a half-life, a third-life, or even a (1/\u221a2)-life, can be used in exactly the same way as half-life; but the mean life and half-life t1/2 have been adopted as standard times associated with exponential decay.\nTime-variable quantities:\n\nTotal activity\u2014 A, is the number of decays per unit time of a radioactive sample.\nNumber of particles\u2014N, is the total number of particles in the sample.\nSpecific activity\u2014SA, number of decays per unit time per amount of substance of the sample at time set to zero (t = 0). \"Amount of substance\" can be the mass, volume or moles of the initial sample.These are related as follows:\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              (\n              2\n              )\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        (\n        2\n        )\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln(2)}{\\lambda }}=\\tau \\ln(2)}\n  \n\n  \n    \n      \n        A\n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03bb\n        N\n      \n    \n    {\\displaystyle A=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}=\\lambda N}\n  \n\n  \n    \n      \n        \n          S\n          \n            A\n          \n        \n        \n          a\n          \n            0\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \n            \n              |\n            \n          \n          \n            t\n            =\n            0\n          \n        \n        =\n        \u03bb\n        \n          N\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle S_{A}a_{0}=-{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}{\\bigg |}_{t=0}=\\lambda N_{0}}\n  where N0 is the initial amount of active substance \u2014 substance that has the same percentage of unstable particles as when the substance was formed.\n\n\n== Mathematics of radioactive decay ==\n\n\n=== Universal law of radioactive decay ===\nRadioactivity is one very frequently given example of exponential decay. The law describes the statistical behaviour of a large number of nuclides, rather than individual atoms. In the following formalism, the number of nuclides or the nuclide population N, is of course a discrete variable (a natural number)\u2014but for any physical sample N is so large that it can be treated as a continuous variable. Differential calculus is used to model the behaviour of nuclear decay.\nThe mathematics of radioactive decay depend on a key assumption that a nucleus of a radionuclide has no \"memory\" or way of translating its history into its present behavior. A nucleus does not \"age\" with the passage of time. Thus, the probability of its breaking down does not increase with time, but stays constant no matter how long the nucleus has existed. This constant probability may vary greatly between different types of nuclei, leading to the many different observed decay rates. However, whatever the probability is, it does not change. This is in marked contrast to complex objects which do show aging, such as automobiles and humans. These systems do have a chance of breakdown per unit of time, that increases from the moment they begin their existence.\n\n\n==== One-decay process ====\nConsider the case of a nuclide A that decays into another B by some process A \u2192 B (emission of other particles, like electron neutrinos \u03bde and electrons e\u2212 as in beta decay, are irrelevant in what follows). The decay of an unstable nucleus is entirely random in time so it is impossible to predict when a particular atom will decay. However, it is equally likely to decay at any instant in time. Therefore, given a sample of a particular radioisotope, the number of decay events \u2212dN expected to occur in a small interval of time dt is proportional to the number of atoms present N, that is\n\n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                d\n              \n              N\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u221d\n        N\n        .\n      \n    \n    {\\displaystyle -{\\frac {\\mathrm {d} N}{\\mathrm {d} t}}\\propto N.}\n  Particular radionuclides decay at different rates, so each has its own decay constant \u03bb. The expected decay \u2212dN/N is proportional to an increment of time, dt:\n\nThe negative sign indicates that N decreases as time increases, as the decay events follow one after another. The solution to this first-order differential equation is the function:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  where N0 is the value of N at time t = 0, with the decay constant expressed as \u03bb or 1/\u03c4We have for all time t:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            \n              t\n              o\n              t\n              a\n              l\n            \n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle N_{A}+N_{B}=N_{\\mathrm {total} }=N_{A0},}\n  where Ntotal is the constant number of particles throughout the decay process, which is equal to the initial number of A nuclides since this is the initial substance.\nIf the number of non-decayed A nuclei is:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        \n        \n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-{\\lambda }t}\\,\\!}\n  then the number of nuclei of B, i.e. the number of decayed A nuclei, is\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \u2212\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}=N_{A0}-N_{A}=N_{A0}-N_{A0}e^{-{\\lambda }t}=N_{A0}\\left(1-e^{-{\\lambda }t}\\right).}\n  The number of decays observed over a given interval obeys Poisson statistics. If the average number of decays is <N>, the probability of a given number of decays N is\n\n  \n    \n      \n        P\n        (\n        N\n        )\n        =\n        \n          \n            \n              \u27e8\n              N\n              \n                \u27e9\n                \n                  N\n                \n              \n              exp\n              \u2061\n              (\n              \u2212\n              \u27e8\n              N\n              \u27e9\n              )\n            \n            \n              N\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P(N)={\\frac {\\langle N\\rangle ^{N}\\exp(-\\langle N\\rangle )}{N!}}.}\n  \n\n\n==== Chain-decay processes ====\nChain of two decays\nNow consider the case of a chain of two decays: one nuclide A decaying into another B by one process, then B decaying into another C by a second process, i.e. A \u2192 B \u2192 C. The previous equation cannot be applied to the decay chain, but can be generalized as follows. Since A decays into B, then B decays into C, the activity of A adds to the total number of B nuclides in the present sample, before those B nuclides decay and reduce the number of nuclides leading to the later sample. In other words, the number of second generation nuclei B increases as a result of the first generation nuclei decay of A, and decreases as a result of its own decay into the third generation nuclei C. The sum of these two terms gives the law for a decay chain for two nuclides:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            B\n          \n        \n        \n          N\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            A\n          \n        \n        \n          N\n          \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}=-\\lambda _{B}N_{B}+\\lambda _{A}N_{A}.}\n  The rate of change of NB, that is dNB/dt, is related to the changes in the amounts of A and B, NB can increase as B is produced from A and decrease as B produces C.\nRe-writing using the previous results:\n\nThe subscripts simply refer to the respective nuclides, i.e. NA is the number of nuclides of type A, NA0 is the initial number of nuclides of type A, \u03bbA is the decay constant for A - and similarly for nuclide B. Solving this equation for NB gives:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              \n                \u03bb\n                \n                  B\n                \n              \n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    B\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{B}={\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right).}\n  In the case where B is a stable nuclide (\u03bbB = 0), this equation reduces to the previous solution:\n\n  \n    \n      \n        \n          lim\n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u2192\n            0\n          \n        \n        \n          [\n          \n            \n              \n                \n                  \n                    N\n                    \n                      A\n                      0\n                    \n                  \n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n                \n                  \n                    \u03bb\n                    \n                      B\n                    \n                  \n                  \u2212\n                  \n                    \u03bb\n                    \n                      A\n                    \n                  \n                \n              \n            \n            \n              (\n              \n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        A\n                      \n                    \n                    t\n                  \n                \n                \u2212\n                \n                  e\n                  \n                    \u2212\n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    t\n                  \n                \n              \n              )\n            \n          \n          ]\n        \n        =\n        \n          \n            \n              \n                N\n                \n                  A\n                  0\n                \n              \n              \n                \u03bb\n                \n                  A\n                \n              \n            \n            \n              0\n              \u2212\n              \n                \u03bb\n                \n                  A\n                \n              \n            \n          \n        \n        \n          (\n          \n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n            \u2212\n            1\n          \n          )\n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \n                  \u03bb\n                  \n                    A\n                  \n                \n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\lim _{\\lambda _{B}\\rightarrow 0}\\left[{\\frac {N_{A0}\\lambda _{A}}{\\lambda _{B}-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-e^{-\\lambda _{B}t}\\right)\\right]={\\frac {N_{A0}\\lambda _{A}}{0-\\lambda _{A}}}\\left(e^{-\\lambda _{A}t}-1\\right)=N_{A0}\\left(1-e^{-\\lambda _{A}t}\\right),}\n  as shown above for one decay. The solution can be found by the integration factor method, where the integrating factor is e\u03bbBt. This case is perhaps the most useful, since it can derive both the one-decay equation (above) and the equation for multi-decay chains (below) more directly.\nChain of any number of decays\nFor the general case of any number of consecutive decays in a decay chain, i.e. A1 \u2192 A2 \u00b7\u00b7\u00b7 \u2192 Ai \u00b7\u00b7\u00b7 \u2192 AD, where D is the number of decays and i is a dummy index (i = 1, 2, 3, ...D), each nuclide population can be found in terms of the previous population. In this case N2 = 0, N3 = 0,..., ND = 0. Using the above result in a recursive form:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  j\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \u03bb\n          \n            j\n          \n        \n        \n          N\n          \n            j\n          \n        \n        +\n        \n          \u03bb\n          \n            j\n            \u2212\n            1\n          \n        \n        \n          N\n          \n            (\n            j\n            \u2212\n            1\n            )\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n              \n                j\n                \u2212\n                1\n              \n            \n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{j}}{\\mathrm {d} t}}=-\\lambda _{j}N_{j}+\\lambda _{j-1}N_{(j-1)0}e^{-\\lambda _{j-1}t}.}\n  The general solution to the recursive problem is given by Bateman's equations:\n\n\n==== Alternative decay modes ====\nIn all of the above examples, the initial nuclide decays into just one product. Consider the case of one initial nuclide that can decay into either of two products, that is A \u2192 B and A \u2192 C in parallel. For example, in a sample of potassium-40, 89.3% of the nuclei decay to calcium-40 and 10.7% to argon-40. We have for all time t:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            A\n          \n        \n        +\n        \n          N\n          \n            B\n          \n        \n        +\n        \n          N\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle N=N_{A}+N_{B}+N_{C}}\n  which is constant, since the total number of nuclides remains constant. Differentiating with respect to time:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        N\n                        \n                          A\n                        \n                      \n                    \n                    \n                      \n                        d\n                      \n                      t\n                    \n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  (\n                  \n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              B\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                    +\n                    \n                      \n                        \n                          \n                            d\n                          \n                          \n                            N\n                            \n                              C\n                            \n                          \n                        \n                        \n                          \n                            d\n                          \n                          t\n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n            \n              \n                \u2212\n                \u03bb\n                \n                  N\n                  \n                    A\n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  N\n                  \n                    A\n                  \n                \n                \n                  (\n                  \n                    \n                      \u03bb\n                      \n                        B\n                      \n                    \n                    +\n                    \n                      \u03bb\n                      \n                        C\n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}&=-\\left({\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}\\right)\\\\-\\lambda N_{A}&=-N_{A}\\left(\\lambda _{B}+\\lambda _{C}\\right)\\\\\\end{aligned}}}\n  defining the total decay constant \u03bb in terms of the sum of partial decay constants \u03bbB and \u03bbC:\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        .\n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}.}\n  Notice that \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  A\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        <\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  B\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0\n        ,\n        \n          \n            \n              \n                d\n              \n              \n                N\n                \n                  C\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        >\n        0.\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} N_{A}}{\\mathrm {d} t}}<0,{\\frac {\\mathrm {d} N_{B}}{\\mathrm {d} t}}>0,{\\frac {\\mathrm {d} N_{C}}{\\mathrm {d} t}}>0.}\n  Solving this equation for NA:\n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n        =\n        \n          N\n          \n            A\n            0\n          \n        \n        \n          e\n          \n            \u2212\n            \u03bb\n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle N_{A}=N_{A0}e^{-\\lambda t}.}\n  where NA0 is the initial number of nuclide A. When measuring the production of one nuclide, one can only observe the total decay constant \u03bb. The decay constants \u03bbB and \u03bbC determine the probability for the decay to result in products B or C as follows:\n\n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                B\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle N_{B}={\\frac {\\lambda _{B}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right),}\n  \n  \n    \n      \n        \n          N\n          \n            C\n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                C\n              \n            \n            \u03bb\n          \n        \n        \n          N\n          \n            A\n            0\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bb\n                t\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle N_{C}={\\frac {\\lambda _{C}}{\\lambda }}N_{A0}\\left(1-e^{-\\lambda t}\\right).}\n  because the fraction \u03bbB/\u03bb of nuclei decay into B while the fraction \u03bbC/\u03bb of nuclei decay into C.\n\n\n=== Corollaries of the decay laws ===\nThe above equations can also be written using quantities related to the number of nuclide particles N in a sample;\n\nThe activity: A = \u03bbN.\nThe amount of substance: n = N/L.\nThe mass: M = Arn = ArN/L.where L = 6.022\u00d71023 is Avogadro's constant, Ar is the relative atomic mass number, and the amount of the substance is in moles.\n\n\n=== Decay timing: definitions and relations ===\n\n\n==== Time constant and mean-life ====\nFor the one-decay solution A \u2192 B:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the equation indicates that the decay constant \u03bb has units of t\u22121, and can thus also be represented as 1/\u03c4, where \u03c4 is a characteristic time of the process called the time constant.\nIn a radioactive decay process, this time constant is also the mean lifetime for decaying atoms. Each atom \"lives\" for a finite amount of time before it decays, and it may be shown that this mean lifetime is the arithmetic mean of all the atoms' lifetimes, and that it is \u03c4, which again is related to the decay constant as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            1\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau ={\\frac {1}{\\lambda }}.}\n  This form is also true for two-decay processes simultaneously A \u2192 B + C, inserting the equivalent values of decay constants (as given above)\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        \n      \n    \n    {\\displaystyle \\lambda =\\lambda _{B}+\\lambda _{C}\\,}\n  into the decay solution leads to:\n\n  \n    \n      \n        \n          \n            1\n            \u03c4\n          \n        \n        =\n        \u03bb\n        =\n        \n          \u03bb\n          \n            B\n          \n        \n        +\n        \n          \u03bb\n          \n            C\n          \n        \n        =\n        \n          \n            1\n            \n              \u03c4\n              \n                B\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              \u03c4\n              \n                C\n              \n            \n          \n        \n        \n      \n    \n    {\\displaystyle {\\frac {1}{\\tau }}=\\lambda =\\lambda _{B}+\\lambda _{C}={\\frac {1}{\\tau _{B}}}+{\\frac {1}{\\tau _{C}}}\\,}\n  \n\n\n==== Half-life ====\nA more commonly used parameter is the half-life. Given a sample of a particular radionuclide, the half-life is the time taken for half the radionuclide's atoms to decay. For the case of one-decay nuclear reactions:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            \n              \u03bb\n            \n            t\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-{\\lambda }t}=N_{0}\\,e^{-t/\\tau },\\,\\!}\n  the half-life is related to the decay constant as follows: set N = N0/2 and t = T1/2 to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              2\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        2.\n      \n    \n    {\\displaystyle t_{1/2}={\\frac {\\ln 2}{\\lambda }}=\\tau \\ln 2.}\n  This relationship between the half-life and the decay constant shows that highly radioactive substances are quickly spent, while those that radiate weakly endure longer. Half-lives of known radionuclides vary widely, from more than 1019 years, such as for the very nearly stable nuclide 209Bi, to 10\u221223 seconds for highly unstable ones.\nThe factor of ln(2) in the above relations results from the fact that the concept of \"half-life\" is merely a way of selecting a different base other than the natural base e for the lifetime expression. The time constant \u03c4 is the e -1 -life, the time until only 1/e remains, about 36.8%, rather than the 50% in the half-life of a radionuclide. Thus, \u03c4 is longer than t1/2. The following equation can be shown to be valid:\n\n  \n    \n      \n        N\n        (\n        t\n        )\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          2\n          \n            \u2212\n            t\n            \n              /\n            \n            \n              t\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        .\n        \n        \n      \n    \n    {\\displaystyle N(t)=N_{0}\\,e^{-t/\\tau }=N_{0}\\,2^{-t/t_{1/2}}.\\,\\!}\n  Since radioactive decay is exponential with a constant probability, each process could as easily be described with a different constant time period that (for example) gave its \"(1/3)-life\" (how long until only 1/3 is left) or \"(1/10)-life\" (a time period until only 10% is left), and so on. Thus, the choice of \u03c4 and t1/2 for marker-times, are only for convenience, and from convention. They reflect a fundamental principle only in so much as they show that the same proportion of a given radioactive substance will decay, during any time-period that one chooses.\nMathematically, the nth life for the above situation would be found in the same way as above\u2014by setting N = N0/n, t = T1/n and substituting into the decay solution to obtain\n\n  \n    \n      \n        \n          t\n          \n            1\n            \n              /\n            \n            n\n          \n        \n        =\n        \n          \n            \n              ln\n              \u2061\n              n\n            \n            \u03bb\n          \n        \n        =\n        \u03c4\n        ln\n        \u2061\n        n\n        .\n      \n    \n    {\\displaystyle t_{1/n}={\\frac {\\ln n}{\\lambda }}=\\tau \\ln n.}\n  \n\n\n=== Example ===\nA sample of 14C has a half-life of 5,730 years and a decay rate of 14 disintegration per minute (dpm) per gram of natural carbon.\nIf an artifact is found to have radioactivity of 4 dpm per gram of its present C, we can find the approximate age of the object using the above equation:\n\n  \n    \n      \n        N\n        =\n        \n          N\n          \n            0\n          \n        \n        \n        \n          e\n          \n            \u2212\n            t\n            \n              /\n            \n            \u03c4\n          \n        \n        ,\n      \n    \n    {\\displaystyle N=N_{0}\\,e^{-t/\\tau },}\n  where: \n  \n    \n      \n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        =\n        4\n        \n          /\n        \n        14\n        \u2248\n        0.286\n        ,\n      \n    \n    {\\displaystyle {\\frac {N}{N_{0}}}=4/14\\approx 0.286,}\n  \n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            \n              T\n              \n                1\n                \n                  /\n                \n                2\n              \n            \n            \n              ln\n              \u2061\n              2\n            \n          \n        \n        \u2248\n        8267\n      \n    \n    {\\displaystyle \\tau ={\\frac {T_{1/2}}{\\ln 2}}\\approx 8267}\n   years,\n\n  \n    \n      \n        t\n        =\n        \u2212\n        \u03c4\n        \n        ln\n        \u2061\n        \n          \n            N\n            \n              N\n              \n                0\n              \n            \n          \n        \n        \u2248\n        10356\n      \n    \n    {\\displaystyle t=-\\tau \\,\\ln {\\frac {N}{N_{0}}}\\approx 10356}\n   years.\n\n\n== Changing decay rates ==\nThe radioactive decay modes of electron capture and internal conversion are known to be slightly sensitive to chemical and environmental effects that change the electronic structure of the atom, which in turn affects the presence of 1s and 2s electrons that participate in the decay process. A small number of mostly light nuclides are affected. For example, chemical bonds can affect the rate of electron capture to a small degree (in general, less than 1%) depending on the proximity of electrons to the nucleus. In 7Be, a difference of 0.9% has been observed between half-lives in metallic and insulating environments. This relatively large effect is because beryllium is a small atom whose valence electrons are in 2s atomic orbitals, which are subject to electron capture in 7Be because (like all s atomic orbitals in all atoms) they naturally penetrate into the nucleus.\nIn 1992, Jung et al. of the Darmstadt Heavy-Ion Research group observed an accelerated \u03b2\u2212 decay of 163Dy66+. Although neutral 163Dy is a stable isotope, the fully ionized 163Dy66+ undergoes \u03b2\u2212 decay into the K and L shells to 163Ho66+ with a half-life of 47 days.Rhenium-187 is another spectacular example. 187Re normally beta decays to 187Os with a half-life of 41.6 \u00d7 109 years, but studies using fully ionised 187Re atoms (bare nuclei) have found that this can decrease to only 33 years. This is attributed to \"bound-state \u03b2\u2212 decay\" of the fully ionised atom \u2013 the electron is emitted into the \"K-shell\" (1s atomic orbital), which cannot occur for neutral atoms in which all low-lying bound states are occupied.\n\nA number of experiments have found that decay rates of other modes of artificial and naturally occurring radioisotopes are, to a high degree of precision, unaffected by external conditions such as temperature, pressure, the chemical environment, and electric, magnetic, or gravitational fields. Comparison of laboratory experiments over the last century, studies of the Oklo natural nuclear reactor (which exemplified the effects of thermal neutrons on nuclear decay), and astrophysical observations of the luminosity decays of distant supernovae (which occurred far away so the light has taken a great deal of time to reach us), for example, strongly indicate that unperturbed decay rates have been constant (at least to within the limitations of small experimental errors) as a function of time as well.Recent results suggest the possibility that decay rates might have a weak dependence on environmental factors. It has been suggested that measurements of decay rates of silicon-32, manganese-54, and radium-226 exhibit small seasonal variations (of the order of 0.1%).  However, such measurements are highly susceptible to systematic errors, and a subsequent paper has found no evidence for such correlations in seven other isotopes (22Na, 44Ti, 108Ag, 121Sn, 133Ba, 241Am, 238Pu), and sets upper limits on the size of any such effects. The decay of radon-222 was once reported to exhibit large 4% peak-to-peak seasonal variations (see plot),  which were proposed to be related to either solar flare activity or the distance from the Sun, but detailed analysis of the experiment's design flaws, along with comparisons to other, much more stringent and systematically controlled, experiments refute this claim.\n\n\n=== GSI anomaly ===\n\nAn unexpected series of experimental results for the rate of decay of heavy highly charged radioactive ions circulating in a storage ring has provoked theoretical activity in an effort to find a convincing explanation. The rates of weak decay of two radioactive species with half lives of about 40 s and 200 s are found to have a significant oscillatory modulation, with a period of about 7 s.\nThe observed phenomenon is known as the GSI anomaly, as the storage ring is a facility at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany.  As the decay process produces an electron neutrino, some of the proposed explanations for the observed rate oscillation invoke neutrino properties. Initial ideas related to flavour oscillation met with skepticism.  A more recent proposal involves mass differences between neutrino mass eigenstates.\n\n\n== Theoretical basis of decay phenomena ==\nThe neutrons and protons that constitute nuclei, as well as other particles that approach close enough to them, are governed by several interactions. The strong nuclear force, not observed at the familiar macroscopic scale, is the most powerful force over subatomic distances. The electrostatic force is almost always significant, and, in the case of beta decay, the weak nuclear force is also involved.\nThe combined effects of these forces produces a number of different phenomena in which energy may be released by rearrangement of particles in the nucleus, or else the change of one type of particle into others. These rearrangements and transformations may be hindered energetically, so that they do not occur immediately. In certain cases, random quantum vacuum fluctuations are theorized to promote relaxation to a lower energy state (the \"decay\") in a phenomenon known as quantum tunneling. Radioactive decay half-life of nuclides has been measured over timescales of 55 orders of magnitude, from 2.3 \u00d7 10\u221223 seconds (for hydrogen-7) to 6.9 \u00d7 1031 seconds (for tellurium-128). The limits of these timescales are set by the sensitivity of instrumentation only, and there are no known natural limits to how brief or long a decay half-life for radioactive decay of a radionuclide may be.\nThe decay process, like all hindered energy transformations, may be analogized by a snowfield on a mountain. While friction between the ice crystals may be supporting the snow's weight, the system is inherently unstable with regard to a state of lower potential energy. A disturbance would thus facilitate the path to a state of greater entropy; the system will move towards the ground state, producing heat, and the total energy will be distributable over a larger number of quantum states thus resulting in an avalanche. The total energy does not change in this process, but, because of the second law of thermodynamics, avalanches have only been observed in one direction and that is toward the \"ground state\" \u2014 the state with the largest number of ways in which the available energy could be distributed.\nSuch a collapse (a gamma-ray decay event) requires a specific activation energy. For a snow avalanche, this energy comes as a disturbance from outside the system, although such disturbances can be arbitrarily small. In the case of an excited atomic nucleus decaying by gamma radiation in a spontaneous emission of electromagnetic radiation, the arbitrarily small disturbance comes from quantum vacuum fluctuations.A radioactive nucleus (or any excited system in quantum mechanics) is unstable, and can, thus, spontaneously stabilize to a less-excited system. The resulting transformation alters the structure of the nucleus and results in the emission of either a photon or a high-velocity particle that has mass (such as an electron, alpha particle, or other type).\n\n\n== Occurrence and applications ==\nAccording to the Big Bang theory, stable isotopes of the lightest five elements (H, He, and traces of Li, Be, and B) were produced very shortly after the emergence of the universe, in a process called Big Bang nucleosynthesis. These lightest stable nuclides (including deuterium) survive to today, but any radioactive isotopes of the light elements produced in the Big Bang (such as tritium) have long since decayed. Isotopes of elements heavier than boron were not produced at all in the Big Bang, and these first five elements do not have any long-lived radioisotopes. Thus, all radioactive nuclei are, therefore, relatively young with respect to the birth of the universe, having formed later in various other types of nucleosynthesis in stars (in particular, supernovae), and also during ongoing interactions between stable isotopes and energetic particles. For example, carbon-14, a radioactive nuclide with a half-life of only 5,730 years, is constantly produced in Earth's upper atmosphere due to interactions between cosmic rays and nitrogen.\nNuclides that are produced by radioactive decay are called radiogenic nuclides, whether they themselves are stable or not. There exist stable radiogenic nuclides that were formed from short-lived extinct radionuclides in the early solar system. The extra presence of these stable radiogenic nuclides (such as Xe-129 from primordial I-129) against the background of primordial stable nuclides can be inferred by various means.\nRadioactive decay has been put to use in the technique of radioisotopic labeling, which is used to track the passage of a chemical substance through a complex system (such as a living organism). A sample of the substance is synthesized with a high concentration of unstable atoms. The presence of the substance in one or another part of the system is determined by detecting the locations of decay events.\nOn the premise that radioactive decay is truly random (rather than merely chaotic), it has been used in hardware random-number generators. Because the process is not thought to vary significantly in mechanism over time, it is also a valuable tool in estimating the absolute ages of certain materials. For geological materials, the radioisotopes and some of their decay products become trapped when a rock solidifies, and can then later be used (subject to many well-known qualifications) to estimate the date of the solidification. These include checking the results of several simultaneous processes and their products against each other, within the same sample. In a similar fashion, and also subject to qualification, the rate of formation of carbon-14 in various eras, the date of formation of organic matter within a certain period related to the isotope's half-life may be estimated, because the carbon-14 becomes trapped when the organic matter grows and incorporates the new carbon-14 from the air. Thereafter, the amount of carbon-14 in organic matter decreases according to decay processes that may also be independently cross-checked by other means (such as checking the carbon-14 in individual tree rings, for example).\n\n\n=== Szilard\u2013Chalmers effect ===\nThe Szilard\u2013Chalmers effect is defined as the breaking of a chemical bond between an atom and the molecule that the atom is part of, as a result of a nuclear reaction of the atom. The effect can be used to separate isotopes by chemical means. The discovery of this effect is due to L. Szil\u00e1rd and T.A. Chalmers.\n\n\n== Origins of radioactive nuclides ==\n\nRadioactive primordial nuclides found in the Earth are residues from ancient supernova explosions that occurred before the formation of the solar system. They are the fraction of radionuclides that survived from that time, through the formation of the primordial solar nebula, through planet accretion, and up to the present time. The naturally occurring short-lived radiogenic radionuclides found in today's rocks, are the daughters of those radioactive primordial nuclides. Another minor source of naturally occurring radioactive nuclides are cosmogenic nuclides, that are formed by cosmic ray bombardment of material in the Earth's atmosphere or crust. The decay of the radionuclides in rocks of the Earth's mantle and crust contribute significantly to Earth's internal heat budget.\n\n\n== Decay chains and multiple modes ==\n\nThe daughter nuclide of a decay event may also be unstable (radioactive). In this case, it too will decay, producing radiation. The resulting second daughter nuclide may also be radioactive. This can lead to a sequence of several decay events called a decay chain (see this article for specific details of important natural decay chains). Eventually, a stable nuclide is produced.\n\nAn example is the natural decay chain of 238U:\n\nUranium-238 decays, through alpha-emission, with a half-life of 4.5 billion years to thorium-234\nwhich decays, through beta-emission, with a half-life of 24 days to protactinium-234\nwhich decays, through beta-emission, with a half-life of 1.2 minutes to uranium-234\nwhich decays, through alpha-emission, with a half-life of 240 thousand years to thorium-230\nwhich decays, through alpha-emission, with a half-life of 77 thousand years to radium-226\nwhich decays, through alpha-emission, with a half-life of 1.6 thousand years to radon-222\nwhich decays, through alpha-emission, with a half-life of 3.8 days to polonium-218\nwhich decays, through alpha-emission, with a half-life of 3.1 minutes to lead-214\nwhich decays, through beta-emission, with a half-life of 27 minutes to bismuth-214\nwhich decays, through beta-emission, with a half-life of 20 minutes to polonium-214\nwhich decays, through alpha-emission, with a half-life of 160 microseconds to lead-210\nwhich decays, through beta-emission, with a half-life of 22 years to bismuth-210\nwhich decays, through beta-emission, with a half-life of 5 days to polonium-210\nwhich decays, through alpha-emission, with a half-life of 140 days to lead-206, which is a stable nuclide.Some radionuclides may have several different paths of decay. For example, approximately 36% of bismuth-212 decays, through alpha-emission, to thallium-208 while approximately 64% of bismuth-212 decays, through beta-emission, to polonium-212. Both thallium-208 and polonium-212 are radioactive daughter products of bismuth-212, and both decay directly to stable lead-208.\n\n\n== Associated hazard warning signs ==\n\n\t\t\n\t\t\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Inline ===\n\n\n=== General ===\n\"Radioactivity\", Encyclop\u00e6dia Britannica. 2006. Encyclop\u00e6dia Britannica Online. December 18, 2006\nRadio-activity by Ernest Rutherford Phd, Encyclop\u00e6dia Britannica Eleventh Edition\n\n\n== External links ==\nThe Lund/LBNL Nuclear Data Search \u2013 Contains tabulated information on radioactive decay types and energies.\nNomenclature of nuclear chemistry\nSpecific activity and related topics.\nThe Live Chart of Nuclides \u2013 IAEA\nInteractive Chart of Nuclides\nHealth Physics Society Public Education Website\n Beach, Chandler B., ed. (1914). \"Becquerel Rays\". The New Student's Reference Work. Chicago: F. E. Compton and Co. \nAnnotated bibliography for radioactivity from the Alsos Digital Library for Nuclear Issues\nStochastic Java applet on the decay of radioactive atoms by Wolfgang Bauer\nStochastic Flash simulation on the decay of radioactive atoms by David M. Harrison\n\"Henri Becquerel: The Discovery of Radioactivity\", Becquerel's 1896 articles online and analyzed on BibNum [click '\u00e0 t\u00e9l\u00e9charger' for English version].\n\"Radioactive change\", Rutherford & Soddy article (1903), online and analyzed on Bibnum [click '\u00e0 t\u00e9l\u00e9charger' for English version].",
        "unit": "radioactivity",
        "url": "https://en.wikipedia.org/wiki/Radioactive_decay"
    },
    {
        "_id": "Minute",
        "clean": "Minute",
        "text": "The minute is a unit of time or angle. As a unit of time, the minute is most of times equal to \u200b1\u204460 (the first sexagesimal fraction) of an hour, or 60 seconds. In the UTC time standard, a minute on rare occasions has 61 seconds, a consequence of leap seconds (there is a provision to insert a negative leap second, which would result in a 59-second minute, but this has never happened in more than 40 years under this system). As a unit of angle, the minute of arc is equal to \u200b1\u204460 of a degree, or 60 seconds (of arc). Although not an SI unit for either time or angle, the minute is accepted for use with SI units for both. The SI symbols for minute or minutes are min for time measurement, and the prime symbol after a number, e.g. 5\u2032, for angle measurement. The prime is also sometimes used informally to denote minutes of time.\n\n\n== History ==\nIn contrast to the hour, the minute (and the second) does not have a clear historical background. An early use of sexagesimal divisions of the hour is found in John of Sacrobosco's Computus (ca. 1235), where it was used in discussions of the length of the tropical year.  Another motivation that has been suggested for the emergence of these fine divisions of time was the construction of \"precision\" timepieces (mechanical and water clocks). However, no specific records of the origin for the division as \u200b1\u204460 part of the hour (and the second \u200b1\u204460 of the minute) have ever been found.\nHistorically, the word \"minute\" comes from the Latin pars minuta prima, meaning \"first small part\".  This division of the hour can be further refined with a \"second small part\" (Latin: pars minuta secunda), and this is where the word \"second\" comes from.  For even further refinement, the term \"third\" (\u200b1\u204460 of a second) remains in some languages, for example Polish (tercja) and Turkish (salise), although most modern usage subdivides seconds by using decimals.  The symbol notation of the prime for minutes and double prime for seconds can be seen as indicating the first and second cut of the hour (similar to how the foot is the first cut of the yard or perhaps chain, with inches as the second cut).  In 1267, the medieval scientist Roger Bacon, writing in Latin, defined the division of time between full moons as a number of hours, minutes, seconds, thirds, and fourths (horae, minuta, secunda, tertia, and quarta) after noon on specified calendar dates.\n\n\n== See also ==\nInternational System of Units\nLatitude and longitude\nOrders of magnitude (time)\n\n\n== Notes and references ==\n\n\n== Bibliography ==\nHenry Campbell Black, Black's Law Dictionary, 6th Edition, entry on Minute. West Publishing Company, St. Paul, Minnesota, 1991.\nEric W. Weisstein. \"Arc Minute.\" From MathWorld\u2014A Wolfram",
        "unit": "minute",
        "url": "https://en.wikipedia.org/wiki/Minute"
    },
    {
        "_id": "Second",
        "clean": "Second",
        "text": "The second is the SI base unit of time, commonly understood and historically defined as \u200b1\u204486400 of a day \u2013 this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Another intuitive understanding is that it is about the time between beats of a human heart.  Mechanical and electric clocks and watches usually have a face with 60 tickmarks representing seconds and minutes, traversed by a second hand and minute hand.  Digital clocks and watches often have a two-digit counter that cycles through seconds.  In common parlance, a \"clock tick\" is a second, though most modern clocks are digital electronic, and do not actually tick.  The second is also part of several other units of measurement like velocity, acceleration, and frequency.\nThough the historical definition of the unit was based upon this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is  a much steadier timekeeper: 1 second is defined to be exactly 9 192 631 770 cycles of a Caesium atomic clock.\nBecause the Earth's rotation varies and is also slowing ever so slightly, a leap second is added to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths.  In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second.\nAn everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond.  Camera shutter speeds usually range from \u200b1\u204460 second to \u200b1\u2044250 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today.  Small divisions of time could not be counted back then, so such divisions were figurative.  The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century.  Starting in the 1950s, atomic clocks became better timekeepers than earth's rotation, and they continue to set the standard today.\n\n\n== Clocks and solar time ==\nA mechanical clock, one which does not depend on measuring the relative rotational position of the earth, keeps uniform time called mean time, within whatever accuracy is intrinsic to it. That means that every second, minute and every other division of time counted by the clock will be the same duration as any other identical division of time. But a sundial which measures the relative position of the sun in the sky called apparent time, does not keep uniform time.  The time kept by a sundial varies by time of year, meaning that seconds, minutes and every other division of time is a different duration at different times of the year. The time of day measured with mean time versus apparent time may differ by as much as 15 minutes, but a single day will differ from the next by only a small amount; 15 minutes is a cumulative difference over a part of the year. The effect is due chiefly to the obliqueness of earth's axis with respect to its orbit around the sun.\nThe difference between apparent solar time and mean time was recognized by astronomers since antiquity, but prior to the invention of accurate mechanical clocks in the mid-17th century, sundials were the only reliable timepieces, and apparent solar time was the generally accepted standard.\n\n\n== Events and units of time in seconds ==\nFractions of a second are usually denoted in decimal notation, i.e. 2.01 seconds, or two and one hundredth seconds. Multiples of seconds are usually expressed as minutes and seconds, or hours, minutes and seconds of clock time, separated by colons, such as 11:23:24, or 45:23 (the latter notation can give rise to ambiguity, because the same notation is used to denote hours and minutes).  It rarely makes sense to express longer periods of time like hours or days in seconds, because they are awkwardly large numbers.  For the metric unit of second, there are decimal prefixes representing 10\u221224 to 1024 seconds.\nSome common units of time in seconds are: a minute is 60 seconds; an hour is 3,600 seconds; a day is 86,400 seconds; a week is 604,800 seconds; a year (other than leap years) is 31,536,000 seconds; and a (Gregorian) century is typically 3,155,673,600 seconds; with all of the above excluding any possible leap seconds.\nSome common events in seconds are: a stone falls about 4.9 meters from rest in one second; a pendulum of length about one meter has a swing of one second, so pendulum clocks have pendulums about a meter long; the fastest human sprinters run 10 meters in a second; an ocean wave in deep water travels about 23 meters in one second; sound travels about 343 meters in one second in air; light takes 1.3 seconds to reach Earth from the surface of the Moon, a distance of 384,400 kilometers.\n\n\n== Other units incorporating seconds ==\nA second is part of other units, such as frequency measured in hertz (inverse seconds or second\u22121), speed (meters per second) and acceleration (meters per second squared).  The metric system unit becquerel, a measure of radioactive decay, is measured in inverse seconds.  The meter is defined in terms of the speed of light and the second; definitions of the metric base units ampere and candela also depend on the second. Of the 22 named derived units of the SI, only three: degree Celsius, radian, and steradian, do not depend on the second.  Many derivative units for everyday things are reported in terms of larger units of time, not seconds, such as clock time in hours and minutes, velocity of a car in miles per hour or kilometers per hour, kilowatt hours of electricity usage, and speed of a turntable in rotations per minute.\n\n\n== Timekeeping standards ==\nA set of atomic clocks throughout the world keeps time by consensus: the clocks \"vote\" on the correct time, and all voting clocks are steered to agree with the consensus, which is called International Atomic Time (TAI). TAI \"ticks\" atomic seconds.Civil time is defined to agree with the rotation of the earth. The international standard for timekeeping is Coordinated Universal Time (UTC). This time scale \"ticks\" the same atomic seconds as TAI, but inserts or omits leap seconds as necessary to correct for variations in the rate of rotation of the earth.A time scale in which the seconds are not exactly equal to atomic seconds is UT1, a form of universal time. UT1 is defined by the rotation of the earth with respect to the sun, and does not contain any leap seconds. UT1 always differs from UTC by less than a second.\n\n\n== Optical lattice clock ==\nWhile they are not yet part of any timekeeping standard, optical lattice clocks with frequencies in the visible light spectrum now exist and are the most accurate timekeepers of all.  A strontium clock with frequency 430 THz, in the red range of visible light, now holds the accuracy record: it will gain or lose less than a second in 15 billion years, which is longer than the estimated age of the universe. Such a clock can measure a change in its height of as little as 2 cm by the change in its rate due to gravitational time dilation.\n\n\n== History of definition ==\n\nThere have only ever been three definitions of the second: as a fraction of the day, as a fraction of an extrapolated year, and as the microwave frequency of a caesium atomic clock, and they have realized a sexagesimal division of the day from ancient astronomical calendars.\n\n\n=== Sexagesimal divisions of calendar time and day ===\nCivilizations in the classic period and before constructed divisions of the calendar as well as arcs according to a sexagesimal system of counting, but none used the term second, and none was a precursor to the modern second.  Sundials and water clocks were among the earliest timekeeping devices, and units of time were measured in degrees of arc.  Conceptual units of time smaller than realizable on sundials were also used.\nThere are references to 'second' as part of a lunar month in the writings of natural philosophers of the Middle Ages, but no evidence that 'seconds' were ever realizable or adopted as part of timekeeping based on the lunar calendar.\n\n\n=== Fraction of solar day ===\nThe earliest mechanical clocks which appeared starting in the 14th century had displays that divided the hour into halves, thirds, quarters and sometimes even 12 parts, but never by 60. In fact, the hour was not commonly understood to be the duration of 60 minutes. It was not practical for timekeepers to consider minutes until the first mechanical clocks that displayed minutes appeared near the end of the 16th century. By that time, sexagesimal divisions of time were well established in Europe.The earliest clocks to display seconds appeared during the last half of the 16th century. The second became accurately measurable with the development of mechanical clocks keeping mean time, as opposed to the apparent time displayed by sundials. The earliest spring-driven timepiece with a second hand which marked seconds is an unsigned clock depicting Orpheus in the Fremersdorf collection, dated between 1560 and 1570. During the 3rd quarter of the 16th century, Taqi al-Din built a clock with marks every 1/5 minute.\nIn 1579, Jost B\u00fcrgi built a clock for William of Hesse that marked seconds. In 1581, Tycho Brahe redesigned clocks that displayed minutes at his observatory so they also displayed seconds. However, they were not yet accurate enough for seconds. In 1587, Tycho complained that his four clocks disagreed by plus or minus four seconds.\nIn 1656, Dutch scientist Christiaan Huygens invented the first pendulum clock. It had a pendulum length of just under a meter which gave it a swing of one second, and an escapement that ticked every second. It was the first clock that could accurately keep time in seconds. By the 1730s, 80 years later, John Harrison's maritime chronometers could keep time accurate to within one second in 100 days.\nIn 1832, Gauss proposed using the second as the base unit of time in his millimeter-milligram-second system of units. The British Association for the Advancement of Science (BAAS) in 1862 stated that \"All men of science are agreed to use the second of mean solar time as the unit of time.\" BAAS formally proposed the CGS system in 1874, although this system was gradually replaced over the next 70 years by MKS units. Both the CGS and MKS systems used the same second as their base unit of time. MKS was adopted internationally during the 1940s, defining the second as \u200b1\u204486,400 of a mean solar day.\n\n\n=== Fraction of an ephemeris year ===\n\nSome time in the late 1940s, quartz crystal oscillator clocks with an operating frequency of ~100 kHz advanced to keep time with accuracy better than 1 part in 108 over an operating period of a day.  It became apparent that a consensus of such clocks kept better time than the rotation of the Earth. Metrologists also knew that Earth's orbit around the Sun (a year) was much more stable than earth's rotation. This led to proposals as early as 1950 to define the second as a fraction of a year.\nThe Earth's motion was described in Newcomb's Tables of the Sun (1895), which provided a formula for estimating the motion of the Sun relative to the epoch 1900 based on astronomical observations made between 1750 and 1892. This resulted in adoption of an ephemeris time scale expressed in units of the sidereal year at that epoch by the IAU in 1952. This extrapolated timescale brings the observed positions of the celestial bodies into accord with Newtonian dynamical theories of their motion. In 1955, the tropical year, considered more fundamental than the sidereal year, was chosen by the IAU as the unit of time. The tropical year in the definition was not measured but calculated from a formula describing a mean tropical year that decreased linearly over time.\nIn 1956, the second was redefined in terms of a year relative to that epoch. The second was thus defined as \"the fraction \u200b1\u204431,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time\". This definition was adopted as part of the International System of Units in 1960.\n\n\n=== \"Atomic\" second ===\nBut even the best mechanical, electric motorized and quartz crystal-based clocks develop discrepancies, and virtually none are good enough to realize an ephemeris second. Far better for timekeeping is the natural and exact \"vibration\" in an energized atom. The frequency of vibration (i.e., radiation) is very specific depending on the type of atom and how it is excited. Since 1967, the second has been defined as exactly 9,192,631,770 times the period of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom. This length of a second was selected to correspond exactly to the length of the ephemeris second previously defined. Atomic clocks use such a frequency to measure seconds by counting cycles per second at that frequency. Radiation of this kind is one of the most stable and reproducible phenomena of nature. The current generation of atomic clocks is accurate to within one second in a few hundred million years.\nAtomic clocks now set the length of a second and the time standard for the world.\n\n\n== SI multiples ==\nSI prefixes are commonly used to measure time less than a second, but rarely for multiples of a second (which is known as metric time). Instead, the non-SI units minutes, hours, days, Julian years, Julian centuries, and Julian millennia are used.\n\n\n== See also ==\n\nOrders of magnitude (time)\nTime standard\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nNational Physical Laboratory: Trapped ion optical frequency standards \nHigh-accuracy strontium ion optical clock; National Physical Laboratory (2005)\nNational Research Council of Canada: Optical frequency standard based on a single trapped ion\nNIST: Definition of the second; notice the cesium atom must be in its ground state at 0 K\nOfficial BIPM definition of the second\nThe leap second: its history and possible future\nWhat is a Cesium atom clock?\nAccuracy of the time \u2014 Astronoo",
        "unit": "second",
        "url": "https://en.wikipedia.org/wiki/Second"
    },
    {
        "_id": "Concentration",
        "clean": "Concentration",
        "text": "In chemistry, concentration is the abundance of a constituent divided by the total volume of a mixture. Several types of mathematical description can be distinguished: mass concentration, molar concentration, number concentration, and volume concentration. A concentration can be any kind of chemical mixture, but most frequently solutes and solvents in solutions. The molar (amount) concentration has variants such as normal concentration and osmotic concentration.\n\n\n== Qualitative description ==\n\nOften in informal, non-technical language, concentration is described in a qualitative way, through the use of adjectives such as \"dilute\" for solutions of relatively low concentration and \"concentrated\" for solutions of relatively high concentration. To concentrate a solution, one must add more solute (for example, alcohol), or reduce the amount of solvent (for example, water). By contrast, to dilute a solution, one must add more solvent, or reduce the amount of solute. Unless two substances are fully miscible there exists a concentration at which no further solute will dissolve in a solution. At this point, the solution is said to be saturated. If additional solute is added to a saturated solution, it will not dissolve, except in certain circumstances, when supersaturation may occur. Instead, phase separation will occur, leading to coexisting phases, either completely separated or mixed as a suspension. The point of saturation depends on many variables such as ambient temperature and the precise chemical nature of the solvent and solute.\nConcentrations are often called levels, reflecting the mental schema of levels on the vertical axis of a graph, which can be high or low (for example, \"high serum levels of bilirubin\" are concentrations of bilirubin in the blood serum that are greater than normal).\n\n\n== Quantitative notation ==\nThere are four quantities that describe concentration:\n\n\n=== Mass concentration ===\n\nThe mass concentration \n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\rho _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03c1\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\rho _{i}={\\frac {m_{i}}{V}}.}\n  The SI unit is kg/m3 (equal to g/L).\n\n\n=== Molar concentration ===\n\nThe molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle c_{i}={\\frac {n_{i}}{V}}.}\n  The SI unit is mol/m3. However, more commonly the unit mol/L (= mol/dm3) is used.\n\n\n=== Number concentration ===\n\nThe number concentration \n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle C_{i}}\n   is defined as the number of entities of a constituent \n  \n    \n      \n        \n          N\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle N_{i}}\n   in a mixture divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n        =\n        \n          \n            \n              N\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle C_{i}={\\frac {N_{i}}{V}}.}\n  The SI unit is 1/m3.\n\n\n=== Volume concentration ===\nThe volume concentration \n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\phi _{i}}\n   (not to be confused with volume fraction) is defined as the volume of a constituent \n  \n    \n      \n        \n          V\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle V_{i}}\n   divided by the volume of the mixture \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n        =\n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        .\n      \n    \n    {\\displaystyle \\phi _{i}={\\frac {V_{i}}{V}}.}\n  Being dimensionless, it is expressed as a number, e.g., 0.18 or 18%; its unit is 1.\n\n\n== Related quantities ==\nSeveral other quantities can be used to describe the composition of a mixture. Note that these should not be called concentrations.\n\n\n=== Normality ===\n\nNormality is defined as the molar concentration \n  \n    \n      \n        \n          c\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle c_{i}}\n   divided by an equivalence factor \n  \n    \n      \n        \n          f\n          \n            \n              e\n              q\n            \n          \n        \n      \n    \n    {\\displaystyle f_{\\mathrm {eq} }}\n  . Since the definition of the equivalence factor depends on context (which reaction is being studied), IUPAC and NIST discourage the use of normality.\n\n\n=== Molality ===\n\n(Not to be confused with Molarity)\nThe molality of a solution \n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle b_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the mass of the solvent \n  \n    \n      \n        \n          m\n          \n            \n              s\n              o\n              l\n              v\n              e\n              n\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {solvent} }}\n   (not the mass of the solution):\n\n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  s\n                  o\n                  l\n                  v\n                  e\n                  n\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle b_{i}={\\frac {n_{i}}{m_{\\mathrm {solvent} }}}.}\n  The SI unit for molality is mol/kg.\n\n\n=== Mole fraction ===\n\nThe mole fraction \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   (in moles) divided by the total amount of all constituents in a mixture \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  :\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              n\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }}}.}\n  The SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole fractions.\n\n\n=== Mole ratio ===\n\nThe mole ratio \n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle r_{i}}\n   is defined as the amount of a constituent \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   divided by the total amount of all other constituents in a mixture:\n\n  \n    \n      \n        \n          r\n          \n            i\n          \n        \n        =\n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              \n                n\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                n\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle r_{i}={\\frac {n_{i}}{n_{\\mathrm {tot} }-n_{i}}}.}\n  If \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n   is much smaller than \n  \n    \n      \n        \n          n\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle n_{\\mathrm {tot} }}\n  , the mole ratio is almost identical to the mole fraction.\nThe SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole ratios.\n\n\n=== Mass fraction ===\n\nThe mass fraction \n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle w_{i}}\n   is the fraction of one substance with mass \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   to the mass of the total mixture \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , defined as:\n\n  \n    \n      \n        \n          w\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              m\n              \n                \n                  t\n                  o\n                  t\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle w_{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }}}.}\n  The SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass fractions.\n\n\n=== Mass ratio ===\n\nThe mass ratio \n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\zeta _{i}}\n   is defined as the mass of a constituent \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   divided by the total mass of all other constituents in a mixture:\n\n  \n    \n      \n        \n          \u03b6\n          \n            i\n          \n        \n        =\n        \n          \n            \n              m\n              \n                i\n              \n            \n            \n              \n                m\n                \n                  \n                    t\n                    o\n                    t\n                  \n                \n              \n              \u2212\n              \n                m\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\zeta _{i}={\\frac {m_{i}}{m_{\\mathrm {tot} }-m_{i}}}.}\n  If \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle m_{i}}\n   is much smaller than \n  \n    \n      \n        \n          m\n          \n            \n              t\n              o\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle m_{\\mathrm {tot} }}\n  , the mass ratio is almost identical to the mass fraction.\nThe SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass ratios.\n\n\n== Dependence on volume ==\nConcentration depends on the variation of the volume of the solution with temperature due mainly to thermal expansion.\n\n\n== Table of concentrations and related quantities ==\n\n\n== See also ==\nDilution ratio\nDose concentration\nSerial dilution\nWine/water mixing problem\n\n\n== References ==",
        "unit": "concentration",
        "url": "https://en.wikipedia.org/wiki/Concentration"
    },
    {
        "_id": "Ton",
        "clean": "Ton",
        "text": "The ton is a unit of measure. It has a long history and has acquired a number of meanings and uses over the years. It is used principally as a unit of mass. Its original use as a measurement of volume has continued in the capacity of cargo ships and in terms such as the freight ton. It can also be used as a measure of energy, for truck classification, or as a colloquial term.\nIt is derived from the tun, the term applied to a cask of the largest capacity. This could contain a volume between 175 and 213 imperial gallons (210 and 256 US gal; 800 and 970 l), which could weigh around 2,000 pounds (910 kg) and occupy some 60 cubic feet (1.7 m3) of space. The origin for the word ton comes from ancient Greek \u03b8\u03cd\u03bd\u03bd\u03bf\u03c2 (th\u00fannos, tuna fish).\nIn the United Kingdom the ton is defined as 2,240 avoirdupois pounds (1,016 kg). This is equivalent to 20 hundredweight, a hundredweight being eight stone, and a stone weighing 14 pounds.  From 1965 the UK embarked upon a programme of metrication and gradually introduced metric units, including the tonne (metric ton), defined as 1000 kg (2,204 lb). The UK Weights and Measures Act 1985 explicitly excluded from use for trade many units and terms, including the ton and the term \"metric ton\" for \"tonne\".In the United States and Canada a ton is defined to be 2,000 pounds (907 kg).\nWhere confusion is possible, the 2240 lb ton is called \"long ton\" and the 2000 lb ton \"short ton\"; the tonne is distinguished by its spelling, but usually pronounced the same as ton, hence the US term \"metric ton\". In the UK the final \"e\" of \"tonne\" can also be pronounced (), or \"metric ton\" when it is necessary to make the distinction.\nWhere accuracy is required the correct term must be used, but for many purposes this is not necessary: the metric and long tons differ by only 1.6%, and the short ton is within 11% of both. The ton is the heaviest unit of weight referred to in colloquial speech.\nThe term \"ton\" is also  used to refer to a number of units of volume, ranging from 35 to 100 cubic feet (0.99 to 2.83 m3) in capacity.\nIt can also be used as a unit of energy, expressed as an equivalent of coal burnt or TNT detonated.\nIn refrigeration, a ton is a unit of power, sometimes called a ton of refrigeration.  It is the power required to melt or freeze one short ton of ice per day.  The refrigeration ton hour is a unit of energy, the energy required to melt or freeze \u200b1\u204424 short ton of ice.\n\n\n== Units of mass/weight ==\nThere are several similar units of mass or volume called the ton:\n\n\n=== Others ===\nThe long ton is used for petroleum products such as aviation fuel.\nDeadweight ton (abbreviation 'DWT' or 'dwt') is a measure of a ship's carrying capacity, including bunker oil, fresh water, ballast water, crew and provisions. It is expressed in tonnes (1000 kg) or long tons (2240 pounds, about 1016 kg). This measurement is also used in the U.S. tonnage of naval ships.\nIncreasingly, tonnes are being used rather than long tons in measuring the displacement of ships. See tonnage.\nHarbour ton used in South Africa in the 20th century, 2000 pounds or one short ton.Both the long ton and the short ton are 20 hundredweight, the long hundredweight and the short hundredweight being 112 and 100 pounds respectively. Before the twentieth century there were several definitions. Prior to the 15th century in England, the ton was 20 hundredweight, each of 108 lb, giving a ton of 2,160 pounds (980 kg).  In the nineteenth century in different parts of Britain, definitions of 2240, 2352, and 2400 lb were used, with 2000 lb for explosives; the legal ton was usually [sic] 2240 lb.\nAssay ton (abbreviation 'AT') is not a unit of measurement, but a standard quantity used in assaying ores of precious metals; it is \u200b29 1\u20446 grams (short assay ton) or \u200b32 2\u20443 grams (long assay ton), the amount which bears the same ratio to a milligram as a short or long ton bears to a troy ounce. In other words, the number of milligrams of a particular metal found in a sample of this size gives the number of troy ounces contained in a short or long ton of ore.\nIn documents that predate 1960 the word ton is sometimes spelled tonne, but in more recent documents tonne refers exclusively to the metric ton.\nIn nuclear power plants tHM and MTHM mean tonnes of heavy metals, and MTU means tonnes of uranium. In the steel industry, the abbreviation THM means 'tons/tonnes hot metal', which refers to the amount of liquid iron or steel that is produced, particularly in the context of blast furnace production or specific consumption.\nA dry ton or dry tonne has the same mass value, but the material (sludge, slurries, compost, and similar mixtures in which solid material is soaked with or suspended in water) has been dried to a relatively low, consistent moisture level (dry weight). If the material is in its natural, wet state, it is called a wet ton or wet tonne.\n\n\n== Units of volume ==\n\nThe displacement, essentially the weight, of a ship is traditionally expressed in long tons. To simplify measurement it is determined by measuring the volume, rather than weight, of water displaced, and calculating the weight from the volume and density.\nFor practical purposes the displacement ton (DT) is a unit of volume, 35 cubic feet (0.9911 m3), the approximate volume occupied by one ton of seawater (the actual volume varies with salinity and temperature). It is slightly less than the 224 imperial gallons (1.018 m3) of the water ton (based on distilled water).\nOne measurement ton or freight ton is equal to 40 cubic feet (1.133 m3), but historically it has had several different definitions. It is sometimes abbreviated as \"MTON\".  It is used to determine the amount of money to be charged as \"Freight\" in carrying different sorts of cargo. In general if a cargo is heavier than salt water, the actual tonnage is used. If it is lighter than salt water, e.g. feathers, freight is calculated using Measurement Tons of 40 cubic feet. The freight ton represents the volume of a truck, train or other freight carrier. In the past it has been used for a cargo ship but the register ton is now preferred. It is correctly abbreviated as \"FT\" but some users are now using freight ton to represent a weight of 1 tonne (1,000 kg; 2,205 lb), thus the more common abbreviations are now M/T, MT, or MTON (for measurement ton), which still cause it to be confused with the tonne, or even the megatonne.\nThe register ton is a unit of volume used for the cargo capacity of a ship, defined as 100 cubic feet (2.832 m3). It is often abbreviated RT or GRT for gross registered ton (The former providing confusion with the refrigeration ton). It is known as a tonneau de mer in Belgium, but, in France, a tonneau de mer is 1.44 cubic metres (50.85 cu ft).\nThe Panama Canal/Universal Measurement System (PC/UMS) is based on net tonnage, modified for Panama Canal billing purposes. PC/UMS is based on a mathematical formula to calculate a vessel's total volume; a PC/UMS net ton is equivalent to 100 cubic feet of capacity.The water ton is used chiefly in Great Britain, in statistics dealing with petroleum products, and is defined as 224 imperial gallons (35.96 cu ft; 1.018 m3), the volume occupied by 1 long ton (2,240 lb; 1,016 kg) of water under the conditions that define the imperial gallon.\n\n\n== Units of energy and power ==\n\n\n=== Ton of TNT ===\n\nA ton of TNT or tonne of TNT is a unit of energy equal to 109 (thermochemical) calories, also known as a gigacalorie (Gcal), equal to 4.184 gigajoules (GJ).\nA kiloton of TNT or kilotonne of TNT is a unit of energy equal to 1012 calories, also known as a teracalorie (Tcal), equal to 4.184 terajoules (TJ).\nA megaton of TNT (1,000,000 metric tonnes) or megatonne of TNT is a unit of energy equal to 1015 calories, also known (infrequently) as a petacalorie (Pcal), equal to 4.184 petajoules (PJ).Note that these are small calories (cal). The large or dietary calorie (Cal) is equal to one kilocalorie (kcal), and is gradually being replaced by the latter correct term.\nEarly values for the explosive energy released by trinitrotoluene (TNT) ranged from 900 to 1100 calories per gram. In order to standardise the use of the term TNT as a unit of energy, an arbitrary value was assigned based on 1000 calories (1 kcal or 4.184 kJ) per gram. Thus there is no longer a direct connection to the chemical TNT itself. It is now merely a unit of energy that happens to be expressed using words normally associated with mass (e.g., kilogram, tonne, pound). The definition applies for both spellings: ton of TNT and tonne of TNT.\nMeasurements in tons of TNT have been used primarily to express nuclear weapon yields, though they have also been used since in seismology as well.\n\n\n=== Tonne of oil equivalent ===\nA tonne of oil equivalent (toe), sometimes ton of oil equivalent, is a conventional value, based on the amount of energy released by burning one tonne of crude oil. The unit is used, for example, by the International Energy Agency (IEA), for the reported world energy consumption as TPES in millions of toe (Mtoe).\nOther sources convert 1 toe into 1.28 tonne of coal equivalent (tce). 1 toe is also standardized as 7.33 barrel of oil equivalent (boe).\n\n\n=== Tonne of coal equivalent ===\nA tonne of coal equivalent (tce), sometimes ton of coal equivalent, is a conventional value, based on the amount of energy released by burning one tonne of coal. Plural name is tonnes of coal equivalent.\n\nPer the World Coal Association: 1 tonne of coal equivalent (tce) corresponds to 0.697 tonne of oil equivalent (toe)\nPer the International Energy Agency 1 tonne of coal equivalent (tce) corresponds to 0.700 tonne of oil equivalent (toe)\n\n\n=== Refrigeration ===\n\nThe unit ton is used in refrigeration and air conditioning to measure the rate of heat absorption. Prior to the introduction of mechanical refrigeration, cooling was accomplished by delivering ice.  Installing one ton of mechanical refrigeration capacity replaced the daily delivery of one ton of ice.\n\nIn North America, a standard ton of refrigeration is 12,000 BTU/h (3,517 W). \"The heat absorption per day is approximately the heat of fusion of 1 ton of ice at 32 \u00b0F (0 \u00b0C).\" This is approximately the power required to melt one short ton (2,000 lb or 907 kg) of ice at 0 \u00b0C (32 \u00b0F) in 24 hours, thus representing the delivery of 1 short ton (0.893 long tons; 0.907 t) of ice per day.\nA less common usage is the power required to cool 1 long ton (2,240 lb or 1,016 kg = 1 long ton or 1.120 short tons or 1.016 t) of water by 1 \u00b0F (0.56 \u00b0C) every 10 minutes = 13,440 BTU/h (3,939 W).A refrigeration ton should be regarded as power produced by a chiller when operating in standard AHRI conditions, which are typically 44 \u00b0F (7 \u00b0C) for chilled water unit, and 95 \u00b0F (35 \u00b0C) air entering the condenser. This is commonly referred to as \"true ton\". Manufacturers can also provide tables for chillers operating at other chilled water temperature conditions (as 65 \u00b0F or 18.3 \u00b0C) which can show more favorable data, which are not valid when making performance comparisons among units unless conversion rates are applied.The refrigeration ton is commonly abbreviated as RT.\n\n\n== Informal tons ==\nTon is also used informally, often as slang, to mean a large amount of something, material or not.  For example, \"I have a ton of homework to do this weekend.\"\nIn Britain, a ton is colloquially used to refer to 100 of a given unit. Ton can thus refer to a speed of 100 miles per hour, and is prefixed by an indefinite article, e.g. \"Lee was doing a ton down the motorway\"; to money e.g. \"How much did you pay for that?\" \"A ton\" (\u00a3100); to 100 points in a game e.g. \"Eric just threw a ton in our darts game\" (in some games, e.g. cricket, more commonly called a century); or to a hundred of any other countable figure.\nIn Dutch, when talking about money a ton is used to indicate 100,000. For example a house costing 2 ton would cost 200,000 euros.  This convention has been in use since at least the 18th century.\nIn Finnish, tonni is often used as a synonym for one thousand (1000), especially when referring to money. For example, \"tonnin seteli\" was a 1000 mark's banknote and a popular TV show was called \"Kymppitonni\" (\"ten tons\" = 10,000 marks).\n\n\n== See also ==\n\n\n== References ==",
        "unit": "ton",
        "url": "https://en.wikipedia.org/wiki/Ton"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Dynamic (shear) viscosity ===\n\nThe dynamic viscosity of a fluid expresses its resistance to shearing flows, where adjacent layers move parallel to each other with different speeds. It can be defined through the idealized situation known as a Couette flow, where a layer of fluid is trapped between two horizontal plates, one fixed and one moving horizontally at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  . This fluid has to be homogeneous in the layer and at different shear stresses. (The plates are assumed to be very large so that one need not consider what happens near their edges.)\nIf the speed of the top plate is low enough, the fluid particles will move parallel to it, and their speed will vary linearly from zero at the bottom to u at the top. Each layer of fluid will move faster than the one just below it, and friction between them will give rise to a force resisting their relative motion. In particular, the fluid will apply on the top plate a force in the direction opposite to its motion, and an equal but opposite one to the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nThe magnitude F of this force is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc in this formula is the viscosity (specifically, the dynamic viscosity) of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second).\nThe ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). Isaac Newton expressed the viscous forces by the differential equation\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This formula assumes that the flow is moving along parallel lines to x-axis. Furthermore, it assumes that the y-axis, perpendicular to the flow, points in the direction of maximum shear velocity. This equation can be used where the velocity does not vary linearly with y, such as in fluid flowing through a pipe. This equation is called the defining equation for shear viscosity. The viscosity is not a material constant, but a material property that depends on physical properties like temperature. The variation of the dynamic viscosity \u03bc at a given temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   can be evaluated on the basis of the dynamic viscosity at room temperature (\n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n        =\n        296.15\n        K\n      \n    \n    {\\displaystyle T_{0}=296.15K}\n  ) by the equation: \n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              120\n            \n            \n              T\n              +\n              120\n            \n          \n        \n        (\n        \n          \n            T\n            \n              T\n              \n                0\n              \n            \n          \n        \n        \n          )\n          \n            \n              3\n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =\\mu _{0}{\\frac {T_{0}+120}{T+120}}({\\frac {T}{T_{0}}})^{\\frac {3}{2}}}\n  \nThe functional relationship between viscosity and other physical properties is described by mathematical viscosity models called constitutive equations which are usually more complex than the defining equation for viscosity. There exist  many viscosity models, and based on type of development-reasoning, some viscosity models are selected and presented in the article Viscosity models for mixtures.\nUse of the Greek letter mu (\u03bc) for the dynamic viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC.\n\n\n=== Kinematic viscosity ===\nThe kinematic viscosity (also called \"momentum diffusivity\") is the ratio of the dynamic viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {m^{2}/s} }\n  . \n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  A convenient concept when analyzing the Reynolds number, which expresses the ratio of the inertial forces to the viscous forces, is:\n\n  \n    \n      \n        \n          R\n          e\n        \n        =\n        \n          \n            \n              \u03c1\n              V\n              D\n            \n            \u03bc\n          \n        \n        =\n        \n          \n            \n              V\n              D\n            \n            \u03bd\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathrm {Re} ={\\frac {\\rho VD}{\\mu }}={\\frac {VD}{\\nu }},}\n  where D is a diameter in the system, and V is the velocity of the fluid with respect to the object (m/s).\n\n\n=== Bulk viscosity ===\n\nWhen a compressible fluid is compressed or expanded evenly, without shear, it may still exhibit a form of internal friction that resists its flow. These forces are related to the rate of compression or expansion by a factor called the volume viscosity, bulk viscosity or second viscosity.\nThe bulk viscosity is important only when the fluid is being rapidly compressed or expanded, such as in sound and shock waves. Bulk viscosity explains the loss of energy in those waves, as described by Stokes' law of sound attenuation.\n\n\n=== Viscosity tensor ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure.\nIn very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model, the relationship is by definition a linear map, described by a viscosity tensor that, multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor.\nThe viscosity tensor has nine independent degrees of freedom in general. For isotropic Newtonian fluids, these can be reduced to two independent parameters. The most usual decomposition yields the dynamic viscosity \u03bc and the bulk viscosity \u03c3.\n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes. It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nIn general, the viscosity of a system depends in detail on how the molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the transient time correlation function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, calculating the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations. On the other hand, much more progress can be made for a dilute gas. Even elementary assumptions about how gas molecules move and interact lead to a basic understanding of the molecular origins of viscosity. More sophisticated treatments can be constructed by systematically coarse-graining the equations of motion of the gas molecules. An example of such a treatment is Chapman\u2013Enskog theory, which derives expressions for the viscosity of a dilute gas from the Boltzmann equation.Momentum transport in gases is generally mediated by discrete molecular collisions, and in liquids by attractive forces which bind molecules close together. Because of this, the dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n=== Gases ===\n\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. An elementary calculation for a dilute gas at temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   and density \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   gives\n\n  \n    \n      \n        \u03bc\n        =\n        \u03b1\n        \u03c1\n        \u03bb\n        \n          \n            \n              \n                2\n                \n                  k\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                m\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\alpha \\rho \\lambda {\\sqrt {\\frac {2k_{B}T}{\\pi m}}},}\n  where \n  \n    \n      \n        \n          k\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle k_{B}}\n   is the Boltzmann constant, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   the molecular mass, and \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   a numerical constant on the order of \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  . The quantity \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  , the mean free path, measures the average distance a molecule travels between collisions. Even without a priori knowledge of \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , this expression has interesting implications. In particular, since \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is typically inversely proportional to density and increases with temperature, \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   itself should increase with temperature and be independent of density. In fact, both of these predictions persist in more sophisticated treatments, and accurately describe experimental observations. Note that this behavior runs counter to common intuition regarding liquids, for which viscosity typically decreases with temperature.\nFor rigid elastic spheres of diameter \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  , \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   can be computed, giving\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            \u03b1\n            \n              \u03c0\n              \n                3\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                k\n                \n                  B\n                \n              \n              m\n              T\n            \n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu ={\\frac {\\alpha }{\\pi ^{3/2}}}{\\frac {\\sqrt {k_{B}mT}}{\\sigma ^{2}}}.}\n  In this case \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is independent of temperature, so \n  \n    \n      \n        \u03bc\n        \u221d\n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu \\propto T^{1/2}}\n  . For more complicated molecular models, however, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   depends on temperature in a non-trivial way, and simple kinetic arguments as used here are inadequate. More fundamentally, the notion of a mean free path becomes imprecise for particles that interact over a finite range, which limits the usefulness of the concept for describing real-world gases.\n\n\n==== Chapman\u2013Enskog theory ====\n\nA technique developed by Sydney Chapman and David Enskog in the early 1900s allows a more refined calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is based on the Boltzmann equation, which provides a systematic statistical description of a dilute gas in terms of intermolecular interactions. As such, their technique allows accurate calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   for more realistic molecular models, such as those incorporating intermolecular attraction rather than just hard-core repulsion.\nIt turns out that a more realistic modeling of interactions is essential for accurate prediction of the temperature dependence of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  , which experiments show increases more rapidly than the \n  \n    \n      \n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle T^{1/2}}\n   trend predicted for rigid elastic spheres. Indeed, the Chapman\u2013Enskog analysis shows that the predicted temperature dependence can be tuned by varying the parameters in various molecular models. A simple example is the Sutherland model, which describes rigid elastic spheres with weak mutual attraction. In such a case, the attractive force can be treated perturbatively, which leads to a particularly simple expression for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  :\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            5\n            \n              16\n              \n                \u03c3\n                \n                  2\n                \n              \n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    k\n                    \n                      B\n                    \n                  \n                  m\n                  T\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            1\n            \n              /\n            \n            2\n          \n        \n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  S\n                  T\n                \n              \n            \n            )\n          \n          \n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu ={\\frac {5}{16\\sigma ^{2}}}\\left({\\frac {k_{B}mT}{\\pi }}\\right)^{1/2}\\left(1+{\\frac {S}{T}}\\right)^{-1},}\n  where \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is independent of temperature, being determined only by the parameters of the intermolecular attraction. To connect with experiment, it is convenient to rewrite as\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            3\n            \n              /\n            \n            2\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              S\n            \n            \n              T\n              +\n              S\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}\\left({\\frac {T}{T_{0}}}\\right)^{3/2}{\\frac {T_{0}+S}{T+S}},}\n  where \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the viscosity at temperature \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  . If \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is known from experiments at \n  \n    \n      \n        T\n        =\n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T=T_{0}}\n   and at least one other temperature, then \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   can be calculated. It turns out that expressions for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   obtained in this way are accurate for a number of gases over a sizable range of temperatures. On the other hand, Chapman and Cowling argue that this success does not imply that molecules actually interact according to the Sutherland model. Rather, they interpret the prediction for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   as a simple interpolation which is valid for some gases over fixed ranges of temperature, but otherwise does not provide a picture of intermolecular interactions which is fundamentally correct and general. Slightly more sophisticated models, such as the Lennard\u2013Jones potential, may provide a better picture, but only at the cost of a more opaque dependence on temperature. In some systems the assumption of spherical symmetry must be abandoned as well, as is the case for vapors with highly polar molecules like H2O.\n\n\n=== Liquids ===\n\nIn contrast with gases, there is no simple yet accurate picture for the molecular origins of viscosity in liquids. \nAt the simplest level of description, the relative motion of adjacent layers in a liquid is opposed primarily by attractive molecular forces\nacting across the layer boundary. In this picture, one (correctly) expects viscosity to decrease with temperature. This is because\nincreasing temperature increases the random thermal motion of the molecules, which makes it easier for them to overcome their attractive interactions.Building on this visualization, a simple theory can be constructed in analogy with the discrete structure of a solid: groups of molecules in a liquid \nare visualized as forming \"cages\" which surround and enclose single molecules. These cages can be occupied or unoccupied, and\nstronger molecular attraction corresponds to stronger cages.\nDue to random thermal motion, a molecule \"hops\" between cages at a rate which varies inversely with the strength of molecular attractions. In equilibrium these \"hops\" are not biased in any direction.\nOn the other hand, in order for two adjacent layers to move relative to each other, the \"hops\" must be biased in the direction\nof the relative motion. The force required to sustain this directed motion can be estimated for a given shear rate, leading to\n\nwhere \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is the Avogadro constant, \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is the Planck constant, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of a mole of liquid, and \n  \n    \n      \n        \n          T\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle T_{b}}\n   is the boiling temperature. This result has the same form as the widespread and accurate empirical relation \n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are constants fit from data. One the other hand, several authors express caution with respect to this model.\nErrors as large as 30% can be encountered using equation (1), compared with fitting equation (2) to experimental data. More fundamentally, the physical assumptions underlying equation (1) have been extensively criticized. It has also been argued that the exponential dependence in equation (1) does not necessarily describe experimental observations more accurately than simpler, non-exponential expressions.In light of these shortcomings, the development of a less ad-hoc model is a matter of practical interest.\nForegoing simplicity in favor of precision, it is possible to write rigorous expressions for viscosity starting from the fundamental equations of motion for molecules. A classic example \nof this approach is Irving-Kirkwood theory. On the other hand, such expressions\nare given as averages over multiparticle correlation functions and are therefore difficult to apply in practice. \nIn general, empirically derived expressions (based on existing viscosity measurements) appear to be the only consistently reliable means of calculating viscosity in liquids.\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Blends of liquids ==\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n        +\n        \n          \n            \n              \u03b2\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\beta }}+{\\frac {\\beta x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\beta }}}\n  \n\n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  =mole fraction of particle species \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464. \nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654. \n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity for frequently encountered pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "kinematic viscosity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "Jansky",
        "clean": "Jansky",
        "text": "The jansky (symbol Jy) is a non-SI unit of spectral flux density, or spectral irradiance, used especially in radio astronomy. It is equivalent to 10\u221226 watts per square metre per hertz.\nThe flux density or monochromatic flux, \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  , of a source is the integral of the spectral radiance, \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , over the source solid angle:\n\n  \n    \n      \n        S\n        =\n        \n          \u222c\n          \n            source\n          \n        \n        B\n        (\n        \u03b8\n        ,\n        \u03d5\n        )\n        \n        \n          d\n        \n        \u03a9\n        .\n      \n    \n    {\\displaystyle S=\\iint \\limits _{\\text{source}}B(\\theta ,\\phi )\\,\\mathrm {d} \\Omega .}\n  The unit is named after pioneering US radio astronomer Karl Guthe Jansky and is defined as\n\n  \n    \n      \n        1\n         \n        \n          Jy\n        \n        =\n        \n          10\n          \n            \u2212\n            26\n          \n        \n        \n          \n            W\n            \n              \n                \n                  m\n                \n                \n                  2\n                \n              \n              \n                \u22c5\n              \n              \n                Hz\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 1~{\\text{Jy}}=10^{-26}{\\frac {\\text{W}}{{\\text{m}}^{2}{\\cdot }{\\text{Hz}}}}}\n   (SI) \n  \n    \n      \n        =\n        \n          10\n          \n            \u2212\n            23\n          \n        \n        \n          \n            erg\n            \n              \n                s\n              \n              \n                \u22c5\n              \n              \n                \n                  cm\n                \n                \n                  2\n                \n              \n              \n                \u22c5\n              \n              \n                Hz\n              \n            \n          \n        \n      \n    \n    {\\displaystyle =10^{-23}{\\frac {\\text{erg}}{{\\text{s}}{\\cdot }{\\text{cm}}^{2}{\\cdot }{\\text{Hz}}}}}\n   (cgs).Since the jansky is obtained by integrating over the whole source solid angle, it is most simply used to describe point sources; for example, the Third Cambridge Catalogue of Radio Sources (3C) reports results in Jy.\n\nFor extended sources, the surface brightness is often described with units of Jy per solid angle; for example, far-infrared (FIR) maps from the IRAS satellite are in MJy/sr.\nAlthough extended sources at all wavelengths can be reported with these units, for radio-frequency maps, extended sources have traditionally been described in terms of a brightness temperature; for example the Haslam et al. 408 MHz all-sky continuum survey is reported in terms of a brightness temperature in K.\n\n\n== Unit conversions ==\nJansky units are not a standard SI Unit, so it may be necessary to convert the measurements made in the unit to the SI equivalent in terms of watts per square metre per hertz (W/(m2\u00b7Hz)). However, other unit conversions are possible with respect to measuring this unit.\n\n\n=== AB magnitude ===\nThe flux density in Jy can be converted to a magnitude basis, for suitable assumptions about the spectrum. For instance, converting an AB magnitude to a flux-density in microjanskys is straightforward:\n\n  \n    \n      \n        \n          S\n          \n            v\n          \n        \n         \n        [\n        \u03bc\n        \n          Jy\n        \n        ]\n        =\n        \n          10\n          \n            6\n          \n        \n        \u22c5\n        \n          10\n          \n            23\n          \n        \n        \u22c5\n        \n          10\n          \n            \u2212\n            (\n            \n              AB\n            \n            +\n            48.6\n            )\n            \n              /\n            \n            2.5\n          \n        \n        =\n        \n          10\n          \n            (\n            23.9\n            \u2212\n            \n              AB\n            \n            )\n            \n              /\n            \n            2.5\n          \n        \n        .\n      \n    \n    {\\displaystyle S_{v}~[\\mu {\\text{Jy}}]=10^{6}\\cdot 10^{23}\\cdot 10^{-({\\text{AB}}+48.6)/2.5}=10^{(23.9-{\\text{AB}})/2.5}.}\n  \n\n\n=== dBW/(m2\u22c5Hz) ===\nThe linear flux density in Jy can be converted to a decibel basis, suitable for use in fields of telecommunication and radio engineering.\n1 jansky is equal to \u2212260 dBW/(m2\u00b7Hz), or \u2212230 dBm/(m2\u00b7Hz):\n\n  \n    \n      \n        \n          P\n          \n            \n              dBW\n            \n            \n              /\n            \n            (\n            \n              \n                m\n              \n              \n                2\n              \n            \n            \u22c5\n            \n              Hz\n            \n            )\n          \n        \n        =\n        10\n        \n          log\n          \n            10\n          \n        \n        \u2061\n        (\n        \n          P\n          \n            Jy\n          \n        \n        )\n        \u2212\n        260\n        ,\n      \n    \n    {\\displaystyle P_{{\\text{dBW}}/({\\text{m}}^{2}\\cdot {\\text{Hz}})}=10\\log _{10}(P_{\\text{Jy}})-260,}\n  \n  \n    \n      \n        \n          P\n          \n            \n              dBm\n            \n            \n              /\n            \n            (\n            \n              \n                m\n              \n              \n                2\n              \n            \n            \u22c5\n            \n              Hz\n            \n            )\n          \n        \n        =\n        10\n        \n          log\n          \n            10\n          \n        \n        \u2061\n        (\n        \n          P\n          \n            Jy\n          \n        \n        )\n        \u2212\n        230.\n      \n    \n    {\\displaystyle P_{{\\text{dBm}}/({\\text{m}}^{2}\\cdot {\\text{Hz}})}=10\\log _{10}(P_{\\text{Jy}})-230.}\n  \n\n\n== Usage ==\nThe flux to which the jansky refers can be in any form of energy.\nIt was created for and is still most frequently used in reference to electromagnetic energy, especially in the context of radio astronomy.\nThe brightest astronomical radio sources have flux densities of the order of 1\u2013100 janskys.  For example, the Third Cambridge Catalogue of Radio Sources lists some 300 to 400 radio sources in the Northern Hemisphere brighter than 9 Jy at 159 MHz.  This range makes the jansky a suitable unit for radio astronomy.\nGravitational waves also carry energy, so their flux density can also be expressed in terms of janskys.  Typical signals on Earth are expected to be 1020 Jy or more.  However, because of the poor coupling of gravitational waves to matter, such signals are difficult to detect.\nWhen measuring broadband continuum emissions, where the energy is roughly evenly distributed across the detector bandwidth, the detected signal will increase in proportion to the bandwidth of the detector (as opposed to signals with bandwidth narrower than the detector bandpass). To calculate the flux density in janskys, the total power detected (in watts) is divided by the receiver collecting area (in square meters), and then divided by the detector bandwidth (in hertz).  The flux density of astronomical sources is many orders of magnitude below 1 W/(m2\u00b7Hz), so the result is multiplied by 1026 to get a more appropriate unit for natural astrophysical phenomena.The millijansky, mJy, was sometimes referred to as a milli flux unit (m.f.u.) in the astronomical literature.\n\n\n== Orders of magnitude ==\nNote: Unless noted, all values are as seen from the Earth's surface.\n\n\n== References ==",
        "unit": "millijansky",
        "url": "https://en.wikipedia.org/wiki/Jansky"
    },
    {
        "_id": "Torque",
        "clean": "Torque",
        "text": "Torque, moment, or moment of force is rotational force. Just as a linear force is a push or a pull, a torque can be thought of as a twist to an object. In three dimensions, the torque is a pseudovector; for point particles, it is given by the cross product of the position vector (distance vector) and the force vector.\nThe symbol for torque is typically \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n  , the lowercase Greek letter tau. When it is called moment of force, it is commonly denoted by M.\nThe magnitude of torque of a rigid body depends on three quantities: the force applied, the lever arm vector connecting the origin to the point of force application, and the angle between the force and lever arm vectors. In symbols:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} \\,\\!}\n  \n  \n    \n      \n        \u03c4\n        =\n        \u2016\n        \n          r\n        \n        \u2016\n        \n        \u2016\n        \n          F\n        \n        \u2016\n        sin\n        \u2061\n        \u03b8\n        \n        \n      \n    \n    {\\displaystyle \\tau =\\|\\mathbf {r} \\|\\,\\|\\mathbf {F} \\|\\sin \\theta \\,\\!}\n  where\n\n  \n    \n      \n        \n          \u03c4\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n   is the torque vector and \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is the magnitude of the torque,\nr is the position vector (a vector from the origin of the coordinate system defined to the point where the force is applied)\nF is the force vector,\n\u00d7 denotes the cross product, which is defined as magnitudes of the respective vectors times sin \u03b8.\n\u03b8 is the angle between the force vector and the lever arm vector.The SI unit for torque is N\u22c5m. For more on the units of torque, see Units.\n\n\n== Defining terminology ==\n\nTorque is referred to using different vocabulary depending on geographical location and field of study. This article refers to the definition used in US physics in its usage of the word torque. In the UK and in US mechanical engineering, torque is referred to as moment of force, usually shortened to moment. In US physics and UK physics terminology these terms are interchangeable, unlike in US mechanical engineering, where the term torque is used for the closely related \"resultant moment of a couple\".Torque is defined mathematically as the rate of change of angular momentum of an object. The definition of torque states that one or both of the angular velocity or the moment of inertia of an object are changing. Moment is the general term used for the tendency of one or more applied forces to rotate an object about an axis, but not necessarily to change the angular momentum of the object (the concept which is called torque in physics). For example, a rotational force applied to a shaft causing acceleration, such as a drill bit accelerating from rest, results in a moment called a torque. By contrast, a lateral force on a beam produces a moment (called a bending moment), but since the angular momentum of the beam is not changing, this bending moment is not called a torque. Similarly with any force couple on an object that has no change to its angular momentum, such moment is also not called a torque.\nThis article follows the US physics terminology by calling all moments by the term torque, whether or not they cause the angular momentum of an object to change.\n\n\n== History ==\nThe concept of torque, also called moment or couple, originated with the studies of Archimedes on levers. The term torque was apparently introduced into English scientific literature by James Thomson, the brother of Lord Kelvin, in 1884.\n\n\n== Definition and relation to angular momentum ==\n\nA force applied at a right angle to a lever multiplied by its distance from the lever's fulcrum (the length of the lever arm) is its torque. A force of three newtons applied two metres from the fulcrum, for example, exerts the same torque as a force of one newton applied six metres from the fulcrum. The direction of the torque can be determined by using the right hand grip rule: if the fingers of the right hand are curled from the direction of the lever arm to the direction of the force, then the thumb points in the direction of the torque.More generally, the torque on a particle (which has the position r in some reference frame) can be defined as the cross product:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} ,}\n  where r is the particle's position vector relative to the fulcrum, and F is the force acting on the particle. The magnitude \u03c4 of the torque is given by\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        F\n        sin\n        \u2061\n        \u03b8\n        ,\n        \n      \n    \n    {\\displaystyle \\tau =rF\\sin \\theta ,\\!}\n  where r is the distance from the axis of rotation to the particle, F is the magnitude of the force applied, and \u03b8 is the angle between the position and force vectors. Alternatively,\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        \n          F\n          \n            \u22a5\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =rF_{\\perp },}\n  where F\u22a5 is the amount of force directed perpendicularly to the position of the particle. Any force directed parallel to the particle's position vector does not produce a torque.It follows from the properties of the cross product that the torque vector is perpendicular to both the position and force vectors. The torque vector points along the axis of the rotation that the force vector (starting from rest) would initiate. The resulting torque vector direction is determined by the right-hand rule.The unbalanced torque on a body along axis of rotation determines the rate of change of the body's angular momentum,\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}}\n  where L is the angular momentum vector and t is time. If multiple torques are acting on the body, it is instead the net torque which determines the rate of change of the angular momentum:\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        \u22ef\n        +\n        \n          \n            \u03c4\n          \n          \n            n\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}+\\cdots +{\\boldsymbol {\\tau }}_{n}={\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}.}\n  For the motion of a point particle,\n\n  \n    \n      \n        \n          L\n        \n        =\n        I\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {L} =I{\\boldsymbol {\\omega }},}\n  where I is the moment of inertia and \u03c9 is the angular velocity. It follows that\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              (\n              I\n              \n                \u03c9\n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        I\n        \n          \n            \n              \n                d\n              \n              \n                \u03c9\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              I\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        \n          \n            \n              \n                d\n              \n              (\n              m\n              \n                r\n                \n                  2\n                \n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        2\n        r\n        \n          p\n          \n            \n              |\n            \n            \n              |\n            \n          \n        \n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} (I{\\boldsymbol {\\omega }})}{\\mathrm {d} t}}=I{\\frac {\\mathrm {d} {\\boldsymbol {\\omega }}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} I}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+{\\frac {\\mathrm {d} (mr^{2})}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+2rp_{||}{\\boldsymbol {\\omega }},}\n  where \u03b1 is the angular acceleration of the particle, and p|| is the radial component of its linear momentum. This equation is the rotational analogue of Newton's Second Law for point particles, and is valid for any type of trajectory. Note that although force and acceleration are always parallel and directly proportional, the torque \u03c4 need not be parallel or directly proportional to the angular acceleration \u03b1. This arises from the fact that although mass is always conserved, the moment of inertia in general is not.\n\n\n=== Proof of the equivalence of definitions ===\nThe definition of angular momentum for a single particle is:\n\n  \n    \n      \n        \n          L\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          p\n        \n      \n    \n    {\\displaystyle \\mathbf {L} =\\mathbf {r} \\times {\\boldsymbol {p}}}\n  where \"\u00d7\" indicates the vector cross product, p is the particle's linear momentum, and r is the displacement vector from the origin (the origin is assumed to be a fixed location anywhere in space). The time-derivative of this is:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times {\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}\\times {\\boldsymbol {p}}.}\n  This result can easily be proven by splitting the vectors into components and applying the product rule. Now using the definition of force \n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} ={\\frac {\\mathrm {d} {\\boldsymbol {p}}}{\\mathrm {d} t}}}\n   (whether or not mass is constant) and the definition of velocity \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          v\n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}=\\mathbf {v} }\n  \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          p\n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} +\\mathbf {v} \\times {\\boldsymbol {p}}.}\n  The cross product of momentum \n  \n    \n      \n        \n          p\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {p}}}\n   with its associated velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is zero because velocity and momentum are parallel, so the second term vanishes.\nBy definition, torque \u03c4 = r \u00d7 F. Therefore, torque on a particle is equal to the\nfirst derivative of its angular momentum with respect to time.\nIf multiple forces are applied, Newton's second law instead reads Fnet = ma, and it follows that\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}=\\mathbf {r} \\times \\mathbf {F} _{\\mathrm {net} }={\\boldsymbol {\\tau }}_{\\mathrm {net} }.}\n  This is a general proof.\n\n\n== Units ==\nTorque has dimension force times distance, symbolically L2MT\u22122. Official SI literature suggests using the unit newton metre (N\u22c5m) or the unit joule per radian. The unit newton metre is properly denoted N\u22c5m or N m. This avoids ambiguity with mN, millinewtons.\nThe SI unit for energy or work is the joule. It is dimensionally equivalent to a force of one newton acting over a distance of one metre, but it is not used for torque. Energy and torque are entirely different concepts, so the practice of using different unit names (i.e., reserving newton metres for torque and using only joules for energy) helps avoid mistakes and misunderstandings. The dimensional equivalence of these units is not simply a coincidence: a torque of 1 N\u22c5m applied through a full revolution will require an energy of exactly 2\u03c0 joules. Mathematically,\n\n  \n    \n      \n        E\n        =\n        \u03c4\n        \u03b8\n         \n      \n    \n    {\\displaystyle E=\\tau \\theta \\ }\n  where E is the energy, \u03c4 is magnitude of the torque, and \u03b8 is the angle moved (in radians). This equation motivates the alternate unit name joules per radian.In Imperial units, \"pound-force-feet\" (lbf\u22c5ft), \"foot-pounds-force\", \"inch-pounds-force\", \"ounce-force-inches\" (ozf\u22c5in) are used, and other non-SI units of torque includes \"metre-kilograms-force\". For all these units, the word \"force\" is often left out. For example, abbreviating \"pound-force-foot\" to simply \"pound-foot\" (in this case, it would be implicit that the \"pound\" is pound-force and not pound-mass). This is an example of the confusion caused by the use of English units that may be avoided with SI units because of the careful distinction in SI between force (in newtons) and mass (in kilograms).\nTorque is sometimes listed with units that do not make dimensional sense, such as the gram-centimeter. In this case, \"gram\" should be understood as the force given by the weight of 1 gram on the surface of the Earth (i.e. 0.00980665 N). The surface of the Earth has a standard gravitational field strength of 9.80665 N/kg.\n\n\n== Special cases and other facts ==\n\n\n=== Moment arm formula ===\n\nA very useful special case, often given as the definition of torque in fields other than physics, is as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          moment arm\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{moment arm}})({\\text{force}}).}\n  The construction of the \"moment arm\" is shown in the figure to the right, along with the vectors r and F mentioned above. The problem with this definition is that it does not give the direction of the torque but only the magnitude, and hence it is difficult to use in three-dimensional cases. If the force is perpendicular to the displacement vector r, the moment arm will be equal to the distance to the centre, and torque will be a maximum for the given force. The equation for the magnitude of a torque, arising from a perpendicular force:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          distance to centre\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{distance to centre}})({\\text{force}}).}\n  For example, if a person places a force of 10 N at the terminal end of a wrench that is 0.5 m long (or a force of 10 N exactly 0.5 m from the twist point of a wrench of any length), the torque will be 5 N.m \u2013 assuming that the person moves the wrench by applying force in the plane of movement and perpendicular to the wrench.\n\n\n=== Static equilibrium ===\nFor an object to be in static equilibrium, not only must the sum of the forces be zero, but also the sum of the torques (moments) about any point. For a two-dimensional situation with horizontal and vertical forces, the sum of the forces requirement is two equations: \u03a3H = 0 and \u03a3V = 0, and the torque a third equation: \u03a3\u03c4 = 0. That is, to solve statically determinate equilibrium problems in two-dimensions, three equations are used.\n\n\n=== Net force versus torque ===\nWhen the net force on the system is zero, the torque measured from any point in space is the same. For example, the torque on a current-carrying loop in a uniform magnetic field is the same regardless of your point of reference. If the net force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   is not zero, and \n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}}\n   is the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}}\n  , then the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}}\n   is \u2026\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n        +\n        (\n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u2212\n        \n          \n            r\n          \n          \n            2\n          \n        \n        )\n        \u00d7\n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{2}={\\boldsymbol {\\tau }}_{1}+(\\mathbf {r} _{1}-\\mathbf {r} _{2})\\times \\mathbf {F} }\n  \n\n\n== Machine torque ==\n\nTorque is part of the basic specification of an engine: the power output of an engine is expressed as its torque multiplied by its rotational speed of the axis. Internal-combustion engines produce useful torque only over a limited range of rotational speeds (typically from around 1,000\u20136,000 rpm for a small car). The varying torque output over that range can be  measured with a dynamometer, and shown as a torque curve.\nSteam engines and electric motors tend to produce maximum torque close to zero rpm, with the torque diminishing as rotational speed rises (due to increasing friction and other constraints). Reciprocating steam engines and electric motors can start heavy loads from zero RPM without a clutch.\n\n\n== Relationship between torque, power, and energy ==\nIf a force is allowed to act through a distance, it is doing mechanical work. Similarly, if torque is allowed to act through a rotational distance, it is doing work. Mathematically, for rotation about a fixed axis through the center of mass,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n         \n        \n          d\n        \n        \u03b8\n        ,\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\ \\mathrm {d} \\theta ,}\n  where W is work, \u03c4 is torque, and \u03b81 and \u03b82 represent (respectively) the initial and final angular positions of the body.\n\n\n=== Proof ===\nThe work done by a variable force acting over a finite linear displacement \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is given by integrating the force with respect to an elemental linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n  \n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {s}}}\n  However, the infinitesimal linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}}\n   is related to a corresponding angular displacement \n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {\\theta }}}\n   and the radius vector \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   as \n\n  \n    \n      \n        \n          d\n        \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n        =\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\vec {s}}=\\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  Substitution in the above expression for work gives\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n  The expression \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}\\times {\\vec {r}}}\n   is a scalar triple product given by \n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]}\n  . An alternate expression for the same scalar triple product is\n\n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n            \n            \n              \n                \n                  r\n                  \u2192\n                \n              \n            \n          \n          ]\n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\left[{\\vec {F}}\\,\\mathrm {d} {\\vec {\\theta }}\\,{\\vec {r}}\\right]={\\vec {r}}\\times {\\vec {F}}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  But as per the definition of torque,\n\n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\tau }}={\\vec {r}}\\times {\\vec {F}}}\n  Corresponding substitution in the expression of work gives,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  Since the parameter of integration has been changed from linear displacement to angular displacement, the limits of the integration also change correspondingly, giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}{\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}}\n  If the torque and the angular displacement are in the same direction, then the scalar product reduces to a product of magnitudes; i.e., \n  \n    \n      \n        \n          \n            \n              \u03c4\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u03b8\n              \u2192\n            \n          \n        \n        =\n        \n          |\n          \n            \n              \n                \u03c4\n                \u2192\n              \n            \n          \n          |\n        \n        \n          |\n          \n            \n            \n              d\n            \n            \n              \n                \n                  \u03b8\n                  \u2192\n                \n              \n            \n          \n          |\n        \n        cos\n        \u2061\n        0\n        =\n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle {\\vec {\\tau }}\\cdot \\mathrm {d} {\\vec {\\theta }}=\\left|{\\vec {\\tau }}\\right|\\left|\\,\\mathrm {d} {\\vec {\\theta }}\\right|\\cos 0=\\tau \\,\\mathrm {d} \\theta }\n   giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\,\\mathrm {d} \\theta }\n  It follows from the work-energy theorem that W also represents the change in the rotational kinetic energy Er of the body, given by\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        I\n        \n          \u03c9\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle E_{\\mathrm {r} }={\\tfrac {1}{2}}I\\omega ^{2},}\n  where I is the moment of inertia of the body and \u03c9 is its angular speed.Power is the work per unit time, given by\n\n  \n    \n      \n        P\n        =\n        \n          \u03c4\n        \n        \u22c5\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle P={\\boldsymbol {\\tau }}\\cdot {\\boldsymbol {\\omega }},}\n  where P is power, \u03c4 is torque, \u03c9 is the angular velocity, and \u22c5 represents the scalar product.\nAlgebraically, the equation may be rearranged to compute torque for a given angular speed and power output. Note that the power injected by the torque depends only on the instantaneous angular speed \u2013 not on whether the angular speed increases, decreases, or remains constant while the torque is being applied (this is equivalent to the linear case where the power injected by a force depends only on the instantaneous speed \u2013 not on the resulting acceleration, if any).\nIn practice, this relationship can be observed in bicycles: Bicycles are typically composed of two road wheels, front and rear gears (referred to as sprockets) meshing with a circular chain, and a derailleur mechanism if the bicycle's transmission system allows multiple gear ratios to be used (i.e. multi-speed bicycle), all of which attached to the frame. A cyclist, the person who rides the bicycle, provides the input power by turning pedals, thereby cranking the front sprocket (commonly referred to as chainring). The input power provided by the cyclist is equal to the product of cadence (i.e. the number of pedal revolutions per minute) and the torque on spindle of the bicycle's crankset. The bicycle's drivetrain transmits the input power to the road wheel, which in turn conveys the received power to the road as the output power of the bicycle. Depending on the gear ratio of the bicycle, a (torque, rpm)input pair is converted to a (torque, rpm)output pair. By using a larger rear gear, or by switching to a lower gear in multi-speed bicycles, angular speed of the road wheels is decreased while the torque is increased, product of which (i.e. power) does not change.\nConsistent units must be used. For metric SI units, power is watts, torque is newton metres and angular speed is radians per second (not rpm and not revolutions per second).\nAlso, the unit newton metre is dimensionally equivalent to the joule, which is the unit of energy. However, in the case of torque, the unit is assigned to a vector, whereas for energy, it is assigned to a scalar.\n\n\n=== Conversion to other units ===\nA conversion factor may be necessary when using different units of power or torque.  For example, if rotational speed (revolutions per time) is used in place of angular speed (radians per time), we multiply by a factor of 2\u03c0 radians per revolution. In the following formulas, P is power, \u03c4 is torque, and \u03bd (Greek letter nu) is rotational speed.\n\n  \n    \n      \n        P\n        =\n        \u03c4\n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \u03bd\n      \n    \n    {\\displaystyle P=\\tau \\cdot 2\\pi \\cdot \\nu }\n  Showing units:\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \u03c4\n        \n          \n            (\n            N\n            \u22c5\n            m\n            )\n          \n        \n        \u22c5\n        2\n        \u03c0\n        \n          \n            (\n            r\n            a\n            d\n            \n              /\n            \n            r\n            e\n            v\n            )\n          \n        \n        \u22c5\n        \u03bd\n        \n          \n            (\n            r\n            e\n            v\n            \n              /\n            \n            s\n            e\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})=\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rev/sec)}}}\n  Dividing by 60 seconds per minute gives us the following.\n\n  \n    \n      \n        P\n        (\n        \n          \n            W\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  N\n                  \u22c5\n                  m\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              \n                \n                  (\n                  r\n                  p\n                  m\n                  )\n                \n              \n            \n            60\n          \n        \n      \n    \n    {\\displaystyle P({\\rm {W}})={\\frac {\\tau {\\rm {(N\\cdot m)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu {\\rm {(rpm)}}}{60}}}\n  where rotational speed is in revolutions per minute (rpm).\nSome people (e.g., American automotive engineers) use horsepower (imperial mechanical) for power, foot-pounds (lbf\u22c5ft) for torque and rpm for rotational speed. This results in the formula changing to:\n\n  \n    \n      \n        P\n        (\n        \n          \n            h\n            p\n          \n        \n        )\n        =\n        \n          \n            \n              \u03c4\n              \n                \n                  (\n                  l\n                  b\n                  f\n                  \u22c5\n                  f\n                  t\n                  )\n                \n              \n              \u22c5\n              2\n              \u03c0\n              \n                \n                  (\n                  r\n                  a\n                  d\n                  \n                    /\n                  \n                  r\n                  e\n                  v\n                  )\n                \n              \n              \u22c5\n              \u03bd\n              (\n              \n                \n                  r\n                  p\n                  m\n                \n              \n              )\n            \n            \n              33\n              ,\n              000\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P({\\rm {hp}})={\\frac {\\tau {\\rm {(lbf\\cdot ft)}}\\cdot 2\\pi {\\rm {(rad/rev)}}\\cdot \\nu ({\\rm {rpm}})}{33,000}}.}\n  The constant below (in foot pounds per minute) changes with the definition of the horsepower; for example, using metric horsepower, it becomes approximately 32,550.\nUse of other units (e.g., BTU per hour for power) would require a different custom conversion factor.\n\n\n=== Derivation ===\nFor a rotating object, the linear distance covered at the circumference of rotation is the product of the radius with the angle covered.  That is:  linear distance = radius \u00d7 angular distance.   And by definition, linear distance = linear speed \u00d7 time = radius \u00d7 angular speed \u00d7 time.\nBy the definition of torque: torque = radius \u00d7 force. We can rearrange this to determine force = torque \u00f7 radius. These two values can be substituted into the definition of power:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        force\n                      \n                      \u22c5\n                      \n                        linear distance\n                      \n                    \n                    time\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        (\n                        \n                          \n                            \n                              torque\n                              r\n                            \n                          \n                        \n                        )\n                      \n                      \u22c5\n                      (\n                      r\n                      \u22c5\n                      \n                        angular speed\n                      \n                      \u22c5\n                      t\n                      )\n                    \n                    t\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                \n                  angular speed\n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\frac {{\\text{force}}\\cdot {\\text{linear distance}}}{\\text{time}}}\\\\[6pt]&={\\frac {\\left({\\dfrac {\\text{torque}}{r}}\\right)\\cdot (r\\cdot {\\text{angular speed}}\\cdot t)}{t}}\\\\[6pt]&={\\text{torque}}\\cdot {\\text{angular speed}}.\\end{aligned}}}\n  The radius r and time t have dropped out of the equation.  However, angular speed must be in radians, by the assumed direct relationship between linear speed and angular speed at the beginning of the derivation.  If the rotational speed is measured in revolutions per unit of time, the linear speed and distance are increased proportionately by 2\u03c0 in the above derivation to give:\n\n  \n    \n      \n        \n          power\n        \n        =\n        \n          torque\n        \n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \n          rotational speed\n        \n        .\n        \n      \n    \n    {\\displaystyle {\\text{power}}={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}.\\,}\n  If torque is in newton metres and rotational speed in revolutions per second, the above equation gives power in newton metres per second or watts.  If Imperial units are used, and if torque is in pounds-force feet and rotational speed in revolutions per minute, the above equation gives power in foot pounds-force per minute.  The horsepower form of the equation is then derived by applying the conversion factor 33,000 ft\u22c5lbf/min per horsepower:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                2\n                \u03c0\n                \u22c5\n                \n                  rotational speed\n                \n                \u22c5\n                \n                  \n                    \n                      \n                        ft\n                      \n                      \u22c5\n                      \n                        lbf\n                      \n                    \n                    min\n                  \n                \n                \u22c5\n                \n                  \n                    horsepower\n                    \n                      33\n                      ,\n                      000\n                      \u22c5\n                      \n                        \n                          \n                            \n                              ft\n                            \n                            \u22c5\n                            \n                              lbf\n                            \n                          \n                          min\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2248\n                \n                  \n                    \n                      \n                        torque\n                      \n                      \u22c5\n                      \n                        RPM\n                      \n                    \n                    \n                      5\n                      ,\n                      252\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}\\cdot {\\frac {\\text{horsepower}}{33,000\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}}}\\\\[6pt]&\\approx {\\frac {{\\text{torque}}\\cdot {\\text{RPM}}}{5,252}}\\end{aligned}}}\n  because \n  \n    \n      \n        5252.113122\n        \u2248\n        \n          \n            \n              33\n              ,\n              000\n            \n            \n              2\n              \u03c0\n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle 5252.113122\\approx {\\frac {33,000}{2\\pi }}.\\,}\n  \n\n\n== Principle of moments ==\nThe Principle of Moments, also known as Varignon's theorem (not to be confused with the geometrical theorem of the same name) states that the sum of torques due to several forces applied to a single point is equal to the torque due to the sum (resultant) of the forces. Mathematically, this follows from:\n\n  \n    \n      \n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            1\n          \n        \n        )\n        +\n        (\n        \n          r\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            2\n          \n        \n        )\n        +\n        \u22ef\n        =\n        \n          r\n        \n        \u00d7\n        (\n        \n          \n            F\n          \n          \n            1\n          \n        \n        +\n        \n          \n            F\n          \n          \n            2\n          \n        \n        +\n        \u22ef\n        )\n        .\n      \n    \n    {\\displaystyle (\\mathbf {r} \\times \\mathbf {F} _{1})+(\\mathbf {r} \\times \\mathbf {F} _{2})+\\cdots =\\mathbf {r} \\times (\\mathbf {F} _{1}+\\mathbf {F} _{2}+\\cdots ).}\n  \n\n\n== Torque multiplier ==\n\nTorque can be multiplied via three methods:  by locating the fulcrum such that the length of a lever is increased; by using a longer lever; or by the use of a speed reducing gearset or gear box.  Such a mechanism multiplies torque, as rotation rate is reduced.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\"Horsepower and Torque\" An article showing how power, torque, and gearing affect a vehicle's performance.\n\"Torque vs. Horsepower: Yet Another Argument\" An automotive perspective\nTorque and Angular Momentum in Circular Motion  on Project PHYSNET.\nAn interactive simulation of torque\nTorque Unit Converter\nA feel for torque An order-of-magnitude interactive.",
        "unit": "torque",
        "url": "https://en.wikipedia.org/wiki/Torque"
    },
    {
        "_id": "Pound_sterling",
        "clean": "Pound sterling",
        "text": "The pound sterling (symbol: \u00a3; ISO code: GBP), commonly known as the pound and less commonly referred to as Sterling, is the official currency of the United Kingdom, Jersey, Guernsey, the Isle of Man, South Georgia and the South Sandwich Islands, the British Antarctic Territory, and Tristan da Cunha. It is subdivided into 100 pence (singular: penny, abbreviated: p). A number of nations that do not use sterling also have currencies called the pound.  At various times, the pound sterling was commodity money or bank notes backed by silver or gold, but it is currently fiat money, backed only by the economy in the areas where it is accepted. The pound sterling is the world's oldest currency still in use and which has been in continuous use since its inception.Sterling is the fourth most-traded currency in the foreign exchange market, after the United States dollar, the euro, and the Japanese yen. Together with those three currencies and the Chinese yuan  it forms the basket of currencies which calculate the value of IMF special drawing rights. Sterling is also the third most-held reserve currency in global reserves (about 4%).The British Crown dependencies of Guernsey, Jersey and the Isle of Man produce their own local issues of sterling (the Guernsey pound, the Jersey pound and the Manx pound) which are considered fully equivalent to UK sterling in their respective regions. The pound sterling is also used in Gibraltar (alongside the Gibraltar pound), the Falkland Islands (alongside the Falkland Islands pound), Saint Helena and Ascension Island in Saint Helena, Ascension and Tristan da Cunha (alongside the Saint Helena pound). The Bank of England is the central bank for the pound sterling, issuing its own coins and banknotes, and regulating issuance of banknotes by private banks in Scotland and Northern Ireland. Banknotes issued by other jurisdictions are not regulated by the Bank of England; local governments use Bank of England notes as backing for local issuance by allowing them to be exchanged 1:1 at face value.\n\n\n== Names ==\nThe full official name pound sterling (plural: pounds sterling), is used mainly in formal contexts and also when it is necessary to distinguish the United Kingdom currency from other currencies with the same name. Otherwise the term pound is normally used. The currency name is sometimes abbreviated to just sterling, particularly in the wholesale financial markets, but not when referring to specific amounts; for example, \"Payment is accepted in sterling\" but never \"These cost five sterling\". The abbreviations \"ster.\" and \"stg.\" are sometimes used. The term \"British pound\" is sometimes incorrectly used in less formal contexts, and it is not an official name of the currency.\nThe exchange rate of the pound sterling against the US Dollar is referred to as \"cable\" in the wholesale foreign exchange markets. The origins of this term are attributed to the fact that in the 1800s, the GBP/USD exchange rate was transmitted via transatlantic cable. Forex traders of GBP/USD are sometimes referred to as \"cable dealers\". GBP/USD is now the only currency pair with its own name in the foreign exchange markets, after IEP/USD, known as \"wire\" particularly in the forward FX markets, no longer exists after the Irish Pound was replaced by the euro in 1999.\n\nThere is apparent convergence of opinion regarding the origin of the term \"pound sterling\", toward its derivation from the name of a small Norman silver coin, and away from its association with Easterlings (Germanic traders) or other etymologies. Hence, the Oxford English Dictionary (and sources derived therefrom) state that the \"most plausible\" etymology is derivation from the Old English steorra for \"star\" with the added diminutive suffix \"-ling\", to mean \"little star\" and to refer to a silver penny of the English Normans. As another established source notes, the compound expression was then derived:silver coins known as \"sterlings\" were issued in the Saxon kingdoms, 240 of them being minted from a pound of silver... Hence, large payments came to be reckoned in \"pounds of sterlings,\" a phrase later shortened...\n However, the perceived narrow window of the issuance of this coin, and the fact that coin designs changed frequently in the period in question, led Philip Grierson to reject this in favour of a more complex theory.Another argument that the Hanseatic League was the origin for both the origin of its definition and manufacture, and in its name is that the German name for the Baltic is \"Ost See\", or \"East Sea\", and from this the Baltic merchants were called \"Osterlings\", or \"Easterlings\". In 1260, Henry III granted them a charter of protection and land for their Kontor, the Steelyard of London, which by the 1340s was also called \"Easterlings Hall\", or Esterlingeshalle. Because the League's money was not frequently debased like that of England, English traders stipulated to be paid in pounds of the \"Easterlings\", which was contracted to \"'sterling\".For further discussion of the etymology of \"sterling\", see sterling silver.\nThe currency sign for the pound is \u00a3, which is usually written with a single cross-bar (as on sterling bank notes), though a version with a double cross-bar (\u20a4) is also sometimes seen. This symbol derives from medieval Latin documents; the Roman words libra, solidus, and denarius (\u00a3sd) referred to pounds, shillings and pence in the British pre-decimal (duodecimal) currency system and the black-letter \"L\" was the abbreviation for libra, the basic Roman unit of weight.\nThe ISO 4217 currency code is GBP, formed from \"GB\", the ISO 3166-1 alpha-2 code for the United Kingdom, and the first letter of \"pound\". It does not stand for \"Great Britain Pound\" or \"Great British Pound\". Occasionally, the abbreviation \"UKP\" is used but this is non-standard because the ISO 3166 country code for the United Kingdom is GB (see Terminology of the British Isles). The Crown dependencies use their own (non-ISO) codes: GGP (Guernsey pound), JEP (Jersey pound) and IMP (Isle of Man pound). Stocks are often traded in pence, so traders may refer to pence sterling, GBX (sometimes GBp), when listing stock prices.\nA common slang term for the pound sterling or pound is quid, which is singular and plural, except in the common phrase \"Quids in!\" The term may have come via Italian immigrants from \"scudo\", the name for a number of coins used in Italy until the 19th century; or from Latin 'quid' via the common phrase quid pro quo, literally, \"what for what,\" or, figuratively, \"An equal exchange or substitution\".\n\n\n== Subdivisions and other units ==\n\n\n=== Decimal coinage ===\nSince decimalisation in 1971 (see Decimal Day), the pound has been divided into 100 pence (until 1981 described on the coinage as \"new pence\"). The symbol for the penny is \"p\"; hence an amount such as 50p (\u00a30.50) properly pronounced \"fifty pence\" is more colloquially, quite often, pronounced \"fifty pee\" /f\u026afti pi/. This also helped to distinguish between new and old pence amounts during the changeover to the decimal system. A decimal halfpenny was issued until 1984, but was removed due to having a higher cost to manufacture than its face value.\n\n\n=== Pre-decimal ===\n\nBefore decimalisation, the pound was divided into 20 shillings and each shilling into 12 pence, making 240 pence to the pound. The symbol for the shilling was \"s.\"\u2014not from the first letter of the word, but from the Latin solidus. The symbol for the penny was \"d.\", from the French denier, from the Latin denarius (the solidus and denarius were Roman coins). A mixed sum of shillings and pence, such as 3 shillings and 6 pence, was written as \"3/6\" or \"3s. 6d.\" and spoken as \"three and six\" or \"three and sixpence\" except for \"1/1,\" \"2/1\" etc., which were spoken as \"one and a penny\", \"two and a penny\", etc.). 5 shillings, for example, was written as \"5s.\" or, more commonly, \"5/\u2013\".\nVarious coin denominations had, and in some cases continue to have, special names\u2014such as crown, farthing, sovereign and guinea. See Coins of the pound sterling and List of British coins and banknotes for details.\nBy the 1950s, coins of Kings George III, George IV and William IV had disappeared from circulation, but coins (at least the penny) bearing the head of any British king or queen from Queen Victoria onwards could be found in circulation. Silver coins were replaced by those in cupro-nickel in 1947, and by the 1960s the silver coins were rarely seen. Silver/cupro-nickel shillings (from any period after 1816) and florins (2 shillings) remained as legal tender after decimalisation (as 5p and 10p respectively) until 1993, but are now officially demonetised.\n\n\n== History ==\nThe pound sterling is the world's oldest currency still in use.\n\n\n=== Anglo-Saxon ===\n\nThe pound was a unit of account in Anglo-Saxon England, equal to 240 silver pennies and equivalent to one pound weight of silver. It evolved into the modern British currency, the pound sterling.\nThe accounting system of 4 farthings = 1 penny, 12 pence = 1 shilling, 20 shillings = 1 pound was adopted from that introduced by Charlemagne to the Frankish Empire (see French livre).\nThe origins of sterling lie in the reign of King Offa of Mercia (757\u2013796), who introduced the silver penny. It copied the denarius of the new currency system of Charlemagne's Frankish Empire. As in the Carolingian system, 240 pennies weighed 1 pound (corresponding to Charlemagne's libra), with the shilling corresponding to Charlemagne's solidus and equal to 12d. At the time of the penny's introduction, it weighed 22.5 troy grains of fine silver (32 tower grains; about 1.5 g), indicating that the Mercian pound weighed 5,400 troy grains (the Mercian pound became the basis of the tower pound, which also weighed 5,400 troy grains, equivalent to 7,680 tower grains, about 350g).\n\n\n=== Medieval ===\nThe early pennies were struck from fine silver (as pure as was available). However, in 1158, a new coinage was introduced by King Henry II (known as the Tealby penny) which was struck from 0.925 (92.5%) silver. This became the standard until the 20th century and is today known as sterling silver, named after its association with the currency. Sterling silver is harder than the 0.999 (99.9%) fine silver that was traditionally used, and so sterling silver coins did not wear down as rapidly as fine silver coins. The English currency was almost exclusively silver until 1344, when the gold noble was successfully introduced into circulation. However, silver remained the legal basis for sterling until 1816.\nDuring the time of Henry III, the pound sterling equalled the tower (weight) pound. In the 28th year of Edward I (around 1300), the tale (money) pound, or pound sterling, first began to differ from (weigh less than) the tower pound, from which it originated, for by indenture of that year the pound weight was to contain 20s. 3d. in tale pound. In the 27th year of Edward III (around 1354), the pound sterling was now only 80% of the pound weight, or 9 oz 12 dwt (or 9.6 oz) tower. By an Act of 13 Henry IV (around 1412), the pound weight of standard silver was to contain thirty shillings in tale, or one and a half pounds sterling; thus the pound sterling reduced to two-thirds of a pound weight, or 8 oz tower. The pound sterling was adjusted in weight several more times thereafter.\nIn the reign of Henry IV (1399\u20131413), the penny was reduced in weight to 15 grains (0.97 g) of silver, with a further reduction to 12 grains (0.78 g) in 1464.\n\n\n=== Tudor ===\nDuring the reigns of Henry VIII and Edward VI, the silver coinage was drastically debased, although the pound was redefined to the troy pound of 5,760 grains (373 g) in 1526. In 1544, a silver coinage was issued containing just one-third silver and two-thirds copper\u2014equating to .333 silver, or 33.3% pure. The result was a coin copper in appearance but relatively pale in colour. In 1552, a new silver coinage was introduced, struck in sterling silver. However, the penny's weight was reduced to 8 grains (0.52 g), so 1 troy pound of sterling silver produced 60 shillings of coins. This silver standard was known as the \"60-shilling standard\" and lasted until 1601 when a \"62-shilling standard\" was introduced, reducing the penny's weight to \u200b7 23\u204431 grains (0.50 g).\nThroughout this period, the size and value of the gold coinage fluctuated considerably.\n\n\n=== Unofficial gold standard ===\nIn 1663, a new gold coinage was introduced based on the 22 carat fine guinea. Fixed in weight at \u200b44 1\u20442 to the troy pound from 1670, this coin's value varied considerably until 1717, when it was fixed at 21 shillings (21/-, 1.05 pounds). However, despite the efforts of Sir Isaac Newton, Master of the Mint, to reduce the guinea's value, this valuation overvalued gold relative to silver when compared to the valuations in other European countries. In line with Gresham's Law, British merchants sent silver abroad in payments whilst goods for export were paid for with gold. As a consequence of these flows of silver out and gold in, Great Britain was effectively on a gold standard. Trade with China aggravated this outflow, as the Chinese refused to accept anything but silver in payment for exports. From the mid-17th century, around 28,000 metric tons (27,600 imperial tons) of silver were received by China, principally from European powers, in exchange for Chinese tea and other goods. In order to trade with China, Great Britain had first to trade with the other European nations to receive silver, which led to the East India Company redressing this trade imbalance through the indirect sale of opium to the Chinese.Domestic offtake further reduced silver in circulation, as the improving fortunes of the merchant class led to increased demand for tablewares. Silversmiths had always regarded coinage as a source of raw material, already verified for fineness by the government. As a result, sterling coins were being melted and fashioned into sterling silverware at an accelerating rate. A 1697 Act of Parliament tried to stem this tide by raising the minimum acceptable fineness on wrought plate from sterling's 92.5% to a new Britannia silver standard of 95.83%. Silverware made purely from melted coins would be found wanting when the silversmith took his wares to the Assay Office, thus discouraging the melting of coins.\n\n\n=== Establishment of modern currency ===\nThe Bank of England was founded in 1694, followed by the Bank of Scotland a year later. Both began to issue paper money.\n\n\n=== Currency of Great Britain (1707) and the United Kingdom (1801) ===\nThe pound Scots once had much the same value as the pound sterling, but it suffered far higher devaluation until in the 17th century it was pegged to sterling at a value of 12 pounds Scots = 1 pound sterling.\nIn 1707, the Kingdom of England and the Kingdom of Scotland merged to form the Kingdom of Great Britain. In accordance with the Treaty of Union, the currency of Great Britain was sterling, with the pound Scots soon being replaced by sterling at the pegged value.\nIn 1801, Great Britain and the Kingdom of Ireland were united to form the United Kingdom of Great Britain and Ireland. However, the Irish pound continued to exist and was not replaced by sterling until January 1826. The conversion rate had long been thirteen Irish pounds to twelve pounds sterling. The Irish pound was readopted in 1928, six years after the Anglo-Irish Treaty restored Irish independence.\n\n\n=== Use in the Empire ===\n\nSterling circulated in much of the British Empire. In some parts, it was used alongside local currencies. For example, the gold sovereign was legal tender in Canada despite the use of the Canadian dollar. Several colonies and dominions adopted the pound as their own currency. These included Australia, Barbados, British West Africa, Cyprus, Fiji, British India, the Irish Free State, Jamaica, New Zealand, South Africa and Southern Rhodesia. Some of these retained parity with sterling throughout their existence (e.g. the South African pound), whilst others deviated from parity after the end of the gold standard (e.g. the Australian pound). These currencies and others tied to sterling constituted the sterling area.\nThe original English colonies on mainland North America were not party to the sterling area because the above-mentioned silver shortage in England coincided with these colonies' formative years. As a result of equitable trade (and rather less equitable piracy), the Spanish milled dollar became the most common coin within the English colonies.\n\n\n=== Gold standard ===\nDuring the American war of independence and the Napoleonic wars, Bank of England notes were legal tender, and their value floated relative to gold. The Bank also issued silver tokens to alleviate the shortage of silver coins. In 1816, the gold standard was adopted officially, with the silver standard reduced to 66 shillings (66/-, \u00a33 6s), rendering silver coins a \"token\" issue (i.e. not containing their value in precious metal). In 1817, the sovereign was introduced, valued at 20 shillings. Struck in 22\u2011carat gold, it contained 113 grains (7.3 g) of gold and replaced the guinea as the standard British gold coin without changing the gold standard. In 1825, the Irish pound, which had been pegged to sterling since 1801 at a rate of 13 Irish pounds = 12 pounds sterling, was replaced, at the same rate, with sterling.\nBy the 19th century the pound sterling was widely accepted outside Britain. The American Nellie Bly carried Bank of England notes on her 1889\u20131890 trip around the world in 72 days. During the late 19th and early 20th centuries, many other countries adopted the gold standard. As a consequence, conversion rates between different currencies could be determined simply from the respective gold standards. The pound sterling was equal to 4.85 United States dollars, 5.25 Canadian dollars, 12.10 Dutch guilders, 26.28 French francs (or equivalent currencies in the Latin Monetary Union), 20.43 German marks or 24.02 Austro-Hungarian krone. After the International Monetary Conference of 1867 in Paris, the possibility of the UK joining the Latin Monetary Union was discussed, and a Royal Commission on International Coinage examined the issues, resulting in a decision against joining monetary union.\nThe gold standard was suspended at the outbreak of the war in 1914, with Bank of England and Treasury notes becoming legal tender. Before World War I, the United Kingdom had one of the world's strongest economies, holding 40% of the world's overseas investments. But after the end of the war, the country was indebted: Britain owed \u00a3850 million (\u00a337.3 billion as of 2015) with interest costing the country some 40% of all government spending. To try to resume stability, a version of the gold standard was reintroduced in 1925, under which the currency was fixed to gold at its pre-war peg, but one could only exchange currency for gold bullion, not for coins. This was abandoned on 21 September 1931, during the Great Depression, and sterling suffered an initial devaluation of some 25%.\n\n\n=== Bretton Woods ===\n\nIn 1940, an agreement with the US pegged the pound to the U.S. dollar at a rate of \u00a31 = $4.03. (Only the year before, it had been $4.86.) This rate was maintained through the Second World War and became part of the Bretton Woods system which governed post-war exchange rates. Under continuing economic pressure, and despite months of denials that it would do so, on 19 September 1949 the government devalued the pound by 30.5% to $2.80. The move prompted several other currencies to be devalued against the dollar.\nOperation Bernhard was the codename of a secret Nazi plan devised during the Second World War by the RSHA and the SS to destabilise the British economy via economic warfare by flooding the global economy and the British Empire with forged Bank of England \u00a35, \u00a310, \u00a320, and \u00a350 notes.\nIn 1961, 1964, and 1966, the pound came under renewed pressure, as speculators were selling pounds for dollars. In summer 1966, with the value of the pound falling in the currency markets, exchange controls were tightened by the Wilson government. Among the measures, tourists were banned from taking more than \u00a350 out of the country in travellers' cheques and remittances, plus \u00a315 in cash; this restriction was not lifted until 1979. The pound was devalued by 14.3% to $2.40 on 18 November 1967.\n\n\n=== Decimalisation ===\n\nUntil decimalisation, amounts were stated in pounds, shillings, and pence, with various widely understood notations. The same amount was denoted by 32s 6d, 32/6, \u00a31 12s 6d, \u00a31/12/6. It was customary to specify some prices (for example professional fees and auction prices for works of art) in guineas (one guinea was 21 shillings) although guinea coins were no longer in use.\nFormal parliamentary proposals to decimalise sterling were first made in 1824 when Sir John Wrottesley, MP for Staffordshire, asked in the British House of Commons whether consideration had been given to decimalising the currency. Wrottesley raised the issue in the House of Commons again in 1833, and it was again raised by John Bowring, MP for Kilmarnock Burghs, in 1847 whose efforts led to the introduction in 1848 of what was in effect the first decimal coin in the United Kingdom, the florin, valued at one-tenth of a pound sterling. However, full decimalisation was resisted, although the florin coin, re-designated as ten new pence, survived the transfer to a full decimal system in 1971, with examples surviving in British coinage until 1993.\nJohn Benjamin Smith, MP for Stirling Burghs, raised the issue of full decimalisation again in Parliament in 1853, resulting in the Chancellor of the Exchequer, William Gladstone, announcing soon afterwards that \"the great question of a decimal coinage\" was \"now under serious consideration\". A full proposal for the decimalisation of sterling was then tabled in the House of Commons in June 1855, by William Brown, MP for Lancashire Southern, with the suggestion that the pound sterling be divided into one thousand parts, each called a \"mil\", or alternatively a farthing, as the pound was then equivalent to 960 farthings which could easily be rounded up to one thousand farthings in the new system. This did not result in the conversion of the pound sterling into a decimal system, but it was agreed to establish a Royal Commission to look into the issue. However, largely due to the hostility to decimalisation of two of the appointed commissioners, Lord Overstone (a banker) and John Hubbard (Governor of the Bank of England), decimalisation in Britain was effectively quashed for over a hundred years.However, the pound sterling was decimalised in various British colonial territories before the United Kingdom (and in several cases in line with William Brown's proposal that the pound be divided into 1,000 parts, called mils). These included Hong Kong from 1863 to 1866; Cyprus from 1955 until 1960 (and continued on the island as the division of the Cypriot pound until 1983); and the Palestine Mandate from 1926 until 1948.Towards the end of the Second World War, various attempts to decimalise the pound sterling in the United Kingdom were made. Later, in 1966, the British government decided to include in the Queen's Speech a plan to convert the pound into a decimal currency. As a result of this, on 15 February 1971, the UK decimalised the pound sterling, replacing the shilling and penny with a single subdivision, the new penny. For example, a price tag of \u00a31 12s 6d became \u200b\u00a31.62 1\u20442. The word \"new\" was omitted from coins minted after 1981.\n\n\n=== Free-floating pound ===\nWith the breakdown of the Bretton Woods system, the pound floated from August 1971 onwards. At first it appreciated a little, rising to almost $2.65 in March 1972 from $2.42, the upper bound of the band in which it had been fixed. The sterling area effectively ended at this time, when the majority of its members also chose to float freely against the pound and the dollar.\n\n\n=== 1976 sterling crisis ===\nJames Callaghan became Prime Minister in 1976. He was immediately told the economy was facing huge problems, according to documents released in 2006 by the National Archives. The effects of the 1973 oil crisis were still being felt, with inflation rising to over 27% in 1975. Financial markets were beginning to believe the pound was overvalued, and in April that year The Wall Street Journal advised the sale of sterling investments in the face of high taxes, in a story that ended with \"goodbye, Great Britain. It was nice knowing you\". At the time the UK government was running a budget deficit, and Labour's strategy emphasised high public spending. Callaghan was told there were three possible outcomes: a disastrous free fall in sterling, an internationally unacceptable siege economy, or a deal with key allies to prop up the pound while painful economic reforms were put in place. The US government feared the crisis could endanger NATO and the European Economic Community (EEC), and in light of this the US Treasury set out to force domestic policy changes. In November 1976 the International Monetary Fund (IMF) announced the conditions for a loan, including deep cuts in public expenditure.\n\n\n=== 1979\u201389 ===\nThe Conservative Party was elected to office in 1979, on a programme of fiscal austerity. Initially the pound rocketed, moving above US$2.40, as interest rates rose in response to the monetarist policy of targeting money supply. The high exchange rate was widely blamed for the deep recession of 1981. Sterling fell sharply after 1980; at its lowest, the pound stood at just $1.03 in March 1985, before rising to $1.70 in December 1989.\n\n\n=== Following the Deutsche Mark ===\nIn 1988, Margaret Thatcher's Chancellor of the Exchequer, Nigel Lawson, decided that the pound should \"shadow\" the West German Deutsche Mark (DM), with the unintended result of a rapid rise in inflation as the economy boomed due to low interest rates. (For ideological reasons, the Conservative Government declined to use alternative mechanisms to control the explosion of credit. For this reason, former Prime Minister Edward Heath referred to Lawson as a \"one club golfer\".)Following German reunification in 1990, the reverse held true, as high German borrowing costs to fund Eastern reconstruction, exacerbated by the political decision to convert the Ostmark to the DM on a 1:1 basis, meant that interest rates in other countries shadowing the DM, especially the UK, were far too high relative to domestic circumstances, leading to a housing decline and recession.\n\n\n=== Following the European Currency Unit ===\nOn 8 October 1990 the Conservative government (Third Thatcher ministry) decided to join the European Exchange Rate Mechanism (ERM), with the pound set at DM2.95. However, the country was forced to withdraw from the system on \"Black Wednesday\" (16 September 1992) as Britain's economic performance made the exchange rate unsustainable.\n'Black Wednesday' saw interest rates jump from 10% to 15% in an unsuccessful attempt to stop the pound from falling below the ERM limits. The exchange rate fell to DM2.20. Those who had argued for a lower GBP/DM exchange rate were vindicated as the cheaper pound encouraged exports and contributed to the economic prosperity of the 1990s.\n\n\n=== Following inflation targets ===\nIn 1997, the newly elected Labour government handed over day-to-day control of interest rates to the Bank of England (a policy that had originally been advocated by the Liberal Democrats). The Bank is now responsible for setting its base rate of interest so as to keep inflation (as measured by the Consumer Price Index (CPI)) very close to 2% per annum. Should CPI inflation be more than one percentage point above or below the target, the governor of the Bank of England is required to write an open letter to the Chancellor of the Exchequer explaining the reasons for this and the measures which will be taken to bring this measure of inflation back in line with the 2% target. On 17 April 2007, annual CPI inflation was reported at 3.1% (inflation of the Retail Prices Index was 4.8%). Accordingly, and for the first time, the Governor had to write publicly to the government explaining why inflation was more than one percentage point higher than its target.\n\n\n=== Euro ===\n\nAs a member of the European Union, the United Kingdom could have adopted the euro as its currency. However, the subject was always politically controversial, and the UK negotiated an opt-out on this issue.\nIn 2007, Gordon Brown, then Chancellor of the Exchequer, ruled out membership for the foreseeable future, saying that the decision not to join had been right for Britain and for Europe.On 1 January 2008, with the Republic of Cyprus switching its currency from the Cypriot pound to the euro, the British sovereign bases on Cyprus (Akrotiri and Dhekelia) followed suit, making the Sovereign Base Areas the only territory under British sovereignty to officially use the euro.The 2016 referendum which started the process of United Kingdom's withdrawal from the European Union makes adoption of the euro extremely unlikely.\nThe government of former Prime Minister Tony Blair had pledged to hold a public referendum to decide on adoption of the Euro should \"five economic tests\" be met, to increase the likelihood that any adoption of the euro would be in the national interest. In addition to these internal (national) criteria, the UK would have to meet the European Union's economic convergence criteria (Maastricht criteria) before being allowed to adopt the euro. The Conservative and Liberal Democrat coalition government (2010\u20132015) ruled out joining the euro for that parliamentary term. Currently, the UK's annual government deficit, as a percentage of the GDP, is above the defined threshold.\nThe idea of replacing the pound with the euro was always controversial with the British public, partly because of the pound's identity as a symbol of British sovereignty and because it would, according to many critics, have led to suboptimal interest rates, harming the British economy. In December 2008, the results of a BBC poll of 1000 people suggested that 71% would vote no to the euro, 23% would vote yes, while 6% said they were unsure. The pound did not join the Second European Exchange Rate Mechanism (ERM II) after the euro was created. Denmark and the UK have opt-outs from entry to the euro. Theoretically, every other EU nation must eventually sign up.\nThe Scottish Conservative Party claimed that there was an issue for Scotland in that the adoption of the euro would mean the end of nationally distinctive banknotes, as the euro banknotes do not have national designs. Before the 'No' vote in the Scottish independence referendum in 2014, the Scottish National Party affirmed that the euro would not be the national currency of an independent Scotland.\n\n\n=== Recent exchange rates ===\n\nThe pound and the euro fluctuate in value against one another, although there may be correlation between movements in their respective exchange rates with other currencies such as the US dollar. Inflation concerns in the UK led the Bank of England to raise interest rates in late 2006 and 2007. This caused the pound to appreciate against other major currencies and, with the US dollar depreciating at the same time, the pound hit a 15-year high against the US dollar on 18 April 2007, reaching US$2 the day before, for the first time since 1992. The pound and many other currencies continued to appreciate against the dollar; sterling hit a 26-year high of US$2.1161 on 7 November 2007 as the dollar fell worldwide. From mid-2003 to mid-2007, the pound/euro rate remained within a narrow range (\u20ac1.45 \u00b1 5%).Following the global financial crisis in late 2008, the pound depreciated sharply, reaching $1.38 (US) on 23 January 2009 and falling below \u20ac1.25 against the euro in April 2008. There was a further decline during the remainder of 2008, most dramatically on 29 December when its euro rate hit an all-time low at \u20ac1.0219, while its US dollar rate depreciated. The pound appreciated in early 2009, reaching a peak against the euro of \u20ac1.17 in mid-July. In the following months the pound remained broadly steady against the euro, with the pound's valued on 27 May 2011 at \u20ac1.15 and US$1.65.\nOn 5 March 2009, the Bank of England announced that it would pump \u00a375 billion of new capital into the British economy, through a process known as quantitative easing (QE). This was the first time in the United Kingdom's history that this measure had been used, although the Bank's Governor Mervyn King suggested it was not an experiment.The process saw the Bank of England creating new money for itself, which it then used to purchase assets such as government bonds, secured commercial paper, or corporate bonds. The initial amount stated to be created through this method was \u00a375 billion, although Chancellor of the Exchequer Alistair Darling had given permission for up to \u00a3150 billion to be created if necessary. It was expected that the process would continue for three months, with results only likely in the long term. By 5 November 2009, some \u00a3175 billion had been injected using QE, and the process remained less effective in the long term. In July 2012, the final increase in QE meant it had peaked at \u00a3375 billion, then holding solely UK Government bonds, representing one third of the UK national debt.The result of the 2016 UK referendum on EU membership caused a major decline in the pound against other world currencies as the future of international trade relationships and domestic political leadership became unclear. The referendum result weakened sterling against the euro by 5% overnight. The night before the vote, the pound was trading at \u20ac1.30; the next day, this had fallen to \u20ac1.23. By October 2016, the exchange rate was \u20ac1.12 to the pound, a fall of 14% since the referendum. By the end of August 2017 the pound was even lower, at \u20ac1.08. Against the US dollar, meanwhile, the pound fell from $1.466 to $1.3694 when the referendum result was first revealed, and down to $1.2232 by October 2016, a fall of 16%.\n\n\n=== Annual inflation rate ===\nThe Bank of England had stated in 2009 that the decision had been taken to prevent the rate of inflation falling below the 2% target rate. Mervyn King, the Governor of the Bank of England, had also suggested there were no other monetary options left, as interest rates had already been cut to their lowest level ever (0.5%) and it was unlikely that they would be cut further.The inflation rate rose in following years, reaching 5.2% per year (based on the Consumer Price Index) in September 2011, then decreased to around 2.5% the following year.\n\n\n== Coins ==\n\n\n=== Pre-decimal coins ===\nThe silver penny (plural: pence; abbreviation: d) was the principal and often the only coin in circulation from the 8th century until the 13th century. Although some fractions of the penny were struck (see farthing and halfpenny), it was more common to find pennies cut into halves and quarters to provide smaller change. Very few gold coins were struck, with the gold penny (worth 20 silver pence) a rare example. However, in 1279, the groat, worth 4d, was introduced, with the half groat following in 1344. 1344 also saw the establishment of a gold coinage with the introduction (after the failed gold florin) of the noble worth six shillings and eight pence (6/8) (i.e. 3 nobles to the pound), together with the half and quarter noble. Reforms in 1464 saw a reduction in value of the coinage in both silver and gold, with the noble renamed the ryal and worth 10/- (i.e. 2 to the pound) and the angel introduced at the noble's old value of 6/8.\nThe reign of Henry VII saw the introduction of two important coins: the shilling (abbr.: s; known as the testoon) in 1487 and the pound (known as the sovereign, abbr.: \u00a3 or L) in 1489. In 1526, several new denominations of gold coins were added, including the crown and half crown worth five shillings (5/-), and two shillings and six pence (2/6, two and six) respectively. Henry VIII's reign (1509\u20131547) saw a high level of debasement which continued into the reign of Edward VI (1547\u20131553). This debasement was halted in 1552, and a new silver coinage was introduced, including coins for 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. In the reign of Elizabeth I (1558\u20131603), silver \u200b3\u20444d and \u200b1 1\u20442d coins were added, but these denominations did not last. Gold coins included the half-crown, crown, angel, half-sovereign and sovereign. Elizabeth's reign also saw the introduction of the horse-drawn screw press to produce the first \"milled\" coins.\nFollowing the succession of the Scottish King James VI to the English throne, a new gold coinage was introduced, including the spur ryal (15/-), the unite (20/-) and the rose ryal (30/-). The laurel, worth 20/-, followed in 1619. The first base metal coins were also introduced: tin and copper farthings. Copper halfpenny coins followed in the reign of Charles I. During the English Civil War, a number of siege coinages were produced, often in unusual denominations.\nFollowing the restoration of the monarchy in 1660, the coinage was reformed, with the ending of production of hammered coins in 1662. The guinea was introduced in 1663, soon followed by the \u200b1\u20442, 2 and 5 guinea coins. The silver coinage consisted of denominations of 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. Due to the widespread export of silver in the 18th century, the production of silver coins gradually came to a halt, with the half crown and crown not issued after the 1750s, the 6d and 1/- stopping production in the 1780s. In response, copper 1d and 2d coins and a gold \u200b1\u20443 guinea (7/-) were introduced in 1797. The copper penny was the only one of these coins to survive long.\nTo alleviate the shortage of silver coins, between 1797 and 1804, the Bank of England counterstamped Spanish dollars (8 reales) and other Spanish and Spanish colonial coins for circulation. A small counterstamp of the King's head was used. Until 1800, these circulated at a rate of 4/9 for 8 reales. After 1800, a rate of 5/- for 8 reales was used. The Bank then issued silver tokens for 5/- (struck over Spanish dollars) in 1804, followed by tokens for 1/6 and 3/- between 1811 and 1816.\nIn 1816, a new silver coinage was introduced in denominations of 6d, 1/-, 2/6 (half-crown) and 5/- (crown). The crown was only issued intermittently until 1900. It was followed by a new gold coinage in 1817 consisting of 10/- and \u00a31 coins, known as the half sovereign and sovereign. The silver 4d coin was reintroduced in 1836, followed by the 3d in 1838, with the 4d coin issued only for colonial use after 1855. In 1848, the 2/- florin was introduced, followed by the short-lived double florin in 1887. In 1860, copper was replaced by bronze in the farthing (quarter penny, \u200b1\u20444d), halfpenny and penny.\nDuring the First World War, production of the sovereign and half-sovereign was suspended, and although the gold standard was later restored, the coins saw little circulation thereafter. In 1920, the silver standard, maintained at .925 since 1552, was reduced to .500. In 1937, a nickel-brass 3d coin was introduced; the last silver 3d coins were issued seven years later. In 1947, the remaining silver coins were replaced with cupro-nickel, with the exception of Maundy coinage which was then restored to .925. Inflation caused the farthing to cease production in 1956 and be demonetised in 1960. In the run-up to decimalisation, the halfpenny and half-crown were demonetised in 1969.\n\n\n=== Decimal coins ===\nBritish coinage timeline:\n\n1968: The first decimal coins were introduced. These were cupro-nickel 5p and 10p coins which were equivalent to, and circulated alongside, the one shilling coin and the two shilling or florin coin respectively.\n1969: The curved equilateral heptagonal cupro-nickel 50p coin replaced the 10/- note.\n1971: The decimal coinage was completed when decimalisation came into effect in 1971 with the introduction of the bronze \u200b1\u20442p, 1p and 2p coins and the withdrawal of the 1d and 3d coins.\n1980: Withdrawal of 6d coins, which had circulated at a value of \u200b2 1\u20442p.\n1982: The word \"new\" was dropped from the coinage and a 20p coin was introduced.\n1983: A \u00a31 coin was introduced.\n1983: The \u200b1\u20442p coin was last produced.\n1984: The \u200b1\u20442p coin was demonetised.\n1990: The crown, worth 25p, was re-tariffed for future issues as a commemorative coin at \u00a35.\n1990s: The 5p, 10p and 50p coins became smaller.\n1991: Pre-decimal 1/- coins, which had continued to circulate with a value of 5p, were demonetised in 1991 after the 5p coin became smaller. At the same time larger first generation decimal 5p coins were demonetised.\n1992: Bronze was replaced with copper-plated steel.\n1993: Pre-decimal 2/- coins, or florin, a legacy of the 1848 attempt at decimalisation were demonetised. At the same time larger first generation decimal 10p coins were demonetised.\n1998: The bi-metallic \u00a32 coin was introduced.\n2007: By now the value of copper in the pre-1992 1p and 2p coins (which are 97% copper) exceeded those coins' face value to such an extent that melting down the coins by entrepreneurs was becoming worthwhile (with a premium of up to 11%, with smelting costs reducing this to around 4%)\u2014although this is illegal, and the market value of copper has subsequently fallen dramatically from these earlier peaks.\nIn April 2008, an extensive redesign of the coinage was unveiled. The 1p, 2p, 5p, 10p, 20p and 50p coins feature parts of the Royal Shield on their reverse; and the reverse of the pound coin showed the whole shield. The coins were issued gradually into circulation, starting in mid-2008. They have the same sizes, shapes and weights as those with the old designs which, apart from the round pound coin which was withdrawn in 2017, continue to circulate.\n2012: The 5p and 10p coins were changed from cupro-nickel to nickel-plated steel.\n2017: A more secure twelve-sided \u00a31 coin was introduced to reduce forgery. The old round \u00a31 coin ceased to be legal tender on 15 October 2017.At present, the oldest circulating coins in the UK are the 1p and 2p copper coins introduced in 1971. No other coins from before 1982 are in circulation. Prior to the demonetisation of the larger 10p in 1993, the oldest circulating coins had usually dated from 1947: although older coins (shilling; florin, sixpence to 1980) were still legal tender, inflation meant that their silver content was worth more than their face value, which meant that they tended to be removed from circulation. Before decimalisation in 1971, a handful of change might have contained coins 100 or more years old, bearing any of five monarchs' heads, especially in the copper coins.\n\n\n== Banknotes ==\n\nThe first sterling notes were issued by the Bank of England shortly after its foundation in 1694. Denominations were initially handwritten on the notes at the time of issue. From 1745, the notes were printed in denominations between \u00a320 and \u00a31000, with any odd shillings added by hand. \u00a310 notes were added in 1759, followed by \u00a35 in 1793 and \u00a31 and \u00a32 in 1797. The lowest two denominations were withdrawn after the end of the Napoleonic wars. In 1855, the notes were converted to being entirely printed, with denominations of \u00a35, \u00a310, \u00a320, \u00a350, \u00a3100, \u00a3200, \u00a3300, \u00a3500 and \u00a31000 issued.\nThe Bank of Scotland began issuing notes in 1695. Although the pound Scots was still the currency of Scotland, these notes were denominated in sterling in values up to \u00a3100. From 1727, the Royal Bank of Scotland also issued notes. Both banks issued some notes denominated in guineas as well as pounds. In the 19th century, regulations limited the smallest note issued by Scottish banks to be the \u00a31 denomination, a note not permitted in England.\nWith the extension of sterling to Ireland in 1825, the Bank of Ireland began issuing sterling notes, later followed by other Irish banks. These notes included the unusual denominations of 30/- and \u00a33. The highest denomination issued by the Irish banks was \u00a3100.\nIn 1826, banks at least 65 miles (105 km) from London were given permission to issue their own paper money. From 1844, new banks were excluded from issuing notes in England and Wales but not in Scotland and Ireland. Consequently, the number of private banknotes dwindled in England and Wales but proliferated in Scotland and Ireland. The last English private banknotes were issued in 1921.\nIn 1914, the Treasury introduced notes for 10/- and \u00a31 to replace gold coins. These circulated until 1928, when they were replaced by Bank of England notes. Irish independence reduced the number of Irish banks issuing sterling notes to five operating in Northern Ireland. The Second World War had a drastic effect on the note production of the Bank of England. Fearful of mass forgery by the Nazis (see Operation Bernhard), all notes for \u00a310 and above ceased production, leaving the bank to issue only 10/-, \u00a31 and \u00a35 notes. Scottish and Northern Irish issues were unaffected, with issues in denominations of \u00a31, \u00a35, \u00a310, \u00a320, \u00a350 and \u00a3100.\nThe Bank of England reintroduced \u00a310 notes in 1964. In 1969, the 10/- note was replaced by the 50p coin to prepare for decimalisation. \u00a320 Bank of England notes were reintroduced in 1970, followed by \u00a350 in 1981. A \u00a31 coin was introduced in 1983, and Bank of England \u00a31 notes were withdrawn in 1988. Scottish and Northern Irish banks followed, with only the Royal Bank of Scotland continuing to issue this denomination.\nUK notes include raised print (e.g. on the words \"Bank of England\"); watermarks; embedded metallic thread; holograms; and fluorescent ink visible only under UV lamps. Three printing techniques are involved: offset litho, intaglio and letterpress; and the notes incorporate a total of 85 specialized inks.The Bank of England produces notes named \"giant\" and \"titan\". A giant is a one million pound note, and a titan is a one hundred million pound bank note, of which there are about 40. Giants and titans are used only within the banking system.\n\n\n=== Polymer banknotes ===\nThe \u00a35 polymer banknote, issued by Northern Bank (now Danske Bank) in 2000, was the only polymer note in circulation until 2016, although Danske Bank also produces paper-based \u00a310, \u00a320 and \u00a350 notes. The Bank of England introduced \u00a35 polymer banknotes in September 2016, and the paper \u00a35 notes were withdrawn on 5 May 2017. This date was picked due to its short format, 5/5. A polymer \u00a310 banknote was introduced on 14 September 2017, and the paper note was withdrawn on 1 March 2018. A polymer \u00a320 banknote will be introduced in 2020.\n\n\n== Monetary policy ==\nAs the central bank of the United Kingdom which has been delegated authority by the government, the Bank of England sets the monetary policy for the British pound by controlling the amount of money in circulation.  It has a monopoly on issuance of banknotes in England and Wales, and regulates the amount of banknotes issued by seven authorized banks in Scotland and Northern Ireland.  HM Treasury has reserve powers to give orders to the committee \"if they are required in the public interest and by extreme economic circumstances\" but such orders must be endorsed by Parliament within 28 days.Unlike banknotes which have separate issuers in Scotland and Northern Ireland, all UK coins are issued by the Royal Mint, which is an independent enterprise (wholly owned by the Treasury) which also mints coins for other countries.\nIn Britain's Crown Dependencies, the Manx pound, Jersey pound, and Guernsey pound are unregulated by the Bank of England and are issued independently.  However, they are maintained at a fixed exchange rate by their respective governments, and Bank of England notes have been made legal tender on the islands, forming a sort of one-way de facto currency union.  These currencies do not have ISO 4217 codes so \"GBP\" is usually used to represent all of them; informal codes are used where the difference is important.\nBritish Overseas Territories are responsible for the monetary policy of their own currencies (where they exist), and have their own ISO 4217 codes.  The Falkland Islands pound, Gibraltar pound, and Saint Helena pound are set at a fixed 1:1 exchange rate with the British pound by local governments.\n\n\n== Legal tender and national issues ==\n\nLegal tender in the United Kingdom is defined such that \"a debtor cannot successfully be sued for non-payment if he pays into court in legal tender.\" Parties can alternatively settle a debt by other means with mutual consent. Strictly speaking it is necessary for the debtor to offer the exact amount due as there is no obligation for the other party to provide change.Throughout the UK, \u00a31 and \u00a32 coins are legal tender for any amount, with the other coins being legal tender only for limited amounts. Bank of England notes are legal tender for any amount in England and Wales, but not in Scotland or Northern Ireland. (Bank of England 10/- and \u00a31 notes were legal tender, as were Scottish banknotes, during World War II under the Currency (Defence) Act 1939, which was repealed on 1 January 1946.) Channel Islands and Isle of Man banknotes are legal tender only in their respective jurisdictions.Bank of England, Scottish, Northern Irish, Channel Islands, Isle of Man, Gibraltar, and Falkland banknotes may be offered anywhere in the UK, although there is no obligation to accept them as a means of payment, and acceptance varies. For example, merchants in England generally accept Scottish and Northern Irish bills, but some unfamiliar with them may reject them. However, Scottish and Northern Irish bills both tend to be accepted in Scotland and Northern Ireland, respectively. Merchants in England generally do not accept Jersey, Guernsey, Isle of Man, Gibraltar, and Falkland notes but Isle of Man notes are generally accepted in Northern Ireland. Bank of England notes are generally accepted in the Falklands and Gibraltar, but for example Scottish and Northern Irish notes are not. Since all of the bills are denominated in pounds sterling, banks will exchange them for locally issued bills at face value, though some in the UK have had trouble exchanging Falkland Islands pounds.Commemorative \u00a35 and 25p (crown) coins, rarely seen in circulation, are legal tender, as are the bullion coins issued by the Mint.\n\n\n== Value ==\nIn 2006, the House of Commons Library published a research paper which included an index of prices in pounds for each year between 1750 and 2005, where 1974 was indexed at 100.Regarding the period 1750\u20131914 the document states: \"Although there was considerable year on year fluctuation in price levels prior to 1914 (reflecting the quality of the harvest, wars, etc.) there was not the long-term steady increase in prices associated with the period since 1945\". It goes on to say that \"Since 1945 prices have risen in every year with an aggregate rise of over 27 times\".\nThe value of the index in 1751 was 5.1, increasing to a peak of 16.3 in 1813 before declining very soon after the end of the Napoleonic Wars to around 10.0 and remaining in the range 8.5\u201310.0 at the end of the 19th century. The index was 9.8 in 1914 and peaked at 25.3 in 1920, before declining to 15.8 in 1933 and 1934\u2014prices were only about three times as high as they had been 180 years earlier.Inflation has had a dramatic effect during and after World War II: the index was 20.2 in 1940, 33.0 in 1950, 49.1 in 1960, 73.1 in 1970, 263.7 in 1980, 497.5 in 1990, 671.8 in 2000 and 757.3 in 2005.\nThe following table shows the equivalent amount of goods and services that, in a particular year, could be purchased with \u00a31.The table shows that from 1971 to 2015 the British pound lost about 92% of its buying power.\n\nThe smallest coin in 1971 was the \u200b1\u20442p, worth about 6.4p in 2015 prices.\n\n\n== Exchange rate ==\nThe pound is freely bought and sold on the foreign exchange markets around the world, and its value relative to other currencies therefore fluctuates.As of  27 August 2017, \u00a31 was worth US$1.289, \u20ac1.0808, \u00a5141, CHF 1.22329, A$1.6247, C$1.6083 or INR 82.50.\n\n\n== Reserve ==\nSterling is used as a reserve currency around the world and is currently ranked fourth in value held as reserves.\n\nCurrency composition of official foreign exchange reserves (1965\u20132017)\n\n\n== See also ==\nAngevin pound\nGreen pound\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nRoyal Mint\nCoin Types from Great Britain Lists, pictures, and values of Great Britain coin types\nBritish Coins \u2013 information about British coins (from 1656 to 1952)\nA history of sterling Daily Telegraph\nPurchasing Power of British Pounds from 1264 to 2007\nFive Ways to Compute the Relative Value of a UK Pound Amount, 1830\u2013present\nImages of historic and modern British bank notes\nCurrent wholesale exchange rates between currencies\nHistorical Currency Converter Historical value of the pound in other currencies\nThe banknotes of the United Kingdom (in English) (in German)",
        "unit": "pound sterling",
        "url": "https://en.wikipedia.org/wiki/Pound_sterling"
    },
    {
        "_id": "Barye",
        "clean": "Barye",
        "text": "The barye (symbol: Ba), or sometimes barad, barrie, bary, baryd, baryed, or barie,  is the centimetre\u2013gram\u2013second (CGS) unit of pressure. It is equal to 1 dyne per square centimetre.\n1 Ba = 0.1 Pa = 1\u00d710\u22126 bar = 1\u00d710\u22124 pieze = 0.1 N/m2 = 1 g\u22c5cm\u22121\u22c5s\u22122\n\n\n== See also ==\nMetre\u2013tonne\u2013second system of units\nInternational System of Units\n\n\n== References ==",
        "unit": "barye",
        "url": "https://en.wikipedia.org/wiki/Barye"
    },
    {
        "_id": "Frequency",
        "clean": "Frequency",
        "text": "Frequency is the number of occurrences of a repeating event per unit of time. It is also referred to as temporal frequency, which emphasizes the contrast to spatial frequency and angular frequency. The period is the duration of time of one cycle in a repeating event, so the period is the reciprocal of the frequency.  For example, if a newborn baby's heart beats at a frequency of 120 times a minute, its period\u2014the time interval between beats\u2014is half a second (that is, 60 seconds divided by 120 beats).  Frequency is an important parameter used in science and engineering to specify the rate of oscillatory and vibratory phenomena, such as mechanical vibrations, audio signals (sound), radio waves, and light.\n\n\n== Definitions ==\n\nFor cyclical processes, such as rotation, oscillations, or waves, frequency is defined as a number of cycles per unit time. In physics and engineering disciplines, such as optics, acoustics, and radio, frequency is usually denoted by a Latin letter f or by the Greek letter \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   or \u03bd (nu) (see e.g. Planck's formula).\nThe relation between the frequency and the period \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   of a repeating event or oscillation is given by\n\n  \n    \n      \n        f\n        =\n        \n          \n            1\n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {1}{T}}.}\n  \n\n\n== Units ==\nThe SI derived unit of frequency is the hertz (Hz), named after the German physicist Heinrich Hertz. One hertz means that an event repeats once per second. A previous name for this unit was cycles per second (cps). The SI unit for period is the second.\nA traditional unit of measure used with rotating mechanical devices is revolutions per minute, abbreviated r/min or rpm. 60 rpm equals one hertz.\n\n\n== Period versus frequency ==\nAs a matter of convenience, longer and slower waves, such as ocean surface waves, tend to be described by wave period rather than frequency. Short and fast waves, like audio and radio, are usually described by their frequency instead of period. These commonly used conversions are listed below:\n\n\n== Related types of frequency ==\n\nAngular frequency, usually denoted by the Greek letter \u03c9 (omega), is defined as the rate of change of angular displacement, \u03b8, (during rotation), or the rate of change of the phase of a sinusoidal waveform (notably in oscillations and waves), or as the rate of change of the argument to the sine function:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        =\n        sin\n        \u2061\n        (\n        2\n        \n          \u03c0\n        \n        f\n        t\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t)\\right)=\\sin(\\omega t)=\\sin(2\\mathrm {\\pi } ft)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \u03c9\n        =\n        2\n        \n          \u03c0\n        \n        f\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} t}}=\\omega =2\\mathrm {\\pi } f}\n  Angular frequency is commonly measured in radians per second (rad/s) but, for discrete-time signals, can also be expressed as radians per sampling interval, which is a dimensionless quantity.  Angular frequency (in radians) is larger than regular frequency (in Hz) by a factor of 2\u03c0.Spatial frequency is analogous to temporal frequency, but the time axis is replaced by one or more spatial displacement axes. E.g.:\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        sin\n        \u2061\n        \n          (\n          \n            \u03b8\n            (\n            t\n            ,\n            x\n            )\n          \n          )\n        \n        =\n        sin\n        \u2061\n        (\n        \u03c9\n        t\n        +\n        k\n        x\n        )\n      \n    \n    {\\displaystyle y(t)=\\sin \\left(\\theta (t,x)\\right)=\\sin(\\omega t+kx)}\n  \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b8\n            \n            \n              \n                d\n              \n              x\n            \n          \n        \n        =\n        k\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\theta }{\\mathrm {d} x}}=k}\n  Wavenumber, k, is the spatial frequency analogue of angular temporal frequency and is measured in radians per meter. In the case of more than one spatial dimension, wavenumber is a vector quantity.\n\n\n== In wave propagation ==\n\nFor periodic waves in nondispersive media (that is, media in which the wave speed is independent of frequency), frequency has an inverse relationship to the wavelength, \u03bb (lambda). Even in dispersive media, the frequency f of a sinusoidal wave is equal to the phase velocity v of the wave divided by the wavelength \u03bb of the wave:\n\n  \n    \n      \n        f\n        =\n        \n          \n            v\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {v}{\\lambda }}.}\n  In the special case of electromagnetic waves moving through a vacuum, then v = c, where c is the speed of light in a vacuum, and this expression becomes:\n\n  \n    \n      \n        f\n        =\n        \n          \n            c\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {c}{\\lambda }}.}\n  When waves from a monochrome source travel from one medium to another, their frequency remains the same\u2014only their wavelength and speed change.\n\n\n== Measurement ==\n\nMeasurement of frequency can done in the following ways,\n\n\n=== Counting ===\nCalculating the frequency of a repeating event is accomplished by counting the number of times that event occurs within a specific time period, then dividing the count by the length of the time period. For example, if 71 events occur within 15 seconds the frequency is:\n\n  \n    \n      \n        f\n        =\n        \n          \n            71\n            \n              15\n              \n              \n                s\n              \n            \n          \n        \n        \u2248\n        4.73\n        \n        \n          Hz\n        \n      \n    \n    {\\displaystyle f={\\frac {71}{15\\,{\\text{s}}}}\\approx 4.73\\,{\\text{Hz}}}\n  If the number of counts is not very large, it is more accurate to measure the time interval for a predetermined number of occurrences, rather than the number of occurrences within a specified time.  The latter method introduces a random error into the count of between zero and one count, so on average half a count. This is called gating error and causes an average error in the calculated frequency of \n  \n    \n      \n        \u0394\n        f\n        =\n        \n          \n            1\n            \n              2\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta f={\\frac {1}{2T_{m}}}}\n  , or a fractional error of \n  \n    \n      \n        \n          \n            \n              \u0394\n              f\n            \n            f\n          \n        \n        =\n        \n          \n            1\n            \n              2\n              f\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta f}{f}}={\\frac {1}{2fT_{m}}}}\n   where \n  \n    \n      \n        \n          T\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle T_{m}}\n   is the timing interval and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the measured frequency. This error decreases with frequency, so it is generally a problem at low frequencies where the number of counts N is small.\n\n\n=== Stroboscope ===\nAn older method of measuring the frequency of rotating or vibrating objects is to use a stroboscope. This is an intense repetitively flashing light (strobe light) whose frequency can be adjusted with a calibrated timing circuit. The strobe light is pointed at the rotating object and the frequency adjusted up and down. When the frequency of the strobe equals the frequency of the rotating or vibrating object, the object completes one cycle of oscillation and returns to its original position between the flashes of light, so when illuminated by the strobe the object appears stationary. Then the frequency can be read from the calibrated readout on the stroboscope. A downside of this method is that an object rotating at an integral multiple of the strobing frequency will also appear stationary.\n\n\n=== Frequency counter ===\n\nHigher frequencies are usually measured with a frequency counter. This is an electronic instrument which measures the frequency of an applied repetitive electronic signal and displays the result in hertz on a digital display. It uses digital logic to count the number of cycles during a time interval established by a precision quartz time base. Cyclic processes that are not electrical in nature, such as the rotation rate of a shaft, mechanical vibrations, or sound waves, can be converted to a repetitive electronic signal by transducers and the signal applied to a frequency counter. Frequency counters can currently cover the range up to about 100 GHz. This represents the limit of direct counting methods; frequencies above this must be measured by indirect methods.\n\n\n=== Heterodyne methods ===\nAbove the range of frequency counters, frequencies of electromagnetic signals are often measured indirectly by means of heterodyning (frequency conversion). A reference signal of a known frequency near the unknown frequency is mixed with the unknown frequency in a nonlinear mixing device such as a diode. This creates a heterodyne or \"beat\" signal at the difference between the two frequencies.  If the two signals are close together in frequency the heterodyne is low enough to be measured by a frequency counter. This process only measures the difference between the unknown frequency and the reference frequency. To reach higher frequencies, several stages of heterodyning can be used. Current research is extending this method to infrared and light frequencies (optical heterodyne detection).\n\n\n== Examples ==\n\n\n=== Light ===\n\nVisible light is an electromagnetic wave, consisting of oscillating electric and magnetic fields traveling through space. The frequency of the wave determines its color: 4\u00d71014 Hz is red light, 8\u00d71014 Hz is violet light, and between these (in the range 4-8\u00d71014 Hz) are all the other colors of the visible spectrum. An electromagnetic wave can have a frequency less than 4\u00d71014 Hz, but it will be invisible to the human eye; such waves are called infrared (IR) radiation. At even lower frequency, the wave is called a microwave, and at still lower frequencies it is called a radio wave. Likewise, an electromagnetic wave can have a frequency higher than 8\u00d71014 Hz, but it will be invisible to the human eye; such waves are called ultraviolet (UV) radiation. Even higher-frequency waves are called X-rays, and higher still are gamma rays.\nAll of these waves, from the lowest-frequency radio waves to the highest-frequency gamma rays, are fundamentally the same, and they are all called electromagnetic radiation. They all travel through a vacuum at the same speed (the speed of light), giving them wavelengths inversely proportional to their frequencies.\n\n  \n    \n      \n        \n          c\n          =\n          f\n          \u03bb\n        \n      \n    \n    {\\displaystyle \\displaystyle c=f\\lambda }\n  where c is the speed of light (c in a vacuum, or less in other media), f is the frequency and \u03bb is the wavelength.\nIn dispersive media, such as glass, the speed depends somewhat on frequency, so the wavelength is not quite inversely proportional to frequency.\n\n\n=== Sound ===\n\nSound propagates as mechanical vibration waves of pressure and displacement, in air or other substances.. In general, frequency components of a sound determine its \"color\", its timbre. When speaking about the frequency (in singular) of a sound, it means the property that most determines pitch.The frequencies an ear can hear are limited to a specific range of frequencies.  The audible frequency range for humans is typically given as being between about 20 Hz and 20,000 Hz (20 kHz), though the high frequency limit usually reduces with age. Other species have different hearing ranges. For example, some dog breeds can perceive vibrations up to 60,000 Hz.In many media, such as air, the speed of sound is approximately independent of frequency, so the wavelength of the sound waves (distance between repetitions) is approximately inversely proportional to frequency.\n\n\n=== Line current ===\n\nIn Europe, Africa, Australia, Southern South America, most of Asia, and Russia, the frequency of the alternating current in household electrical outlets is 50 Hz (close to the tone G), whereas in North America and Northern South America, the frequency of the alternating current in household electrical outlets is 60 Hz (between the tones B\u266d and B; that is, a minor third above the European frequency). The frequency of the 'hum' in an audio recording can show where the recording was made, in countries using a European, or an American, grid frequency.\n\n\n== See also ==\n\n\n== Notes and references ==\n\n\n== Further reading ==\nGiancoli, D.C. (1988). Physics for Scientists and Engineers (2nd ed.). Prentice Hall. ISBN 0-13-669201-X. \n\n\n== External links ==\nConversion: frequency to wavelength and back\nConversion: period, cycle duration, periodic time to frequency\nKeyboard frequencies = naming of notes - The English and American system versus the German system\nTeaching resource for 14-16yrs on sound including frequency\nA simple tutorial on how to build a frequency meter\nFrequency - diracdelta.co.uk \u2013 JavaScript calculation.\nA frequency generator with sound, useful for hearing tests",
        "unit": "frequency",
        "url": "https://en.wikipedia.org/wiki/Frequency"
    },
    {
        "_id": "Density",
        "clean": "Density",
        "text": "The density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is \u03c1 (the lower case Greek letter rho), although the Latin letter D can also be used. Mathematically, density is defined as mass divided by volume:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            m\n            V\n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {m}{V}}}\n  where \u03c1 is the density, m is the mass, and V is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate \u2013 this quantity is more specifically called specific weight.\nFor a pure substance the density has the same numerical value as its mass concentration.\nDifferent materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.\nTo simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity \"relative density\" or \"specific gravity\", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.\nThe density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.\nThe reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.\n\n\n== History ==\nIn a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, \"Eureka! Eureka!\" (\u0395\u03cd\u03c1\u03b7\u03ba\u03b1! Greek \"I have found it\"). As a result, the term \"eureka\" entered common parlance and is used today to indicate a moment of enlightenment.\nThe story first appeared in written form in Vitruvius' books of architecture, two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.From the equation for density (\u03c1 = m/V), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m3) and the cgs unit of gram per cubic centimetre (g/cm3) are probably the most commonly used units for density. One g/cm3 is equal to one thousand kg/m3.  One cubic centimetre (abbreviation cc) is equal to one millilitre. In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.\n\n\n== Measurement of density ==\n\n\n=== Homogeneous materials ===\nThe density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.\n\n\n=== Heterogeneous materials ===\nIf the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        d\n        m\n        \n          /\n        \n        d\n        V\n      \n    \n    {\\displaystyle \\rho ({\\vec {r}})=dm/dV}\n  , where \n  \n    \n      \n        d\n        V\n      \n    \n    {\\displaystyle dV}\n   is an elementary volume at position \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . The mass of the body then can be expressed as\n\n  \n    \n      \n        m\n        =\n        \n          \u222b\n          \n            V\n          \n        \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        V\n        .\n      \n    \n    {\\displaystyle m=\\int _{V}\\rho ({\\vec {r}})\\,dV.}\n  \n\n\n=== Non-compact materials ===\nIn practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules.\nVoids are regions which contain something other than the considered material.  Commonly the void is air, but it could also be vacuum,  liquid, solid, or a different gas or gaseous mixture.\nThe bulk volume of a material\u2014inclusive of the void fraction\u2014is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions.\nMass divided by bulk volume determines bulk density.  This is not the same thing as volumetric mass density.\nTo determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning.  For the close-packing of equal spheres the non-void fraction can be at most about 74%.  It can also be determined empirically.  Some bulk materials, however, such as sand, have a variable void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling.\nIn practice, the void fraction is not necessarily air, or even gaseous.  In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water\u2014once any air bubbles are thoroughly driven out\u2014is potentially more consistent than dry sand measured with an air void.\nIn the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).\nMass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.\n\n\n== Changes of density ==\n\nIn general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 \u00b0C and 4 \u00b0C; similar behavior is observed in silicon at low temperatures.\nThe effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10\u22126 bar\u22121 (1 bar = 0.1 MPa) and a typical thermal expansivity is 10\u22125 K\u22121. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.\nIn contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              M\n              P\n            \n            \n              R\n              T\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\rho ={\\frac {MP}{RT}},}\n  where M is the molar mass, P is the pressure, R is the universal gas constant, and T is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.\nIn the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \n            \n              \u03c1\n              \n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            \n              1\n              +\n              \u03b1\n              \u22c5\n              \u0394\n              T\n            \n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {\\rho _{T_{0}}}{1+\\alpha \\cdot \\Delta T}}}\n  where \n  \n    \n      \n        \n          \u03c1\n          \n            \n              T\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho _{T_{0}}}\n   is the density at a reference temperature, \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is the thermal expansion coefficient of the material at temperatures close to \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  .\n\n\n== Density of solutions ==\nThe density of a solution is the sum of mass (massic) concentrations of the components of that solution.\nMass (massic) concentration of each given component \u03c1i in a solution sums to density of the solution.\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03f1\n          \n            i\n          \n        \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\varrho _{i}\\,}\n  Expressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:\n\n  \n    \n      \n        \u03c1\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            V\n          \n        \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \u03c6\n          \n            i\n          \n        \n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \u03c1\n          \n            i\n          \n        \n        \n          \n            \n              V\n              \n                i\n              \n            \n            \n              \n                \u2211\n                \n                  i\n                \n              \n              \n                V\n                \n                  i\n                \n              \n              +\n              \n                \u2211\n                \n                  i\n                \n              \n              \n                \n                  \n                    V\n                    \n                      E\n                    \n                  \n                \n                \n                  i\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho =\\sum _{i}\\rho _{i}{\\frac {V_{i}}{V}}\\,=\\sum _{i}\\rho _{i}\\varphi _{i}=\\sum _{i}\\rho _{i}{\\frac {V_{i}}{\\sum _{i}V_{i}+\\sum _{i}{V^{E}}_{i}}}}\n  provided that there is no interaction between the components.\nKnowing the relation between excess volumes and activity coefficients of the  components, one can determine the activity coefficients.\n\n  \n    \n      \n        \n          \n            \n              \n                V\n                \n                  E\n                \n              \n              \u00af\n            \n          \n          \n            i\n          \n        \n        =\n        R\n        T\n        \n          \n            \n              \u2202\n              ln\n              \u2061\n              \n                \u03b3\n                \n                  i\n                \n              \n            \n            \n              \u2202\n              P\n            \n          \n        \n      \n    \n    {\\displaystyle {\\overline {V^{E}}}_{i}=RT{\\frac {\\partial \\ln \\gamma _{i}}{\\partial P}}}\n  \n\n\n== Densities ==\n\n\n=== Various materials ===\n\n\n=== Others ===\n\n\n=== Water ===\n\n\n=== Air ===\n\n\n=== Molar volumes of liquid and solid phase of elements ===\n\n\n== Common units ==\nThe SI unit for density is:\n\nkilogram per cubic metre (kg/m3)The litre and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:\n\nkilogram per litre (kg/L)\ngram per millilitre (g/mL)\nmetric ton per cubic metre (t/m3)Densities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m3). Liquid water has a density of about 1 kg/dm3, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm3.\n\nkilogram per cubic decimetre (kg/dm3)\ngram per cubic centimetre (g/cm3)\n1 g/cm3 = 1000 kg/m3\nmegagram (metric ton) per cubic metre (Mg/m3)In US customary units density can be stated in:\n\nAvoirdupois ounce per cubic inch (1 g/cc \u2248 0.578036672 oz/cu in)\nAvoirdupois ounce per fluid ounce (1 g/cc \u2248 1.04317556 oz/fl. oz = 1.04317556 lbs/pint)\nAvoirdupois pound per cubic inch (1 g/cc \u2248 0.036127292 lb/cu in)\npound per cubic foot (1 g/cc \u2248 62.427961 lb/cu ft)\npound per cubic yard (1 g/cc \u2248 1685.5549 lb/cu yd)\npound per US liquid gallon (1 g/cc \u2248 8.34540445 lb/gal)\npound per US bushel (1 g/cc \u2248 77.6888513 lb/bu)\nslug per cubic footImperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The Imperial gallon was based on the concept that an Imperial fluid ounce of water would have a mass of one Avoirdupois ounce, and indeed 1 g/cc \u2248 1.00224129 ounces per Imperial fluid ounce = 10.0224129 pounds per Imperial gallon. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n \"Density\". Encyclop\u00e6dia Britannica. 8 (11th ed.). 1911. \n \"Density\". The New Student's Reference Work. 1914. \nVideo: Density Experiment with Oil and Alcohol\nVideo: Density Experiment with Whiskey and Water\nGlass Density Calculation \u2013 Calculation of the density of glass at room temperature and of glass melts at 1000 \u2013 1400\u00b0C\nList of Elements of the Periodic Table \u2013 Sorted by Density\nCalculation of saturated liquid densities for some components\nField density test\nOn-line calculator for densities and partial molar volumes of aqueous solutions of some common electrolytes and their mixtures, at temperatures up to 323.15 K.\nWater \u2013 Density and specific weight\nTemperature dependence of the density of water \u2013 Conversions of density units\nA delicious density experiment\nWater density calculator Water density for a given salinity and temperature.\nLiquid density calculator Select a liquid from the list and calculate density as a function of temperature.\nGas density calculator Calculate density of a gas for as a function of temperature and pressure.\nDensities of various materials.\nDetermination of Density of Solid, instructions for performing classroom experiment.\ndensity prediction\ndensity prediction",
        "unit": "density",
        "url": "https://en.wikipedia.org/wiki/Density"
    },
    {
        "_id": "Viscosity",
        "clean": "Viscosity",
        "text": "The viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water.Viscosity is the property of a fluid which opposes the relative motion between two surfaces of the fluid that are moving at different velocities. In simple terms, viscosity means friction between the molecules of fluid. When the fluid is forced through a tube, the particles which compose the fluid generally move more quickly near the tube's axis and more slowly near its walls; therefore some stress (such as a pressure difference between the two ends of the tube) is needed to overcome the friction between particle layers to keep the fluid moving. For a given velocity pattern, the stress required is proportional to the fluid's viscosity.\nA fluid that has no resistance to shear stress is known as an ideal or inviscid fluid. Zero viscosity is observed only at very low temperatures in superfluids. Otherwise, all fluids have positive viscosity and are technically said to be viscous or viscid. A fluid with a relatively high viscosity, such as pitch, may appear to be a solid.\n\n\n== Etymology ==\nThe word \"viscosity\" is derived from the Latin \"viscum\", meaning mistletoe and also a viscous glue made from mistletoe berries.\n\n\n== Definition ==\n\n\n=== Dynamic (shear) viscosity ===\n\nThe dynamic viscosity of a fluid expresses its resistance to shearing flows, where adjacent layers move parallel to each other with different speeds. It can be defined through the idealized situation known as a Couette flow, where a layer of fluid is trapped between two horizontal plates, one fixed and one moving horizontally at constant speed \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  . This fluid has to be homogeneous in the layer and at different shear stresses. (The plates are assumed to be very large so that one need not consider what happens near their edges.)\nIf the speed of the top plate is low enough, the fluid particles will move parallel to it, and their speed will vary linearly from zero at the bottom to u at the top. Each layer of fluid will move faster than the one just below it, and friction between them will give rise to a force resisting their relative motion. In particular, the fluid will apply on the top plate a force in the direction opposite to its motion, and an equal but opposite one to the bottom plate. An external force is therefore required in order to keep the top plate moving at constant speed.\nThe magnitude F of this force is found to be proportional to the speed u and the area A of each plate, and inversely proportional to their separation y: \n\n  \n    \n      \n        F\n        =\n        \u03bc\n        A\n        \n          \n            u\n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle F=\\mu A{\\frac {u}{y}}.}\n  The proportionality factor \u03bc in this formula is the viscosity (specifically, the dynamic viscosity) of the fluid, with units of \n  \n    \n      \n        \n          Pa\n        \n        \u22c5\n        \n          s\n        \n      \n    \n    {\\displaystyle {\\text{Pa}}\\cdot {\\text{s}}}\n   (pascal-second).\nThe ratio u/y is called the rate of shear deformation or shear velocity, and is the derivative of the fluid speed in the direction perpendicular to the plates (see illustrations to the right). Isaac Newton expressed the viscous forces by the differential equation\n\n  \n    \n      \n        \u03c4\n        =\n        \u03bc\n        \n          \n            \n              \u2202\n              u\n            \n            \n              \u2202\n              y\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =\\mu {\\frac {\\partial u}{\\partial y}},}\n  where \u03c4 = F/A, and \u2202u/\u2202y is the local shear velocity. This formula assumes that the flow is moving along parallel lines to x-axis. Furthermore, it assumes that the y-axis, perpendicular to the flow, points in the direction of maximum shear velocity. This equation can be used where the velocity does not vary linearly with y, such as in fluid flowing through a pipe. This equation is called the defining equation for shear viscosity. The viscosity is not a material constant, but a material property that depends on physical properties like temperature. The variation of the dynamic viscosity \u03bc at a given temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   can be evaluated on the basis of the dynamic viscosity at room temperature (\n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n        =\n        296.15\n        K\n      \n    \n    {\\displaystyle T_{0}=296.15K}\n  ) by the equation: \n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              120\n            \n            \n              T\n              +\n              120\n            \n          \n        \n        (\n        \n          \n            T\n            \n              T\n              \n                0\n              \n            \n          \n        \n        \n          )\n          \n            \n              3\n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =\\mu _{0}{\\frac {T_{0}+120}{T+120}}({\\frac {T}{T_{0}}})^{\\frac {3}{2}}}\n  \nThe functional relationship between viscosity and other physical properties is described by mathematical viscosity models called constitutive equations which are usually more complex than the defining equation for viscosity. There exist  many viscosity models, and based on type of development-reasoning, some viscosity models are selected and presented in the article Viscosity models for mixtures.\nUse of the Greek letter mu (\u03bc) for the dynamic viscosity is common among mechanical and chemical engineers, as well as physicists. However, the Greek letter eta (\u03b7) is also used by chemists, physicists, and the IUPAC.\n\n\n=== Kinematic viscosity ===\nThe kinematic viscosity (also called \"momentum diffusivity\") is the ratio of the dynamic viscosity \u03bc to the density of the fluid \u03c1. It is usually denoted by the Greek letter nu (\u03bd) and has units \n  \n    \n      \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {m^{2}/s} }\n  . \n\n  \n    \n      \n        \u03bd\n        =\n        \n          \n            \u03bc\n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle \\nu ={\\frac {\\mu }{\\rho }}}\n  A convenient concept when analyzing the Reynolds number, which expresses the ratio of the inertial forces to the viscous forces, is:\n\n  \n    \n      \n        \n          R\n          e\n        \n        =\n        \n          \n            \n              \u03c1\n              V\n              D\n            \n            \u03bc\n          \n        \n        =\n        \n          \n            \n              V\n              D\n            \n            \u03bd\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathrm {Re} ={\\frac {\\rho VD}{\\mu }}={\\frac {VD}{\\nu }},}\n  where D is a diameter in the system, and V is the velocity of the fluid with respect to the object (m/s).\n\n\n=== Bulk viscosity ===\n\nWhen a compressible fluid is compressed or expanded evenly, without shear, it may still exhibit a form of internal friction that resists its flow. These forces are related to the rate of compression or expansion by a factor called the volume viscosity, bulk viscosity or second viscosity.\nThe bulk viscosity is important only when the fluid is being rapidly compressed or expanded, such as in sound and shock waves. Bulk viscosity explains the loss of energy in those waves, as described by Stokes' law of sound attenuation.\n\n\n=== Viscosity tensor ===\n\nIn general, the stresses within a flow can be attributed partly to the deformation of the material from some rest state (elastic stress), and partly to the rate of change of the deformation over time (viscous stress). In a fluid, by definition, the elastic stress includes only the hydrostatic pressure.\nIn very general terms, the fluid's viscosity is the relation between the strain rate and the viscous stress. In the Newtonian fluid model, the relationship is by definition a linear map, described by a viscosity tensor that, multiplied by the strain rate tensor (which is the gradient of the flow's velocity), gives the viscous stress tensor.\nThe viscosity tensor has nine independent degrees of freedom in general. For isotropic Newtonian fluids, these can be reduced to two independent parameters. The most usual decomposition yields the dynamic viscosity \u03bc and the bulk viscosity \u03c3.\n\n\n== Newtonian and non-Newtonian fluids ==\n\nNewton's law of viscosity is a constitutive equation (like Hooke's law, Fick's law, and Ohm's law): it is not a fundamental law of nature but an approximation that holds in some materials and fails in others.\nA fluid that behaves according to Newton's law, with a viscosity \u03bc that is independent of the stress, is said to be Newtonian. Gases, water, and many common liquids can be considered Newtonian in ordinary conditions and contexts. There are many non-Newtonian fluids that significantly deviate from that law in some way or other. For example:\n\nShear-thickening liquids, whose viscosity increases with the rate of shear strain.\nShear-thinning liquids, whose viscosity decreases with the rate of shear strain.\nThixotropic liquids, that become less viscous over time when shaken, agitated, or otherwise stressed.\nRheopectic (dilatant) liquids, that become more viscous over time when shaken, agitated, or otherwise stressed.\nBingham plastics that behave as a solid at low stresses but flow as a viscous fluid at high stresses.Shear-thinning liquids are very commonly, but misleadingly, described as thixotropic.\nEven for a Newtonian fluid, the viscosity usually depends on its composition and temperature. For gases and other compressible fluids, it depends on temperature and varies very slowly with pressure.\nThe viscosity of some fluids may depend on other factors. A magnetorheological fluid, for example, becomes thicker when subjected to a magnetic field, possibly to the point of behaving like a solid.\n\n\n== In solids ==\nThe viscous forces that arise during fluid flow must not be confused with the elastic forces that arise in a solid in response to shear, compression or extension stresses. While in the latter the stress is proportional to the amount of shear deformation, in a fluid it is proportional to the rate of deformation over time. (For this reason, Maxwell used the term fugitive elasticity for fluid viscosity.)\nHowever, many liquids (including water) will briefly react like elastic solids when subjected to sudden stress. Conversely, many \"solids\" (even granite) will flow like liquids, albeit very slowly, even under arbitrarily small stress. Such materials are therefore best described as possessing both elasticity (reaction to deformation) and viscosity (reaction to rate of deformation); that is, being viscoelastic.\nIndeed, some authors have claimed that amorphous solids, such as glass and many polymers, are actually liquids with a very high viscosity (greater than 1012 Pa\u00b7s).\n However, other authors dispute this hypothesis, claiming instead that there is some threshold for the stress, below which most solids will not flow at all, and that alleged instances of glass flow in window panes of old buildings are due to the crude manufacturing process of older eras rather than to the viscosity of glass.Viscoelastic solids may exhibit both shear viscosity and bulk viscosity. The extensional viscosity is a linear combination of the shear and bulk viscosities that describes the reaction of a solid elastic material to elongation. It is widely used for characterizing polymers.\nIn geology, earth materials that exhibit viscous deformation at least three orders of magnitude greater than their elastic deformation are sometimes called rheids.\n\n\n== Measurement ==\n\nViscosity is measured with various types of viscometers and rheometers. A rheometer is used for those fluids that cannot be defined by a single value of viscosity and therefore require more parameters to be set and measured than is the case for a viscometer. Close temperature control of the fluid is essential to acquire accurate measurements, particularly in materials like lubricants, whose viscosity can double with a change of only 5 \u00b0C.\nFor some fluids, the viscosity is constant over a wide range of shear rates (Newtonian fluids). The fluids without a constant viscosity (non-Newtonian fluids) cannot be described by a single number. Non-Newtonian fluids exhibit a variety of different correlations between shear stress and shear rate.\nOne of the most common instruments for measuring kinematic viscosity is the glass capillary viscometer.\nIn coating industries, viscosity may be measured with a cup in which the efflux time is measured. There are several sorts of cup \u2013 such as the Zahn cup and the Ford viscosity cup \u2013 with the usage of each type varying mainly according to the industry. The efflux time can also be converted to kinematic viscosities (centistokes, cSt) through the conversion equations.Also used in coatings, a Stormer viscometer uses load-based rotation in order to determine viscosity. The viscosity is reported in Krebs units (KU), which are unique to Stormer viscometers.\nVibrating viscometers can also be used to measure viscosity. Resonant, or vibrational viscometers work by creating shear waves within the liquid. In this method, the sensor is submerged in the fluid and is made to resonate at a specific frequency. As the surface of the sensor shears through the liquid, energy is lost due to its viscosity. This dissipated energy is then measured and converted into a viscosity reading. A higher viscosity causes a greater loss of energy.Extensional viscosity can be measured with various rheometers that apply extensional stress.\nVolume viscosity can be measured with an acoustic rheometer.\nApparent viscosity is a calculation derived from tests performed on drilling fluid used in oil or gas well development. These calculations and tests help engineers develop and maintain the properties of the drilling fluid to the specifications required.\n\n\n== Units ==\n\n\n=== Dynamic viscosity, \u03bc ===\nBoth the physical unit of dynamic viscosity in SI units, the poiseuille (Pl), and cgs units, the poise (P), are named after Jean L\u00e9onard Marie Poiseuille. The poiseuille, which is rarely used, is equivalent to the pascal second (Pa\u00b7s), or (N\u00b7s)/m2, or kg/(m\u00b7s). If a fluid is placed between two plates with distance one meter, and one plate is pushed sideways with a shear stress of one pascal, and it moves at x meters per second, then it has viscosity of 1/x pascal seconds. For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s, while a typical motor oil could have a viscosity of about 250 mPa\u00b7s. The units used in practice are either Pa\u00b7s and its submultiples or the cgs poise referred to below, and its submultiples.\nThe cgs physical unit for dynamic viscosity, the poise (P), is also named after Jean Poiseuille. It is more commonly expressed, particularly in ASTM standards, as centipoise (cP) since the latter is equal to the SI multiple millipascal seconds (mPa\u00b7s). For example, water at 20 \u00b0C has a viscosity of 1.002 mPa\u00b7s = 1.002 cP.\n\n1 Pl = 1 Pa\u00b7s\n1 P = 1 dPa\u00b7s = 0.1 Pa\u00b7s = 0.1 kg\u00b7m\u22121\u00b7s\u22121\n1 cP = 1 mPa\u00b7s = 0.001 Pa\u00b7s = 0.001 N\u00b7s\u00b7m\u22122 = 0.001 kg\u00b7m\u22121\u00b7s\u22121.\n\n\n=== Kinematic viscosity, \u03bd ===\nThe SI unit of kinematic viscosity is m2/s.\nThe cgs physical unit for kinematic viscosity is the stokes (St), named after Sir George Gabriel Stokes. It is sometimes expressed in terms of centistokes (cSt). In U.S. usage, stoke is sometimes used as the singular form.\n\n1 St = 1 cm2\u00b7s\u22121 = 10\u22124 m2\u00b7s\u22121.\n1 cSt = 1 mm2\u00b7s\u22121 = 10\u22126 m2\u00b7s\u22121.Water at 20 \u00b0C has a kinematic viscosity of about 10\u22126 m2\u00b7s\u22121 or 1 cSt.\nThe kinematic viscosity is sometimes referred to as diffusivity of momentum, because it is analogous to diffusivity of heat and diffusivity of mass. It is therefore used in dimensionless numbers which compare the ratio of the diffusivities.\n\n\n=== Fluidity ===\nThe reciprocal of viscosity is fluidity, usually symbolized by \u03c6 = 1/\u03bc or F = 1/\u03bc, depending on the convention used, measured in reciprocal poise (P\u22121, or cm\u00b7s\u00b7g\u22121), sometimes called the rhe. Fluidity is seldom used in engineering practice.\nThe concept of fluidity can be used to determine the viscosity of an ideal solution. For two components A and B, the fluidity when A and B are mixed is\n\n  \n    \n      \n        F\n        \u2248\n        \n          \u03c7\n          \n            \n              A\n            \n          \n        \n        \n          F\n          \n            \n              A\n            \n          \n        \n        +\n        \n          \u03c7\n          \n            \n              B\n            \n          \n        \n        \n          F\n          \n            \n              B\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F\\approx \\chi _{\\mathrm {A} }F_{\\mathrm {A} }+\\chi _{\\mathrm {B} }F_{\\mathrm {B} },}\n  which is only slightly simpler than the equivalent equation in terms of viscosity:\n\n  \n    \n      \n        \u03bc\n        \u2248\n        \n          \n            1\n            \n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          A\n                        \n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    \n                      \u03c7\n                      \n                        \n                          B\n                        \n                      \n                    \n                    \n                      \u03bc\n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu \\approx {\\frac {1}{{\\dfrac {\\chi _{\\mathrm {A} }}{\\mu _{\\mathrm {A} }}}+{\\dfrac {\\chi _{\\mathrm {B} }}{\\mu _{\\mathrm {B} }}}}},}\n  where \u03c7A and \u03c7B are the mole fractions of components A and B respectively, and \u03bcA and \u03bcB are the components' pure viscosities.\n\n\n=== Non-standard units ===\nThe reyn is a British unit of dynamic viscosity.\nViscosity index is a measure for the change of viscosity with temperature. It is used in the automotive industry to characterise lubricating oil.\nAt one time the petroleum industry relied on measuring kinematic viscosity by means of the Saybolt viscometer, and expressing kinematic viscosity in units of Saybolt universal seconds (SUS). Other abbreviations such as SSU (Saybolt seconds universal) or SUV (Saybolt universal viscosity) are sometimes used. Kinematic viscosity in centistokes can be converted from SUS according to the arithmetic and the reference table provided in ASTM D 2161.\n\n\n== Molecular origins ==\n\nIn general, the viscosity of a system depends in detail on how the molecules constituting the system interact. There are no simple but correct expressions for the viscosity of a fluid. The simplest exact expressions are the Green\u2013Kubo relations for the linear shear viscosity or the transient time correlation function expressions derived by Evans and Morriss in 1985. Although these expressions are each exact, calculating the viscosity of a dense fluid using these relations currently requires the use of molecular dynamics computer simulations. On the other hand, much more progress can be made for a dilute gas. Even elementary assumptions about how gas molecules move and interact lead to a basic understanding of the molecular origins of viscosity. More sophisticated treatments can be constructed by systematically coarse-graining the equations of motion of the gas molecules. An example of such a treatment is Chapman\u2013Enskog theory, which derives expressions for the viscosity of a dilute gas from the Boltzmann equation.Momentum transport in gases is generally mediated by discrete molecular collisions, and in liquids by attractive forces which bind molecules close together. Because of this, the dynamic viscosities of liquids are typically several orders of magnitude higher than dynamic viscosities of gases.\n\n\n=== Gases ===\n\nViscosity in gases arises principally from the molecular diffusion that transports momentum between layers of flow. An elementary calculation for a dilute gas at temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   and density \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   gives\n\n  \n    \n      \n        \u03bc\n        =\n        \u03b1\n        \u03c1\n        \u03bb\n        \n          \n            \n              \n                2\n                \n                  k\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                m\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\alpha \\rho \\lambda {\\sqrt {\\frac {2k_{B}T}{\\pi m}}},}\n  where \n  \n    \n      \n        \n          k\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle k_{B}}\n   is the Boltzmann constant, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   the molecular mass, and \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   a numerical constant on the order of \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  . The quantity \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  , the mean free path, measures the average distance a molecule travels between collisions. Even without a priori knowledge of \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , this expression has interesting implications. In particular, since \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is typically inversely proportional to density and increases with temperature, \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   itself should increase with temperature and be independent of density. In fact, both of these predictions persist in more sophisticated treatments, and accurately describe experimental observations. Note that this behavior runs counter to common intuition regarding liquids, for which viscosity typically decreases with temperature.\nFor rigid elastic spheres of diameter \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  , \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   can be computed, giving\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            \u03b1\n            \n              \u03c0\n              \n                3\n                \n                  /\n                \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                k\n                \n                  B\n                \n              \n              m\n              T\n            \n            \n              \u03c3\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mu ={\\frac {\\alpha }{\\pi ^{3/2}}}{\\frac {\\sqrt {k_{B}mT}}{\\sigma ^{2}}}.}\n  In this case \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is independent of temperature, so \n  \n    \n      \n        \u03bc\n        \u221d\n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu \\propto T^{1/2}}\n  . For more complicated molecular models, however, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   depends on temperature in a non-trivial way, and simple kinetic arguments as used here are inadequate. More fundamentally, the notion of a mean free path becomes imprecise for particles that interact over a finite range, which limits the usefulness of the concept for describing real-world gases.\n\n\n==== Chapman\u2013Enskog theory ====\n\nA technique developed by Sydney Chapman and David Enskog in the early 1900s allows a more refined calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  . It is based on the Boltzmann equation, which provides a systematic statistical description of a dilute gas in terms of intermolecular interactions. As such, their technique allows accurate calculation of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   for more realistic molecular models, such as those incorporating intermolecular attraction rather than just hard-core repulsion.\nIt turns out that a more realistic modeling of interactions is essential for accurate prediction of the temperature dependence of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  , which experiments show increases more rapidly than the \n  \n    \n      \n        \n          T\n          \n            1\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle T^{1/2}}\n   trend predicted for rigid elastic spheres. Indeed, the Chapman\u2013Enskog analysis shows that the predicted temperature dependence can be tuned by varying the parameters in various molecular models. A simple example is the Sutherland model, which describes rigid elastic spheres with weak mutual attraction. In such a case, the attractive force can be treated perturbatively, which leads to a particularly simple expression for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  :\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \n            5\n            \n              16\n              \n                \u03c3\n                \n                  2\n                \n              \n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    k\n                    \n                      B\n                    \n                  \n                  m\n                  T\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            1\n            \n              /\n            \n            2\n          \n        \n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  S\n                  T\n                \n              \n            \n            )\n          \n          \n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu ={\\frac {5}{16\\sigma ^{2}}}\\left({\\frac {k_{B}mT}{\\pi }}\\right)^{1/2}\\left(1+{\\frac {S}{T}}\\right)^{-1},}\n  where \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is independent of temperature, being determined only by the parameters of the intermolecular attraction. To connect with experiment, it is convenient to rewrite as\n\n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                T\n                \n                  T\n                  \n                    0\n                  \n                \n              \n            \n            )\n          \n          \n            3\n            \n              /\n            \n            2\n          \n        \n        \n          \n            \n              \n                T\n                \n                  0\n                \n              \n              +\n              S\n            \n            \n              T\n              +\n              S\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =\\mu _{0}\\left({\\frac {T}{T_{0}}}\\right)^{3/2}{\\frac {T_{0}+S}{T+S}},}\n  where \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the viscosity at temperature \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  . If \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is known from experiments at \n  \n    \n      \n        T\n        =\n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T=T_{0}}\n   and at least one other temperature, then \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   can be calculated. It turns out that expressions for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   obtained in this way are accurate for a number of gases over a sizable range of temperatures. On the other hand, Chapman and Cowling argue that this success does not imply that molecules actually interact according to the Sutherland model. Rather, they interpret the prediction for \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   as a simple interpolation which is valid for some gases over fixed ranges of temperature, but otherwise does not provide a picture of intermolecular interactions which is fundamentally correct and general. Slightly more sophisticated models, such as the Lennard\u2013Jones potential, may provide a better picture, but only at the cost of a more opaque dependence on temperature. In some systems the assumption of spherical symmetry must be abandoned as well, as is the case for vapors with highly polar molecules like H2O.\n\n\n=== Liquids ===\n\nIn contrast with gases, there is no simple yet accurate picture for the molecular origins of viscosity in liquids. \nAt the simplest level of description, the relative motion of adjacent layers in a liquid is opposed primarily by attractive molecular forces\nacting across the layer boundary. In this picture, one (correctly) expects viscosity to decrease with temperature. This is because\nincreasing temperature increases the random thermal motion of the molecules, which makes it easier for them to overcome their attractive interactions.Building on this visualization, a simple theory can be constructed in analogy with the discrete structure of a solid: groups of molecules in a liquid \nare visualized as forming \"cages\" which surround and enclose single molecules. These cages can be occupied or unoccupied, and\nstronger molecular attraction corresponds to stronger cages.\nDue to random thermal motion, a molecule \"hops\" between cages at a rate which varies inversely with the strength of molecular attractions. In equilibrium these \"hops\" are not biased in any direction.\nOn the other hand, in order for two adjacent layers to move relative to each other, the \"hops\" must be biased in the direction\nof the relative motion. The force required to sustain this directed motion can be estimated for a given shear rate, leading to\n\nwhere \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is the Avogadro constant, \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is the Planck constant, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of a mole of liquid, and \n  \n    \n      \n        \n          T\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle T_{b}}\n   is the boiling temperature. This result has the same form as the widespread and accurate empirical relation \n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are constants fit from data. One the other hand, several authors express caution with respect to this model.\nErrors as large as 30% can be encountered using equation (1), compared with fitting equation (2) to experimental data. More fundamentally, the physical assumptions underlying equation (1) have been extensively criticized. It has also been argued that the exponential dependence in equation (1) does not necessarily describe experimental observations more accurately than simpler, non-exponential expressions.In light of these shortcomings, the development of a less ad-hoc model is a matter of practical interest.\nForegoing simplicity in favor of precision, it is possible to write rigorous expressions for viscosity starting from the fundamental equations of motion for molecules. A classic example \nof this approach is Irving-Kirkwood theory. On the other hand, such expressions\nare given as averages over multiparticle correlation functions and are therefore difficult to apply in practice. \nIn general, empirically derived expressions (based on existing viscosity measurements) appear to be the only consistently reliable means of calculating viscosity in liquids.\n\n\n== Selected substances ==\n\n\n=== Air ===\n\nThe viscosity of air depends mostly on the temperature. At 15 \u00b0C, the viscosity of air is 1.81\u00d710\u22125 kg/(m\u00b7s), 18.1 \u03bcPa\u00b7s or 1.81\u00d710\u22125 Pa\u00b7s. The kinematic viscosity at 15 \u00b0C is 1.48\u00d710\u22125 m2/s or 14.8 cSt. At 25 \u00b0C, the viscosity is 18.6 \u03bcPa\u00b7s and the kinematic viscosity 15.7 cSt.\n\n\n=== Water ===\n\nThe dynamic viscosity of water is 8.90\u00d710\u22124 Pa\u00b7s or 8.90\u00d710\u22123 dyn\u00b7s/cm2 or 0.890 cP at about 25 \u00b0C.\nAs a function of temperature T (in kelvins): \u03bc = A \u00d7 10B/(T \u2212 C), where A = 2.414\u00d710\u22125 Pa\u00b7s, B = 247.8 K, and C = 140 K.The dynamic viscosity of liquid water at different temperatures up to the normal boiling point is listed below.\n\n\n=== Other substances ===\n\nSome dynamic viscosities of Newtonian fluids are listed below:\n\n\n== Blends of liquids ==\nThe viscosity of the blend of two or more liquids can be estimated using the Refutas equation. The calculation is carried out in three steps.\nThe first step is to calculate the viscosity blending number (VBN) (also called the viscosity blending index) of each component of the blend:\n\n  \n    \n      \n        \n          V\n          B\n          N\n        \n        =\n        14.534\n        \u00d7\n        ln\n        \u2061\n        \n          \n            (\n          \n        \n        ln\n        \u2061\n        (\n        \u03bd\n        +\n        0.8\n        )\n        \n          \n            )\n          \n        \n        +\n        10.975\n        \n      \n    \n    {\\displaystyle \\mathrm {VBN} =14.534\\times \\ln {\\big (}\\ln(\\nu +0.8){\\big )}+10.975\\,}\n     (1)where \u03bd is the kinematic viscosity in centistokes (cSt). It is important that the kinematic viscosity of each component of the blend be obtained at the same temperature.\nThe next step is to calculate the VBN of the blend, using this equation:\n\n  \n    \n      \n        \n          V\n          B\n          \n            N\n            \n              B\n              l\n              e\n              n\n              d\n            \n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                \n                  A\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  A\n                \n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  B\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  B\n                \n              \n            \n          \n          )\n        \n        +\n        \u22ef\n        +\n        \n          (\n          \n            \n              x\n              \n                \n                  N\n                \n              \n            \n            \u00d7\n            \n              V\n              B\n              \n                N\n                \n                  N\n                \n              \n            \n          \n          )\n        \n        \n      \n    \n    {\\displaystyle \\mathrm {VBN_{Blend}} =\\left(x_{\\mathrm {A} }\\times \\mathrm {VBN_{A}} \\right)+\\left(x_{\\mathrm {B} }\\times \\mathrm {VBN_{B}} \\right)+\\cdots +\\left(x_{\\mathrm {N} }\\times \\mathrm {VBN_{N}} \\right)\\,}\n     (2)where xX is the mass fraction of each component of the blend.\nOnce the viscosity blending number of a blend has been calculated using equation (2), the final step is to determine the kinematic viscosity of the blend by solving equation (1) for \u03bd:\n\n  \n    \n      \n        \u03bd\n        =\n        exp\n        \u2061\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    \n                      V\n                      B\n                      \n                        N\n                        \n                          B\n                          l\n                          e\n                          n\n                          d\n                        \n                      \n                    \n                    \u2212\n                    10.975\n                  \n                  14.534\n                \n              \n              )\n            \n          \n          )\n        \n        \u2212\n        0.8\n        ,\n      \n    \n    {\\displaystyle \\nu =\\exp \\left(\\exp \\left({\\frac {\\mathrm {VBN_{Blend}} -10.975}{14.534}}\\right)\\right)-0.8,}\n     (3)where VBNBlend is the viscosity blending number of the blend.\nalternatively use the more accurate Lederer-Roegiers equation [1]\n\n  \n    \n      \n        ln\n        \u2061\n        \n          \u03b7\n          \n            1\n            ,\n            2\n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  1\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  1\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n        +\n        \n          \n            \n              \u03b2\n              \n                x\n                \n                  2\n                \n              \n              ln\n              \u2061\n              \n                \u03b7\n                \n                  2\n                \n              \n            \n            \n              \n                x\n                \n                  1\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \u03b2\n            \n          \n        \n      \n    \n    {\\displaystyle \\ln \\eta _{1,2}={\\frac {x_{1}\\ln \\eta _{1}}{x_{1}+x_{2}\\beta }}+{\\frac {\\beta x_{2}\\ln \\eta _{2}}{x_{1}+x_{2}\\beta }}}\n  \n\n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is based on the difference in intermolecular cohesion energies between the liquids\n\n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n  =dynamic viscosity\n\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  =mole fraction of particle species \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\n\n== Slurry ==\n\nThe term slurry describes mixtures of a liquid and solid particles that retain some fluidity. The viscosity of slurry can be described as relative to the viscosity of the liquid phase:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        =\n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        \n          \u03bc\n          \n            \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }=\\mu _{\\mathrm {r} }\\mu _{\\mathrm {l} },}\n  where \u03bcs and \u03bcl are respectively the dynamic viscosity of the slurry and liquid (Pa\u00b7s), and \u03bcr is the relative viscosity (dimensionless).\nDepending on the size and concentration of the solid particles, several models exist that describe the relative viscosity as a function of volume fraction \u03c6 of solid particles.\nIn the case of extremely low concentrations of fine particles, Einstein's equation may be used:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi }\n  In the case of higher concentrations, a modified equation was proposed by Guth and Simha, which takes into account interaction between the solid particles:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        14.1\n        \n          \u03c6\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +14.1\\varphi ^{2}}\n  Further modification of this equation was proposed by Thomas from the fitting of empirical data:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n        +\n        2.5\n        \u03c6\n        +\n        10.05\n        \n          \u03c6\n          \n            2\n          \n        \n        +\n        A\n        \n          e\n          \n            B\n            \u03c6\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1+2.5\\varphi +10.05\\varphi ^{2}+Ae^{B\\varphi },}\n  where A = 0.00273 and B = 16.6.\nIn the case of high shear stress (above 1 kPa), another empirical equation was proposed by Kitano et al. for polymer melts:\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                \n                  \u03c6\n                  A\n                \n              \n            \n            )\n          \n          \n            \u2212\n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=\\left(1-{\\frac {\\varphi }{A}}\\right)^{-2},}\n  where A = 0.68 for smooth spherical particles.\n\n\n== Nanofluids ==\n\nNanofluid is a novel class of fluid, which is developed by dispersing nano-sized particles in base fluid.Einstein model\nEinstein derived the applicable first theoretical formula for the estimation of viscosity values of composites or mixtures in 1906. This model developed while assuming linear viscous fluid including suspensions of rigid and spherical particles. Einstein\u2019s model is valid for very low volume fraction \n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n  .\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing )}\n  \nBrinkman model\nBrinkman modified Einstein\u2019s model for used with average particle volume fraction up to 4%\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n               \n              (\n              1\n              \u2212\n              \u2205\n              \n                )\n                \n                  2.5\n                \n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \u2205\n        +\n        4.375\n        \n          \u2205\n          \n            2\n          \n        \n        +\n        O\n        (\n        \n          \u2205\n          \n            3\n          \n        \n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}{\\frac {1}{\\ (1-\\varnothing )^{2.5}}}{\\Biggr )}=\\mu _{bf}{\\Big (}1+2.5\\varnothing +4.375\\varnothing ^{2}+O(\\varnothing ^{3}){\\Big )}}\n  \nBatchelor model\nBatchelor reformed Einstein's theoretical model by presenting Brownian motion effect.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        2.5\n        \u2205\n        +\n        6.5\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+2.5\\varnothing +6.5{\\varnothing }^{2})}\n  \nWang et al. model\nWang et al. found a model to predict viscosity of nanofluid as follows.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        (\n        1\n        +\n        7.3\n        \u2205\n        +\n        123\n        \n          \n            \u2205\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}(1+7.3\\varnothing +123{\\varnothing }^{2})}\n  \nMasoumi et al. model\nMasoumi et al. suggested a new viscosity correlation by considering Brownian motion of nanoparticle in nanofluid.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              C\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta C}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                18\n                \n                  K\n                  \n                    B\n                  \n                \n                T\n              \n              \n                \u03c0\n                \n                  \u03c1\n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle V_{B}={\\sqrt {\\frac {18K_{B}T}{\\pi \\rho _{p}{d_{p}}^{3}}}}}\n  \n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                \u03c0\n                \n                  \n                    \n                      d\n                      \n                        p\n                      \n                    \n                  \n                  \n                    3\n                  \n                \n              \n              \n                6\n                \u2205\n              \n            \n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\sqrt[{3}]{\\frac {\\pi {d_{p}}^{3}}{6\\varnothing }}}}\n  \n\n  \n    \n      \n        C\n        =\n        {\n        \n          (\n          \u2212\n          1.133\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          2.771\n          )\n          \u2205\n          +\n          (\n          0.09\n          \n            d\n            \n              p\n            \n          \n          \u2212\n          0.393\n          )\n        \n        }\n        \u00d7\n        \n          10\n          \n            \u2212\n            6\n          \n        \n      \n    \n    {\\displaystyle C=\\{{(-1.133d_{p}-2.771)\\varnothing +(0.09d_{p}-0.393)}\\}\\times 10^{-6}}\n  \nUdawattha et al. model\nUdawattha et al. modified the Masoumi et al. model. The developed model valid for suspension containing micro-size particles.\n  \n    \n      \n        \n          \u03bc\n          \n            n\n            f\n          \n        \n        =\n        \n          \u03bc\n          \n            b\n            f\n          \n        \n        \n          \n            (\n          \n        \n        1\n        +\n        2.5\n        \n          \u2205\n          \n            e\n          \n        \n        +\n        \n          \n            \n              \n                \u03c1\n                \n                  p\n                \n              \n              \n                V\n                \n                  B\n                \n              \n              \n                \n                  \n                    d\n                    \n                      p\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n            \n              72\n              \u03b4\n              [\n              T\n              \u00d7\n              \n                10\n                \n                  \u2212\n                  10\n                \n              \n              \u00d7\n              \n                \u2205\n                \n                  \u2212\n                  0.002\n                  T\n                  \u2212\n                  0.284\n                \n              \n              ]\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mu _{nf}=\\mu _{bf}{\\Biggl (}1+2.5\\varnothing _{e}+{\\frac {\\rho _{p}V_{B}{d_{p}}^{2}}{72\\delta [T\\times 10^{-10}\\times \\varnothing ^{-0.002T-0.284}]}}{\\Biggr )}}\n  \n\n  \n    \n      \n        \n          \u2205\n          \n            e\n          \n        \n        =\n        \u2205\n        \n          \n            \n              \n                (\n              \n            \n            1\n            +\n            \n              \n                h\n                r\n              \n            \n            \n              \n                )\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\varnothing _{e}=\\varnothing {{\\Biggl (}1+{\\frac {h}{r}}{\\Biggr )}}^{3}}\n  \nwhere\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the viscosity of the sample, in [Pa\u00b7s]\n\n  \n    \n      \n        n\n        f\n      \n    \n    {\\displaystyle nf}\n   is nanofluid\n\n  \n    \n      \n        b\n        f\n      \n    \n    {\\displaystyle bf}\n   is basefluid\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is particle\n\n  \n    \n      \n        \u2205\n      \n    \n    {\\displaystyle \\varnothing }\n   is volume fraction\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of the sample, in [kg\u00b7m\u22123]\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is distance between two particles\n\n  \n    \n      \n        \n          V\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle V_{B}}\n   is Brownian motion of particle\n\n  \n    \n      \n        \n          K\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle K_{B}}\n   is the Boltzmann constant\n\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is Temperature of the sample, in [K]\n\n  \n    \n      \n        \n          d\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle d_{p}}\n   is diameter of a particle\n\n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is nanolayer thickness (1 nm)\n\n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is radius of a particle\n\n\n== Amorphous materials ==\n\nViscous flow in amorphous materials (e.g. in glasses and melts) is a thermally activated process:\n\n  \n    \n      \n        \u03bc\n        =\n        A\n        \n          e\n          \n            \n              Q\n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =Ae^{\\frac {Q}{RT}},}\n  where Q is activation energy, T is temperature, R is the molar gas constant and A is approximately a constant.\nThe viscous flow in amorphous materials is characterized by a deviation from the Arrhenius-type behavior: Q changes from a high value QH at low temperatures (in the glassy state) to a low value QL at high temperatures (in the liquid state). Depending on this change, amorphous materials are classified as either\n\nstrong when: QH \u2212 QL < QL or\nfragile when: QH \u2212 QL \u2265 QL.The fragility of amorphous materials is numerically characterized by Doremus' fragility ratio:\n\n  \n    \n      \n        \n          R\n          \n            \n              D\n            \n          \n        \n        =\n        \n          \n            \n              Q\n              \n                \n                  H\n                \n              \n            \n            \n              Q\n              \n                \n                  L\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{\\mathrm {D} }={\\frac {Q_{\\mathrm {H} }}{Q_{\\mathrm {L} }}}}\n  and strong materials have RD < 2 whereas fragile materials have RD \u2265 2.\n\nThe viscosity of amorphous materials is quite exactly described by a two-exponential equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            1\n          \n        \n        T\n        \n          (\n          \n            1\n            +\n            \n              A\n              \n                2\n              \n            \n            \n              e\n              \n                \n                  B\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            +\n            C\n            \n              e\n              \n                \n                  D\n                  \n                    R\n                    T\n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{1}T\\left(1+A_{2}e^{\\frac {B}{RT}}\\right)\\left(1+Ce^{\\frac {D}{RT}}\\right),}\n  with constants A1, A2, B, C and D related to thermodynamic parameters of joining bonds of an amorphous material.\nNot very far from the glass transition temperature, Tg, this equation can be approximated by a Vogel\u2013Fulcher\u2013Tammann (VFT) equation.\nIf the temperature is significantly lower than the glass transition temperature, T \u226a Tg, then the two-exponential equation simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              L\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    H\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {L} }Te^{\\frac {Q_{\\mathrm {H} }}{RT}}}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              H\n            \n          \n        \n        =\n        \n          H\n          \n            \n              d\n            \n          \n        \n        +\n        \n          H\n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle Q_{\\mathrm {H} }=H_{\\mathrm {d} }+H_{\\mathrm {m} },}\n  where Hd is the enthalpy of formation of broken bonds (termed configurons) and Hm is the enthalpy of their motion.\nWhen the temperature is less than the glass transition temperature, T < Tg, the activation energy of viscosity is high because the amorphous materials are in the glassy state and most of their joining bonds are intact.\nIf the temperature is much higher than the glass transition temperature, T \u226b Tg, the two-exponential equation also simplifies to an Arrhenius-type equation:\n\n  \n    \n      \n        \u03bc\n        =\n        \n          A\n          \n            \n              H\n            \n          \n        \n        T\n        \n          e\n          \n            \n              \n                Q\n                \n                  \n                    L\n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mu =A_{\\mathrm {H} }Te^{\\frac {Q_{\\mathrm {L} }}{RT}},}\n  with\n\n  \n    \n      \n        \n          Q\n          \n            \n              L\n            \n          \n        \n        =\n        \n          H\n          \n            \n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Q_{\\mathrm {L} }=H_{\\mathrm {m} }.}\n  When the temperature is higher than the glass transition temperature, T > Tg, the activation energy of viscosity is low because amorphous materials are melted and have most of their joining bonds broken, which facilitates flow.\n\n\n== Eddy viscosity ==\nIn the study of turbulence in fluids, a common practical strategy for calculation is to ignore the small-scale vortices (or eddies) in the motion and to calculate a large-scale motion with an eddy viscosity that characterizes the transport and dissipation of energy in the smaller-scale flow (see large eddy simulation). Values of eddy viscosity used in modeling ocean circulation may be from 5\u00d7104 to 1\u00d7106 Pa\u00b7s depending upon the resolution of the numerical grid.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nHatschek, Emil (1928). The Viscosity of Liquids. New York: Van Nostrand. OCLC 53438464. \nMassey, B. S.; Ward-Smith, A. J. (2011). Mechanics of Fluids (9th ed.). London & New York: Spon Press. ISBN 978-0-415-60259-4. OCLC 690084654. \n\n\n== External links ==\nFluid properties - high accuracy calculation of viscosity for frequently encountered pure liquids and gases\nGas viscosity calculator as function of temperature\nAir viscosity calculator as function of temperature and pressure\nFluid Characteristics Chart - a table of viscosities and vapor pressures for various fluids\nGas Dynamics Toolbox - calculate coefficient of viscosity for mixtures of gases\nGlass Viscosity Measurement - viscosity measurement, viscosity units and fixpoints, glass viscosity calculation\nKinematic Viscosity - conversion between kinematic and dynamic viscosity\nPhysical Characteristics of Water - a table of water viscosity as a function of temperature\nVogel\u2013Tammann\u2013Fulcher Equation Parameters\nCalculation of temperature-dependent dynamic viscosities for some common components\n\"Test Procedures for Testing Highway and Nonroad Engines and Omnibus Technical Amendments\" - United States Environmental Protection Agency\nArtificial viscosity\nViscosity of Air, Dynamic and Kinematic, Engineers Edge",
        "unit": "fluidity",
        "url": "https://en.wikipedia.org/wiki/Viscosity"
    },
    {
        "_id": "Fuel_efficiency",
        "clean": "Fuel efficiency",
        "text": "Fuel efficiency is a form of thermal efficiency, meaning the ratio from effort to result of a process that converts chemical potential energy contained in a carrier (fuel) into kinetic energy or work. Overall fuel efficiency may vary per device, which in turn may vary per application fuel efficiency, especially fossil fuel power plants or industries dealing with combustion, such as ammonia production during the Haber process.\nIn the context of transport, fuel economy is the energy efficiency of a particular vehicle,  given as a ratio of distance traveled per unit of fuel consumed. It is dependent on engine efficiency, transmission design, and tire design. Fuel economy is expressed in miles per gallon (mpg) in the USA and usually also in the UK (imperial gallon); there is sometimes confusion as the imperial gallon is 20% larger than the US gallon so that mpg values are not directly comparable. In countries using the metric system fuel economy is stated as \"fuel consumption\" in liters per 100 kilometers (L/100 km). Litres per mil are used in Norway and Sweden.\nFuel consumption is a more accurate measure of a vehicle\u2019s performance because it is a linear relationship while fuel economy leads to distortions in efficiency improvements.Weight-specific efficiency (efficiency per unit weight) may be stated for freight, and passenger-specific efficiency (vehicle efficiency per passenger).\n\n\n== Vehicle design ==\nFuel efficiency is dependent on many parameters of a vehicle, including its engine parameters, aerodynamic drag, weight, AC usage, fuel and rolling resistance. There have been advances in all areas of vehicle design in recent decades. Fuel efficiency of vehicles can also be improved by careful maintenance and driving habits.Hybrid vehicles use two or more power sources for propulsion. In many designs, a small combustion engine is combined with electric motors.  Kinetic energy which would otherwise be lost to heat during braking is recaptured as electrical power to improve fuel efficiency. Engines automatically shut off when vehicles come to a stop and start again when the accelerator is pressed preventing wasted energy from idling.\n\n\n== Fleet efficiency ==\nFleet efficiency describes the average efficiency of a population of vehicles.  Technological advances in efficiency may be offset by a change in buying habits with a propensity to heavier vehicles, which are less efficient, all else being equal.\n\n\n== Energy efficiency terminology ==\nEnergy efficiency is similar to fuel efficiency but the input is usually in units of energy such as British thermal units (BTU), megajoules (MJ), gigajoules (GJ), kilocalories (kcal), or kilowatt-hours (kW\u00b7h).  The inverse of \"energy efficiency\" is \"energy intensity\", or the amount of input energy required for a unit of output such as MJ/passenger-km (of passenger transport), BTU/ton-mile or kJ/t-km (of freight transport), GJ/t (for production of steel and other materials), BTU/(kW\u00b7h) (for electricity generation), or litres/100 km (of vehicle travel). Litres per 100 km is also a measure of \"energy intensity\" where the input is measured by the amount of fuel and the output is measured by the distance travelled.  For example: Fuel economy in automobiles.\nGiven a heat value of a fuel, it would be trivial to convert from fuel units (such as litres of gasoline) to energy units (such as MJ) and conversely. But there are two problems with comparisons made using energy units:\n\nThere are two different heat values for any hydrogen-containing fuel which can differ by several percent (see below).\nWhen comparing transportation energy costs, it must be remembered that a kilowatt hour of electric energy may require an amount of fuel with heating value of 2 or 3 kilowatt hours to produce it.\n\n\n== Energy content of fuel ==\nThe specific energy content of a fuel is the heat energy obtained when a certain quantity is burned (such as a gallon, litre, kilogram).  It is sometimes called the heat of combustion.  There exists two different values of specific heat energy for the same batch of fuel.  One is the high (or gross) heat of combustion and the other is the low (or net) heat of combustion.  The high value is obtained when, after the combustion, the water in the exhaust is in liquid form.  For the low value, the exhaust has all the water in vapor form (steam).  Since water vapor gives up heat energy when it changes from vapor to liquid, the liquid water value is larger since it includes the latent heat of vaporization of water.  The difference between the high and low values is significant, about 8 or 9%.  This accounts for most of the apparent discrepancy in the heat value of gasoline. In the U.S. (and the table) the high heat values have traditionally been used, but in many other countries, the low heat values are commonly used.\n\nNeither the gross heat of combustion nor the net heat of combustion gives the theoretical amount of mechanical energy (work) that can be obtained from the reaction. (This is given by the change in Gibbs free energy, and is around 45.7 MJ/kg for gasoline.) The actual amount of mechanical work obtained from fuel (the inverse of the specific fuel consumption) depends on the engine. A figure of 17.6 MJ/kg is possible with a gasoline engine, and 19.1 MJ/kg for a diesel engine. See Brake specific fuel consumption for more information.\n\n\n== Fuel efficiency of motor vehicles ==\n\nThe fuel efficiency of motor vehicles can be expressed in more ways:\n\nFuel consumption is the amount of fuel used per unit distance; for example, litres per 100 kilometres (L/100 km). In this case, the lower the value, the more economic a vehicle is (the less fuel it needs to travel a certain distance); this is the measure generally used across Europe (except the UK, Denmark and The Netherlands - see below), New Zealand, Australia and Canada. Also in Uruguay, Paraguay, Guatemala, Colombia, China, and Madagascar., as also in post-Soviet space.\nFuel economy is the distance travelled per unit volume of fuel used; for example, kilometres per litre (km/L) or miles per gallon (MPG), where 1 MPG (imperial) \u2248 0.354006 km/L.  In this case, the higher the value, the more economic a vehicle is (the more distance it can travel with a certain volume of fuel). This measure is popular in the USA and the UK (mpg), but in Europe, India, Japan, South Korea and Latin America the metric unit km/L is used instead.Converting from mpg or to L/100 km (or vice versa) involves the use of the reciprocal function, which is not distributive. Therefore, the average of two fuel economy numbers gives different values if those units are used, because one of the functions is reciprocal, thus not linear. If two people calculate the fuel economy average of two groups of cars with different units, the group with better fuel economy may be one or the other. However, from the point of energy used as a shared method of measure, the result shall be the same in both the cases.\nThe formula for converting to miles per US gallon (exactly 3.785411784 L) from L/100 km is \n  \n    \n      \n        \n          \n            \n              235.215\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {235.215}{x}}}\n  , where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is value of L/100 km. For miles per Imperial gallon (exactly 4.54609 L) the formula is \n  \n    \n      \n        \n          \n            \n              282.481\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {282.481}{x}}}\n  .\nIn parts of Europe, the two standard measuring cycles for \"litre/100 km\" value are \"urban\" traffic with speeds up to 50 km/h from a cold start, and then \"extra urban\" travel at various speeds up to 120 km/h which follows the urban test. A combined figure is also quoted showing the total fuel consumed in divided by the total distance traveled in both tests. A reasonably modern European supermini and many mid-size cars, including station wagons, may manage motorway travel at 5 L/100 km (47 mpg US/56 mpg imp) or 6.5 L/100 km in city traffic (36 mpg US/43 mpg imp), with carbon dioxide emissions of around 140 g/km.\nAn average North American mid-size car travels 21 mpg (US) (11 L/100 km) city, 27 mpg (US) (9 L/100 km) highway; a full-size SUV usually travels 13 mpg (US) (18 L/100 km) city and 16 mpg (US) (15 L/100 km) highway.  Pickup trucks vary considerably; whereas a 4 cylinder-engined light pickup can achieve 28 mpg (8 L/100 km), a V8 full-size pickup with extended cabin only travels 13 mpg (US) (18 L/100 km) city and 15 mpg (US) (15 L/100 km) highway.\nThe average fuel economy is higher in Europe due to the higher cost of fuel. In the UK, a gallon of gas without tax would cost US$1.97, but with taxes cost US$6.06 in 2005. The average cost in the United States was US$2.61. Consumers prefer \"muscle cars\" but choose more fuel efficient ones when gas prices increase.European-built cars are generally more fuel-efficient than US vehicles. While Europe has many higher efficiency diesel cars, European gasoline vehicles are on average also more efficient than gasoline-powered vehicles in the USA. Most European vehicles cited in the CSI study run on diesel engines, which tend to achieve greater fuel efficiency than gas engines. Selling those cars in the United States is difficult because of emission standards, notes Walter McManus, a fuel economy expert at the University of Michigan Transportation Research Institute. \"For the most part, European diesels don\u2019t meet U.S. emission standards\", McManus said in 2007. Another reason why many European models are not marketed in the United States is that labor unions object to having the big 3 import any new foreign built models regardless of fuel economy while laying off workers at home.An example of European cars' capabilities of fuel economy is the microcar Smart Fortwo cdi, which can achieve up to 3.4 l/100 km (69.2 mpg US) using a turbocharged three-cylinder 41 bhp (30 kW) Diesel engine. The Fortwo is produced by Daimler AG and is currently only sold by one company in the United States. Furthermore, the current (and to date already 10-year-old) world record in fuel economy of production cars is held by the Volkswagen Group, with special production models (labeled \"3L\") of the Volkswagen Lupo and the Audi A2, consuming as little as 3 L/100 km (94 mpg\u2011imp; 78 mpg\u2011US).Diesel engines generally achieve greater fuel efficiency than petrol (gasoline) engines. Passenger car diesel engines have energy efficiency of up to 41% but more typically 30%, and petrol engines of up to 37.3%, but more typically 20%. That is one of the reasons why diesels have better fuel efficiency than equivalent petrol cars. A common margin is 25% more miles per gallon for an efficient turbodiesel.\nFor example, the current model Skoda Octavia, using Volkswagen engines, has a combined European fuel efficiency of 41.3 mpg for the 105 bhp (78 kW) petrol engine and 52.3 mpg for the 105 bhp (78 kW) \u2014 and heavier \u2014 diesel engine. The higher compression ratio is helpful in raising the energy efficiency, but diesel fuel also contains approximately 10% more energy per unit volume than gasoline which contributes to the reduced fuel consumption for a given power output.\nIn 2002, the United States had 85,174,776 trucks, and averaged 13.5 miles per US gallon (17.4 L/100 km; 16.2 mpg\u2011imp). Large trucks, over 33,000 pounds (15,000 kg), averaged 5.7 miles per US gallon (41 L/100 km; 6.8 mpg\u2011imp).\nThe average economy of automobiles in the United States in 2002 was 22.0 miles per US gallon (10.7 L/100 km; 26.4 mpg\u2011imp). By 2010 this had increased to 23.0 miles per US gallon (10.2 L/100 km; 27.6 mpg\u2011imp). Average fuel economy in the United States gradually declined until 1973, when it reached a low of 13.4 miles per US gallon (17.6 L/100 km; 16.1 mpg\u2011imp) and gradually has increased since, as a result of higher fuel cost. A study indicates that a 10% increase in gas prices will eventually produce a 2.04% increase in fuel economy. One method by car makers to increase fuel efficiency is lightweighting in which lighter-weight materials are substituted in for improved engine performance and handling.\n\n\n== Fuel efficiency in microgravity ==\nHow fuel combusts affects how much energy is produced. The National Aeronautics and Space Administration (NASA) has investigated fuel consumption in microgravity.\nThe common distribution of a flame under normal gravity conditions depends on convection, because soot tends to rise to the top of a flame, such as in a candle, making the flame yellow. In microgravity or zero gravity, such as an environment in outer space, convection no longer occurs, and the flame becomes spherical, with a tendency to become more blue and more efficient. There are several possible explanations for this difference, of which the most likely one given is the hypothesis that the temperature is evenly distributed enough that soot is not formed and complete combustion occurs., National Aeronautics and Space Administration, April 2005. Experiments by NASA in microgravity reveal that diffusion flames in microgravity allow more soot to be completely oxidised after they are produced than diffusion flames on Earth, because of a series of mechanisms that behaved differently in microgravity when compared to normal gravity conditions.LSP-1 experiment results, National Aeronautics and Space Administration, April 2005. Premixed flames in microgravity burn at a much slower rate and more efficiently than even a candle on Earth, and last much longer.\n\n\n== Transportation ==\n\n\n=== Fuel efficiency in transportation ===\n\n\n=== Vehicle efficiency and transportation pollution ===\n\nFuel efficiency directly affects emissions causing pollution by affecting the amount of fuel used. However, it also depends on the fuel source used to drive the vehicle concerned. Cars for example, can run on a number of fuel types other than gasoline, such as natural gas, LPG or biofuel or electricity which creates various quantities of atmospheric pollution.\nA kilogram of carbon, whether contained in petrol, diesel, kerosene, or any other hydrocarbon fuel in a vehicle, leads to approximately 3.6 kg of CO2 emissions.  Due to the carbon content of gasoline, its combustion emits 2.3 kg/l (19.4 lb/US gal) of CO2; since diesel fuel is more energy dense per unit volume, diesel emits 2.6 kg/l (22.2 lb/US gal).  This figure is only the CO2 emissions of the final fuel product and does not include additional CO2 emissions created during the drilling, pumping, transportation and refining steps required to produce the fuel. Additional measures to reduce overall emission includes improvements to the efficiency of air conditioners, lights and tires.\n\n\n=== Driving technique ===\n\nMany drivers have the potential to improve their fuel efficiency significantly. These five basic fuel-efficient driving techniques can be effective. Simple things such as keeping tires properly inflated, having a vehicle well-maintained and avoiding idling can dramatically improve fuel efficiency.There is a growing community of enthusiasts known as hypermilers who develop and practice driving techniques to increase fuel efficiency and reduce consumption. Hypermilers have broken records of fuel efficiency, for example, achieving 109 miles per gallon in a Prius. In non-hybrid vehicles these techniques are also beneficial, with fuel efficiencies of up to 59 MPG in a Honda Accord or 30 MPG in an Acura MDX.\n\n\n== Advanced technology improvements to improve fuel efficiency ==\nThe most efficient machines for converting energy to rotary motion are electric motors, as used in electric vehicles. However, electricity is not a primary energy source so the efficiency of the electricity production has also to be taken into account. Currently railway trains can be powered using electricity, delivered through an additional running rail, overhead catenary system or by on-board generators used in diesel-electric locomotives as common on the US and UK rail networks. Pollution produced from centralised generation of electricity is emitted at a distant power station, rather than \"on site\". Pollution can be reduced by using more railway electrification and low carbon power for electricity. Some railways, such as the French SNCF and Swiss federal railways derive most, if not 100% of their power, from hydroelectric or nuclear power stations, therefore atmospheric pollution from their rail networks is very low. This was reflected in a study by AEA Technology between a Eurostar train and airline journeys between London and Paris, which showed the trains on average emitting 10 times less CO2, per passenger, than planes, helped in part by French nuclear generation.\n\n\n=== Hydrogen Fuel Cells ===\nIn the future, hydrogen cars may be commercially available. Toyota is test marketing hydrogen fuel cell powered vehicles in southern California where a series of hydrogen fueling stations has been established. Powered either through chemical reactions in a fuel cell that create electricity to drive very efficient electrical motors or by directly burning hydrogen in a combustion engine (near identically to a natural gas vehicle, and similarly compatible with both natural gas and gasoline); these vehicles promise to have near-zero pollution from the tailpipe (exhaust pipe). Potentially the atmospheric pollution could be minimal, provided the hydrogen is made by electrolysis using electricity from non-polluting sources such as solar, wind or hydroelectricity or nuclear. Commercial hydrogen production uses fossil fuels and produces more carbon dioxide than hydrogen.\nBecause there are pollutants involved in the manufacture and destruction of a car and the production, transmission and storage of electricity and hydrogen, the use of the label \"zero pollution\" should be understood as applying only to the car's conversion of stored energy into transportation.\nIn 2004, a consortium of major auto-makers \u2014 BMW, General Motors, Honda, Toyota and Volkswagen/Audi \u2014 came up with \"Top Tier Detergent Gasoline Standard\" to gasoline brands in the US and Canada that meet their minimum standards for detergent content and do not contain metallic additives. Top Tier gasoline contains higher levels of detergent additives in order to prevent the build-up of deposits (typically, on fuel injector and intake valve) known to reduce fuel economy and engine performance.\n\n\n=== Electric Turbo Compounding (ETC) ===\nElectric Turbo Compounding (ETC) is a technology solution to the challenge of improving energy efficiency for the stationary power generation industry.\nFossil fuel based power generation is predicted to continue for decades, especially in developing economies. This is against the global need to reduce carbon emissions, of which, a high percentage is produced by the power sector worldwide.\nETC works by making gas and diesel-powered gensets (Electric Generators) work more effectively and cleaner, by recovering waste energy from the exhaust to improve power density and fuel efficiency.\n\n\n==== Advantages of using ETC ====\nHelps developing economies with unreliable or insufficient power infrastructure. \nGives independent power providers (IPPs), power rental companies and generator OEMs (original equipment manufacturers) a competitive advantage and potential increased market share.\nImproves overall efficiency of the genset, including fuel input costs and helping end-users reduce amount of fuel burned. \nTypically 4-7% less fuel consumption for both diesel and gas gensets. \nFewer carbon emissions.\nIncreased power density. \nCapability to increase power output and capacity, with improved fuel efficiency.\nETC system integration offers a step change in efficiency without increasing service or maintenance requirements.\nThe cost of generating power through waste heat recovery is substantially less than burning more fuel, even with low diesel prices.\n\n\n==== Disadvantages of using ETC ====\nUpfront costs incur an additional expense for businesses.\nThe need to update existing turbomachinery and recertification of the unit adds additional costs and can be time consuming.\nThere will be additional weight to add an ETC to a current unit.\nProcess still uses fossil fuels, thus still has a carbon footprint in a renewable age.\nThey are bespoke to each generator so the design, build and implementation can be a lengthy process.\nThere are challenges with high speed turbo generators such as high stress in the rotors, heat generation of the electrical machine and rotordynamics of the turbo generator system.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nUS Government website on fuel economy\nUK DfT comparisons on road and rail\nNASA Offers a $1.5 Million Prize for a Fast and Fuel-Efficient Aircraft\nCar Fuel Consumption Official Figures\nSpritmonitor.de \"the most fuel efficient cars\" - Database of thousands of (mostly German) car owners' actual fuel consumption figures (cf. Spritmonitor)\nSearchable fuel economy data from the EPA - United States Environmental Protection Agency\npenghemat bbm - Alat penghemat bbm\nNy Times: A Road Test of Alternative Fuel Visions",
        "unit": "fuel consumption",
        "url": "https://en.wikipedia.org/wiki/Fuel_efficiency"
    },
    {
        "_id": "Pound_(mass)",
        "clean": "Pound (mass)",
        "text": "The pound or pound-mass is a unit of mass \nused in the imperial, United States customary and other systems of measurement. Various definitions have been used; the most common today is the international avoirdupois pound, which is legally defined as exactly 0.45359237 kilograms, and which is divided into 16 avoirdupois ounces. The international standard symbol for the avoirdupois pound is lb; an alternative symbol is lbm (for most pound definitions), # (chiefly in the U.S.), and \u2114 or \u2033\u0336 (specifically for the apothecaries' pound).\nThe unit is descended from the Roman libra (hence the abbreviation \"lb\").  The English word pound is cognate with, among others,  German Pfund, Dutch pond, and Swedish pund.  All ultimately derive from a borrowing into Proto-Germanic of the  Latin expression l\u012bbra pond\u014d (\"a pound by weight\"), in which the word pond\u014d is the ablative case of the Latin noun pondus (\"weight\").Usage of the unqualified term pound reflects the historical conflation of mass and weight. This accounts for the modern distinguishing terms pound-mass and pound-force.\n\n\n== Current use ==\nThe United States and countries of the Commonwealth of Nations agreed upon common definitions for the pound and the yard. Since 1 July 1959, the international avoirdupois pound (symbol lb) has been defined as exactly 0.45359237 kg.In the United Kingdom, the use of the international pound was implemented in the Weights and Measures Act 1963.\nThe yard or the metre shall be the unit of measurement of length and the pound or the kilogram shall be the unit of measurement of mass by reference to which any measurement involving a measurement of length or mass shall be made in the United Kingdom; and- (a) the yard shall be 0.9144 metre exactly; (b) the pound shall be 0.45359237 kilogram exactly.\n\nAn avoirdupois pound is equal to 16 avoirdupois ounces and to exactly 7,000 grains. The conversion factor between the kilogram and the international pound was therefore chosen to be divisible by 7, and an (international) grain is thus equal to exactly 64.79891 milligrams.\nIn the UK, the process of metrication and European units of measurement directives were expected to eliminate the use of the pound and ounce, but in 2007 the European Commission abandoned the requirement for metric-only labelling on packaged goods there, and allowed for dual metric\u2013imperial marking to continue indefinitely. When used as a measurement of body weight the UK practice remains to use the stone of 14 pounds as the primary measure e.g. \"11 stone 4 pounds\", rather than \"158 pounds\" (as done in the US), or \"72 kilograms\" as used elsewhere.\nThe US has not adopted the metric system despite many efforts to do so, and the pound remains widely used as one of the key United States customary units.\n\n\n== Historic use ==\n\nHistorically, in different parts of the world, at different points in time, and for different applications, the pound (or its translation) has referred to broadly similar but not identical standards of mass or force.\n\n\n=== Roman libra ===\n\nThe libra (Latin for \"scales / balance\") is an ancient Roman unit of mass that was equivalent to approximately 328.9 grams. It was divided into 12 unciae (singular: uncia), or ounces. The libra is the origin of the abbreviation for pound, \"lb\".\n\n\n=== In Britain ===\nA number of different definitions of the pound have historically been used in Britain. Amongst these were the avoirdupois pound and the obsolete Tower, merchant's and London pounds. Troy pounds and ounces remain in use only for the weight of certain precious metals, especially in the trade; these are normally quoted just in ounces (e.g. \"500 ounces\") and, when the type of ounce is not explicitly stated, the troy system is assumed.\nHistorically, the pound sterling was a Tower pound of silver. In 1528, the standard was changed to the Troy pound.\n\n\n==== Avoirdupois pound ====\nThe avoirdupois pound, also known as the wool pound, first came into general use c. 1300. It was initially equal to 6992 troy grains. The pound avoirdupois was divided into 16 ounces. During the reign of Queen Elizabeth, the avoirdupois pound was redefined as 7,000 troy grains. Since then, the grain has often been an integral part of the avoirdupois system. By 1758, two Elizabethan Exchequer standard weights for the avoirdupois pound existed, and when measured in troy grains they were found to be of 7,002 grains and 6,999 grains.\n\n\n==== Imperial Standard Pound ====\nIn the United Kingdom, weights and measures have been defined by a long series of Acts of Parliament, the intention of which has been to regulate the sale of commodities. Materials traded in the marketplace are quantified according to accepted units and standards in order to avoid fraud. The standards themselves are legally defined so as to facilitate the resolution of disputes brought to the courts; only legally defined measures will be recognised by the courts. Quantifying devices used by traders (weights, weighing machines, containers of volumes, measures of length) are subject to official inspection, and penalties apply if they are fraudulent.\nThe Weights and Measures Act of 1878 marked a major overhaul of the British system of weights and measures, and the definition of the pound given there remained in force until the 1960s. The pound was defined thus (Section 4) \"The ... platinum weight ... deposited in the Standards department of the Board of Trade ... shall continue to be the imperial standard of ... weight ... and the said platinum weight shall continue to be the Imperial Standard for determining the Imperial Standard Pound for the United Kingdom\". Paragraph 13 states that the weight in vacuo of this standard shall be called the Imperial Standard Pound, and that all other weights mentioned in the act and permissible for commerce shall be ascertained from it alone. The First Schedule of the Act gave more details of the standard pound: it is a platinum cylinder nearly 1.35 inches (34 mm) high, and 1.15 inches (29 mm) diameter, and the edges are carefully rounded off. It has a groove about 0.34 inches (8.6 mm) from the top, to allow the cylinder to be lifted using an ivory fork. It was constructed following the destruction of the Houses of Parliament by fire in 1834, and is stamped P.S. 1844, 1 lb (P.S. stands for \"Parliamentary Standard\"). This definition of the Imperial pound remains unchanged.\n\n\n==== Relationship to the kilogram ====\nThe 1878 Act said that contracts worded in terms of metric units would be deemed by the courts to be made according to the Imperial units defined in the Act, and a table of metric equivalents was supplied so that the Imperial equivalents could be legally calculated. This defined, in UK law, metric units in terms of Imperial ones. The equivalence for the pound was given as 1 lb = 453.59265 g or 0.45359 kg, which made the kilogram equivalent to about 2.2046213 lb. In 1883, it was determined jointly by the Standards Department of the Board of Trade and the Bureau International that 0.4535924277 kg was a better approximation, and this figure, rounded to 0.45359243 kg was given legal status by an Order in Council in May 1898.However, in 1963, a new Weights and Measures Act reversed this relationship and the pound was defined for the first time as a mass equal to 0.45359237 kg to match the definition of the international pound agreed in 1959.\n\n\n==== Troy pound ====\n\nA troy pound is equal to 12 troy ounces and to 5,760 grains, that is exactly 373.2417216 grams. Troy weights were used in England by jewellers. Apothecaries also used the troy pound and ounce, but added the drachms and scruples unit in the Apothecaries' system of weights.\nTroy weight may take its name from the French market town of Troyes in France where English merchants traded at least as early as the early 9th century.The troy pound is no longer in general use or a legal unit for trade (it was abolished in the United Kingdom on 6 January 1879 by the Weights and Measures Act of 1878), but the troy ounce, \u200b1\u204412 of a troy pound, is still used for measurements of gems such as opals, and precious metals such as silver, platinum and particularly gold.\n\n\n==== Tower pound ====\n\nThe system called Tower weight was the more general name for King Offa's pound. This dates to 757 AD and was based on the silver penny. This in turn was struck over Arabic dirhams (2d). The pound was based on the weight of 120 Arabic silver dirhams, which have been found in Offa's Dyke. The same coin weight was used throughout the Hanseatic League.The Tower pound was also called the Moneyers' Pound (referring to the Saxon moneyers before the Conquest), the easterling pound, which may refer to traders of eastern Germany, or to traders on the shore of the eastern Baltic sea, or dealers of Asiatic goods who settled at the Steelyard wharf; and the Rochelle Pound by French writers, because it was also in use at Rochelle. An almost identical weight was employed by the Germans for weighing gold and silver.\nThe mercantile pound (1304) of 6750 troy grains, or 9600 Tower grains, derives from this pound, as 25 shilling-weights or 15 Tower ounces, for general commercial use. Multiple pounds based on the same ounce were quite common. In much of Europe, the apothecaries' and commercial pounds were different numbers of the same ounce.The Tower system was referenced to a standard prototype found in the Tower of London and ran concurrently with the avoirdupois and troy systems until the reign of Henry VIII, when a royal proclamation dated 1526 required that the troy pound to be used for mint purposes instead of the Tower pound. No standards of the Tower pound are known to have survived.The Tower pound was equivalent to about 350 grams.\n\n\n==== Merchants' pound ====\nThe merchants' pound (mercantile pound, libra mercantoria, or commercial pound) was considered to be composed of 25 rather than 20 Tower shillings of 12 pence. It was equal to 9,600 wheat grains (15 tower ounces or 6,750 grains) and was used in England until the 14th century for goods other than money and medicine (\"electuaries\").\n\n\n==== London pound ====\nThe London pound is that of the Hansa, as used in their various trading places.  The London pound is based on 16 ounces, each ounce divided as the tower ounce.  It never became a legal standard in England; the use of this pound waxed and waned with the influence of the Hansa itself.\nA London pound was equal to 7,200 troy grains (16 troy ounces) or, equivalently, 10,240 tower grains (16 tower ounces).\n\n\n=== In the United States ===\nIn the United States, the avoirdupois pound as a unit of mass has been officially defined in terms of the kilogram since the Mendenhall Order of 1893. That Order defined the pound to be 2.20462 pounds to a kilogram. The following year, this relationship was refined as 2.20462234 pounds to a kilogram, following a determination of the British pound.According to a 1959 NIST publication, the United States 1894 pound differed from the international pound by approximately one part in 10 million. The difference is so insignificant that it can be ignored for almost all practical purposes.\n\n\n=== Byzantine litra ===\n\nThe Byzantines used a series of measurements known as pounds (Latin: libra, Greek: \u03bb\u03af\u03c4\u03c1\u03b1, litra). The most common was the logarik\u0113 litra (\u03bb\u03bf\u03b3\u03b1\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"pound of account\"), established by Constantine the Great in 309/310. It formed the basis of the Byzantine monetary system, with one litra of gold equivalent to 72 solidi. A hundred litrai were known as a kent\u0113narion (\u03ba\u03b5\u03bd\u03c4\u03b7\u03bd\u03ac\u03c1\u03b9\u03bf\u03bd, \"hundredweight\"). Its weight seems to have decreased gradually from the original 324 grams to 319. Due to its association with gold, it was also known as the chrysaphik\u0113 litra (\u03c7\u03c1\u03c5\u03c3\u03b1\u03c6\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"gold pound\") or thalassia litra (\u03b8\u03b1\u03bb\u03ac\u03c3\u03c3\u03b9\u03b1 \u03bb\u03af\u03c4\u03c1\u03b1, \"maritime pound\"), but it could also be used as a measure of land, equalling a fortieth of the thalassios modios.The soualia litra was specifically used for weighing olive oil or wood, and corresponded to 4/5 of the logarik\u0113, i.e. 256 g. Some outlying regions, especially in later times, adopted various local measures, based on Italian, Arab or Turkish measures. The most important of these was the argyrik\u0113 litra (\u03b1\u03c1\u03b3\u03c5\u03c1\u03b9\u03ba\u03ae \u03bb\u03af\u03c4\u03c1\u03b1, \"silver pound\") of 333 g, found in Trebizond and Cyprus, and probably of Arab origin.\n\n\n=== French livre ===\n\nSince the Middle Ages, various pounds (livre) have been used in France. Since the 19th century, a livre has referred to the metric pound, 500g.\nThe livre esterlin was equivalent to about 367.1 grams (5,665 gr) and was used between the late 9th century and the mid-14th century.The livre poids de marc or livre de Paris was equivalent to about 489.5 grams (7,554 gr) and was used between the 1350s and the late 18th century. It was introduced by the government of John II.\nThe livre m\u00e9trique was set equal to the kilogram by the decree of 13 Brumaire an IX between 1800 and 1812. This was a form of official metric pound.The livre usuelle (customary unit) was defined as 500 grams by the decree of 28 March 1812. It was abolished as a unit of mass effective 1 January 1840 by a decree of 4 July 1837, but is still used informally.\n\n\n=== German and Austrian Pfund ===\nOriginally derived from the Roman libra, the definition varied throughout Germany in the Middle Ages and onward. The measures and weights of the Habsburg monarchy were reformed in 1761 by Empress Maria Theresia of Austria. The unusually heavy Habsburg (civil) pound of 16 ounces was later defined in terms of 560.012 grams. Bavarian reforms in 1809 and 1811 adopted essentially the same standard pound. In Prussia, a reform in 1816 defined a uniform civil pound in terms of the Prussian foot and distilled water, resulting in a Prussian pound of 467.711 grams.\nBetween 1803 and 1815, all German regions west of the River Rhine were French, organised in the departements: Roer, Sarre, Rhin-et-Moselle, and Mont-Tonnerre. As a result of the Congress of Vienna, these became part of various German states. However, many of these regions retained the metric system and adopted a metric pound of precisely 500 grams. In 1854, the pound of 500 grams also became the official mass standard of the German Customs Union, but local pounds continued to co-exist with the Zollverein pound for some time in some German states. Nowadays, the term Pfund is still in common use and universally refers to a pound of 500 grams.\n\n\n=== Russian funt ===\nThe Russian pound (\u0424\u0443\u043d\u0442, funt) is an obsolete Russian unit of measurement of mass. It is equal to 409.51718 grams. In 1899, the Russian pound was the basic unit of weight and all other units of weight were formed from it.\n\n\n=== Sk\u00e5lpund ===\nThe Sk\u00e5lpund was a Scandinavian measurement that varied in weight between regions. From the 17th century onward, it was equal to 425.076 grams in Sweden but was abandoned in 1889 when Sweden switched to the metric system.\nIn Norway, the same name was used for a weight of 498.1 grams. In Denmark, it equalled 471 grams.\nIn the 19th century, Denmark followed Germany's lead and redefined the pound as 500 grams.\n\n\n=== Jersey pound ===\nA Jersey pound is an obsolete unit of mass used on the island of Jersey from the 14th century to the 19th century. It was equivalent to about 7,561 grains (490 grams). It may have been derived from the French livre poids de marc.\n\n\n=== Trone pound ===\nThe trone pound is one of a number of obsolete Scottish units of measurement. It was equivalent to between 21 and 28 avoirdupois ounces (about 600-800 grams).\n\n\n=== Metric pounds ===\nIn many countries, upon the introduction of a metric system, the pound (or its translation) became an informal term for 500 grams. In German, the term is Pfund, in French livre, in Dutch pond, in Spanish and Portuguese libra, in Italian libbra, and in Danish and Swedish pund.\nThough not from the same linguistic origin, the Chinese j\u012bn (\u65a4, also known as \"catty\") has a modern definition of exactly 500 grams, divided into 10 li\u01ceng (\u4e24). Traditionally about 605 grams, the jin has been in use for more than two thousand years, serving the same purpose as \"pound\" for the common-use measure of weight.\nHundreds of older pounds were replaced in this way. Examples of the older pounds are one of around 459 to 460 grams in Spain, Portugal, and Latin America; one of 498.1 grams in Norway; and several different ones in what is now Germany.\nAlthough the use of the pound as an informal term persists in these countries to a varying degree, scales and measuring devices are denominated only in grams and kilograms. A pound of product must be determined by weighing the product in grams as the use of the pound is not sanctioned for trade within the European Union.\n\n\n== Use in weaponry ==\nSmoothbore cannon and carronades are designated by the weight in imperial pounds of round solid iron shot of diameter to fit the barrel. A cannon that fires a six-pound ball, for example, is called a six-pounder. Standard sizes are 6, 12, 18, 24, 32 and 42 pounds; 68-pounders also exist, and other nonstandard weapons use the same scheme. See carronade.\nA similar definition, using lead balls, exists for determining the gauge of shotguns.\n\n\n== See also ==\nPound-force\n\n\n== Notes ==\n\n\n== External links ==\n\n\n=== Conversion between units ===\nU.S. National Institute of Standards and Technology Special Publication 811\nNational Institute of Standards and Technology Handbook 130",
        "unit": "pound-mass",
        "url": "https://en.wikipedia.org/wiki/Pound_(mass)"
    },
    {
        "_id": "Energy",
        "clean": "Energy",
        "text": "In physics, energy is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object.  Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton.\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.\nMass and energy are closely related. Due to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale.\nLiving organisms require available energy to stay alive, such as the energy humans get from food.  Human civilization requires energy to function, which it gets from  energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth.\n\n\n== FormsEdit ==\n\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object -- or the composite motion of the components of an object - and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may stored in the field itself.\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient refer to particular combinations of potential and kinetic energy as its own form. For example, macroscopic mechanical energy is the sum of translational and rotational kinetic and potential energy in a system neglects the kinetic energy due to temperature, and nuclear energy which combines utilize potentials from the nuclear force and the weak force), among others.\n\n\n== HistoryEdit ==\n\nThe word energy derives from the Ancient Greek: \u1f10\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1, translit. energeia, lit. 'activity, operation', which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\nIn the late 17th century, Gottfried Leibniz proposed the idea of the Latin: vis viva, or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total vis viva was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the random motion of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from vis viva only by a factor of two.\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of vis viva, in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\n\n\n== Units of measureEdit ==\n\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\nIn the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second.  Thus, one joule is one watt-second, and 3600 joules equal one watt-hour.  The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\n\n\n== Scientific useEdit ==\n\n\n=== Classical mechanicsEdit ===\n\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\nWork, a function of energy, is force times distance.\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle W=\\int _{C}\\mathbf {F} \\cdot \\mathrm {d} \\mathbf {s} }\n  This says that the work (\n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  ) is equal to the line integral of the force F along a path C; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy minus the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\n\n\n=== ChemistryEdit ===\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor e\u2212E/kT \u2013 that is the probability of molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation.The activation energy necessary for a chemical reaction can be in the form of thermal energy.\n\n\n=== BiologyEdit ===\n\nIn biology, energy is an attribute of all biological systems from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or an organelle of a biological organism. Energy is thus often said to be stored by cells in the structures of molecules of substances such as carbohydrates (including sugars), lipids, and proteins, which release energy when reacted with oxygen in respiration. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, assuming an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.Sunlight's radiant energy is also captured by plants as chemical potential energy in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into the high-energy compounds carbohydrates, lipids, and proteins. Plants also release oxygen during photosynthesis, which is utilized by living organisms as an electron acceptor, to release the energy of carbohydrates, lipids, and proteins. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark, in a forest fire, or it may be made available more slowly for animal or human metabolism, when these molecules are ingested, and catabolism is triggered by enzyme action.\nAny living organism relies on an external source of energy\u2014radiant energy from the Sun in the case of green plants, chemical energy in some form in the case of animals\u2014to be able to grow and reproduce. The daily 1500\u20132000 Calories (6\u20138 MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidised to carbon dioxide and water in the mitochondria\n\n  \n    \n      \n        \n          \n            C\n            \n              6\n            \n            \n              \n            \n          \n          \n            H\n            \n              12\n            \n            \n              \n            \n          \n          \n            O\n            \n              6\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            O\n            \n              2\n            \n            \n              \n            \n          \n          \u27f6\n          6\n          \n          \n            CO\n            \n              2\n            \n            \n              \n            \n          \n          +\n          6\n          \n          \n            H\n            \n              2\n            \n            \n              \n            \n          \n          O\n        \n      \n    \n    {\\displaystyle {\\ce {C6H12O6 + 6O2 -> 6CO2 + 6H2O}}}\n  \nC57H110O6 + 81.5O2 \u2192 57CO2 + 55H2Oand some of the energy is used to convert ADP into ATP.\n\nADP + HPO42\u2212 \u2192 ATP + H2OThe rest of the chemical energy in O2 and the carbohydrate or fat is converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100 m race: 4 kJ\ngain in gravitational potential energy of a 150 kg weight lifted through 2 metres: 3 kJ\nDaily food intake of a normal adult: 6\u20138 MJIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy), and it is true that most real machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology: to take just the first step in the food chain, of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\n\n\n=== Earth sciencesEdit ===\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations brought about by solar energy on the atmosphere of the planet Earth.\nSunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives many weather phenomena, save those generated by volcanic events. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement.\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may be later released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars created these atoms.\n\n\n=== CosmologyEdit ===\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\n\n\n=== Quantum mechanicsEdit ===\n\nIn quantum mechanics, energy is defined in terms of the energy operator\nas a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: \n  \n    \n      \n        E\n        =\n        h\n        \u03bd\n      \n    \n    {\\displaystyle E=h\\nu }\n   (where \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is Planck's constant and \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\n\n\n=== RelativityEdit ===\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{0}=mc^{2}}\n  ,where\n\nm is the mass of the body,\nc is the speed of light in vacuum,\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is the rest energy.For example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles.  This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.Energy and mass are manifestations of one and the same underlying physical property of a system.  This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of space-time (= boosts).\n\n\n== TransformationEdit ==\n\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery, from chemical energy to electric energy; a dam: gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator; or a heat engine, from heat to work.\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\nEnergy transformations in the universe over time are characterized by various kinds of potential energy that has been available since the Big Bang later being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nuclear decay, in which energy is released that was originally \"stored\" in heavy isotopes (such as uranium and thorium), by nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae, to store energy in the creation of these heavy elements before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic energy and thermal energy in a very short time. Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at maximum. At its lowest point the kinetic energy is at maximum and is equal to the decrease of potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\nEnergy is also transferred from potential energy (\n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle E_{p}}\n  ) to kinetic energy (\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n  ) and then back to potential energy constantly. This is referred to as conservation of energy. In this closed system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\n\nThe equation can then be simplified further since \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        =\n        m\n        g\n        h\n      \n    \n    {\\displaystyle E_{p}=mgh}\n   (mass times acceleration due to gravity times the height) and \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{k}={\\frac {1}{2}}mv^{2}}\n   (half mass times velocity squared). Then the total amount of energy can be found by adding \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        +\n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            t\n            o\n            t\n            a\n            l\n          \n        \n      \n    \n    {\\displaystyle E_{p}+E_{k}=E_{total}}\n  .\n\n\n=== Conservation of energy and mass in transformationEdit ===\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula E = mc\u00b2, derived by Albert Einstein (1905) quantifies the relationship between rest-mass and rest-energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J. J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass-energy equivalence#History for further information).\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since \n  \n    \n      \n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle c^{2}}\n   is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~\n  \n    \n      \n        9\n        \u00d7\n        \n          10\n          \n            16\n          \n        \n      \n    \n    {\\displaystyle 9\\times 10^{16}}\n   joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics.\n\n\n=== Reversible and non-reversible transformationsEdit ===\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).\nAs the universe evolves in time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or other kinds of increases in disorder). This has been referred to as the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), grows less and less.\n\n\n== Conservation of energyEdit ==\n\nThe fact that energy can be neither created nor be destroyed is called the law of conservation of energy.  In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out by work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\nRichard Feynman said during a 1961 lecture:\nThere is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law\u2014it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same.\n\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle - it is impossible to define the exact amount of energy during any definite time interval. The uncertainty principle should not be confused with energy conservation - rather it provides mathematical limits to which energy can in principle be defined and measured.\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appears as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n\n  \n    \n      \n        \u0394\n        E\n        \u0394\n        t\n        \u2265\n        \n          \n            \u210f\n            2\n          \n        \n      \n    \n    {\\displaystyle \\Delta E\\Delta t\\geq {\\frac {\\hbar }{2}}}\n  which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since H and t are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\nIn particle physics, this inequality permits a qualitative understanding of virtual particles which carry momentum, exchange by which and with real particles, is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons (which are simply lowest quantum mechanical energy state of photons) are also responsible for electrostatic interaction between electric charges (which results in Coulomb law), for spontaneous radiative decay of exited atomic and nuclear states, for the Casimir force, for van der Waals bond forces and some other observable phenomena.\n\n\n== Energy transferEdit ==\n\n\n=== Closed systemsEdit ===\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\n\nwhere \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the amount of energy transferred, \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n    represents the work done on the system, and \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   represents the heat flow into the system. As a simplification, the heat term, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , is sometimes ignored, especially when the thermal efficiency of the transfer is high.\n\nThis simplified equation is the one used to define the joule, for example.\n\n\n=== Open systemsEdit ===\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (both of these process are illustrated by fueling an auto, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , one may write\n\n\n== ThermodynamicsEdit ==\n\n\n=== Internal energyEdit ===\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\n\n\n=== First law of thermodynamicsEdit ===\nThe first law of thermodynamics asserts that energy (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a gain in energy signified by a positive quantity) is given as\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        T\n        \n          d\n        \n        S\n        \u2212\n        P\n        \n          d\n        \n        V\n        \n      \n    \n    {\\displaystyle \\mathrm {d} E=T\\mathrm {d} S-P\\mathrm {d} V\\,}\n  ,where the first term on the right is the heat transferred into the system, expressed in terms of temperature T and entropy S (in which entropy increases and the change dS is positive when the system is heated), and the last term on the right hand side is identified as work done on the system, where pressure is P and volume V (the negative sign results since compression of the system requires work to be done on it and so the volume change, dV, is negative when work is done on the system).\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and pV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a closed system is expressed in a general form by\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        \u03b4\n        Q\n        +\n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\mathrm {d} E=\\delta Q+\\delta W}\n  where \n  \n    \n      \n        \u03b4\n        Q\n      \n    \n    {\\displaystyle \\delta Q}\n   is the heat supplied to the system and \n  \n    \n      \n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\delta W}\n   is the work applied to the system.\n\n\n=== Equipartition of energyEdit ===\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternatively kinetic and potential. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over the whole cycle, or over many cycles, net energy is thus equally split between kinetic and potential. This is called equipartition principle; total energy of a system with many degrees of freedom is equally split among all available degrees of freedom.\nThis principle is vitally important to understanding the behaviour of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is called the second law of thermodynamics. The second law of thermodynamics is valid only for systems which are near or in equilibrium state. For non-equilibrium systems, the laws governing system\u2019s behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way to maximize its entropy production.\n\n\n== See alsoEdit ==\n\nCombustion\nIndex of energy articles\nIndex of wave articles\nOrders of magnitude (energy)\nPower station\nTransfer energy\n\n\n== NotesEdit ==\n\n\n== ReferencesEdit ==\n\n\n== Further readingEdit ==\n\n\n== External linksEdit ==\n\nEnergy at Curlie (based on DMOZ)\nDifferences between Heat and Thermal energy - BioCab",
        "unit": "energy",
        "url": "https://en.wikipedia.org/wiki/Energy"
    },
    {
        "_id": "Magnetic_field",
        "clean": "Magnetic field",
        "text": "A magnetic field is a vector field that describes the magnetic influence of electrical currents and magnetized materials. In everyday life, the effects of magnetic fields are most readily encountered with nearby permanent magnets, which pull on magnetic materials (such as iron) and attract or repel other magnets. Magnetic fields surround and are created by magnetized material and by moving electric charges (electric currents) such as those used in electromagnets. Magnetic fields exert forces on nearby moving electrical charges and torques on nearby magnets. In addition, a magnetic field that varies with location exerts a force on magnetic materials. Both the strength and direction of a magnetic field varies with location. As such, it is an example of a vector field.\nThe term 'magnetic field' is used for two distinct but closely related fields denoted by the symbols B and H. In the International System of Units, H is measured in units of amperes per meter and B is measured in teslas or newtons per meter per ampere.  H and B differ in how they account for magnetization. In a vacuum, B and H are the same aside from units; but in a magnetized material, B/\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   and H differ by the magnetization M of the material at that point in the material.\nMagnetic fields are produced by moving electric charges and the intrinsic magnetic moments of elementary particles associated with a fundamental quantum property, their spin. Magnetic fields and electric fields are interrelated, and are both components of the electromagnetic force, one of the four fundamental forces of nature.\nMagnetic fields are widely used throughout modern technology, particularly in electrical engineering and electromechanics. Rotating magnetic fields are used in both electric motors and generators. The interaction of magnetic fields in electric devices such as transformers is studied in the discipline of magnetic circuits. Magnetic forces give information about the charge carriers in a material through the Hall effect. The Earth produces its own magnetic field, which shields the Earth's ozone layer from the solar wind and is important in navigation using a compass.\n\n\n== History ==\n\nAlthough magnets and magnetism were studied much earlier, the research of magnetic fields began in 1269 when French scholar Petrus Peregrinus de Maricourt mapped out the magnetic field on the surface of a spherical magnet using iron needles. Noting that the resulting field lines crossed at two points he named those points 'poles' in analogy to Earth's poles. He also clearly articulated the principle that magnets always have both a north and south pole, no matter how finely one slices them.\nAlmost three centuries later, William Gilbert of Colchester replicated Petrus Peregrinus' work and was the first to state explicitly that Earth is a magnet. Published in 1600, Gilbert's work, De Magnete, helped to establish magnetism as a science.\nIn 1750, John Michell stated that magnetic poles attract and repel in accordance with an inverse square law. Charles-Augustin de Coulomb experimentally verified this in 1785 and stated explicitly that the north and south poles cannot be separated. Building on this force between poles, Sim\u00e9on Denis Poisson (1781\u20131840) created the first successful model of the magnetic field, which he presented in 1824. In this model, a magnetic H-field is produced by 'magnetic poles' and magnetism is due to small pairs of north/south magnetic poles.\n\nThree discoveries challenged this foundation of magnetism, though. First, in 1819, Hans Christian \u00d8rsted discovered that an electric current generates a magnetic field encircling it. Then in 1820, Andr\u00e9-Marie Amp\u00e8re showed that parallel wires with currents attract one another if the currents are in the same direction and repel if they are in opposite directions. Finally, Jean-Baptiste Biot and F\u00e9lix Savart discovered the Biot\u2013Savart law in 1820, which correctly predicts the magnetic field around any current-carrying wire.\nExtending these experiments, Amp\u00e8re published his own successful model of magnetism in 1825. In it, he showed the equivalence of electrical currents to magnets and proposed that magnetism is due to perpetually flowing loops of current instead of the dipoles of magnetic charge in Poisson's model. This has the additional benefit of explaining why magnetic charge can not be isolated. Further, Amp\u00e8re derived both Amp\u00e8re's force law describing the force between two currents and Amp\u00e8re's law, which, like the Biot\u2013Savart law, correctly described the magnetic field generated by a steady current. Also in this work, Amp\u00e8re introduced the term electrodynamics to describe the relationship between electricity and magnetism.\nIn 1831, Michael Faraday discovered electromagnetic induction when he found that a changing magnetic field generates an encircling electric field. He described this phenomenon in what is known as Faraday's law of induction. Later, Franz Ernst Neumann proved that, for a moving conductor in a magnetic field, induction is a consequence of Amp\u00e8re's force law. In the process, he introduced the magnetic vector potential, which was later shown to be equivalent to the underlying mechanism proposed by Faraday.\nIn 1850, Lord Kelvin, then known as William Thomson, distinguished between two magnetic fields now denoted H and B. The former applied to Poisson's model and the latter to Amp\u00e8re's model and induction. Further, he derived how H and B relate to each other.\nThe reason H and B are used for the two magnetic fields has been a source of some debate among science historians. Most agree that Kelvin avoided M to prevent confusion with the SI fundamental unit of length, the Metre, abbreviated \"m\". Others believe the choices were purely random.Between 1861 and 1865, James Clerk Maxwell developed and published Maxwell's equations, which explained and united all of classical electricity and magnetism. The first set of these equations was published in a paper entitled On Physical Lines of Force in 1861. These equations were valid although incomplete. Maxwell completed his set of equations in his later 1865 paper A Dynamical Theory of the Electromagnetic Field and demonstrated the fact that light is an electromagnetic wave. Heinrich Hertz experimentally confirmed this fact in 1887.\nThe twentieth century extended electrodynamics to include relativity and quantum mechanics. Albert Einstein, in his paper of 1905 that established relativity, showed that both the electric and magnetic fields are part of the same phenomena viewed from different reference frames. (See moving magnet and conductor problem for details about the thought experiment that eventually helped Albert Einstein to develop special relativity.) Finally, the emergent field of quantum mechanics was merged with electrodynamics to form quantum electrodynamics (QED).\n\n\n== Definitions, units and measurement ==\n\n\n=== The B-field ===\nThe magnetic field can be defined in several equivalent ways based on the effects it has on its environment.\nOften the magnetic field is defined by the force it exerts on a moving charged particle. It is known from experiments in electrostatics that a particle of charge q in an electric field E experiences a force F = qE. However, in other situations, such as when a charged particle moves in the vicinity of a current-carrying wire, the force also depends on the velocity of that particle. Fortunately, the velocity dependent portion can be separated out such that the force on the particle satisfies the Lorentz force law,\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        (\n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {F} =q(\\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} ).}\n  Here v is the particle's velocity and \u00d7 denotes the cross product. The vector B is termed the magnetic field, and it is defined as the vector field necessary to make the Lorentz force law correctly describe the motion of a charged particle. This definition allows the determination of B in the following way\n[T]he command, \"Measure the direction and magnitude of the vector B at such and such a place,\" calls for the following operations: Take a particle of known charge q. Measure the force on q at rest, to determine E. Then measure the force on the particle when its velocity is v; repeat with v in some other direction. Now find a B that makes the Lorentz force law fit all these results\u2014that is the magnetic field at the place in question.\n\nAlternatively, the magnetic field can be defined in terms of the torque it produces on a magnetic dipole (see magnetic torque on permanent magnets below).\n\n\n=== The H-field ===\nIn addition to B, there is a quantity H, which is often called the magnetic field. In a vacuum, B and H are proportional to each other, with the multiplicative constant depending on the physical units. Inside a material they are different (see H and B inside and outside magnetic materials). The term \"magnetic field\" is historically reserved for H while using other terms for B. Informally, though, and formally for some recent textbooks mostly in physics, the term 'magnetic field' is used to describe B as well as or in place of H.\nThere are many alternative names for both (see sidebar).\n\n\n=== Units ===\nIn SI units, B is measured in teslas (symbol: T) and correspondingly \u03a6B (magnetic flux) is measured in webers (symbol: Wb) so that a flux density of 1 Wb/m2 is 1 tesla. The SI unit of tesla is equivalent to (newton\u00b7second)/(coulomb\u00b7metre). In Gaussian-cgs units, B is measured in gauss (symbol: G). (The conversion is 1 T = 10000 G.) One nanotesla is equivalent to 1 gamma (symbol: \u03b3). The H-field is measured in amperes per metre (A/m) in SI units, and in oersteds (Oe) in cgs units.\n\n\n=== Measurement ===\nThe precision attained for a magnetic field measurement for Gravity Probe B experiment is 5 attoteslas (5\u00d710\u221218 T); the largest magnetic field produced in a laboratory is 2.8 kT (VNIIEF in Sarov, Russia, 1998). The magnetic field of some astronomical objects such as magnetars are much higher; magnetars range from 0.1 to 100 GT (108 to 1011 T).  See orders of magnitude (magnetic field).\nDevices used to measure the local magnetic field are called magnetometers. Important classes of magnetometers include using induction magnetometer (or search-coil magnetometer) which measure only varying magnetic field, rotating coil magnetometer, Hall effect magnetometers, NMR magnetometers, SQUID magnetometers, and fluxgate magnetometers. The magnetic fields of distant astronomical objects are measured through their effects on local charged particles. For instance, electrons spiraling around a field line produce synchrotron radiation that is detectable in radio waves.\n\n\n== Magnetic field lines ==\n\nMapping the magnetic field of an object is simple in principle. First, measure the strength and direction of the magnetic field at a large number of locations (or at every point in space). Then, mark each location with an arrow (called a vector) pointing in the direction of the local magnetic field with its magnitude proportional to the strength of the magnetic field.\nAn alternative method to map the magnetic field is to 'connect' the arrows to form magnetic field lines. The direction of the magnetic field at any point is parallel to the direction of nearby field lines, and the local density of field lines can be made proportional to its strength. Magnetic field lines are like streamlines in fluid flow, in that they represent something continuous, and a different resolution would show more or fewer lines.\nAn advantage of using magnetic field lines as a representation is that many laws of magnetism (and electromagnetism) can be stated completely and concisely using simple concepts such as the 'number' of field lines through a surface. These concepts can be quickly 'translated' to their mathematical form. For example, the number of field lines through a given surface is the surface integral of the magnetic field.\nVarious phenomena have the effect of \"displaying\" magnetic field lines as though the field lines were physical phenomena. For example, iron filings placed in a magnetic field, form lines that correspond to 'field lines'. Magnetic field \"lines\" are also visually displayed in polar auroras, in which plasma particle dipole interactions create visible streaks of light that line up with the local direction of Earth's magnetic field.\nField lines can be used as a qualitative tool to visualize magnetic forces. In ferromagnetic substances like iron and in plasmas, magnetic forces can be understood by imagining that the field lines exert a tension, (like a rubber band) along their length, and a pressure perpendicular to their length on neighboring field lines.  'Unlike' poles of magnets attract because they are linked by many field lines; 'like' poles repel because their field lines do not meet, but run parallel, pushing on each other. The rigorous form of this concept is the electromagnetic stress\u2013energy tensor.\n\n\n== Magnetic field and permanent magnets ==\n\nPermanent magnets are objects that produce their own persistent magnetic fields. They are made of ferromagnetic materials, such as iron and nickel, that have been magnetized, and they have both a north and a south pole.\n\n\n=== Magnetic field of permanent magnets ===\n\nThe magnetic field of permanent magnets can be quite complicated, especially near the magnet. The magnetic field of a small straight magnet is proportional to the magnet's strength (called its magnetic dipole moment m). The equations are non-trivial and also depend on the distance from the magnet and the orientation of the magnet. For simple magnets, m points in the direction of a line drawn from the south to the north pole of the magnet. Flipping a bar magnet is equivalent to rotating its m by 180 degrees.\nThe magnetic field of larger magnets can be obtained by modeling them as a collection of a large number of small magnets called dipoles each having their own m. The magnetic field produced by the magnet then is the net magnetic field of these dipoles. And, any net force on the magnet is a result of adding up the forces on the individual dipoles.\nThere are two competing models for the nature of these dipoles. These two models produce two different magnetic fields, H and B. Outside a material, though, the two are identical (to a multiplicative constant) so that in many cases the distinction can be ignored. This is particularly true for magnetic fields, such as those due to electric currents, that are not generated by magnetic materials.\n\n\n=== Magnetic pole model and the H-field ===\n\nIt is sometimes useful to model the force and torques between two magnets as due to magnetic poles repelling or attracting each other in the same manner as the Coulomb force between electric charges. This is called the Gilbert model of magnetism, after William Gilbert. In this model, a magnetic H-field is produced by magnetic charges that are 'smeared' around each pole. These magnetic charges are in fact related to the magnetization field M.\nThe H-field, therefore, is analogous to the electric field E, which starts at a positive electric charge and ends at a negative electric charge. Near the north pole, therefore, all H-field lines point away from the north pole (whether inside the magnet or out) while near the south pole all H-field lines point toward the south pole (whether inside the magnet or out). Too, a north pole feels a force in the direction of the H-field while the force on the south pole is opposite to the H-field.\nIn the magnetic pole model, the elementary magnetic dipole m is formed by two opposite magnetic poles of pole strength qm separated by a small distance vector d, such that m = qm\u2009d. The magnetic pole model predicts correctly the field H both inside and outside magnetic materials, in particular the fact that  H is opposite to the magnetization field M inside a permanent magnet.\nSince it is based on the fictitious idea of a magnetic charge density, the Gilbert model has limitations. Magnetic poles cannot exist apart from each other as electric charges can, but always come in north/south pairs. If a magnetized object is divided in half, a new pole appears on the surface of each piece, so each has a pair of complementary poles. The magnetic pole model does not account for magnetism that is produced by electric currents.\n\n\n=== Amperian loop model and the B-field ===\n\nAfter \u00d8rsted discovered that electric currents produce a magnetic field and Ampere discovered that electric currents attracted and repelled each other similar to magnets, it was natural to hypothesize that all magnetic fields are due to electric current loops. In this model developed by Ampere, the elementary magnetic dipole that makes up all magnets is a sufficiently small Amperian loop of current I. The dipole moment of this loop is m = IA where A is the area of the loop.\nThese magnetic dipoles produce a magnetic B-field. One important property of the B-field produced this way is that magnetic B-field lines neither start nor end (mathematically, B is a solenoidal vector field); a field line either extends to infinity or wraps around to form a closed curve. To date, no exception to this rule has been found. (See magnetic monopole below.) Magnetic field lines exit a magnet near its north pole and enter near its south pole, but inside the magnet B-field lines continue through the magnet from the south pole back to the north. If a B-field line enters a magnet somewhere it has to leave somewhere else; it is not allowed to have an end point. Magnetic poles, therefore, always come in N and S pairs.\nMore formally, since all the magnetic field lines that enter any given region must also leave that region, subtracting the 'number' of field lines that enter the region from the number that exit gives identically zero. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} =0,}\n  where the integral is a surface integral over the closed surface S (a closed surface is one that completely surrounds a region with no holes to let any field lines escape). Since dA points outward, the dot product in the integral is positive for B-field pointing out and negative for B-field pointing in.\nThere is also a corresponding differential form of this equation covered in Maxwell's equations below.\n\n\n=== Force between magnets ===\n\nThe force between two small magnets is quite complicated and depends on the strength and orientation of both magnets and the distance and direction of the magnets relative to each other. The force is particularly sensitive to rotations of the magnets due to magnetic torque. The force on each magnet depends on its magnetic moment and the magnetic field of the other.\nTo understand the force between magnets, it is useful to examine the magnetic pole model given above. In this model, the H-field of one magnet pushes and pulls on both poles of a second magnet. If this H-field is the same at both poles of the second magnet then there is no net force on that magnet since the force is opposite for opposite poles. If, however, the magnetic field of the first magnet is nonuniform (such as the H near one of its poles), each pole of the second magnet sees a different field and is subject to a different force. This difference in the two forces moves the magnet in the direction of increasing magnetic field and may also cause a net torque.\nThis is a specific example of a general rule that magnets are attracted (or repulsed depending on the orientation of the magnet) into regions of higher magnetic field. Any non-uniform magnetic field, whether caused by permanent magnets or electric currents, exerts a force on a small magnet in this way.\nThe details of the Amperian loop model are different and more complicated but yield the same result: that magnetic dipoles are attracted/repelled into regions of higher magnetic field.\nMathematically, the force on a small magnet having a magnetic moment m due to a magnetic field B is:\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \u2207\n        \n        \n          (\n          \n            \n              m\n            \n            \u22c5\n            \n              B\n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =\\mathbf {\\nabla } \\left(\\mathbf {m} \\cdot \\mathbf {B} \\right),}\n  where the gradient \u2207 is the change of the quantity m \u00b7 B per unit distance and the direction is that of maximum increase of m \u00b7 B. To understand this equation, note that the dot product m \u00b7 B = mBcos(\u03b8), where m and B represent the magnitude of the m and B vectors and \u03b8 is the angle between them. If m is in the same direction as B then the dot product is positive and the gradient points 'uphill' pulling the magnet into regions of higher B-field (more strictly larger m \u00b7 B). This equation is strictly only valid for magnets of zero size, but is often a good approximation for not too large magnets. The magnetic force on larger magnets is determined by dividing them into smaller regions each having their own m then summing up the forces on each of these very small regions.\n\n\n=== Magnetic torque on permanent magnets ===\n\nIf two like poles of two separate magnets are brought near each other, and one of the magnets is allowed to turn, it promptly rotates to align itself with the first. In this example, the magnetic field of the stationary magnet creates a magnetic torque on the magnet that is free to rotate. This magnetic torque \u03c4 tends to align a magnet's poles with the magnetic field lines. A compass, therefore, turns to align itself with Earth's magnetic field.\nMagnetic torque is used to drive electric motors. In one simple motor design, a magnet is fixed to a freely rotating shaft and subjected to a magnetic field from an array of electromagnets. By continuously switching the electric current through each of the electromagnets, thereby flipping the polarity of their magnetic fields, like poles are kept next to the rotor; the resultant torque is transferred to the shaft. See Rotating magnetic fields below.\n\nAs is the case for the force between magnets, the magnetic pole model leads more readily to the correct equation. Here, two equal and opposite magnetic charges experiencing the same H also experience equal and opposite forces. Since these equal and opposite forces are in different locations, this produces a torque proportional to the distance (perpendicular to the force) between them. With the definition of m as the pole strength times the distance between the poles, this leads to \u03c4 = \u03bc0mHsin\u03b8, where \u03bc0 is a constant called the vacuum permeability, measuring 4\u03c0\u00d710\u22127 V\u00b7s/(A\u00b7m) and \u03b8 is the angle between H and m.\nThe Amperian loop model also predicts the same magnetic torque. Here, it is the B field interacting with the Amperian current loop through a Lorentz force described below. Again, the results are the same although the models are completely different.\n\nMathematically, the torque \u03c4 on a small magnet is proportional both to the applied magnetic field and to the magnetic moment m of the magnet:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          m\n        \n        \u00d7\n        \n          B\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          m\n        \n        \u00d7\n        \n          H\n        \n        ,\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {m} \\times \\mathbf {B} =\\mu _{0}\\mathbf {m} \\times \\mathbf {H} ,\\,}\n  where \u00d7 represents the vector cross product. Note that this equation includes all of the qualitative information included above. There is no torque on a magnet if m is in the same direction as the magnetic field. (The cross product is zero for two vectors that are in the same direction.) Further, all other orientations feel a torque that twists them toward the direction of magnetic field.\n\n\n== Magnetic field and electric currents ==\nCurrents of electric charges both generate a magnetic field and feel a force due to magnetic B-fields.\n\n\n=== Magnetic field due to moving charges and electric currents ===\n\nAll moving charged particles produce magnetic fields. Moving point charges, such as electrons, produce complicated but well known magnetic fields that depend on the charge, velocity, and acceleration of the particles.Magnetic field lines form in concentric circles around a cylindrical current-carrying conductor, such as a length of wire. The direction of such a magnetic field can be determined by using the \"right hand grip rule\" (see figure at right). The strength of the magnetic field decreases with distance from the wire. (For an infinite length wire the strength is inversely proportional to the distance.)\n\nBending a current-carrying wire into a loop concentrates the magnetic field inside the loop while weakening it outside. Bending a wire into multiple closely spaced loops to form a coil or \"solenoid\" enhances this effect. A device so formed around an iron core may act as an electromagnet, generating a strong, well-controlled magnetic field. An infinitely long cylindrical electromagnet has a uniform magnetic field inside, and no magnetic field outside. A finite length electromagnet produces a magnetic field that looks similar to that produced by a uniform permanent magnet, with its strength and polarity determined by the current flowing through the coil.\nThe magnetic field generated by a steady current I (a constant flow of electric charges, in which charge neither accumulates nor is depleted at any point) is described by the Biot\u2013Savart law:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \n          \u222b\n          \n            \n              w\n              i\n              r\n              e\n            \n          \n        \n        \n          \n            \n              \n                d\n              \n              \n                \u2113\n              \n              \u00d7\n              \n                \n                  \n                    r\n                    ^\n                  \n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{4\\pi }}\\int _{\\mathrm {wire} }{\\frac {\\mathrm {d} {\\boldsymbol {\\ell }}\\times \\mathbf {\\hat {r}} }{r^{2}}},}\n  where the integral sums over the wire length where vector d\u2113 is the vector line element with direction in the same sense as the current I, \u03bc0 is the magnetic constant, r is the distance between the location of d\u2113 and the location where the magnetic field is calculated, and r\u0302 is a unit vector in the direction of r.  In the case of a sufficiently long wire, this becomes:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              I\n            \n            \n              2\n              \u03c0\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B} ={\\frac {\\mu _{0}I}{2\\pi r}}}\n  where r is the distance from the wire.A slightly more general way of relating the current \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n   to the B-field is through Amp\u00e8re's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          I\n          \n            \n              e\n              n\n              c\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {B} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\mu _{0}I_{\\mathrm {enc} },}\n  where the line integral is over any arbitrary loop and \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle {I}}\n  enc is the current enclosed by that loop. Amp\u00e8re's law is always valid for steady currents and can be used to calculate the B-field for certain highly symmetric situations such as an infinite wire or an infinite solenoid.\nIn a modified form that accounts for time varying electric fields, Amp\u00e8re's law is one of four Maxwell's equations that describe electricity and magnetism.\n\n\n=== Force on moving charges and current ===\n\n\n==== Force on a charged particle ====\n\nA charged particle moving in a B-field experiences a sideways force that is proportional to the strength of the magnetic field, the component of the velocity that is perpendicular to the magnetic field and the charge of the particle. This force is known as the Lorentz force, and is given by\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        \n          E\n        \n        +\n        q\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =q\\mathbf {E} +q\\mathbf {v} \\times \\mathbf {B} ,}\n  where\nF is the force, q is the electric charge of the particle, v is the instantaneous velocity  of the particle, and B is the magnetic field (in teslas).\nThe Lorentz force is always perpendicular to both the velocity of the particle and the magnetic field that created it. When a charged particle moves in a static magnetic field, it traces a helical path in which the helix axis is parallel to the magnetic field, and in which the speed of the particle remains constant. Because the magnetic force is always perpendicular to the motion, the magnetic field can do no work on an isolated charge. It can only do work indirectly, via the electric field generated by a changing magnetic field. It is often claimed that the magnetic force can do work to a non-elementary magnetic dipole, or to charged particles whose motion is constrained by other forces, but this is incorrect because the work in those cases is performed by the electric forces of the charges deflected by the magnetic field.\n\n\n==== Force on current-carrying wire ====\n\nThe force on a current carrying wire is similar to that of a moving charge as expected since a current carrying wire is a collection of moving charges. A current-carrying wire feels a force in the presence of a magnetic field. The Lorentz force on a macroscopic current is often referred to as the Laplace force.\nConsider a conductor of length \u2113, cross section A, and charge q due to electric current i. If this conductor is placed in a magnetic field of magnitude B that makes an angle \u03b8 with the velocity of charges in the conductor, the force exerted on a single charge q is\n\n  \n    \n      \n        F\n        =\n        q\n        v\n        B\n        sin\n        \u2061\n        \u03b8\n        ,\n      \n    \n    {\\displaystyle F=qvB\\sin \\theta ,}\n  so, for N charges where \n\n  \n    \n      \n        N\n        =\n        n\n        \u2113\n        A\n      \n    \n    {\\displaystyle N=n\\ell A}\n  ,the force exerted on the conductor is\n\n  \n    \n      \n        f\n        =\n        F\n        N\n        =\n        q\n        v\n        B\n        n\n        \u2113\n        A\n        sin\n        \u2061\n        \u03b8\n        =\n        B\n        i\n        \u2113\n        sin\n        \u2061\n        \u03b8\n      \n    \n    {\\displaystyle f=FN=qvBn\\ell A\\sin \\theta =Bi\\ell \\sin \\theta }\n  ,where i = nqvA.\n\n\n==== Direction of force ====\n\nThe direction of force on a charge or a current can be determined by a mnemonic known as the right-hand rule (see the figure). Using the right hand, pointing the thumb in the direction of the current, and the fingers in the direction of the magnetic field, the resulting force on the charge points outwards from the palm. The force on a negatively charged particle is in the opposite direction. If both the speed and the charge are reversed then the direction of the force remains the same. For that reason a magnetic field measurement (by itself) cannot distinguish whether there is a positive charge moving to the right or a negative charge moving to the left. (Both of these cases produce the same current.)  On the other hand, a magnetic field combined with an electric field can distinguish between these, see Hall effect below.\nAn alternative mnemonic to the right hand rule is Flemings's left hand rule.\n\n\n== Relation between H and B ==\nThe formulas derived for the magnetic field above are correct when dealing with the entire current. A magnetic material placed inside a magnetic field, though, generates its own bound current, which can be a challenge to calculate.  (This bound current is due to the sum of atomic sized current loops and the spin of the subatomic particles such as electrons that make up the material.)  The H-field as defined above helps factor out this bound current; but to see how, it helps to introduce the concept of magnetization first.\n\n\n=== Magnetization ===\n\nThe magnetization vector field M represents how strongly a region of material is magnetized. It is defined as the net magnetic dipole moment per unit volume of that region. The magnetization of a uniform magnet is therefore a material constant, equal to the magnetic moment m of the magnet divided by its volume. Since the SI unit of magnetic moment is A\u22c5m2, the SI unit of magnetization M is ampere per meter, identical to that of the H-field.\nThe magnetization M field of a region points in the direction of the average magnetic dipole moment in that region. Magnetization field lines, therefore, begin near the magnetic south pole and ends near the magnetic north pole. (Magnetization does not exist outside the magnet.)\nIn the Amperian loop model, the magnetization is due to combining many tiny Amperian loops to form a resultant current called bound current. This bound current, then, is the source of the magnetic B field due to the magnet. (See Magnetic dipoles below and magnetic poles vs. atomic currents for more information.) Given the definition of the magnetic dipole, the magnetization field follows a similar law to that of Ampere's law:\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              b\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {M} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {b} },}\n  where the integral is a line integral over any closed loop and Ib is the 'bound current' enclosed by that closed loop.\nIn the magnetic pole model, magnetization begins at and ends at magnetic poles. If a given region, therefore, has a net positive 'magnetic pole strength' (corresponding to a north pole) then it has more magnetization field lines entering it than leaving it. Mathematically this is equivalent to:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {M} \\cdot \\mathrm {d} \\mathbf {A} =-q_{\\mathrm {M} }}\n  ,where the integral is a closed surface integral over the closed surface S and qM is the 'magnetic charge' (in units of magnetic flux) enclosed by S. (A closed surface completely surrounds a region with no holes to let any field lines escape.) The negative sign occurs because the magnetization field moves from south to north.\n\n\n=== H-field and magnetic materials ===\n\nIn SI units, the H-field is related to the B-field by\n\n  \n    \n      \n        \n          H\n        \n         \n        \u2261\n         \n        \n          \n            \n              B\n            \n            \n              \u03bc\n              \n                0\n              \n            \n          \n        \n        \u2212\n        \n          M\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {H} \\ \\equiv \\ {\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} .}\n  In terms of the H-field, Ampere's law is\n\n  \n    \n      \n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          \n            \n              \u222e\n              \n            \n          \n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \n                  B\n                \n                \n                  \u03bc\n                  \n                    0\n                  \n                \n              \n            \n            \u2212\n            \n              M\n            \n          \n          )\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        \n          I\n          \n            \n              t\n              o\n              t\n            \n          \n        \n        \u2212\n        \n          I\n          \n            \n              b\n            \n          \n        \n        =\n        \n          I\n          \n            \n              f\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=\\oint \\left({\\frac {\\mathbf {B} }{\\mu _{0}}}-\\mathbf {M} \\right)\\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=I_{\\mathrm {tot} }-I_{\\mathrm {b} }=I_{\\mathrm {f} },}\n  where If represents the 'free current' enclosed by the loop so that the line integral of H does not depend at all on the bound currents.For the differential equivalent of this equation see Maxwell's equations. Ampere's law leads to the boundary condition \n\n  \n    \n      \n        \n          (\n          \n            \n              \n                H\n                \n                  1\n                \n                \n                  \u2225\n                \n              \n            \n            \u2212\n            \n              \n                H\n                \n                  2\n                \n                \n                  \u2225\n                \n              \n            \n          \n          )\n        \n        =\n        \n          \n            K\n          \n          \n            \n              f\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\left(\\mathbf {H_{1}^{\\parallel }} -\\mathbf {H_{2}^{\\parallel }} \\right)=\\mathbf {K} _{\\mathrm {f} }\\times {\\hat {\\mathbf {n} }},}\n  where Kf is the surface free current density and the unit normal \n  \n    \n      \n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {n} }}}\n   points in the direction from medium 2 to medium 1.Similarly, a surface integral of H over any closed surface is independent of the free currents and picks out the \"magnetic charges\" within that closed surface:\n\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            S\n          \n        \n        \u2061\n        (\n        \n          B\n        \n        \u2212\n        \n          \u03bc\n          \n            0\n          \n        \n        \n          M\n        \n        )\n        \u22c5\n        \n          d\n        \n        \n          A\n        \n        =\n        0\n        \u2212\n        (\n        \u2212\n        \n          q\n          \n            \n              M\n            \n          \n        \n        )\n        =\n        \n          q\n          \n            \n              M\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\oint _{S}\\mu _{0}\\mathbf {H} \\cdot \\mathrm {d} \\mathbf {A} =\\oint _{S}(\\mathbf {B} -\\mu _{0}\\mathbf {M} )\\cdot \\mathrm {d} \\mathbf {A} =0-(-q_{\\mathrm {M} })=q_{\\mathrm {M} },}\n  which does not depend on the free currents.\nThe H-field, therefore, can be separated into two independent parts:\n\n  \n    \n      \n        \n          H\n        \n        =\n        \n          \n            H\n          \n          \n            0\n          \n        \n        +\n        \n          \n            H\n          \n          \n            \n              d\n            \n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle \\mathbf {H} =\\mathbf {H} _{0}+\\mathbf {H} _{\\mathrm {d} },\\,}\n  where H0 is the applied magnetic field due only to the free currents and Hd is the demagnetizing field due only to the bound currents.\nThe magnetic H-field, therefore, re-factors the bound current in terms of \"magnetic charges\". The H field lines loop only around 'free current' and, unlike the magnetic B field, begins and ends near magnetic poles as well.\n\n\n=== Magnetism ===\n\nMost materials respond to an applied B-field by producing their own magnetization M and therefore their own B-field. Typically, the response is weak and exists only when the magnetic field is applied. The term magnetism describes how materials respond on the microscopic level to an applied magnetic field and is used to categorize the magnetic phase of a material. Materials are divided into groups based upon their magnetic behavior:\n\nDiamagnetic materials produce a magnetization that opposes the magnetic field.\nParamagnetic materials produce a magnetization in the same direction as the applied magnetic field.\nFerromagnetic materials and the closely related ferrimagnetic materials and antiferromagnetic materials  can have a magnetization independent of an applied B-field with a complex relationship between the two fields.\nSuperconductors (and ferromagnetic superconductors) are materials that are characterized by perfect conductivity below a critical temperature and magnetic field. They also are highly magnetic and can be perfect diamagnets below a lower critical magnetic field. Superconductors often have a broad range of temperatures and magnetic fields (the so-named mixed state) under which they exhibit a complex hysteretic dependence of M on B.In the case of paramagnetism and diamagnetism, the magnetization M is often proportional to the applied magnetic field such that:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \u03bc\n        \n          H\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} =\\mu \\mathbf {H} ,}\n  where \u03bc is a material dependent parameter called the permeability. In some cases the permeability may be a second rank tensor so that H may not point in the same direction as B. These relations between B  and H are examples of constitutive equations. However, superconductors and ferromagnets have a more complex B to H relation; see magnetic hysteresis.\n\n\n== Energy stored in magnetic fields ==\n\nEnergy is needed to generate a magnetic field both to work against the electric field that a changing magnetic field creates and to change the magnetization of any material within the magnetic field. For non-dispersive materials, this same energy is released when the magnetic field is destroyed so that this energy can be modeled as being stored in the magnetic field.\nFor linear, non-dispersive, materials (such that B = \u03bcH where \u03bc is frequency-independent), the energy density is:\n\n  \n    \n      \n        u\n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              \n                B\n              \n              \u22c5\n              \n                B\n              \n            \n            \n              2\n              \u03bc\n            \n          \n        \n        =\n        \n          \n            \n              \u03bc\n              \n                H\n              \n              \u22c5\n              \n                H\n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle u={\\frac {\\mathbf {B} \\cdot \\mathbf {H} }{2}}={\\frac {\\mathbf {B} \\cdot \\mathbf {B} }{2\\mu }}={\\frac {\\mu \\mathbf {H} \\cdot \\mathbf {H} }{2}}.}\n  If there are no magnetic materials around then \u03bc can be replaced by \u03bc0. The above equation cannot be used for nonlinear materials, though; a more general expression given below must be used.\nIn general, the incremental amount of work per unit volume \u03b4W needed to cause a small change of magnetic field \u03b4B is:\n\n  \n    \n      \n        \u03b4\n        W\n        =\n        \n          H\n        \n        \u22c5\n        \u03b4\n        \n          B\n        \n        .\n      \n    \n    {\\displaystyle \\delta W=\\mathbf {H} \\cdot \\delta \\mathbf {B} .}\n  Once the relationship between H and B is known this equation is used to determine the work needed to reach a given magnetic state. For hysteretic materials such as ferromagnets and superconductors, the work needed also depends on how the magnetic field is created. For linear non-dispersive materials, though, the general equation leads directly to the simpler energy density equation given above.\n\n\n== Electromagnetism: the relationship between magnetic and electric fields ==\n\n\n=== Faraday's Law: Electric force due to a changing B-field ===\n\nA changing magnetic field, such as a magnet moving through a conducting coil, generates an electric field (and therefore tends to drive a current in such a coil). This is known as Faraday's law and forms the basis of many electrical generators and electric motors.\nMathematically, Faraday's law is:\n\n  \n    \n      \n        \n          \n            E\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              \u03a6\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\mathcal {E}}=-{\\frac {\\mathrm {d} \\Phi }{\\mathrm {d} t}},}\n  where \n  \n    \n      \n        \n          \n            \n              E\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\mathcal {E}}}\n   is the electromotive force (or EMF, the voltage generated around a closed loop) and \u03a6 is the magnetic flux\u2014the product of the area times the magnetic field normal to that area.  (This definition of magnetic flux is why B is often referred to as magnetic flux density.)The negative sign represents the fact that any current generated by a changing magnetic field in a coil produces a magnetic field that opposes the change in the magnetic field that induced it. This phenomenon is known as Lenz's law.\nThis integral formulation of Faraday's law can be converted into a differential form, which applies under slightly different conditions. This form is covered as one of Maxwell's equations below.\n\n\n=== Maxwell's correction to Amp\u00e8re's Law: The magnetic field due to a changing electric field ===\n\nSimilar to the way that a changing magnetic field generates an electric field, a changing electric field generates a magnetic field. This fact is known as Maxwell's correction to Amp\u00e8re's law and is applied as an additive term to Ampere's law as given above. This additional term is proportional to the time rate of change of the electric flux and is similar to Faraday's law above but with a different and positive constant out front. (The electric flux through an area is proportional to the area times the perpendicular part of the electric field.)\nThe full law including the correction term is known as the Maxwell\u2013Amp\u00e8re equation. It is not commonly given in integral form because the effect is so small that it can typically be ignored in most cases where the integral form is used.\nThe Maxwell term is critically important in the creation and propagation of electromagnetic waves. Maxwell's correction to Amp\u00e8re's Law together with Faraday's law of induction describes how mutually changing electric and magnetic fields interact to sustain each other and thus to form electromagnetic waves, such as light: a changing electric field generates a changing magnetic field, which generates a changing electric field again. These, though, are usually described using the differential form of this equation given below.\n\n\n=== Maxwell's equations ===\n\nLike all vector fields, a magnetic field has two important mathematical properties that relates it to its sources.  (For B the sources are currents and changing electric fields.) These two properties, along with the two corresponding properties of the electric field, make up Maxwell's Equations. Maxwell's Equations together with the Lorentz force law form a complete description of classical electrodynamics including both electricity and magnetism.\nThe first property is the divergence of a vector field A, \u2207 \u00b7 A, which represents how A 'flows' outward from a given point. As discussed above, a B-field line never starts or ends at a point but instead forms a complete loop. This is mathematically equivalent to saying that the divergence of B is zero. (Such vector fields are called solenoidal vector fields.) This property is called Gauss's law for magnetism and is equivalent to the statement that there are no isolated magnetic poles or magnetic monopoles. The electric field on the other hand begins and ends at electric charges so that its divergence is non-zero and proportional to the charge density (See Gauss's law).\nThe second mathematical property is called the curl, such that \u2207 \u00d7 A represents how A curls or 'circulates' around a given point. The result of the curl is called a 'circulation source'. The equations for the curl of B and of E are called the Amp\u00e8re\u2013Maxwell equation and Faraday's law respectively. They represent the differential forms of the integral equations given above.\nThe complete set of Maxwell's equations then are:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  E\n                \n              \n              \n                \n                =\n                \n                  \n                    \u03c1\n                    \n                      \u03b5\n                      \n                        0\n                      \n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  B\n                \n              \n              \n                \n                =\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  J\n                \n                +\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  \u03b5\n                  \n                    0\n                  \n                \n                \n                  \n                    \n                      \u2202\n                      \n                        E\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {E} &={\\frac {\\rho }{\\varepsilon _{0}}},\\\\\\nabla \\times \\mathbf {B} &=\\mu _{0}\\mathbf {J} +\\mu _{0}\\varepsilon _{0}{\\frac {\\partial \\mathbf {E} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}},\\end{aligned}}}\n  where J = complete microscopic current density and \u03c1 is the charge density.\nAs discussed above, materials respond to an applied electric E field and an applied magnetic B field by producing their own internal 'bound' charge and current distributions that contribute to E and B but are difficult to calculate. To circumvent this problem, H and D fields are used to re-factor Maxwell's equations in terms of the free current density Jf and free charge density \u03c1f:\n\n  \n    \n      \n        \n          \n            \n              \n                \u2207\n                \u22c5\n                \n                  B\n                \n              \n              \n                \n                =\n                0\n                ,\n              \n            \n            \n              \n                \u2207\n                \u22c5\n                \n                  D\n                \n              \n              \n                \n                =\n                \n                  \u03c1\n                  \n                    \n                      f\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  H\n                \n              \n              \n                \n                =\n                \n                  \n                    J\n                  \n                  \n                    \n                      f\n                    \n                  \n                \n                +\n                \n                  \n                    \n                      \u2202\n                      \n                        D\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                ,\n              \n            \n            \n              \n                \u2207\n                \u00d7\n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        B\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\nabla \\cdot \\mathbf {B} &=0,\\\\\\nabla \\cdot \\mathbf {D} &=\\rho _{\\mathrm {f} },\\\\\\nabla \\times \\mathbf {H} &=\\mathbf {J} _{\\mathrm {f} }+{\\frac {\\partial \\mathbf {D} }{\\partial t}},\\\\\\nabla \\times \\mathbf {E} &=-{\\frac {\\partial \\mathbf {B} }{\\partial t}}.\\end{aligned}}}\n  These equations are not any more general than the original equations (if the 'bound' charges and currents in the material are known). They also must be supplemented by the relationship between B and H as well as that between E and D. On the other hand, for simple relationships between these quantities this form of Maxwell's equations can circumvent the need to calculate the bound charges and currents.\n\n\n=== Electric and magnetic fields: different aspects of the same phenomenon ===\n\nAccording to the special theory of relativity, the partition of the electromagnetic force into separate electric and magnetic components is not fundamental, but varies with the observational frame of reference: An electric force perceived by one observer may be perceived by another (in a different frame of reference) as a magnetic force, or a mixture of electric and magnetic forces.\nFormally, special relativity combines the electric and magnetic fields into a rank-2 tensor, called the electromagnetic tensor. Changing reference frames mixes these components. This is analogous to the way that special relativity mixes space and time into spacetime, and mass, momentum and energy into four-momentum.\n\n\n=== Magnetic vector potential ===\n\nIn advanced topics such as quantum mechanics and relativity it is often easier to work with a potential formulation of electrodynamics rather than in terms of the electric and magnetic fields. In this representation, the vector potential A, and the scalar potential \u03c6, are defined such that:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  B\n                \n              \n              \n                \n                =\n                \u2207\n                \u00d7\n                \n                  A\n                \n                ,\n              \n            \n            \n              \n                \n                  E\n                \n              \n              \n                \n                =\n                \u2212\n                \u2207\n                \u03c6\n                \u2212\n                \n                  \n                    \n                      \u2202\n                      \n                        A\n                      \n                    \n                    \n                      \u2202\n                      t\n                    \n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {B} &=\\nabla \\times \\mathbf {A} ,\\\\\\mathbf {E} &=-\\nabla \\varphi -{\\frac {\\partial \\mathbf {A} }{\\partial t}}.\\end{aligned}}}\n  The vector potential A may be interpreted as a generalized potential momentum per unit charge just as \u03c6 is interpreted as a generalized potential energy per unit charge.\nMaxwell's equations when expressed in terms of the potentials can be cast into a form that agrees with special relativity with little effort. In relativity A together with \u03c6 forms the four-potential, analogous to the four-momentum that combines the momentum and energy of a particle. Using the four potential instead of the electromagnetic tensor has the advantage of being much simpler\u2014and it can be easily modified to work with quantum mechanics.\n\n\n=== Quantum electrodynamics ===\n\nIn modern physics, the electromagnetic field is understood to be not a classical field, but rather a quantum field; it is represented not as a vector of three numbers at each point, but as a vector of three quantum operators at each point. The most accurate modern description of the electromagnetic interaction (and much else) is quantum electrodynamics (QED), which is incorporated into a more complete theory known as the Standard Model of particle physics.\nIn QED, the magnitude of the electromagnetic interactions between charged particles (and their antiparticles) is computed using perturbation theory. These rather complex formulas produce a remarkable pictorial representation as Feynman diagrams in which virtual photons are exchanged.\nPredictions of QED agree with experiments to an extremely high degree of accuracy: currently about 10\u221212 (and limited by experimental errors); for details see precision tests of QED. This makes QED one of the most accurate physical theories constructed thus far.\nAll equations in this article are in the classical approximation, which is less accurate than the quantum description mentioned here. However, under most everyday circumstances, the difference between the two theories is negligible.\n\n\n== Important uses and examples of magnetic field ==\n\n\n=== Earth's magnetic field ===\n\nThe Earth's magnetic field is produced by convection of a liquid iron alloy in the outer core. In a dynamo process, the movements drive a feedback process in which electric currents create electric and magnetic fields that in turn act on the currents.The field at the surface of the Earth is approximately the same as if a giant bar magnet were positioned at the center of the Earth and tilted at an angle of about 11\u00b0 off the rotational axis of the Earth (see the figure). The north pole of a magnetic compass needle points roughly north, toward the North Magnetic Pole. However, because a magnetic pole is attracted to its opposite, the North Magnetic Pole is actually the south pole of the geomagnetic field. This confusion in terminology arises because the pole of a magnet is defined by the geographical direction it points.Earth's magnetic field is not constant\u2014the strength of the field and the location of its poles vary. Moreover, the poles periodically reverse their orientation in a process called geomagnetic reversal. The most recent reversal occurred 780,000 years ago.\n\n\n=== Rotating magnetic fields ===\n\nThe rotating magnetic field is a key principle in the operation of alternating-current motors. A permanent magnet in such a field rotates so as to maintain its alignment with the external field. This effect was conceptualized by Nikola Tesla, and later utilized in his, and others', early AC (alternating current) electric motors.\nA rotating magnetic field can be constructed using two orthogonal coils with 90 degrees phase difference in their AC currents. However, in practice such a system would be supplied through a three-wire arrangement with unequal currents.\nThis inequality would cause serious problems in standardization of the conductor size and so, to overcome it, three-phase systems are used where the three currents are equal in magnitude and have 120 degrees phase difference. Three similar coils having mutual geometrical angles of 120 degrees create the rotating magnetic field in this case. The ability of the three-phase system to create a rotating field, utilized in electric motors, is one of the main reasons why three-phase systems dominate the world's electrical power supply systems.\nSynchronous motors use DC-voltage-fed rotor windings, which lets the excitation of the machine be controlled\u2014and induction motors use short-circuited rotors (instead of a magnet) following the rotating magnetic field of a multicoiled stator. The short-circuited turns of the rotor develop eddy currents in the rotating field of the stator, and these currents in turn move the rotor by the Lorentz force.\nIn 1882, Nikola Tesla identified the concept of the rotating magnetic field. In 1885, Galileo Ferraris independently researched the concept. In 1888, Tesla gained U.S. Patent 381,968 for his work. Also in 1888, Ferraris published his research in a paper to the Royal Academy of Sciences in Turin.\n\n\n=== Hall effect ===\n\nThe charge carriers of a current-carrying conductor placed in a transverse magnetic field experience a sideways Lorentz force; this results in a charge separation in a direction perpendicular to the current and to the magnetic field. The resultant voltage in that direction is proportional to the applied magnetic field. This is known as the Hall effect.\nThe Hall effect is often used to measure the magnitude of a magnetic field. It is used as well to find the sign of the dominant charge carriers in materials such as semiconductors (negative electrons or positive holes).\n\n\n=== Magnetic circuits ===\n\nAn important use of H is in magnetic circuits where B = \u03bcH inside a linear material. Here, \u03bc is the magnetic permeability of the material. This result is similar in form to Ohm's law J = \u03c3E, where J is the current density, \u03c3 is the conductance and E is the electric field. Extending this analogy, the counterpart to the macroscopic Ohm's law (I = V\u2044R) is:\n\n  \n    \n      \n        \u03a6\n        =\n        \n          \n            \n              F\n              R\n            \n          \n          \n            \n              m\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\Phi ={\\frac {F}{R}}_{\\mathrm {m} },}\n  where \n  \n    \n      \n        \u03a6\n        =\n        \u222b\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\displaystyle \\Phi =\\int \\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} }\n   is the magnetic flux in the circuit, \n  \n    \n      \n        F\n        =\n        \u222b\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle F=\\int \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is the magnetomotive force  applied to the circuit, and Rm is the reluctance of the circuit. Here the reluctance Rm is a quantity similar in nature to resistance for the flux.\nUsing this analogy it is straightforward to calculate the magnetic flux of complicated magnetic field geometries, by using all the available techniques of circuit theory.\n\n\n=== Magnetic field shape descriptions ===\n\nAn azimuthal magnetic field is one that runs east\u2013west.\nA meridional magnetic field is one that runs north\u2013south. In the solar dynamo model of the Sun, differential rotation of the solar plasma causes the meridional magnetic field to stretch into an azimuthal magnetic field, a process called the omega-effect. The reverse process is called the alpha-effect.\nA dipole magnetic field is one seen around a bar magnet or around a charged elementary particle with nonzero spin.\nA quadrupole magnetic field is one seen, for example, between the poles of four bar magnets. The field strength grows linearly with the radial distance from its longitudinal axis.\nA solenoidal magnetic field is similar to a dipole magnetic field, except that a solid bar magnet is replaced by a hollow electromagnetic coil magnet.\nA toroidal magnetic field occurs in a doughnut-shaped coil, the electric current spiraling around the tube-like surface, and is found, for example, in a tokamak.\nA poloidal magnetic field is generated by a current flowing in a ring, and is found, for example, in a tokamak.\nA radial magnetic field is one in which field lines are directed from the center outwards, similar to the spokes in a bicycle wheel. An example can be found in a loudspeaker transducers (driver).\nA helical magnetic field is corkscrew-shaped, and sometimes seen in space plasmas such as the Orion Molecular Cloud.\n\n\n=== Magnetic dipoles ===\n\nThe magnetic field of a magnetic dipole is depicted in the figure. From outside, the ideal magnetic dipole is identical to that of an ideal electric dipole of the same strength. Unlike the electric dipole, a magnetic dipole is properly modeled as a current loop having a current I and an area a. Such a current loop has a magnetic moment of:\n\n  \n    \n      \n        m\n        =\n        I\n        a\n        ,\n        \n      \n    \n    {\\displaystyle m=Ia,\\,}\n  where the direction of m is perpendicular to the area of the loop and depends on the direction of the current using the right-hand rule. An ideal magnetic dipole is modeled as a real magnetic dipole whose area a has been reduced to zero and its current I increased to infinity such that the product m = Ia is finite. This model clarifies the connection between angular momentum and magnetic moment, which is the basis of the Einstein\u2013de Haas effect rotation by magnetization and its inverse, the Barnett effect or magnetization by rotation. Rotating the loop faster (in the same direction) increases the current and therefore the magnetic moment, for example.\nIt is sometimes useful to model the magnetic dipole similar to the electric dipole with two equal but opposite magnetic charges (one south the other north) separated by distance d. This model produces an H-field not a B-field. Such a model is deficient, though, both in that there are no magnetic charges and in that it obscures the link between electricity and magnetism. Further, as discussed above it fails to explain the inherent connection between angular momentum and magnetism.\n\n\n=== Magnetic monopole (hypothetical) ===\n\nA magnetic monopole is a hypothetical particle (or class of particles) that has, as its name suggests, only one magnetic pole (either a north pole or a south pole). In other words, it would possess a \"magnetic charge\" analogous to an electric charge. Magnetic field lines would start or end on magnetic monopoles, so if they exist, they would give exceptions to the rule that magnetic field lines neither start nor end.\nModern interest in this concept stems from particle theories, notably Grand Unified Theories and superstring theories, that predict either the existence, or the possibility, of magnetic monopoles. These theories and others have inspired extensive efforts to search for monopoles. Despite these efforts, no magnetic monopole has been observed to date.In recent research, materials known as spin ices can simulate monopoles, but do not contain actual monopoles.\n\n\n== See also ==\n\n\n=== General ===\nMagnetohydrodynamics \u2013 the study of the dynamics of electrically conducting fluids\nMagnetic hysteresis \u2013 application to ferromagnetism\nMagnetic nanoparticles \u2013 extremely small magnetic particles that are tens of atoms wide\nMagnetic reconnection \u2013 an effect that causes solar flares and auroras\nMagnetic potential \u2013 the vector and scalar potential representation of magnetism\nSI electromagnetism units \u2013 common units used in electromagnetism\nOrders of magnitude (magnetic field) \u2013 list of magnetic field sources and measurement devices from smallest magnetic fields to largest detected\nUpward continuation\n\n\n=== Mathematics ===\nMagnetic helicity \u2013 extent to which a magnetic field wraps around itself\n\n\n=== Applications ===\nDynamo theory \u2013 a proposed mechanism for the creation of the Earth's magnetic field\nHelmholtz coil \u2013 a device for producing a region of nearly uniform magnetic field\nMagnetic field viewing film \u2013 Film used to view the magnetic field of an area\nMaxwell coil \u2013 a device for producing a large volume of an almost constant magnetic field\nStellar magnetic field \u2013 a discussion of the magnetic field of stars\nTeltron tube \u2013 device used to display an electron beam and demonstrates effect of electric and magnetic fields on moving charges\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==",
        "unit": "magnetic field",
        "url": "https://en.wikipedia.org/wiki/Magnetic_field"
    },
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "minute of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Lumber",
        "clean": "Lumber",
        "text": "Lumber (American English; used only in North America) or timber (used in the rest of the English speaking world) is a type of wood that has been processed into beams and planks, a stage in the process of wood production. Lumber is mainly used for structural purposes but has many other uses as well.\nThere are two main types of lumber. It may be supplied either rough-sawn, or surfaced on one or more of its faces. Besides pulpwood, rough lumber is the raw material for furniture-making and other items requiring additional cutting and shaping. It is available in many species, usually hardwoods; but it is also readily available in softwoods, such as white pine and red pine, because of their low cost.Finished lumber is supplied in standard sizes, mostly for the construction industry \u2013 primarily softwood, from coniferous species, including pine, fir and spruce (collectively spruce-pine-fir), cedar, and hemlock, but also some hardwood, for high-grade flooring. It is more commonly made from softwood than hardwoods, and 80% of lumber comes from softwood.\n\n\n== Terminology ==\nIn the United States milled boards of wood are referred to as lumber. However, in Britain and other Commonwealth nations, the term timber is instead used to describe sawn wood products, like floor boards.\nIn the United States and Canada, generally timber describes standing or felled trees. Specifically in Canada, lumber describes cut and surfaced wood.In the United Kingdom, the word lumber is rarely used in relation to wood and has several other meanings, including unused or unwanted items. Referring to wood, Timber is almost universally used instead.\n\n\n=== Remanufactured lumber ===\n\nRemanufactured lumber is the result of secondary or tertiary processing/cutting of previously milled lumber. Specifically, it is lumber cut for industrial or wood-packaging use. Lumber is cut by ripsaw or resaw to create dimensions that are not usually processed by a primary sawmill.\nResawing is the splitting of 1-inch through 12-inch hardwood or softwood lumber into two or more thinner pieces of full-length boards. For example, splitting a ten-foot 2\u00d74 into two ten-foot 1\u00d74s is considered resawing.\n\n\n=== Plastic lumber ===\n\nStructural lumber may also be produced from recycled plastic and new plastic stock. Its introduction has been strongly opposed by the forestry industry. Blending fiberglass in plastic lumber enhances its strength, durability, and fire resistance. Plastic fiberglass structural lumber can have a \"class 1 flame spread rating of 25 or less, when tested in accordance with ASTM standard E 84,\" which means it burns slower than almost all treated wood lumber.\n\n\n== Conversion of wood logs ==\nLogs are converted into timber by being sawn, hewn, or split. Sawing with a rip saw is the most common method, because sawing allows logs of lower quality, with irregular grain and large knots, to be used and is more economical. There are various types of sawing:\n\nPlain sawn (flat sawn, through and through, bastard sawn) \u2013 A log sawn through without adjusting the position of the log and the grain runs across the width of the boards.\nQuarter sawn and rift sawn \u2013 These terms have been confused in history but generally mean lumber sawn so the annual rings are reasonably perpendicular to the sides (not edges) of the lumber.\nBoxed heart \u2013 The pith remains within the piece with some allowance for exposure.\nHeart center \u2013 the center core of a log.\nFree of heart center (FOHC) \u2013 A side-cut timber without any pith.\nFree of knots (FOK) \u2013 No knots are present.\n\n\n== Dimensional lumber ==\n\nDimensional lumber is lumber that is cut to standardized width and depth, specified in inches. Carpenters extensively use dimensional lumber in framing wooden buildings. Common sizes include 2\u00d74 (pictured) (also two-by-four and other variants, such as four-by-two in Australia, New Zealand, and the UK), 2\u00d76, and 4\u00d74. The length of a board is usually specified separately from the width and depth. It is thus possible to find 2\u00d74s that are four, eight, and twelve feet in length. In Canada and the United States, the standard lengths of lumber are 6, 8, 10, 12, 14, 16, 18, 20, 22 and 24 feet (1.83, 2.44, 3.05, 3.66, 4.27, 4.88, 5.49, 6.10, 6.71 and 7.32 meters).  For wall framing, \"stud\" or \"precut\" sizes are available, and are commonly used. For an eight-, nine-, or ten-foot ceiling height, studs are available in 92 5\u20448 inches (235 cm), 104 5\u20448 inches (266 cm), and 116 5\u20448 inches (296 cm). The term \"stud\" is used inconsistently to specify length; where the exact length matters, one must specify the length explicitly.\n\n\n=== Historical Chinese construction ===\nUnder the prescription of the Method of Construction (\u71df\u9020\u6cd5\u5f0f) issued by the Southern Song government in the early 12th century, timbers were standardized to eight cross-sectional dimensions.  Regardless of the actual dimensions of the timber, the ratio between width and height was maintained at 1:1.5.  Units are in Song Dynasty inches (3.12 cm).\n\nTimber smaller than the 8th class were called \"unclassed\" (\u7b49\u5916).  The width of a timber is referred to as one \"timber\" (\u6750), and the dimensions of other structural components were quoted in multiples of \"timber\"; thus, as the width of the actual timber varied, the dimensions of other components were easily calculated, without resorting to specific figures for each scale.  The dimensions of timbers in similar application show a gradual diminution from the Sui Dyansty (580~618) to the modern era; a 1st class timber during the Sui was reconstructed as 15\u00d710 (Sui Dynasty inches, or 2.94 cm).\n\n\n=== North American softwoods ===\nThe length of a unit of dimensional lumber is limited by the height and girth of the tree it is milled from.  In general the maximum length is 24 ft (7.32 m). Engineered wood products, manufactured by binding the strands, particles, fibers, or veneers of wood, together with adhesives, to form composite materials, offer more flexibility and greater structural strength than typical wood building materials.Pre-cut studs save a framer much time, because they are pre-cut by the manufacturer for use in 8-, 9-, and 10-ft (2.44, 2.74 and 3.05 m) ceiling applications, which means the manufacturer has removed a few inches or centimetres of the piece to allow for the sill plate and the double top plate with no additional sizing necessary.\nIn the Americas, two-bys (2\u00d74s, 2\u00d76s, 2\u00d78s, 2\u00d710s, and 2\u00d712s), named for traditional board thickness in inches, along with the 4\u00d74 (89 mm \u00d7 89 mm), are common lumber sizes used in modern construction. They are the basic building blocks for such common structures as balloon-frame or platform-frame housing. Dimensional lumber made from softwood is typically used for construction, while hardwood boards are more commonly used for making cabinets or furniture.\nLumber's nominal dimensions are larger than the actual standard dimensions of finished lumber.  Historically, the nominal dimensions were the size of the green (not dried), rough (unfinished) boards that eventually became smaller finished lumber through drying and planing (to smooth the wood).  Today, the standards specify the final finished dimensions and the mill cuts the logs to whatever size it needs to achieve those final dimensions.  Typically, that rough cut is smaller than the nominal dimensions because modern technology makes it possible and it uses the logs more efficiently.  For example, a \"2\u00d74\" board historically started out as a green, rough board actually 2 by 4 inches (51 mm \u00d7 102 mm).  After drying and planing, it would be smaller, by a nonstandard amount.  Today, a \"2\u00d74\" board starts out as something smaller than 2 inches by 4 inches and not specified by standards, and after drying and planing is reliably 1 1\u20442 by 3 1\u20442 inches (38 mm \u00d7 89 mm).\n\nEarly standards called for green rough lumber to be of full nominal dimension when dry. However, the dimensions have diminished over time.  In 1910, a typical finished 1-inch (25 mm) board was 13\u204416 in (21 mm).  In 1928, that was reduced by 4%, and yet again by 4% in 1956.  In 1961, at a meeting in Scottsdale, Arizona, the Committee on Grade Simplification and Standardization agreed to what is now the current U.S. standard: in part, the dressed size of a 1-inch (nominal) board was fixed at \u200b3\u20444 inch; while the dressed size of 2 inch (nominal) lumber was reduced from \u200b1 5\u20448 inch to the current \u200b1 1\u20442 inch.Dimensional lumber is available in green, unfinished state, and for that kind of lumber, the nominal dimensions are the actual dimensions.\n\n\n=== Grades and standards ===\n\nIndividual pieces of lumber exhibit a wide range in quality and appearance with respect to knots, slope of grain, shakes and other natural characteristics. Therefore, they vary considerably in strength, utility, and value.\nThe move to set national standards for lumber in the United States began with publication of the American Lumber Standard in 1924, which set specifications for lumber dimensions, grade, and moisture content; it also developed  inspection and accreditation programs.  These standards have changed over the years to meet the changing needs of manufacturers and distributors, with the goal of keeping lumber competitive with other construction products. Current standards are set by the American Lumber Standard Committee, appointed by the U.S. Secretary of Commerce.Design values for most species and grades of visually graded structural products are determined in accordance with ASTM standards, which consider the effect of strength reducing characteristics, load duration, safety and other influencing factors. The applicable standards are based on results of tests conducted in cooperation with the USDA Forest Products Laboratory. Design Values for Wood Construction, which is a supplement to the ANSI/AF&PA National Design Specification\u00ae for Wood Construction, provides these lumber design values, which are recognized by the model building codes.Canada has grading rules that maintain a standard among mills manufacturing similar woods to assure customers of uniform quality. Grades standardize the quality of lumber at different levels and are based on moisture content, size, and manufacture at the time of grading, shipping, and unloading by the buyer. The National Lumber Grades Authority (NLGA) is responsible for writing, interpreting and maintaining Canadian lumber grading rules and standards. The Canadian Lumber Standards Accreditation Board (CLSAB) monitors the quality of Canada's lumber grading and identification system.\nAttempts to maintain lumber quality over time have been challenged by historical changes in the timber resources of the United States \u2013 from the slow-growing virgin forests common over a century ago to the fast-growing plantations now common in today's commercial forests.  Resulting declines in lumber quality have been of concern to both the lumber industry and consumers and have caused increased use of alternative construction products.Machine stress-rated and machine-evaluated lumber is readily available for end-uses where high strength is critical, such as trusses, rafters, laminating stock, I-beams and web joints. Machine grading measures a characteristic such as stiffness or density that correlates with the structural properties of interest, such as bending strength. The result is a more precise understanding of the strength of each piece of lumber than is possible with visually graded lumber, which allows designers to use full-design strength and avoid overbuilding.In Europe, strength grading of rectangular sawn timber (both softwood and hardwood) is done according to EN-14081  and commonly sorted into classes defined by EN-338. For softwoods the common classes are (in increasing strength) C16, C18, C24 and C30.  There are also classes specifically for hardwoods and those in most common use (in increasing strength) are D24, D30, D40, D50, D60 and D70. For these classes, the number refers to the required 5th percentile bending strength in Newtons per square millimetre. There are other strength classes, including T-classes based on tension intended for use in glulam.\n\nC14, used for scaffolding and formwork\nC16 and C24, general construction\nC30, prefab roof trusses and where design requires somewhat stronger joists than C24 can offer. TR26 is also a common trussed rafter strength class in long standing use in the UK.\nC40, usually seen in glulamGrading rules for African and South American sawn timber have been developed by ATIBT according to the rules of the Sciages Aviv\u00e9s Tropicaux Africains (SATA) and is based on clear cuttings \u2013 established by the percentage of the clear surface.\n\n\n=== North American hardwoods ===\nIn North America, market practices for dimensional lumber made from hardwoods varies significantly from the regularized standardized 'dimension lumber' sizes used for sales and specification of softwoods \u2013 hardwood boards are often sold totally rough cut, or machine planed only on the two (broader) face sides. When Hardwood Boards are also supplied with planed faces, it is usually both by random widths of a specified thickness (normally matching milling of softwood dimensional lumbers) and somewhat random lengths. But besides those older (traditional and normal) situations, in recent years some product lines have been widened to also market boards in standard stock sizes; these usually retail in big-box stores and using only a relatively small set of specified lengths; in all cases hardwoods are sold to the consumer by the board-foot (144 cubic inches or 2,360 cubic centimetres), whereas that measure is not used for softwoods at the retailer (to the cognizance of the buyer).\nAlso in North America, hardwood lumber is commonly sold in a \"quarter\" system, when referring to thickness; 4/4 (four quarter) refers to a 1-inch-thick (25 mm) board, 8/4 (eight quarter) is a 2-inch-thick (51 mm) board, etc. This \"quarter\" system is rarely used for softwood lumber; although softwood decking is sometimes sold as 5/4, even though it is actually one-inch thick (from milling 1/8th inch off each side in a motorized planing step of production).\nThe \"quarter\" system of reference is a traditional (cultural) North American lumber industry nomenclature used specifically to indicate the thickness of rough sawn hardwood lumber.\nThe following paragraph is exactly backwards from North American cultural practices where finished retail and rough lumber share the same terminology, as is discussed in the paragraph after about 'architects, designers, and builders':\nIn rough sawn lumber it immediately clarifies that the lumber is not yet milled, avoiding confusion with milled dimension lumber which is measured as actual thickness after machining. Examples \u2013 3/4\", 19mm, or 1x.\nIn recent years architects, designers, and builders have begun to use the \"quarter\" system in specifications as a vogue of insider knowledge, though the materials being specified are finished lumber, thus conflating  the separate systems and causing confusion.\nHardwoods cut for furniture are cut in the fall and winter, after the sap has stopped running in the trees. If hardwoods are cut in the spring or summer the sap ruins the natural color of the timber and decreases the value of the timber for furniture.\n\n\n=== Engineered lumber ===\n\nEngineered lumber is lumber created by a manufacturer and designed for a certain structural purpose. The main categories of engineered lumber are:\nLaminated veneer lumber (LVL) \u2013 LVL comes in \u200b1 3\u20444 inch thicknesses with depths such as \u200b9 1\u20442, \u200b11 7\u20448, 14, 16, 18, and 24 inches, and are often doubled or tripled up. They function as beams to provide support over large spans, such as removed support walls and garage door openings, places where dimensional lumber is insufficient, and also in areas where a heavy load is bearing from a floor, wall or roof above on a somewhat short span where dimensional lumber is  impractical. This type of lumber is compromised if it is altered by holes or notches anywhere within the span or at the ends, but nails can be driven into it wherever necessary to anchor the beam or to add hangers for I-joists or dimensional lumber joists that terminate at an LVL beam.\nWooden I-joists \u2013 sometimes called \"TJI\", \"Trus Joists\" or \"BCI\", all of which are brands of wooden I-joists, they are used for floor joists on upper floors and also in first floor conventional foundation construction on piers as opposed to slab floor construction. They are engineered for long spans and are doubled up in places where a wall will be aligned over them, and sometimes tripled where heavy roof-loaded support walls are placed above them. They consist of a top and bottom chord or flange made from dimensional lumber with a webbing in-between made from oriented strand board (OSB) (or, latterly, steel mesh forms which allow passage of services without cutting). The webbing can be removed up to certain sizes or shapes according to the manufacturer's or engineer's specifications, but for small holes, wooden I-joists come with \"knockouts\", which are perforated, pre-cut areas where holes can be made easily, typically without engineering approval. When large holes are needed, they can typically be made in the webbing only and only in the center third of the span; the top and bottom chords lose their integrity if cut. Sizes and shapes of the hole, and typically the placing of a hole itself, must be approved by an engineer prior to the cutting of the hole and in many areas, a sheet showing the calculations made by the engineer must be provided to the building inspection authorities before the hole will be approved. Some I-joists are made with W-style webbing like a truss to eliminate cutting and to allow ductwork to pass through.\nFinger-jointed lumber \u2013 solid dimensional lumber lengths typically are limited to lengths of 22 to 24 feet, but can be made longer by the technique of \"finger-jointing\" by using small solid pieces, usually 18 to 24 inches long, and joining them together using finger joints and glue to produce lengths that can be up to 36 feet long in 2\u00d76 size. Finger-jointing also is predominant in precut wall studs. It is also an affordable alternative for non-structural hardwood that will be painted (staining would leave the finger-joints visible). Care is taken during construction to avoid nailing directly into a glued joint as stud breakage can occur.\nGlulam beams \u2013 created from 2\u00d74 or 2\u00d76 stock by gluing the faces together to create beams such as 4\u00d712 or 6\u00d716. As such, a beam acts as one larger piece of lumber \u2013 thus eliminating the need to harvest larger, older trees for the same size beam.\nManufactured trusses \u2013 trusses are used in home construction as a pre-fabricated replacement for roof rafters and ceiling joists (stick-framing). It is seen as an easier installation and a better solution for supporting roofs than the use of dimensional lumber's struts and purlins as bracing. In the southern U.S. and elsewhere, stick-framing with dimensional lumber roof support is still predominant. The main drawbacks of trusses are reduced attic space, time required for engineering and ordering, and a cost higher than the dimensional lumber needed if the same project were conventionally framed. The advantages are significantly reduced labor costs (installation is faster than conventional framing), consistency, and overall schedule savings.\n\n\n=== Various pieces and cuts ===\n\nSquare and rectangular forms: Plank, slat, batten, board, lath, strapping (typically \u200b3\u20444 in \u00d7 \u200b1 1\u20442 in), cant (A partially sawn log such as sawn on two sides or squared to a large size and later resawn into lumber. A flitch is a type of cant with wane on one or both sides). Various pieces are also known by their uses such as post, beam, (girt), stud, rafter, joist, sill plate, wall plate.\nRod forms: pole, (dowel), stick (staff, baton)\n\n\n=== Timber piles ===\nIn the United States, pilings are mainly cut from southern yellow pines and Douglas firs. Treated pilings are available in Chromated copper arsenate retentions of 0.60, 0.80 and 2.50 pounds per cubic foot (9.6, 12.8 and 40.0 kg/m3) if treatment is required.\n\n\n== Defects in lumber ==\nDefects occurring in lumber are grouped into the following four divisions:\n\n\n=== Conversion ===\nDuring the process of converting timber to commercial form the following defects may occur:\n\nChip mark: this defect is indicated by the marks or signs placed by chips on the finished surface of timber\nDiagonal grain: improper sawing of timber\nTorn grain: when a small depression is made on the finished surface due to falling of some tool\nWane: presence of original rounded surface in the finished product\n\n\n=== Defects due to fungi and animals ===\nFungi attack timber when these conditions are all present:\n\nThe timber moisture content is above 25% on a dry-weight basis\nThe environment is sufficiently warm\nOxygen (O2) is presentWood with less than 25% moisture (dry weight basis) can remain free of decay for centuries. Similarly, wood submerged in water may not be attacked by fungi if the amount of oxygen is inadequate.\nFungi timber defects:\n\nBlue stain\nBrown rot\nDry rot\nHeart rot\nSap stain\nWet rot\nWhite rotFollowing are the insects and molluscs which are usually responsible for the decay of timber:\n\nWoodboring beetles\nMarine borers (Barnea similis)\nTeredos (Teredo navalis)\nTermites\nCarpenter ants\nCarpenter bees\n\n\n=== Natural forces ===\n\nThere are two main natural forces responsible for causing defects in timber: abnormal growth and rupture of tissues. Rupture of tissue includes cracks or splits in the wood called \"shakes\". \"Ring shake\", \"wind shake\", or \"ring failure\" is when the wood grain separates around the growth rings either while standing or during felling. Shakes may reduce the strength of a timber and the appearance thus reduce lumber grade and may capture moisture, promoting decay. Eastern hemlock is known for having ring shake. A \"check\" is a crack on the surface of the wood caused by the outside of a timber shrinking as it seasons. Checks may extend to the pith and follow the grain. Like shakes, checks can hold water promoting rot. A \"split\" goes all the way through a timber. Checks and splits occur more frequently at the ends of lumber because of the more rapid drying in these locations.\n\n\n=== Seasoning ===\nThe seasoning of lumber is typically either kiln- or air-dried. Defects due to seasoning are the main cause of splits, bowing and honeycombing.\n\n\n== Durability and service life ==\nUnder proper conditions, wood provides excellent, lasting performance. However, it also faces several potential threats to service life, including fungal activity and insect damage \u2013 which can be avoided in numerous ways. Section 2304.11 of the International Building Code  addresses protection against decay and termites. This section provides requirements for non-residential construction applications, such as wood used above ground (e.g., for framing, decks, stairs, etc.), as well as other applications.\nThere are four recommended methods to protect wood-frame structures against durability hazards and thus provide maximum service life for the building. All require proper design and construction:\n\nControlling moisture using design techniques to avoid decay\nProviding effective control of termites and other insects\nUsing durable materials such as pressure treated or naturally durable species of wood where appropriate\nProviding quality assurance during design and construction and throughout the building\u2019s service life using appropriate maintenance practices\n\n\n=== Moisture control ===\nWood is a hygroscopic material, which means it naturally absorbs and releases water to balance its internal moisture content with the surrounding environment. The moisture content of wood is measured by the weight of water as a percentage of the oven-dry weight of the wood fiber. The key to controlling decay is controlling moisture. Once decay fungi are established, the minimum moisture content for decay to propagate is 22 to 24 percent, so building experts recommend 19 percent as the maximum safe moisture content for untreated wood in service. Water by itself does not harm the wood, but rather, wood with consistently high moisture content enables fungal organisms to grow.\nThe primary objective when addressing moisture loads is to keep water from entering the building envelope in the first place, and to balance the moisture content within the building itself. Moisture control by means of accepted design and construction details is a simple and practical method of protecting a wood-frame building against decay. For applications with a high risk of staying wet, designers specify durable materials such as naturally decay-resistant species or wood that has been treated with preservatives. Cladding, shingles, sill plates and exposed timbers or glulam beams are examples of potential applications for treated wood.\n\n\n=== Controlling termites and other insects ===\nFor buildings in termite zones, basic protection practices addressed in current building codes include (but are not limited to) the following:\n\u2022 Grading the building site away from the foundation to provide proper drainage\n\u2022 Covering exposed ground in any crawl spaces with 6-mil polyethylene film and maintaining at least 12 to 18 inches (300 to 460 mm) of clearance between the ground and the bottom of framing members above (12 inches to beams or girders, 18 inches to joists or plank flooring members)\n\u2022 Supporting post columns by concrete piers so that there is at least 6 inches (150 mm) of clear space between the wood and exposed earth\n\u2022 Installing wood framing and sheathing in exterior walls at least eight inches above exposed earth; locating siding at least six inches from the finished grade\n\u2022 Where appropriate, ventilating crawl spaces according to local building codes\n\u2022 Removing building material scraps from the job site before backfilling.\n\u2022 If allowed by local regulation, treating the soil around the foundation with an approved termiticide to provide protection against subterranean termites\n\n\n=== Preservatives ===\n\nTo avoid decay and termite infestation, untreated wood is separated from the ground and other sources of moisture. These separations are required by many building codes and are considered necessary to maintain wood elements in permanent structures at a safe moisture content for decay protection. When it is not possible to separate wood from the sources of moisture, designers often rely on preservative-treated wood.Wood can be treated with a preservative that improves service life under severe conditions without altering its basic characteristics. It can also be pressure-impregnated with fire-retardant chemicals that improve its performance in a fire. One of the early treatments to \"fireproof lumber\", which retard fires, was developed in 1936 by the Protexol Corporation, in which lumber is heavily treated with salt.\nWood does not deteriorate simply because it gets wet. When wood breaks down, it is because an organism is eating it. Preservatives work by making the food source inedible to these organisms. Properly preservative-treated wood can have 5 to 10 times the service life of untreated wood. Preserved wood is used most often for railroad ties, utility poles, marine piles, decks, fences and other outdoor applications. Various treatment methods and types of chemicals are available, depending on the attributes required in the particular application and the level of protection needed.There are two basic methods of treating: with and without pressure. Non-pressure methods are the application of preservative by brushing, spraying or dipping the piece to be treated. Deeper, more thorough penetration is achieved by driving the preservative into the wood cells with pressure. Various combinations of pressure and vacuum are used to force adequate levels of chemical into the wood. Pressure-treating preservatives consist of chemicals carried in a solvent.\nChromated copper arsenate, once the most commonly used wood preservative in North America began being phased out of most residential applications in 2004. Replacing it are amine copper quat and copper azole.\nAll wood preservatives used in the United States and Canada are registered and regularly re-examined for safety by the U.S. Environmental Protection Agency and Health Canada's Pest Management and Regulatory Agency, respectively.\n\n\n== Ancient construction works ==\nTimber was used as a dominant building material in most of the ancient temples of Kerala and coastal Karnataka of India.\n\n\n== Timber framing ==\n\nTimber framing is a style of construction which uses heavier framing elements than modern stick framing, which uses dimensional lumber. The timbers originally were tree boles squared with a broadaxe or adze and joined together with joinery without nails. Modern timber framing has been growing in popularity in the United States since the 1970s.\n\n\n== Environmental effects of lumber ==\nGreen building minimizes the impact or \"environmental footprint\" of a building. Wood is a major building material that is renewable and replenishable in a continuous cycle. Studies show manufacturing wood uses less energy and results in less air and water pollution than steel and concrete. However, demand for lumber is blamed for deforestation.\n\n\n=== Residual wood ===\nThe conversion from coal to biomass power is a growing trend in the United States.The United Kingdom, Uzbekistan, Kazakhstan, Australia, Fiji, Madagascar, Mongolia, Russia, Denmark, Switzerland and Swaziland governments all support an increased role for energy derived from biomass, which are organic materials available on a renewable basis and include residues and/or byproducts of the logging, sawmilling and papermaking processes. In particular, they view it as a way to lower greenhouse gas emissions by reducing consumption of oil and gas while supporting the growth of forestry, agriculture and rural economies. Studies by the U.S. government have found the country\u2019s combined forest and agriculture land resources have the power to sustainably supply more than one-third of its current petroleum consumption.Biomass is already an important source of energy for the North American forest products industry. It is common for companies to have cogeneration facilities, also known as combined heat and power, which convert some of the biomass that results from wood and paper manufacturing to electrical and thermal energy in the form of steam. The electricity is used to, among other things, dry lumber and supply heat to the dryers used in paper-making.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nSathre, R; O'Conner, J (2010). A Synthesis of Research on Wood Products and Greenhouse Gas Impacts (PDF) (2 ed.). FPInnovations. ISBN 978-0-86488-546-3. Archived from the original (PDF) on 2012-03-21. \n\n\n== External links ==\nNational Hardwood Lumber Association (Rules for Grading Hardwood Lumber \u2013 Inspector Training School)\nTimber Development Association of NSW \u2013 Australia\nTDA: Timber Decking Association \u2013 UK\nTRADA: Timber Research And Development Association\nThe Forest Products Laboratory. U.S. main wood products research lab. Madison, WI (E)\nWCTE, World Conference on Timber Engineering\u3000June 20\u201324, 2010, Riva del Garda, Trentino, Italy\nForest Products data in Canada since 1990",
        "unit": "volume (lumber)",
        "url": "https://en.wikipedia.org/wiki/Lumber"
    },
    {
        "_id": "Linear_density",
        "clean": "Linear density",
        "text": "Linear density is the measure of a quantity of any characteristic value per unit of length.  Linear mass density (titer in textile engineering, the amount of mass per unit length) and linear charge density (the amount of electric charge per unit length) are two common examples used in science and engineering.\nThe term linear density is most often used when describing the characteristics of one-dimensional objects, although linear density can also be used to describe the density of a three-dimensional quantity along one particular dimension.  Just as density is most often used to mean mass density, the term linear density likewise often refers to linear mass density.  However, this is only one example of a linear density, as any quantity can be measured in terms of its value along one dimension.\nConsider a long, thin rod of mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear mass density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{m}}\n  , of this one dimensional object, we can simply divide the total mass, \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        m\n        =\n        \n          \n            M\n            L\n          \n        \n      \n    \n    {\\displaystyle m={\\frac {M}{L}}}\n  If we describe the rod as having a varying mass (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        m\n        =\n        m\n        (\n        l\n        )\n      \n    \n    {\\displaystyle m=m(l)}\n  Each infinitesimal unit of mass, \n  \n    \n      \n        d\n        m\n      \n    \n    {\\displaystyle dm}\n  , is equal to the product of its linear mass density, \n  \n    \n      \n        \n          \u03bb\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{m}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        m\n        =\n        \n          \u03bb\n          \n            m\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dm=\\lambda _{m}dl}\n  The linear mass density can then be understood as the derivative of the mass function with respect to the one dimension of the rod (the position along its length \n  \n    \n      \n        m\n        =\n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle m={\\frac {dm}{dl}}}\n  )\nThe SI unit of linear mass density is the kilogram per meter (kg/m).\nLinear density of fibers and yarns can be measured by many methods. The simplest one is to measure a length of material and weigh it. However, this requires a large sample and masks the variability of linear density along the thread, and is difficult to apply if the fibers are crimped or otherwise cannot lay flat relaxed. If the density of the material is known, the fibers are measured individually and have a simple shape, a more accurate method is direct imaging of the fiber with SEM to measure the diameter and calculation of the linear density. Finally, linear density is directly measured with a vibroscope. The sample is tensioned between two hard points, mechanical vibration is induced and the fundamental frequency is measured.\n\n\n== Linear charge density ==\nConsider a long, thin wire of charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  .  To calculate the average linear charge density, \n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}}\n  , of this one dimensional object, we can simply divide the total charge, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , by the total length, \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  :\n\n  \n    \n      \n        \n          \n            \n              \n                \u03bb\n                \u00af\n              \n            \n          \n          \n            q\n          \n        \n        =\n        \n          \n            Q\n            L\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\lambda }}_{q}={\\frac {Q}{L}}}\n  If we describe the wire as having a varying charge (one that varies as a function of position along the length of the rod, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  ), we can write:\n\n  \n    \n      \n        q\n        =\n        q\n        (\n        l\n        )\n      \n    \n    {\\displaystyle q=q(l)}\n  Each infinitesimal unit of charge, \n  \n    \n      \n        d\n        q\n      \n    \n    {\\displaystyle dq}\n  , is equal to the product of its linear charge density, \n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}}\n  , and the infinitesimal unit of length, \n  \n    \n      \n        d\n        l\n      \n    \n    {\\displaystyle dl}\n  :\n\n  \n    \n      \n        d\n        q\n        =\n        \n          \u03bb\n          \n            q\n          \n        \n        d\n        l\n      \n    \n    {\\displaystyle dq=\\lambda _{q}dl}\n  The linear charge density can then be understood as the derivative of the charge function with respect to the one dimension of the wire (the position along its length, \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  )\n\n  \n    \n      \n        \n          \u03bb\n          \n            q\n          \n        \n        =\n        \n          \n            \n              d\n              q\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda _{q}={\\frac {dq}{dl}}}\n  Notice that these steps were the exact same ones we took before to find :\n  \n    \n      \n        \n          \n            \n              d\n              m\n            \n            \n              d\n              l\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {dm}{dl}}}\n  \nThe SI unit of linear charge density is the coulomb per meter (C/m).\n\n\n== Other applications ==\nIn drawing or printing, the term linear density also refers to how densely or heavily a line is drawn.\n\n\n== Units ==\n\nCommon units include:\n\nkilogram per meter\nounce (mass) per foot\nounce (mass) per inch\npound (mass) per yard: used in the North American railway industry for the linear density of rails\npound (mass) per foot\npound (mass) per inch\ntex, a unit of measure for the linear density of fibers, defined as the mass in grams per 1,000 meters\ndenier, a unit of measure for the linear density of fibers, defined as the mass in grams per 9,000 meters\ndecitex (dtex), the SI unit for the linear density of fibers, defined as the mass in grams per 10,000 meters\n\n\n== See also ==\nDensity\nColumnar density\nPaper density\n\n\n== References ==",
        "unit": "linear current density",
        "url": "https://en.wikipedia.org/wiki/Linear_density"
    },
    {
        "_id": "Minute_and_second_of_arc",
        "clean": "Minute and second of arc",
        "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to 1/60 of one degree. Since one degree is 1/360 of a turn (or complete rotation), one minute of arc is 1/21600 of a turn. A minute of arc is \u03c0/10800 of a radian. A second of arc, arcsecond (arcsec), or arc second is 1/60 of an arcminute, 1/3600 of a degree, 1/1296000 of a turn, and \u03c0/648000 (about 1/206265) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is \n  \n    \n      \n        4\n        \u03c0\n        \n          \n            (\n            \n              \n                \n                  10\n                  \n                  800\n                \n                \u03c0\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              466\n              \n              560\n              \n              000\n            \n            \u03c0\n          \n        \n        \u2248\n      \n    \n    {\\displaystyle 4\\pi \\left({\\frac {10\\,800}{\\pi }}\\right)^{2}={\\frac {466\\,560\\,000}{\\pi }}\\approx }\n   148510660 square arcminutes (the surface area of a unit sphere in square units divided by the solid angle area subtended by a square arcminute, also in square units - so that the final result is a dimensionless number).\n\n\n== Symbols and abbreviations ==\nThe standard symbol for marking the arcminute is the prime (\u2032) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (\n  \n    \n      \n        \n          \n            \n              \n                \n                \u2032\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {'}}}\n  ).\nThe standard symbol for the arcsecond is the double prime (\u2033) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1\u2033. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\n\n== Common examples ==\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of 4 kilometres (about 2.5 mi). An arcsecond is also the angle subtended by\n\nan object of diameter 725.27 km at a distance of one astronomical unit,\nan object of diameter 45866916 km at one light-year,\nan object of diameter one astronomical unit (149597871 km) at a distance of one parsec.A milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\n\nHubble Space Telescope has calculational resolution of 0.05 arcseconds and actual resolution of almost 0.1 arcseconds, which is close to the diffraction limit.\ncrescent Venus measures between 60.2 and 66 seconds of arc.\n\n\n== Uses ==\n\n\n=== Astronomy ===\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (\u03b2) and longitude (\u03bb); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (\u03b4), are all measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arc second, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\nThe ESA astrometric space probe Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).Apart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.Space telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\n\n=== Cartography ===\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or \u22481.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use  base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places (1/1000 of a degree) have about 1/4 the precision of degrees-minutes-seconds (1/3600 of a degree) and specify locations within about 120 meters or 400 feet.\n\n\n=== Property cadastral surveying ===\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, North 65\u00b0 39\u2032 18\u2033 West 85.69 feet would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\n\n\n=== Firearms ===\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA is subtended by a sphere with a diameter of 1.047 inches at 100 yards (2.908 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, at 500 yards, 1 MOA is subtended by a sphere with a diameter of 5.235 inches, and at 1000 yards 1 MOA is subtended by a sphere with a diameter of 10.47 inches. \nSince many modern telescopic sights are adjustable in half (1/2), quarter (1/4), or eighth (1/8) MOA increments, also known as clicks, zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that click in fractions of MOA. This makes zeroing and adjustments much easier:\n\nTo adjust a \u200b1\u20442 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 \u00d7 2 = 6 clicks down and 1.5 x 2 = 3 clicks right\nTo adjust a \u200b1\u20444 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 4 = 12 clicks down and 1.5 \u00d7 4 = 6 clicks right\nTo adjust a \u200b1\u20448 MOA scope 3 MOA down and 1.5 MOA right, the scope needs to be adjusted 3 x 8 = 24 clicks down and 1.5 \u00d7 8 = 12 clicks rightAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is 1/10 mil (which approximates \u200b1\u20443 MOA).\n\nTo adjust a 1/10 mil scope 0.9 mil down and 0.4 mil right, the scope needs to be adjusted 9 clicks down and 4 clicks right (which equals approximately 3 and 1.5 MOA respectively).One thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to m minutes of arc can be calculated as follows: group size = tan(m/60) \u00d7 distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan(1/60) \u2248 1.047 inches. In metric units 1 MOA at 100 meters \u2248 2.908 centimeters.\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a 1 MOA rifle should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\nRifle manufacturers and gun magazines often refer to this capability as sub-MOA, meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.The Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 \u00d7 \u03c0 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 mrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system.  A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n(Values in bold face are exact. All mil fractions are given in tenths, which is more convenient for practical use.)\n\n1\u2032 at 100 yards equals 22619/ 21600 = 1.04717593 in \u2248 1.047 inches\n1\u2032 \u2248 0.291 mil (or 2.91 cm at 100 m, approximately  3 cm at 100 m)\n1 mil \u2248 3.44\u2032, so 1/10 mil \u2248 1/3\u2032\n0.1 mil equals exactly 1 cm at 100 m, or approximately 0.36 inches at 100 yards\n\n\n=== Human vision ===\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\n\n=== Materials ===\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n=== Manufacturing ===\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\".\n\n\n== See also ==\nDegree (angle) \u00a7 Subdivisions\nSexagesimal \u00a7 Modern usage\nSquare minute\nSquare second\nMilliradian\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nMOA / mils By Robert Simeone",
        "unit": "second of arc",
        "url": "https://en.wikipedia.org/wiki/Minute_and_second_of_arc"
    },
    {
        "_id": "Area",
        "clean": "Area",
        "text": "Area is the quantity that expresses the extent of a two-dimensional figure or shape, or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a  three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).\nThe area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m2), which is the area of a square whose sides are one metre long.  A shape with an area of three square metres would have the same area as three such squares.  In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.\nThere are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles.  Using these formulas, the area of any polygon can be found by dividing the polygon into triangles.  For shapes with curved boundary, calculus is usually required to compute the area.  Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.\nArea plays an important role in modern mathematics.  In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable.  In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.\n\n\n== Formal definition ==\n\nAn approach to defining what is meant by \"area\" is through axioms. \"Area\" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers which satisfies the following properties:\n\nFor all S in M, a(S) \u2265 0.\nIf S and T are in M then so are S \u222a T and S \u2229 T, and also a(S\u222aT) = a(S) + a(T) \u2212 a(S\u2229T).\nIf S and T are in M with S \u2286 T then T \u2212 S is in M and a(T\u2212S) = a(T) \u2212 a(S).\nIf a set S is in M and S is congruent to T then T is also in M and a(S) = a(T).\nEvery rectangle R is in M. If the rectangle has length h and breadth k then a(R) = hk.\nLet Q be a set enclosed between two step regions S and T. A step region is formed from a finite union of adjacent rectangles resting on a common base, i.e. S \u2286 Q \u2286 T. If there is a unique number c such that a(S) \u2264 c \u2264 a(T) for all such step regions S and T, then a(Q) = c.It can be proved that such an area function actually exists.\n\n\n== Units ==\n\nEvery unit of length has a corresponding unit of area, namely the area of a square with the given side length.  Thus areas can be measured in square metres (m2), square centimetres (cm2), square millimetres (mm2), square kilometres (km2), square feet (ft2), square yards (yd2), square miles (mi2), and so forth.  Algebraically, these units can be thought of as the squares of the corresponding length units.\nThe SI unit of area is the square metre, which is considered an SI derived unit.\n\n\n=== Conversions ===\n\nCalculation of the area of a square whose length and width are 1 metre would be:\n1 metre x 1 metre = 1 m2and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:\n3 metres x 2 metres = 6 m2. This is equivalent to 6 million square millimetres. Other useful conversions are:\n\n1 square kilometre = 1,000,000 square metres\n1 square metre = 10,000 square centimetres = 1,000,000 square millimetres\n1 square centimetre = 100 square millimetres.\n\n\n==== Non-metric units ====\nIn non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.\n\n1 foot = 12 inches,the relationship between square feet and square inches is\n\n1 square foot = 144 square inches,where 144 = 122 = 12 \u00d7 12.  Similarly:\n\n1 square yard = 9 square feet\n1 square mile = 3,097,600 square yards = 27,878,400 square feetIn addition, conversion factors include:\n\n1 square inch = 6.4516 square centimetres\n1 square foot = 0.09290304 square metres\n1 square yard = 0.83612736 square metres\n1 square mile = 2.589988110336 square kilometres\n\n\n=== Other units including historical ===\n\nThere are several other common units for area.  The are was the original unit of area in the metric system, with:\n\n1 are = 100 square metresThough the are has fallen out of use, the hectare is still commonly used to measure land:\n1 hectare = 100 ares = 10,000 square metres = 0.01 square kilometresOther uncommon metric units of area include the tetrad, the hectad, and the myriad.\nThe acre is also commonly used to measure land areas, where\n\n1 acre = 4,840 square yards = 43,560 square feet.An acre is approximately 40% of a hectare.\nOn the atomic scale, area is measured in units of barns, such that:\n1 barn = 10\u221228 square meters.The barn is commonly used in describing the cross-sectional area of interaction in nuclear physics.In India,\n\n20 dhurki = 1 dhur\n20 dhur = 1 khatha\n20 khata = 1 bigha\n32 khata = 1 acre\n\n\n== History ==\n\n\n=== Circle area ===\nIn the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.Subsequently, Book I of Euclid's Elements dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book Measurement of a Circle. (The circumference is 2\u03c0r, and the area of a triangle is half the base times the height, yielding the area \u03c0r2 for the disk.) Archimedes approximated the value of \u03c0 (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).\nSwiss scientist Johann Heinrich Lambert in 1761 proved that \u03c0, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that \u03c02 is irrational; this also proves that \u03c0 is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that \u03c0 is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.\n\n\n=== Triangle area ===\nHeron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, Metrica, written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since Metrica is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the Aryabhatiya (section 2.6).\nA formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in Shushu Jiuzhang (\"Mathematical Treatise in Nine Sections\"), written by Qin Jiushao.\n\n\n=== Quadrilateral area ===\nIn the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.\n\n\n=== General polygon area ===\nThe development of Cartesian coordinates by Ren\u00e9 Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.\n\n\n=== Areas determined using calculus ===\nThe development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.\n\n\n== Area formulas ==\n\n\n=== Polygon formulas ===\n\nFor a non-self-intersecting (simple) polygon, the Cartesian coordinates \n  \n    \n      \n        (\n        \n          x\n          \n            i\n          \n        \n        ,\n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{i},y_{i})}\n   (i=0, 1, ..., n-1) of whose n vertices are known, the area is given by the surveyor's formula:\n\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          |\n        \n        \n          \u2211\n          \n            i\n            =\n            0\n          \n          \n            n\n            \u2212\n            1\n          \n        \n        (\n        \n          x\n          \n            i\n          \n        \n        \n          y\n          \n            i\n            +\n            1\n          \n        \n        \u2212\n        \n          x\n          \n            i\n            +\n            1\n          \n        \n        \n          y\n          \n            i\n          \n        \n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle A={\\frac {1}{2}}|\\sum _{i=0}^{n-1}(x_{i}y_{i+1}-x_{i+1}y_{i})|}\n  where when i=n-1, then i+1 is expressed as modulus n and so refers to 0.\n\n\n==== Rectangles ====\n\nThe most basic area formula is the formula for the area of a rectangle.  Given a rectangle with length l and width w, the formula for the area is:\nA = lw (rectangle).That is, the area of the rectangle is the length multiplied by the width.  As a special case, as l = w in the case of a square, the area of a square with side length s is given by the formula:\nA = s2 (square).The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom.  On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.\n\n\n==== Dissection, parallelograms, and triangles ====\n\nMost other simple formulas for area follow from the method of dissection.\nThis involves cutting a shape into pieces, whose areas must sum to the area of the original shape.\nFor an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left.  If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle.  It follows that the area of the parallelogram is the same as the area of the rectangle:\nA = bh  (parallelogram).However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right.  It follows that the area of each triangle is half the area of the parallelogram:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        b\n        h\n      \n    \n    {\\displaystyle A={\\frac {1}{2}}bh}\n    (triangle).Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.\n\n\n=== Area of curved shapes ===\n\n\n==== Circles ====\n\nThe formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method.  Given a circle of radius r, it is possible to partition the circle into sectors, as shown in the figure to the right.  Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram.  The height of this parallelogram is r, and the width is half the circumference of the circle, or \u03c0r.  Thus, the total area of the circle is \u03c0r2:\nA = \u03c0r2  (circle).Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors.  The limit of the areas of the approximate parallelograms is exactly \u03c0r2, which is the area of the circle.This argument is actually a simple application of the ideas of calculus.  In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus.  Using modern methods, the area of a circle can be computed using a definite integral:\n\n  \n    \n      \n        A\n        \n        =\n        \n        2\n        \n          \u222b\n          \n            \u2212\n            r\n          \n          \n            r\n          \n        \n        \n          \n            \n              r\n              \n                2\n              \n            \n            \u2212\n            \n              x\n              \n                2\n              \n            \n          \n        \n        \n        d\n        x\n        \n        =\n        \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle A\\;=\\;2\\int _{-r}^{r}{\\sqrt {r^{2}-x^{2}}}\\,dx\\;=\\;\\pi r^{2}.}\n  \n\n\n==== Ellipses ====\n\nThe formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes x and y the formula is:\n\n  \n    \n      \n        A\n        =\n        \u03c0\n        x\n        y\n        .\n      \n    \n    {\\displaystyle A=\\pi xy.}\n  \n\n\n==== Surface area ====\n\nMost basic formulas for surface area can be obtained by cutting surfaces and flattening them out.  For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle.  Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.\nThe formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out.  The formula for the surface area of a sphere was first obtained by Archimedes in his work On the Sphere and Cylinder.  The formula is:\nA = 4\u03c0r2  (sphere),where r is the radius of the sphere.  As with the formula for the area of a circle, any derivation of this formula inherently uses methods similar to calculus.\n\n\n=== General formulas ===\n\n\n==== Areas of 2-dimensional figures ====\nA triangle: \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        B\n        h\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}Bh}\n   (where B is any side, and h is the distance from the line on which B lies to the other vertex of the triangle). This formula can be used if the height h is known. If the lengths of the three sides are known then Heron's formula can be used: \n  \n    \n      \n        \n          \n            s\n            (\n            s\n            \u2212\n            a\n            )\n            (\n            s\n            \u2212\n            b\n            )\n            (\n            s\n            \u2212\n            c\n            )\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {s(s-a)(s-b)(s-c)}}}\n   where a, b, c are the sides of the triangle, and \n  \n    \n      \n        s\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        a\n        +\n        b\n        +\n        c\n        )\n      \n    \n    {\\displaystyle s={\\tfrac {1}{2}}(a+b+c)}\n   is half of its perimeter. If an angle and its two included sides are given, the area is \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        a\n        b\n        sin\n        \u2061\n        (\n        C\n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}ab\\sin(C)}\n   where C is the given angle and a and b are its included sides. If the triangle is graphed on a coordinate plane, a matrix can be used and is simplified to the absolute value of \n  \n    \n      \n        \n          \n            \n              1\n              2\n            \n          \n        \n        (\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            3\n          \n        \n        +\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            1\n          \n        \n        \u2212\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            2\n          \n        \n        \u2212\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\tfrac {1}{2}}(x_{1}y_{2}+x_{2}y_{3}+x_{3}y_{1}-x_{2}y_{1}-x_{3}y_{2}-x_{1}y_{3})}\n  . This formula is also known as the shoelace formula and is an easy way to solve for the area of a coordinate triangle by substituting the 3 points (x1,y1), (x2,y2), and (x3,y3). The shoelace formula can also be used to find the areas of other polygons when their vertices are known. Another approach for a coordinate triangle is to use calculus to find the area.\nA simple polygon constructed on a grid of equal-distanced points (i.e., points with integer coordinates) such that all the polygon's vertices are grid points: \n  \n    \n      \n        i\n        +\n        \n          \n            b\n            2\n          \n        \n        \u2212\n        1\n      \n    \n    {\\displaystyle i+{\\frac {b}{2}}-1}\n  , where i is the number of grid points inside the polygon and b is the number of boundary points. This result is known as Pick's theorem.\n\n\n==== Area in calculus ====\n\nThe area between a positive-valued curve and the horizontal axis, measured between two values a and b (b is defined as the larger of the two values) on the horizontal axis, is given by the integral from a to b of the function that represents the curve:\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        f\n        (\n        x\n        )\n        \n        d\n        x\n        .\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}f(x)\\,dx.}\n  The area between the graphs of two functions is equal to the integral of one function, f(x), minus the integral of the other function, g(x):\n  \n    \n      \n        A\n        =\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        (\n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        )\n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle A=\\int _{a}^{b}(f(x)-g(x))\\,dx,}\n   where \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n   is the curve with the greater y-value.An area bounded by a function r = r(\u03b8) expressed in polar coordinates is:\n  \n    \n      \n        A\n        =\n        \n          \n            1\n            2\n          \n        \n        \u222b\n        \n          r\n          \n            2\n          \n        \n        \n        d\n        \u03b8\n        .\n      \n    \n    {\\displaystyle A={1 \\over 2}\\int r^{2}\\,d\\theta .}\n  The area enclosed by a parametric curve \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        t\n        )\n        =\n        (\n        x\n        (\n        t\n        )\n        ,\n        y\n        (\n        t\n        )\n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t)=(x(t),y(t))}\n   with endpoints \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        (\n        \n          t\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\vec {u}}(t_{0})={\\vec {u}}(t_{1})}\n   is given by the line integrals:\n  \n    \n      \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \u2212\n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        (\n        x\n        \n          \n            \n              y\n              \u02d9\n            \n          \n        \n        \u2212\n        y\n        \n          \n            \n              x\n              \u02d9\n            \n          \n        \n        )\n        \n        d\n        t\n      \n    \n    {\\displaystyle \\oint _{t_{0}}^{t_{1}}x{\\dot {y}}\\,dt=-\\oint _{t_{0}}^{t_{1}}y{\\dot {x}}\\,dt={1 \\over 2}\\oint _{t_{0}}^{t_{1}}(x{\\dot {y}}-y{\\dot {x}})\\,dt}\n  (see Green's theorem) or the z-component of\n\n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              \n                \u222e\n                \n              \n            \n            \n          \n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \u2061\n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              \n                \n                  u\n                  \u2192\n                \n              \n              \u02d9\n            \n          \n        \n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle {1 \\over 2}\\oint _{t_{0}}^{t_{1}}{\\vec {u}}\\times {\\dot {\\vec {u}}}\\,dt.}\n  \n\n\n==== Bounded area between two quadratic functions ====\nTo find the bounded area between two quadratic functions, we subtract one from the other to write the difference as\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        \u2212\n        g\n        (\n        x\n        )\n        =\n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        a\n        (\n        x\n        \u2212\n        \u03b1\n        )\n        (\n        x\n        \u2212\n        \u03b2\n        )\n      \n    \n    {\\displaystyle f(x)-g(x)=ax^{2}+bx+c=a(x-\\alpha )(x-\\beta )}\n  where f(x) is the quadratic upper bound and g(x) is the quadratic lower bound. Define the discriminant of f(x)-g(x) as\n\n  \n    \n      \n        \u0394\n        =\n        \n          b\n          \n            2\n          \n        \n        \u2212\n        4\n        a\n        c\n        .\n      \n    \n    {\\displaystyle \\Delta =b^{2}-4ac.}\n  By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain\n\n  \n    \n      \n        A\n        =\n        \n          \n            \n              \u0394\n              \n                \n                  \u0394\n                \n              \n            \n            \n              6\n              \n                a\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            a\n            6\n          \n        \n        (\n        \u03b2\n        \u2212\n        \u03b1\n        \n          )\n          \n            3\n          \n        \n        ,\n        \n        a\n        \u2260\n        0.\n      \n    \n    {\\displaystyle A={\\frac {\\Delta {\\sqrt {\\Delta }}}{6a^{2}}}={\\frac {a}{6}}(\\beta -\\alpha )^{3},\\qquad a\\neq 0.}\n  The above remains valid if one of the bounding functions is linear instead of quadratic.\n\n\n==== Surface area of 3-dimensional figures ====\nCone: \n  \n    \n      \n        \u03c0\n        r\n        \n          (\n          \n            r\n            +\n            \n              \n                \n                  r\n                  \n                    2\n                  \n                \n                +\n                \n                  h\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\pi r\\left(r+{\\sqrt {r^{2}+h^{2}}}\\right)}\n  , where r is the radius of the circular base, and h is the height. That can also be rewritten as \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n        +\n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi r^{2}+\\pi rl}\n   or \n  \n    \n      \n        \u03c0\n        r\n        (\n        r\n        +\n        l\n        )\n        \n        \n      \n    \n    {\\displaystyle \\pi r(r+l)\\,\\!}\n   where r is the radius and l is the slant height of the cone. \n  \n    \n      \n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\pi r^{2}}\n   is the base area while \n  \n    \n      \n        \u03c0\n        r\n        l\n      \n    \n    {\\displaystyle \\pi rl}\n   is the lateral surface area of the cone.\ncube: \n  \n    \n      \n        6\n        \n          s\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 6s^{2}}\n  , where s is the length of an edge.\ncylinder: \n  \n    \n      \n        2\n        \u03c0\n        r\n        (\n        r\n        +\n        h\n        )\n      \n    \n    {\\displaystyle 2\\pi r(r+h)}\n  , where r is the radius of a base and h is the height. The 2\n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n  r can also be rewritten as \n  \n    \n      \n        \u03c0\n      \n    \n    {\\displaystyle \\pi }\n   d, where d is the diameter.\nprism: 2B + Ph, where B is the area of a base, P is the perimeter of a base, and h is the height of the prism.\npyramid: \n  \n    \n      \n        B\n        +\n        \n          \n            \n              P\n              L\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle B+{\\frac {PL}{2}}}\n  , where B is the area of the base, P is the perimeter of the base, and L is the length of the slant.\nrectangular prism: \n  \n    \n      \n        2\n        (\n        \u2113\n        w\n        +\n        \u2113\n        h\n        +\n        w\n        h\n        )\n      \n    \n    {\\displaystyle 2(\\ell w+\\ell h+wh)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length, w is the width, and h is the height.\n\n\n==== General formula for surface area ====\nThe general formula for the surface area of the graph of a continuously differentiable function \n  \n    \n      \n        z\n        =\n        f\n        (\n        x\n        ,\n        y\n        )\n        ,\n      \n    \n    {\\displaystyle z=f(x,y),}\n   where \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (x,y)\\in D\\subset \\mathbb {R} ^{2}}\n   and \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   is a region in the xy-plane with the smooth boundary:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          \n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      x\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            \n              \n                (\n                \n                  \n                    \n                      \u2202\n                      f\n                    \n                    \n                      \u2202\n                      y\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            1\n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}{\\sqrt {\\left({\\frac {\\partial f}{\\partial x}}\\right)^{2}+\\left({\\frac {\\partial f}{\\partial y}}\\right)^{2}+1}}\\,dx\\,dy.}\n  An even more general formula for the area of the graph of a parametric surface in the vector form \n  \n    \n      \n        \n          r\n        \n        =\n        \n          r\n        \n        (\n        u\n        ,\n        v\n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {r} =\\mathbf {r} (u,v),}\n   where \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a continuously differentiable vector function of \n  \n    \n      \n        (\n        u\n        ,\n        v\n        )\n        \u2208\n        D\n        \u2282\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (u,v)\\in D\\subset \\mathbb {R} ^{2}}\n   is:\n\n  \n    \n      \n        A\n        =\n        \n          \u222c\n          \n            D\n          \n        \n        \n          |\n          \n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  u\n                \n              \n            \n            \u00d7\n            \n              \n                \n                  \u2202\n                  \n                    r\n                  \n                \n                \n                  \u2202\n                  v\n                \n              \n            \n          \n          |\n        \n        \n        d\n        u\n        \n        d\n        v\n        .\n      \n    \n    {\\displaystyle A=\\iint _{D}\\left|{\\frac {\\partial \\mathbf {r} }{\\partial u}}\\times {\\frac {\\partial \\mathbf {r} }{\\partial v}}\\right|\\,du\\,dv.}\n  \n\n\n=== List of formulas ===\nThe above calculations show how to find the areas of many common shapes.\nThe areas of irregular polygons can be calculated using the \"Surveyor's formula\".\n\n\n=== Relation of area to perimeter ===\nThe isoperimetric inequality states that, for a closed curve of length L (so the region it encloses has perimeter L) and for area A of the region that it encloses,\n\n  \n    \n      \n        4\n        \u03c0\n        A\n        \u2264\n        \n          L\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle 4\\pi A\\leq L^{2},}\n  and  equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.\nAt the other extreme, a figure with given perimeter L could have an arbitrarily small area, as illustrated by a rhombus that is \"tipped over\" arbitrarily far so that two of its angles are arbitrarily close to 0\u00b0 and the other two are arbitrarily close to 180\u00b0.\nFor a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius r. This can be seen from the area formula \u03c0r2 and the circumference formula 2\u03c0r.\nThe area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).\n\n\n=== Fractals ===\nDoubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a  fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.\n\n\n== Area bisectors ==\n\nThere are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.\nAny line through the midpoint of a parallelogram bisects the area.\nAll area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.\n\n\n== Optimization ==\nGiven a wire contour, the surface of least area spanning (\"filling\") it is a minimal surface.  Familiar examples include soap bubbles.\nThe question of the filling area of the Riemannian circle remains open.The circle has the largest area of any two-dimensional object having the same perimeter.\nA cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.\nA version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.The ratio of the area of the incircle to the area of an equilateral triangle, \n  \n    \n      \n        \n          \n            \u03c0\n            \n              3\n              \n                \n                  3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\pi }{3{\\sqrt {3}}}}}\n  , is larger than that of any non-equilateral triangle.The ratio of the area to the square of the perimeter of an equilateral triangle, \n  \n    \n      \n        \n          \n            1\n            \n              12\n              \n                \n                  3\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{12{\\sqrt {3}}}},}\n   is larger than that for any other triangle.\n\n\n== See also ==\nBrahmagupta quadrilateral, a cyclic quadrilateral with integer sides, integer diagonals, and integer area.\nEqui-areal mapping\nHeronian triangle, a triangle with integer sides and integer area.\nList of triangle inequalities#Area\nOne-seventh area triangle, an inner triangle with one-seventh the area of the reference triangle.Routh's theorem, a generalization of the one-seventh area triangle.Orders of magnitude (area)\u2014A list of areas by size.\nPentagon#Derivation of the area formula\nPlanimeter, an instrument for measuring small areas, e.g. on maps.\nQuadrilateral#Area of a convex quadrilateral\nRobbins pentagon, a cyclic pentagon whose side lengths and area are all rational numbers.\n\n\n== References ==\n\n\n== External links ==",
        "unit": "area",
        "url": "https://en.wikipedia.org/wiki/Area"
    }
]